{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Notebook Here is where I have decided to consolidate all of my notes on different topics in tech for easy access from anywhere without having to deal with different accounts, passwords, and 2FA. Feel free to look around but these notes were written mostly to help me better learn and remember different topics and were not written as an expert in any of the areas so mistakes are possible.","title":"The Notebook"},{"location":"#the-notebook","text":"Here is where I have decided to consolidate all of my notes on different topics in tech for easy access from anywhere without having to deal with different accounts, passwords, and 2FA. Feel free to look around but these notes were written mostly to help me better learn and remember different topics and were not written as an expert in any of the areas so mistakes are possible.","title":"The Notebook"},{"location":"ai/behavior-trees/","text":"Behavior Trees Used to program complex behaviors in AI, games, and robotics. Nodes are executed (ticked) with a given frequency child will immediatly return running to parent if the execution is under way success if it has achieved its goal failure otherwise Choosing what logic to encapsulate in the BT versus the actions is an important design decision Advantages More expressive than FSMs Efficient creation of complex systems in a modular and reactive fashion Used often in robotic manipulation tasks since they allow individual behaviors to be reused in the context of another higher level behavior Control Flow Nodes Sequence - ticks each child node in order returns running upon ticking a node that returns running returns failure upon ticking a node that returns failure exits if failure or running are reached and doesnt tick any of the nodes after it returns success only if all the children return success Fallback - ticks each child node in order Returns succes or running upon reaching a child that returns one of them Returns failure if all the children it ticks return failure AKA selector/priority selector nodes Parallel - set a success threshold ticks all the children from left to right returns success if the number of children that return success is past the set threshold return failure if the number of children that return failure is greater than N - M otherwise returns running if any of the children are still running Decorator - manipulates the return status of the child according to a user-defined rule has a single child selectively ticks the child according to a predefined rule Examples: Invert- inverts success/failure status max-N-tries only lets its child fail N times then will always return Failure without ticking the child useful if you dont want to keep calling a command on a system that went down Max-T-Sec lets the child run for T seconds then if it is still runnning will return failure without ticking the child Control flow nodes can have memory meaning they remember what a child returned success or failure in order to avoid re-exceution until a whole sequence or fallback finishes Execution Nodes Leaf nodes are execution nodes (2 types) Action- executes a command when it is ticked returns success if the action is correctly completed returns failure if the action has failed returns running while its running Condition- checks a proposition when ticked returns success or failure depending on if the proposition holds never returns running Other Control Flow Architectures Petri Nets provide an alternative to FSMs that supports design of concurent systems FSMs Pros Common Intuitive and easy to understand Easy to implement Cons Poor maintainability/scalability since they are essentially goto statements Less modular and harder to maintain since they use one-way control transfer (state transitions) just like go to statements This means removing a state from a machine requires changing all transitions to that state Poor reusability since transitions often depend on many internal variables Scalable Hierarchial FSMs (HFSMs) aka state charts uses super states that contain many substates to simplify transitions Subsumption Architecture related to behavior-based robot architecture have several controllers, each implementing a task, running in parallel controllers are ordered in priorty by user and the highest priorty controller out of a list of ones that want to control the robot is given access to the actuators w Teleo-Reactive Approach Decision Trees directed tree representing a list of nested if then clauses to derive decisions leaf nodes- decisions/conclusions/actions to be done Non-leaf nodes- predicates to be evaluated","title":"Behavior Trees"},{"location":"ai/behavior-trees/#behavior-trees","text":"Used to program complex behaviors in AI, games, and robotics. Nodes are executed (ticked) with a given frequency child will immediatly return running to parent if the execution is under way success if it has achieved its goal failure otherwise Choosing what logic to encapsulate in the BT versus the actions is an important design decision","title":"Behavior Trees"},{"location":"ai/behavior-trees/#advantages","text":"More expressive than FSMs Efficient creation of complex systems in a modular and reactive fashion Used often in robotic manipulation tasks since they allow individual behaviors to be reused in the context of another higher level behavior","title":"Advantages"},{"location":"ai/behavior-trees/#control-flow-nodes","text":"Sequence - ticks each child node in order returns running upon ticking a node that returns running returns failure upon ticking a node that returns failure exits if failure or running are reached and doesnt tick any of the nodes after it returns success only if all the children return success Fallback - ticks each child node in order Returns succes or running upon reaching a child that returns one of them Returns failure if all the children it ticks return failure AKA selector/priority selector nodes Parallel - set a success threshold ticks all the children from left to right returns success if the number of children that return success is past the set threshold return failure if the number of children that return failure is greater than N - M otherwise returns running if any of the children are still running Decorator - manipulates the return status of the child according to a user-defined rule has a single child selectively ticks the child according to a predefined rule Examples: Invert- inverts success/failure status max-N-tries only lets its child fail N times then will always return Failure without ticking the child useful if you dont want to keep calling a command on a system that went down Max-T-Sec lets the child run for T seconds then if it is still runnning will return failure without ticking the child Control flow nodes can have memory meaning they remember what a child returned success or failure in order to avoid re-exceution until a whole sequence or fallback finishes","title":"Control Flow Nodes"},{"location":"ai/behavior-trees/#execution-nodes","text":"Leaf nodes are execution nodes (2 types) Action- executes a command when it is ticked returns success if the action is correctly completed returns failure if the action has failed returns running while its running Condition- checks a proposition when ticked returns success or failure depending on if the proposition holds never returns running","title":"Execution Nodes"},{"location":"ai/behavior-trees/#other-control-flow-architectures","text":"Petri Nets provide an alternative to FSMs that supports design of concurent systems FSMs Pros Common Intuitive and easy to understand Easy to implement Cons Poor maintainability/scalability since they are essentially goto statements Less modular and harder to maintain since they use one-way control transfer (state transitions) just like go to statements This means removing a state from a machine requires changing all transitions to that state Poor reusability since transitions often depend on many internal variables Scalable Hierarchial FSMs (HFSMs) aka state charts uses super states that contain many substates to simplify transitions Subsumption Architecture related to behavior-based robot architecture have several controllers, each implementing a task, running in parallel controllers are ordered in priorty by user and the highest priorty controller out of a list of ones that want to control the robot is given access to the actuators w Teleo-Reactive Approach Decision Trees directed tree representing a list of nested if then clauses to derive decisions leaf nodes- decisions/conclusions/actions to be done Non-leaf nodes- predicates to be evaluated","title":"Other Control Flow Architectures"},{"location":"data_structures/binary-tree/","text":"Binary Tree explain like im five picture or visualization Purpose why does it exist? why would you ever choose this over other data structures? what is the data structure optimized for? insertions/deletion? resizing? etc? Advantages Disadvantages Implementations Array : - Can be efficiently stored as an array due to each node having a max of two children - left child: (index * 2) + 1 - right child: (index * 2) + 2 - parent: (index - 1) / 2 (not used on the root!) Nodes : - Can be stored as nodes with left and right child pointers Big O Analysis Array Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Node Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Code Binary Trees Each parent has maximum of two children (left and right child) Predetermined max number of children lets us store binary trees as arrays of size at least 2^{depth - 1} Tree with 3 full levels has 2^3 -1 nodes Array representation allows use of formulas to access specific nodes: - Binary Search Trees: special case of a binary tree where the left child values are less than the parent and the right child values are greater than the parent traversal - in-order: left, cur, right - -, 5, , 3, +, 4 - pre-order: cur, left, right - , -, 5, +, 3, 4 - post-order: left, right, cur - 5,-,3,4,+, - easier for computers to compute in - level-order: across each level from left to right - , -, +, 5, 3, 4 - discards lots of info encoded in the tree so not as useful as the others","title":"Binary Tree"},{"location":"data_structures/binary-tree/#binary-tree","text":"explain like im five picture or visualization","title":"Binary Tree"},{"location":"data_structures/binary-tree/#purpose","text":"why does it exist? why would you ever choose this over other data structures? what is the data structure optimized for? insertions/deletion? resizing? etc?","title":"Purpose"},{"location":"data_structures/binary-tree/#advantages","text":"","title":"Advantages"},{"location":"data_structures/binary-tree/#disadvantages","text":"","title":"Disadvantages"},{"location":"data_structures/binary-tree/#implementations","text":"Array : - Can be efficiently stored as an array due to each node having a max of two children - left child: (index * 2) + 1 - right child: (index * 2) + 2 - parent: (index - 1) / 2 (not used on the root!) Nodes : - Can be stored as nodes with left and right child pointers","title":"Implementations"},{"location":"data_structures/binary-tree/#big-o-analysis","text":"Array Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Node Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion |","title":"Big O Analysis"},{"location":"data_structures/binary-tree/#code","text":"","title":"Code"},{"location":"data_structures/binary-tree/#binary-trees","text":"Each parent has maximum of two children (left and right child) Predetermined max number of children lets us store binary trees as arrays of size at least 2^{depth - 1} Tree with 3 full levels has 2^3 -1 nodes Array representation allows use of formulas to access specific nodes:","title":"Binary Trees"},{"location":"data_structures/binary-tree/#-binary-search-trees-special-case-of-a-binary-tree-where-the-left-child-values-are-less-than-the-parent-and-the-right-child-values-are-greater-than-the-parent","text":"","title":"- Binary Search Trees: special case of a binary tree where the left child values are less than the parent and the right child values are greater than the parent"},{"location":"data_structures/binary-tree/#traversal","text":"- in-order: left, cur, right - -, 5, , 3, +, 4 - pre-order: cur, left, right - , -, 5, +, 3, 4 - post-order: left, right, cur - 5,-,3,4,+, - easier for computers to compute in - level-order: across each level from left to right - , -, +, 5, 3, 4 - discards lots of info encoded in the tree so not as useful as the others","title":"traversal"},{"location":"data_structures/graph/","text":"Graph Theory is the mathematical theory of the properties and applications of graphs/networks Types of Graphs Undirected Graph - edges have no orientation (i.e. edge (u,v) == edge (v,u) ) Directed Graph - edges have orientations (i.e. edge (u,v) is the edge from node u to node v) Weighted Graphs - edges contain a certain weight that represent an arbitrary value such as cost, distance, quantity, etc. (Can be directed or undirected). \u200b Ex: (u, v, w) is the edge from node u to node v with a weight of w Special Graphs Tree an undirected graph with no cycles (equivalent definition- a connected graph with N nodes and N - 1 edges) Rooted Tree is a tree with a designated root node where every edge either points away from or towards the root node \u200b Arborescence (out-tree) - edges point away from the root \u200b Anti-arborescence (in-tree) - edges point towards the root Directed Acyclic Graphs (DAGs) - directed graphs with no cycles. Imporant in representing strctures with dependencies and prerequisites. (All out-trees are DAGs but not all DAGs are out-trees) Bipartite Graph - the vertices can be split into two independent groups U, V such that every edge connects between U and V. Other definitions are- the graph is two colourable or there is no odd length cycle Complete Graph - there is a unique edge between every pair of nodes (complete graph with n vertices is denoted as Kn) Representing Graphs:","title":"Graph"},{"location":"data_structures/hash-table/","text":"Hashmaps: Built on top of an array using a special indexing system. A key-value storage with fast assignments and lookup. A table that represents a map from a set of keys to a set of values. Uses a hash function which turns a key into an index into the underlying array. A hash collision is when a hash function returns the same index for two different keys. Hash collision strategies: Separate Chaining - each array index points to a different data structure (e.g. array of linked lists) Open addressing -a collision triggers a probing sequence to find where to store the value for a given key. Hash table: A key-value store that uses an array and a hashing function to save and retrieve values. Key: The identifier given to a value for later retrieval. Hash function: A function that takes some input and returns a number Compression function: A function that transforms its inputs into some smaller range of possible outputs (e.g. Hash Function) Key property is that it is not reversible Recipe for saving to a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index is empty, if so, save the value (and the key) there. - If the array is full at that index continue to the next possible position depending on your collision strategy. Recipe for retrieving from a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index has contents, if so, check the key saved there. - If the key matches the one you're looking for, return the value. - If the keys don't match, continue to the next position depending on your collision strategy.","title":"Hash table"},{"location":"data_structures/hash-table/#hashmaps","text":"Built on top of an array using a special indexing system. A key-value storage with fast assignments and lookup. A table that represents a map from a set of keys to a set of values. Uses a hash function which turns a key into an index into the underlying array. A hash collision is when a hash function returns the same index for two different keys. Hash collision strategies: Separate Chaining - each array index points to a different data structure (e.g. array of linked lists) Open addressing -a collision triggers a probing sequence to find where to store the value for a given key. Hash table: A key-value store that uses an array and a hashing function to save and retrieve values. Key: The identifier given to a value for later retrieval. Hash function: A function that takes some input and returns a number Compression function: A function that transforms its inputs into some smaller range of possible outputs (e.g. Hash Function) Key property is that it is not reversible Recipe for saving to a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index is empty, if so, save the value (and the key) there. - If the array is full at that index continue to the next possible position depending on your collision strategy. Recipe for retrieving from a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index has contents, if so, check the key saved there. - If the key matches the one you're looking for, return the value. - If the keys don't match, continue to the next position depending on your collision strategy.","title":"Hashmaps:"},{"location":"data_structures/heap/","text":"Heap Used to keep track of max or min values in a dataset Max-Heap: Value of root node is the greatest of all the values in the tree Must be true for all sub-trees Min-Heap Value of the root node is the smallest of all the values in the tree Must be true for all sub-trees Implementation Binary tree representation is stored as an array Random access to nodes is very efficient compared to pointer traversals through a tree Elements are added left to right until an entire level is filled up Leaves no gaps in the array Purpose Useful for: Heap Sort- sort an array in O(nlogn) time Priority Queues- insert() , delete() , extractMpax() and decreaseKey() operations in O(logn) time Finding the k th largest element in an array","title":"Heap"},{"location":"data_structures/heap/#heap","text":"Used to keep track of max or min values in a dataset Max-Heap: Value of root node is the greatest of all the values in the tree Must be true for all sub-trees Min-Heap Value of the root node is the smallest of all the values in the tree Must be true for all sub-trees","title":"Heap"},{"location":"data_structures/heap/#implementation","text":"Binary tree representation is stored as an array Random access to nodes is very efficient compared to pointer traversals through a tree Elements are added left to right until an entire level is filled up Leaves no gaps in the array","title":"Implementation"},{"location":"data_structures/heap/#purpose","text":"Useful for: Heap Sort- sort an array in O(nlogn) time Priority Queues- insert() , delete() , extractMpax() and decreaseKey() operations in O(logn) time Finding the k th largest element in an array","title":"Purpose"},{"location":"data_structures/linked-list/","text":"Linked List A linked list is basically a data structure that consists of chunks of data that are connected to each other by references to where the next (and possibly previous) chunk is stored in the computer's memory. Purpose It is optimized for fast insertions/deletions as well as combining and making segments of lists since all of these things are quickly done with simple pointer assignments. Since linked lists point to different places in memory and require minimal copying of the actual data being stored, linked lists are ideal for storing large pieces of data in a program. For instance, a linked list would be ideal for storing a list of files/images/videos since it does not require actually copying them around when doing operations, it simply just changes the pointers to where they are located in memory. Linked lists are also useful for implementing other data structures such as stacks, queues, adjacency lists, and sparse matrices. Advantages Constant time insertions/deletions to/from front and back of list No sihifting elements up or down when insertions/deletions occur Constant time splicing of multiple lists since its just pointer assignments Dynamic use of memory Dynamically resizes without any additional copying costs No memory pre-allocated that might go unused Efficient way to implement stacks and queues Circular linked lists do not have to deal with null pointers Disadvantages Not stored in contiguous chunk of memory so no random access Direct access to elements via indices is not possible without traversal Take up more memory to store than an array due to the pointers Traversal is more time consuming compared to an array Singly linked list only allow forward traversal Doubly linked lists allow bidirectoional traversal at the cost of an extra back pointer for each node (costly in terms of memory for large lists of millions of nodes) Big O Analysis Singly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(n) traverse to 2nd to last node and change pointers delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Doubly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(1) just change the end nodes' pointers (makes use of prev pointer) delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Code Singly Linked List: class Node: def __init__(self, data = None): self.data = data self.next = None class SinglyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: self.tail.next = Node(data) self.tail = self.tail.next self.length += 1 def prepend(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: temp = Node(data) temp.next = self.head self.head = temp self.length += 1 def delete_front(self): self.head = self.head.next self.length -= 1 Doubly Linked List class Node: def __init__(self, data = None): self.data = data self.next = None self.prev = None class DblyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self, data): old_tail = self.tail old_tail.next = Node(data) self.tail = old_tail.next self.tail.prev = old_tail self.length += 1 def prepend(self, data): new_node = Node(data) self.head.prev = new_node new_node.next = self.head self.head = new_node self.length += 1 def delete_front(self): self.head = self.head.next self.head.prev = None self.length -= 1 def delete_back(self): new_end = self.tail.prev new_end.next = None self.tail = new_end self.length -= 1 Circular Linked List Implemented as a doubly linked list but could also be implemented as singly linked list that only uses a tail pointer where tail.next is the head. class Node: def __init__(self,data=None, next_ = self, prev_ = self): self.data = data self.next = next_ self.prev = prev_ class CircularLinkedList: def __init__(self): self.dummy = Node() self.length = 0 def append(self,data): temp = self.dummy.prev self.dummy.prev = Node(data,self.dummy,temp) temp.next = self.dummy.prev self.length += 1 def prepend(self,data): temp = self.dummy.next self.dummy.next = Node(data,temp,self.dummy) temp.prev = self.dummy.next self.length += 1 def delete_front(self): del_head = self.dummy.next self.dummy.next = del_head.next self.dummy.next.prev = self.dummy self.length -= 1 def delete_back(self): del_tail = self.dummy.prev self.dummy.prev = del_tail.prev self.dummy.prev.next = self.dummy self.length -= 1","title":"Linked List"},{"location":"data_structures/linked-list/#linked-list","text":"A linked list is basically a data structure that consists of chunks of data that are connected to each other by references to where the next (and possibly previous) chunk is stored in the computer's memory.","title":"Linked List"},{"location":"data_structures/linked-list/#purpose","text":"It is optimized for fast insertions/deletions as well as combining and making segments of lists since all of these things are quickly done with simple pointer assignments. Since linked lists point to different places in memory and require minimal copying of the actual data being stored, linked lists are ideal for storing large pieces of data in a program. For instance, a linked list would be ideal for storing a list of files/images/videos since it does not require actually copying them around when doing operations, it simply just changes the pointers to where they are located in memory. Linked lists are also useful for implementing other data structures such as stacks, queues, adjacency lists, and sparse matrices.","title":"Purpose"},{"location":"data_structures/linked-list/#advantages","text":"Constant time insertions/deletions to/from front and back of list No sihifting elements up or down when insertions/deletions occur Constant time splicing of multiple lists since its just pointer assignments Dynamic use of memory Dynamically resizes without any additional copying costs No memory pre-allocated that might go unused Efficient way to implement stacks and queues Circular linked lists do not have to deal with null pointers","title":"Advantages"},{"location":"data_structures/linked-list/#disadvantages","text":"Not stored in contiguous chunk of memory so no random access Direct access to elements via indices is not possible without traversal Take up more memory to store than an array due to the pointers Traversal is more time consuming compared to an array Singly linked list only allow forward traversal Doubly linked lists allow bidirectoional traversal at the cost of an extra back pointer for each node (costly in terms of memory for large lists of millions of nodes)","title":"Disadvantages"},{"location":"data_structures/linked-list/#big-o-analysis","text":"Singly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(n) traverse to 2nd to last node and change pointers delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Doubly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(1) just change the end nodes' pointers (makes use of prev pointer) delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers","title":"Big O Analysis"},{"location":"data_structures/linked-list/#code","text":"Singly Linked List: class Node: def __init__(self, data = None): self.data = data self.next = None class SinglyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: self.tail.next = Node(data) self.tail = self.tail.next self.length += 1 def prepend(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: temp = Node(data) temp.next = self.head self.head = temp self.length += 1 def delete_front(self): self.head = self.head.next self.length -= 1 Doubly Linked List class Node: def __init__(self, data = None): self.data = data self.next = None self.prev = None class DblyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self, data): old_tail = self.tail old_tail.next = Node(data) self.tail = old_tail.next self.tail.prev = old_tail self.length += 1 def prepend(self, data): new_node = Node(data) self.head.prev = new_node new_node.next = self.head self.head = new_node self.length += 1 def delete_front(self): self.head = self.head.next self.head.prev = None self.length -= 1 def delete_back(self): new_end = self.tail.prev new_end.next = None self.tail = new_end self.length -= 1 Circular Linked List Implemented as a doubly linked list but could also be implemented as singly linked list that only uses a tail pointer where tail.next is the head. class Node: def __init__(self,data=None, next_ = self, prev_ = self): self.data = data self.next = next_ self.prev = prev_ class CircularLinkedList: def __init__(self): self.dummy = Node() self.length = 0 def append(self,data): temp = self.dummy.prev self.dummy.prev = Node(data,self.dummy,temp) temp.next = self.dummy.prev self.length += 1 def prepend(self,data): temp = self.dummy.next self.dummy.next = Node(data,temp,self.dummy) temp.prev = self.dummy.next self.length += 1 def delete_front(self): del_head = self.dummy.next self.dummy.next = del_head.next self.dummy.next.prev = self.dummy self.length -= 1 def delete_back(self): del_tail = self.dummy.prev self.dummy.prev = del_tail.prev self.dummy.prev.next = self.dummy self.length -= 1","title":"Code"},{"location":"data_structures/overview/","text":"Overview of Data Structures Its important to note that many of these data structures are implemented using other data structures. For instance, a stack may be implemented with a linked list. Oftentimes more complex data structures are built off of arrays, using more specialized behaviors and rules to increase performance in some aspect (e.g. binary trees can be implented with arrays and using math to calculate node indices). Linear/Sequential Array Linked List Singly/Doubly Linked Circular Stack (LIFO) Queue (FIFO) Tree Binary Tree Binary Heap Binary Search Tree Self Balancing: AVL, Red-Black B Trees 2-3 Trees Trie Associative Hash-table/Map Set","title":"Overview"},{"location":"data_structures/overview/#overview-of-data-structures","text":"Its important to note that many of these data structures are implemented using other data structures. For instance, a stack may be implemented with a linked list. Oftentimes more complex data structures are built off of arrays, using more specialized behaviors and rules to increase performance in some aspect (e.g. binary trees can be implented with arrays and using math to calculate node indices).","title":"Overview of Data Structures"},{"location":"data_structures/overview/#linearsequential","text":"Array Linked List Singly/Doubly Linked Circular Stack (LIFO) Queue (FIFO)","title":"Linear/Sequential"},{"location":"data_structures/overview/#tree","text":"Binary Tree Binary Heap Binary Search Tree Self Balancing: AVL, Red-Black B Trees 2-3 Trees Trie","title":"Tree"},{"location":"data_structures/overview/#associative","text":"Hash-table/Map Set","title":"Associative"},{"location":"data_structures/queue/","text":"Queue Stores data in a first in, first out (FIFO) manner. Basically can be thought of like a line at a store or anywhere. Purpose Queues are great for use where the order of events occur is important Useful for - Breadth first search - Message or print queues - Simulations with ordered events Big O Analysis The follow operations are due to the linked list implementation Operation Big O push (front/back) O(1) pop (front/back) O(1) peek (front/back) O(1) Code from linked-list import DblyLinkedList class Queue: def __init__(self): self.list = DblyLinkedList() def push_front(self,data): self.list.prepend(data) def push_back(self,data): self.list.append(data) def pop_front(self): self.list.delete_front() def pop_back(self): self.list.delete_back() def peek_front(self): return self.list.head def peek_back(self): return self.list.tail","title":"Queue"},{"location":"data_structures/queue/#queue","text":"Stores data in a first in, first out (FIFO) manner. Basically can be thought of like a line at a store or anywhere.","title":"Queue"},{"location":"data_structures/queue/#purpose","text":"Queues are great for use where the order of events occur is important Useful for - Breadth first search - Message or print queues - Simulations with ordered events","title":"Purpose"},{"location":"data_structures/queue/#big-o-analysis","text":"The follow operations are due to the linked list implementation Operation Big O push (front/back) O(1) pop (front/back) O(1) peek (front/back) O(1)","title":"Big O Analysis"},{"location":"data_structures/queue/#code","text":"from linked-list import DblyLinkedList class Queue: def __init__(self): self.list = DblyLinkedList() def push_front(self,data): self.list.prepend(data) def push_back(self,data): self.list.append(data) def pop_front(self): self.list.delete_front() def pop_back(self): self.list.delete_back() def peek_front(self): return self.list.head def peek_back(self): return self.list.tail","title":"Code"},{"location":"data_structures/stack/","text":"Stack Stores data in in a last in, first out (LIFO) manner or first in, last out (FILO) Can be implemented using either an array for when the max size of elements in the stack is known (e.g. deck of cards) or can be implemented using a linked list. Purpose Stacks are optimized for adding and removing things from often, where the order of addition and removal plays an important role in solving a certain problem (e.g. matching parentheses) Useful for: - Depth First Search - Backtracking algorithms (e.g. N queens) - Checking proper brackets/parentheses - Expression Conversions - String reversals - Solving towers of hanoi - Memory management Disadvantages Fixed size when implemented as static array Slow to grow when implemented as dynamic array New/delete operations are slower than array operations for linked list implementation Big O Analysis The follow operations are due to the linked list implementation Operation Big O push O(1) pop O(1) peek O(1) Code from linked-list import DblyLinkedList class Stack: def __init__(self): self.top = DblyLinkedList() self.size = 0 def push(self,data): self.top.prepend(data) def peek(self, data): return self.top.head def pop(self,data): self.top.delete_front()","title":"Stack"},{"location":"data_structures/stack/#stack","text":"Stores data in in a last in, first out (LIFO) manner or first in, last out (FILO) Can be implemented using either an array for when the max size of elements in the stack is known (e.g. deck of cards) or can be implemented using a linked list.","title":"Stack"},{"location":"data_structures/stack/#purpose","text":"Stacks are optimized for adding and removing things from often, where the order of addition and removal plays an important role in solving a certain problem (e.g. matching parentheses) Useful for: - Depth First Search - Backtracking algorithms (e.g. N queens) - Checking proper brackets/parentheses - Expression Conversions - String reversals - Solving towers of hanoi - Memory management","title":"Purpose"},{"location":"data_structures/stack/#disadvantages","text":"Fixed size when implemented as static array Slow to grow when implemented as dynamic array New/delete operations are slower than array operations for linked list implementation","title":"Disadvantages"},{"location":"data_structures/stack/#big-o-analysis","text":"The follow operations are due to the linked list implementation Operation Big O push O(1) pop O(1) peek O(1)","title":"Big O Analysis"},{"location":"data_structures/stack/#code","text":"from linked-list import DblyLinkedList class Stack: def __init__(self): self.top = DblyLinkedList() self.size = 0 def push(self,data): self.top.prepend(data) def peek(self, data): return self.top.head def pop(self,data): self.top.delete_front()","title":"Code"},{"location":"data_structures/template/","text":"Data Structure explain like im five picture or visualization Purpose why does it exist? why would you ever choose this over other data structures? common what is the data structure optimized for? insertions/deletion? resizing? etc? Advantages Disadvantages Big O Analysis Operation Big O Explanation insertion O(1) just change the pointers of each node to insert Code Next Steps: Anki flashcards from the notes Apply to problems that are designed for that data structure Apply to random problems that may or may not use the data structure (so you can begin to find patterns of when to apply the data structure)","title":"Data Structure"},{"location":"data_structures/template/#data-structure","text":"explain like im five picture or visualization","title":"Data Structure"},{"location":"data_structures/template/#purpose","text":"why does it exist? why would you ever choose this over other data structures? common what is the data structure optimized for? insertions/deletion? resizing? etc?","title":"Purpose"},{"location":"data_structures/template/#advantages","text":"","title":"Advantages"},{"location":"data_structures/template/#disadvantages","text":"","title":"Disadvantages"},{"location":"data_structures/template/#big-o-analysis","text":"Operation Big O Explanation insertion O(1) just change the pointers of each node to insert","title":"Big O Analysis"},{"location":"data_structures/template/#code","text":"","title":"Code"},{"location":"data_structures/template/#next-steps","text":"Anki flashcards from the notes Apply to problems that are designed for that data structure Apply to random problems that may or may not use the data structure (so you can begin to find patterns of when to apply the data structure)","title":"Next Steps:"},{"location":"databases/dbms/","text":"Database Mangament Systems (DBMS) Special software program to help create and maintain a database Easy to handle lots of info Handles security, Backups, import/exporting data, & concurrency interacts w/ software apps and programming languages Ex: Amazon.com will interact w/ the DBMS in order to create, read, update, & delete product info Relational Database (SQL) organize data into 1 or more tables Each table has columns and rows A unique key identifies each row Relation Database Management Systems (RDBMS) mySQL,Oracle,postgreSQL,mariaDB,etc Non-Relational Database (noSQL) Not organized in traditional table Key-value stores, Documents, Graphs, Flexible Tablees, etc Non-Relational Database Management Systems (NRDBMS) mongoDB,dynamoDB,apache cassandra, firebase, etc no standard language b/c each implementation is language specific","title":"DBMS"},{"location":"databases/dbms/#database-mangament-systems-dbms","text":"Special software program to help create and maintain a database Easy to handle lots of info Handles security, Backups, import/exporting data, & concurrency interacts w/ software apps and programming languages Ex: Amazon.com will interact w/ the DBMS in order to create, read, update, & delete product info","title":"Database Mangament Systems (DBMS)"},{"location":"databases/dbms/#relational-database-sql","text":"organize data into 1 or more tables Each table has columns and rows A unique key identifies each row Relation Database Management Systems (RDBMS) mySQL,Oracle,postgreSQL,mariaDB,etc","title":"Relational Database (SQL)"},{"location":"databases/dbms/#non-relational-database-nosql","text":"Not organized in traditional table Key-value stores, Documents, Graphs, Flexible Tablees, etc Non-Relational Database Management Systems (NRDBMS) mongoDB,dynamoDB,apache cassandra, firebase, etc no standard language b/c each implementation is language specific","title":"Non-Relational Database (noSQL)"},{"location":"databases/mysql/","text":"MySQL Python Access Connect to the MySQL Database, you get a MySQLConnection object. a. To connect to the database, read the database configuration parameters from config.ini using configparser and pass the resulting dictionary to the constructor of the MySQLConnection Object Instantiate a MySQLCursor object from the the MySQLConnection object. Use the cursor to execute a query by calling its execute() method. Use fetchone() , fetchmany() or fetchall() method to fetch data from the result set. Close the cursor as well as the database connection by calling the close() method of the corresponding object from mysql.connector import MySQLConnection, Error dbconfig = { 'host' = 'localhost', 'database' = 'Books', 'user' = 'root', 'password' = 'password' } conn = None try: conn = MySQLConnection(**dbconfig) cursor = conn.cursor() cursor.execute('SELECT * FROM books LIMIT 5') for row in iter_row(cursor): print(row) except Error as e: print(e) finally: cursor.close() conn.close() Generator that chunks the database calls into a series of fetchmany() calls def iter_row(cursor,size=10): while True: rows = cursor.fetchmany(size) if not rows: break for row in rows: yield row","title":"MySQL"},{"location":"databases/mysql/#mysql","text":"","title":"MySQL"},{"location":"databases/mysql/#python-access","text":"Connect to the MySQL Database, you get a MySQLConnection object. a. To connect to the database, read the database configuration parameters from config.ini using configparser and pass the resulting dictionary to the constructor of the MySQLConnection Object Instantiate a MySQLCursor object from the the MySQLConnection object. Use the cursor to execute a query by calling its execute() method. Use fetchone() , fetchmany() or fetchall() method to fetch data from the result set. Close the cursor as well as the database connection by calling the close() method of the corresponding object from mysql.connector import MySQLConnection, Error dbconfig = { 'host' = 'localhost', 'database' = 'Books', 'user' = 'root', 'password' = 'password' } conn = None try: conn = MySQLConnection(**dbconfig) cursor = conn.cursor() cursor.execute('SELECT * FROM books LIMIT 5') for row in iter_row(cursor): print(row) except Error as e: print(e) finally: cursor.close() conn.close() Generator that chunks the database calls into a series of fetchmany() calls def iter_row(cursor,size=10): while True: rows = cursor.fetchmany(size) if not rows: break for row in rows: yield row","title":"Python Access"},{"location":"databases/sql/","text":"Structured Query Language (SQL) Standardized language for interacting w/ RDBMS used to perform CRUD operations and other admin tasks(e.g user managment, security, backup, etc) SQL code on one RDBMS might not be portable to a different RDBMS b/c SQL implementations vary btw systems 4 Types of Languages in SQL: Data Query Language (DQL) - queries the DB for stored info Data Definition Language (DDL) - defines database schemas Data Control Language (DCL) - controls access to data in DB & manages users and permissions Data Manipulation Laguage (DML) - inserts, updates, and deletes data from DB Keys Primary Key - attribute that is unique for each row in the table Surrogate Key - type of primary key that has no mapping to anything in the real world Natural Key - type of primary key that has a mapping to the real world (e.g. SSN) Foreign Key - stores the primary key of a row in another database table (Link to another table) Can define relationships between tables or within a table Composite Key - type of primary key that is made up of two attributes Used when either of the attributes on their own do not uniquely identify a row Datatypes INT DECIMAL(M,N) -- m: total # digits, n: # digits after decimal place VARCHAR(L) -- String of text of max length L BLOB -- Binary large objects, stores large data like images DATE -- 'YYYY-MM-DD' TIMESTAMP -- 'YYYY-MM-DD HH:MM:SS' Functions --Find Num of Students SELECT COUNT(student_id) FROM students; --Find Num of female student born after 1980 SELECT COUNT(student_id) FROM students WHERE sex = 'F' AND birth_date > '1981-01-01'; --Find avg male salary SELECT AVG(salary) FROM employees WHERE sex = 'M'; --Find sum of all salaries SELECT SUM(salary) FROM employees; --Find num of males & females SELECT COUNT(sex), sex FROM employe GROUP BY sex; --Group By command used for aggregation Queries SELECT student.name AS forename, student.major FROM student ORDER BY name DESC --Descending alphabetical order LIMIT 20; --limits # of entries returned -- Comparison Operators: <, >, <=, >=, =, AND, OR, <> (not equal to) Tables CREATE TABLE student ( student_id INT AUTO_INCREMENT, -- you don't have to insert a primary key b/c its auto incremented name VARCHAR(20) UNIQUE, major VARCHAR(20) DEFAULT 'undecided', PRIMARY KEY(student_id) ); -- Delete a Table DROP TABLE student; --Show the table schema DESCRIBE student; -- Add & Drop Attributes ALTER TABLE student ADD gpa DECIMAL(3,2); ALTER TABLE student DROP COLUMN gpa; Insert, Update, Delete INSERT INTO student VALUES(1,'Jack','Biology'); INSERT INTO student(name) VALUES('Kate'); UPDATE student SET major = 'Computer Science and Engineering' WHERE major = 'Computer Science' OR major = 'Computer Engineering'; DELETE FROM student WHERE student_id > 100;","title":"SQL"},{"location":"databases/sql/#structured-query-language-sql","text":"Standardized language for interacting w/ RDBMS used to perform CRUD operations and other admin tasks(e.g user managment, security, backup, etc) SQL code on one RDBMS might not be portable to a different RDBMS b/c SQL implementations vary btw systems","title":"Structured Query Language (SQL)"},{"location":"databases/sql/#4-types-of-languages-in-sql","text":"Data Query Language (DQL) - queries the DB for stored info Data Definition Language (DDL) - defines database schemas Data Control Language (DCL) - controls access to data in DB & manages users and permissions Data Manipulation Laguage (DML) - inserts, updates, and deletes data from DB","title":"4 Types of Languages in SQL:"},{"location":"databases/sql/#keys","text":"Primary Key - attribute that is unique for each row in the table Surrogate Key - type of primary key that has no mapping to anything in the real world Natural Key - type of primary key that has a mapping to the real world (e.g. SSN) Foreign Key - stores the primary key of a row in another database table (Link to another table) Can define relationships between tables or within a table Composite Key - type of primary key that is made up of two attributes Used when either of the attributes on their own do not uniquely identify a row","title":"Keys"},{"location":"databases/sql/#datatypes","text":"INT DECIMAL(M,N) -- m: total # digits, n: # digits after decimal place VARCHAR(L) -- String of text of max length L BLOB -- Binary large objects, stores large data like images DATE -- 'YYYY-MM-DD' TIMESTAMP -- 'YYYY-MM-DD HH:MM:SS'","title":"Datatypes"},{"location":"databases/sql/#functions","text":"--Find Num of Students SELECT COUNT(student_id) FROM students; --Find Num of female student born after 1980 SELECT COUNT(student_id) FROM students WHERE sex = 'F' AND birth_date > '1981-01-01'; --Find avg male salary SELECT AVG(salary) FROM employees WHERE sex = 'M'; --Find sum of all salaries SELECT SUM(salary) FROM employees; --Find num of males & females SELECT COUNT(sex), sex FROM employe GROUP BY sex; --Group By command used for aggregation","title":"Functions"},{"location":"databases/sql/#queries","text":"SELECT student.name AS forename, student.major FROM student ORDER BY name DESC --Descending alphabetical order LIMIT 20; --limits # of entries returned -- Comparison Operators: <, >, <=, >=, =, AND, OR, <> (not equal to)","title":"Queries"},{"location":"databases/sql/#tables","text":"CREATE TABLE student ( student_id INT AUTO_INCREMENT, -- you don't have to insert a primary key b/c its auto incremented name VARCHAR(20) UNIQUE, major VARCHAR(20) DEFAULT 'undecided', PRIMARY KEY(student_id) ); -- Delete a Table DROP TABLE student; --Show the table schema DESCRIBE student; -- Add & Drop Attributes ALTER TABLE student ADD gpa DECIMAL(3,2); ALTER TABLE student DROP COLUMN gpa;","title":"Tables"},{"location":"databases/sql/#insert-update-delete","text":"INSERT INTO student VALUES(1,'Jack','Biology'); INSERT INTO student(name) VALUES('Kate'); UPDATE student SET major = 'Computer Science and Engineering' WHERE major = 'Computer Science' OR major = 'Computer Engineering'; DELETE FROM student WHERE student_id > 100;","title":"Insert, Update, Delete"},{"location":"dig_sys/ch6-assembly/","text":"Architecture Assembly Language MOV R1, R7 copies the contents of register 7 into register 1 Memory ARM uses byte-addressable memory meaning each byte in memory has a unique address 32-bit word has 4 bytes, so each word address is a multiple of 4 Big Endian- bytes are numbered starting with 0 at the most significant end Little Endian- bytes are numbered starting with 0 at the least significant end LDR destination register, [base register, offset] loads the data from the base register + offset into the destination register STR destination, [base register, offset] writes a data word from the base register + offset address to the destination register Machine Language ARM uses 32-bit instructions that can be either data-processing, memory, or branch. Data-Processing Has 2 source operands 1st source operand which is a register 2nd source operand which is register or (optionally shifted)register cond - conditional execution op - operate code funct - rn - first source register rd - destination register src2 - second source (3 variations) 1) Immediate 2) Register (rm) optionally shifted by a constant (shamt5) 3) Register (rm) shifted by another register (rs) For 2) and 3), sh encodes the type of shift to perform Branch The immediate\u2019s value is relative to 2 instructions in front of the branch instruction (PC + 8) Encoded in two\u2019s complement so there can be negative values for branches in loops","title":"Assembly"},{"location":"dig_sys/ch6-assembly/#architecture","text":"","title":"Architecture"},{"location":"dig_sys/ch6-assembly/#assembly-language","text":"MOV R1, R7 copies the contents of register 7 into register 1","title":"Assembly Language"},{"location":"dig_sys/ch6-assembly/#memory","text":"ARM uses byte-addressable memory meaning each byte in memory has a unique address 32-bit word has 4 bytes, so each word address is a multiple of 4 Big Endian- bytes are numbered starting with 0 at the most significant end Little Endian- bytes are numbered starting with 0 at the least significant end LDR destination register, [base register, offset] loads the data from the base register + offset into the destination register STR destination, [base register, offset] writes a data word from the base register + offset address to the destination register","title":"Memory"},{"location":"dig_sys/ch6-assembly/#machine-language","text":"ARM uses 32-bit instructions that can be either data-processing, memory, or branch.","title":"Machine Language"},{"location":"dig_sys/ch6-assembly/#data-processing","text":"Has 2 source operands 1st source operand which is a register 2nd source operand which is register or (optionally shifted)register cond - conditional execution op - operate code funct - rn - first source register rd - destination register src2 - second source (3 variations) 1) Immediate 2) Register (rm) optionally shifted by a constant (shamt5) 3) Register (rm) shifted by another register (rs) For 2) and 3), sh encodes the type of shift to perform","title":"Data-Processing"},{"location":"dig_sys/ch6-assembly/#branch","text":"The immediate\u2019s value is relative to 2 instructions in front of the branch instruction (PC + 8) Encoded in two\u2019s complement so there can be negative values for branches in loops","title":"Branch"},{"location":"dig_sys/ch7-processor/","text":"Microarchitecture Microarchitecture - the connection between logic and architecture specific arrangement of registers, ALUs, FSMs, memories, etc. A particular architecture like ARM can have many different microarchitectures, each with their own trade-offs on performance, cost, and complexity Architectural State and Instruction Set A computer architecture is defined by its instruction set and architectural state (e.g. 16, 32-bit registers and status register for ARM processor) Based on current architectural state ,the processor executes an instruction with a set of data to produce a new state We will consider only the following instructions for simplicity: Data Processing: ADD , SUB , AND , ORR (no shifts) Memory: LDR and STR Branching: B Design Process Split microarchitectuers into two interacting parts: 1) Datapath- operates on words of data and contains structures like memories, registers, ALUs, and muxes 32-bit arch --> 32-bit datapath 2) Control Unit- receives current instruction from the datapath and tells the datapath how to execute the instruction Signals Produced by control unit: mux select register enable memory write start with hardware containing state elements and add in combinational logic btw the state elements to compute new state based on current state memory is usually split into 2 for instructionsa and data State Elements Status Register: contains the 4 flags from the ALU Program Counter: PC' input is the address of the next instruction PC output is address of the current instructon Instruction Memory: A input is the address of the 32-bit instruction RD output is the 32-bit data (instruction) at the input address Register File: holds registers R0-R14 Read Ports: A1 and A2 inputs are the 4-bit addresses of one of the 16 registers (each specifies a source operand) RD1 and RD2 outputs are the 32-bit register values for the input registers Write Port: A3 input is a 4-bit register address WD3 input is 32-bit data to be written WE3 input specifies whether to write (write enable) If write is asserted, the data is written to the register specified by A3 on the rising edge of the clock R15 is for managing the relationship with the PC read from here should always be PC + 8 Data Memory: WD input is the 32-bit data to write to memory WE input is whether write is enabled (writes on rising edge of the clock) A input is the 32-bit address to read from (if WE = 0 ) or write to (if WE = 1 ) RD output is the 32-bit data read from the specified memory address only has a value if WE = 0 Instruction memory, register file, and data memory are read combinationally (i.e. no clock is involved) The clock is used in the register file and data memory for controlling writes to only occur on the rising edge (i.e. state only changes on rising edge of clock) This makes the microprocessor a synchronous sequential circuit (i.e. microprocessor is a giant FSM or collection of many smaller FSMs) Microarchitectures Single-cycled, multicycleed, and pipelined differ in how the state elements are connected together and in the amount of nonarchitectural state Single-Cycled - executes an entire instruction in one cycle cycle time limited by slowest instruction no nonarchitectural state required Multicycle - executes instructions in a series of shorter cycles Simpler instructions execute in fewer cycles than more complex one Several nonarchitectural state registers to hold intermediate results Cheaper b/c it reuses expensive harware like adders and memories Executes on instruction at a time, but it takes multiple clock cycles Pipelined - executes several instructions simulataneously Requires extra logic for handling dependencies between simultaneously executing instructions Requires nonarchitecutral state registers Use seperate instruction and data caches since they must access instructions and data in the same cycle Used by all commercial high-performance processors Performance Analysis Clock frequency and number of cores are unreliable methods of analyzing a processor since certain processors can do more work in a cycle than others Execution time on benchmark programs is a more reliable way of measuring performance The number of instructions in a program can vary depending on the microarchitecture and the cleverness of the programmer Cycles per instruction (CPI)- # clock cycles required to execute an average instruction Affected by memory system when its not ideal and there are misses Single-Cycle Processor Next instruction is 32 bits or 4 bytes so we need to add 4 to the current instruction PC to get the next instruction PC' The extend block extends the 12 bits from the src2 component to get a properly extended 32 bit result which is send to the ALU with the output from the register file's read output port Result of ALU is the memory address we want to read from (the data at outputby the data memory is then passed to the write port in the register file ) Example: LDR R1, [R2, #5] requires: read value from R2 (should be an address) add offset to it read whats at the resulting address write the data into R1 Controller Combinational logic responsible for calculating the control signals based on the current instruction and current state of the system Inputs: Different parts of the instruction The ALU status flags Outputs: 8 control signals that control the flow of data in the datapath Control Signals PCSrc decides where to get next instruction from 1 : ReadData (result of a write to R15 or a branch instruction) 0 : PC + 4 (next instruction) RegSrc : two bits which controls two muxes that select where the register addresss of the register file should come from MSB decides whether the 1st register address should come from instruction bits or from the value 15 to support operations with R15 LSB decides which part of the instruction bits the 2nd register address should come from RegWrite specifies whether we are writing into a register ImmSrc is two bits that control what kind of immediate extension needed unsigned 8 bit, unsigned 12 bit or signed 24 bit immediate to 32-bit immediate ALUSrc selects where the 2nd ALU argumnet should come from either a register or the result of an immediate extension ALUControl selects which operation the ALU should perform MemWrite specifies whether or not we are writing our data into memory MemToReg selects what results should be passed along either something read from memory or the ALU's result","title":"Microarchitecture"},{"location":"dig_sys/ch7-processor/#microarchitecture","text":"Microarchitecture - the connection between logic and architecture specific arrangement of registers, ALUs, FSMs, memories, etc. A particular architecture like ARM can have many different microarchitectures, each with their own trade-offs on performance, cost, and complexity","title":"Microarchitecture"},{"location":"dig_sys/ch7-processor/#architectural-state-and-instruction-set","text":"A computer architecture is defined by its instruction set and architectural state (e.g. 16, 32-bit registers and status register for ARM processor) Based on current architectural state ,the processor executes an instruction with a set of data to produce a new state We will consider only the following instructions for simplicity: Data Processing: ADD , SUB , AND , ORR (no shifts) Memory: LDR and STR Branching: B","title":"Architectural State and Instruction Set"},{"location":"dig_sys/ch7-processor/#design-process","text":"Split microarchitectuers into two interacting parts: 1) Datapath- operates on words of data and contains structures like memories, registers, ALUs, and muxes 32-bit arch --> 32-bit datapath 2) Control Unit- receives current instruction from the datapath and tells the datapath how to execute the instruction Signals Produced by control unit: mux select register enable memory write start with hardware containing state elements and add in combinational logic btw the state elements to compute new state based on current state memory is usually split into 2 for instructionsa and data","title":"Design Process"},{"location":"dig_sys/ch7-processor/#state-elements","text":"Status Register: contains the 4 flags from the ALU Program Counter: PC' input is the address of the next instruction PC output is address of the current instructon Instruction Memory: A input is the address of the 32-bit instruction RD output is the 32-bit data (instruction) at the input address Register File: holds registers R0-R14 Read Ports: A1 and A2 inputs are the 4-bit addresses of one of the 16 registers (each specifies a source operand) RD1 and RD2 outputs are the 32-bit register values for the input registers Write Port: A3 input is a 4-bit register address WD3 input is 32-bit data to be written WE3 input specifies whether to write (write enable) If write is asserted, the data is written to the register specified by A3 on the rising edge of the clock R15 is for managing the relationship with the PC read from here should always be PC + 8 Data Memory: WD input is the 32-bit data to write to memory WE input is whether write is enabled (writes on rising edge of the clock) A input is the 32-bit address to read from (if WE = 0 ) or write to (if WE = 1 ) RD output is the 32-bit data read from the specified memory address only has a value if WE = 0 Instruction memory, register file, and data memory are read combinationally (i.e. no clock is involved) The clock is used in the register file and data memory for controlling writes to only occur on the rising edge (i.e. state only changes on rising edge of clock) This makes the microprocessor a synchronous sequential circuit (i.e. microprocessor is a giant FSM or collection of many smaller FSMs)","title":"State Elements"},{"location":"dig_sys/ch7-processor/#microarchitectures","text":"Single-cycled, multicycleed, and pipelined differ in how the state elements are connected together and in the amount of nonarchitectural state Single-Cycled - executes an entire instruction in one cycle cycle time limited by slowest instruction no nonarchitectural state required Multicycle - executes instructions in a series of shorter cycles Simpler instructions execute in fewer cycles than more complex one Several nonarchitectural state registers to hold intermediate results Cheaper b/c it reuses expensive harware like adders and memories Executes on instruction at a time, but it takes multiple clock cycles Pipelined - executes several instructions simulataneously Requires extra logic for handling dependencies between simultaneously executing instructions Requires nonarchitecutral state registers Use seperate instruction and data caches since they must access instructions and data in the same cycle Used by all commercial high-performance processors","title":"Microarchitectures"},{"location":"dig_sys/ch7-processor/#performance-analysis","text":"Clock frequency and number of cores are unreliable methods of analyzing a processor since certain processors can do more work in a cycle than others Execution time on benchmark programs is a more reliable way of measuring performance The number of instructions in a program can vary depending on the microarchitecture and the cleverness of the programmer Cycles per instruction (CPI)- # clock cycles required to execute an average instruction Affected by memory system when its not ideal and there are misses","title":"Performance Analysis"},{"location":"dig_sys/ch7-processor/#single-cycle-processor","text":"Next instruction is 32 bits or 4 bytes so we need to add 4 to the current instruction PC to get the next instruction PC' The extend block extends the 12 bits from the src2 component to get a properly extended 32 bit result which is send to the ALU with the output from the register file's read output port Result of ALU is the memory address we want to read from (the data at outputby the data memory is then passed to the write port in the register file ) Example: LDR R1, [R2, #5] requires: read value from R2 (should be an address) add offset to it read whats at the resulting address write the data into R1","title":"Single-Cycle Processor"},{"location":"dig_sys/ch7-processor/#controller","text":"Combinational logic responsible for calculating the control signals based on the current instruction and current state of the system Inputs: Different parts of the instruction The ALU status flags Outputs: 8 control signals that control the flow of data in the datapath","title":"Controller"},{"location":"dig_sys/ch7-processor/#control-signals","text":"PCSrc decides where to get next instruction from 1 : ReadData (result of a write to R15 or a branch instruction) 0 : PC + 4 (next instruction) RegSrc : two bits which controls two muxes that select where the register addresss of the register file should come from MSB decides whether the 1st register address should come from instruction bits or from the value 15 to support operations with R15 LSB decides which part of the instruction bits the 2nd register address should come from RegWrite specifies whether we are writing into a register ImmSrc is two bits that control what kind of immediate extension needed unsigned 8 bit, unsigned 12 bit or signed 24 bit immediate to 32-bit immediate ALUSrc selects where the 2nd ALU argumnet should come from either a register or the result of an immediate extension ALUControl selects which operation the ALU should perform MemWrite specifies whether or not we are writing our data into memory MemToReg selects what results should be passed along either something read from memory or the ALU's result","title":"Control Signals"},{"location":"dig_sys/ch8-mem-sys/","text":"Memory Systems Computer performance depends on both the processor and the memory system Memory is slower than processors so designs try to approximate a memory as fast as a processor Simple memory interface used in previous chapters: Send memory address over the Address bus To read from memory: send MemWrite = 0 and then ReadData will contain the data at the specified address To write to memory: send MemWrite = 1 and send data to be written over the WriteData bus Tradeoffs In practice, a memory system has only 2 of the 3: Fast Large Cheap Can approximate an ideal fast, large, and cheap memory system by combining a fast small cheap memory and a slow large cheap memory. The fast memory stores most commmonly used data and instructions The large memory stores the remainder of the data and instructions Principles of Locality: Used to determine what data to store in the fast memory Temporal Locality: a referenced memory location will tend to be referenced again soon Spatial Locality: a referenced memory location will tend have its nearby addresses also referenced soon Memory Hierarchy Registers Fastest memory access Cache L1 is smaller and faster than secondary cache L2 L2 is larger Main Memory (DRAM) Order of GB Disk memory External hardrives on order of TB, PB, etc. (essentially infinite) Very slow access (e.g 1s) Want to put most useful memory as close to processor as possible to reduce access time Performance Analysis Miss Rate - how often the processor requests data from a memory system and it does not find it Hit Rate - how often the processor requests data from a memory system and it returns Average Memory Access Time (AMAT) - average time a processor must wait for memory per load or store instruction cache --> main memory --> virutal memory on hard disk AMAT = cache access time + cache miss rate(main memory access time + main memory miss rate * virtual memory access time) Amdahl's Law- effort spent increasing the performance of a subsystem is only worth it if the subsystem affects a large percentage of the overall performance Caches Goal is to anticipate all the data needed by processor and fetch it ahead of time so the cache has a 0% miss rate. Caches are located on the same chip as the processor or very close to it. Cache uses temporal and spatial locality to achieve a low miss rate. Cache block/cache line is the group of adjacent words fetched by the cache when it fetches on word from memory. block size- # words in the cache block ( b ) capacity ( C ) contains B = C / b blocks Caches are organized into S sets each of which hold 1+ block of data","title":"Memory Systems"},{"location":"dig_sys/ch8-mem-sys/#memory-systems","text":"Computer performance depends on both the processor and the memory system Memory is slower than processors so designs try to approximate a memory as fast as a processor Simple memory interface used in previous chapters: Send memory address over the Address bus To read from memory: send MemWrite = 0 and then ReadData will contain the data at the specified address To write to memory: send MemWrite = 1 and send data to be written over the WriteData bus","title":"Memory Systems"},{"location":"dig_sys/ch8-mem-sys/#tradeoffs","text":"In practice, a memory system has only 2 of the 3: Fast Large Cheap Can approximate an ideal fast, large, and cheap memory system by combining a fast small cheap memory and a slow large cheap memory. The fast memory stores most commmonly used data and instructions The large memory stores the remainder of the data and instructions Principles of Locality: Used to determine what data to store in the fast memory Temporal Locality: a referenced memory location will tend to be referenced again soon Spatial Locality: a referenced memory location will tend have its nearby addresses also referenced soon","title":"Tradeoffs"},{"location":"dig_sys/ch8-mem-sys/#memory-hierarchy","text":"Registers Fastest memory access Cache L1 is smaller and faster than secondary cache L2 L2 is larger Main Memory (DRAM) Order of GB Disk memory External hardrives on order of TB, PB, etc. (essentially infinite) Very slow access (e.g 1s) Want to put most useful memory as close to processor as possible to reduce access time","title":"Memory Hierarchy"},{"location":"dig_sys/ch8-mem-sys/#performance-analysis","text":"Miss Rate - how often the processor requests data from a memory system and it does not find it Hit Rate - how often the processor requests data from a memory system and it returns Average Memory Access Time (AMAT) - average time a processor must wait for memory per load or store instruction cache --> main memory --> virutal memory on hard disk AMAT = cache access time + cache miss rate(main memory access time + main memory miss rate * virtual memory access time) Amdahl's Law- effort spent increasing the performance of a subsystem is only worth it if the subsystem affects a large percentage of the overall performance","title":"Performance Analysis"},{"location":"dig_sys/ch8-mem-sys/#caches","text":"Goal is to anticipate all the data needed by processor and fetch it ahead of time so the cache has a 0% miss rate. Caches are located on the same chip as the processor or very close to it. Cache uses temporal and spatial locality to achieve a low miss rate. Cache block/cache line is the group of adjacent words fetched by the cache when it fetches on word from memory. block size- # words in the cache block ( b ) capacity ( C ) contains B = C / b blocks Caches are organized into S sets each of which hold 1+ block of data","title":"Caches"},{"location":"dig_sys/ch9-io-sys/","text":"I/O Systems Input/Output (I/O) systems are used to connect a computer with external devices caled peripherals. Example devices for a personal computer include keyboards, monitors, printers, and wireless networks. Example devices for an embedded system include toaster's heating element, a toy's speech synthesizer, an engine's fuel injector, and a satellite's panel motors. Memory-mapped I/O A method of communicating with input-output devices such as printers. Memory-mapped I/O involves dedicating a portion of the address space to I/O devices instead of memory. This allows a store to the specified address to send data to the device while a load from the address will receive data from the device. The blow program writes the value 7 to a an I/O device at a specified memory address. MOV R1, #7 LDR R2, =ioadr STR R1, [R2] ioadr DCD 0x20001000 To read from the the same device: LDR R1, [R2] A device driver is software that communicates with an I/O device. They are often downloaded or installed for things such as printers since writing a device driver requires detailed knowledge about the I/O device hardware including the addresses and behavior of the memory mapped I/O registers. Other programs can access the device by making calls to functions in the device driver, therefore avoiding the need to understand the low-level device hardware. Programmed I/O Certain architectures, such as x86, use specialzied instructions instead of memory-mapped I/O to communicate with I/O devices. LDRIO R1, device1 STRIO R2, device2 Serial I/O When a microcontroller needs to send more bits than free pins so it breaks the message into bits that it sends at each step. There are different standards for serial I/O: Serial Peripheral Interface (SPI) Clocks synchronized btw sender and receiver Universal Asynchronous Receiver/Transmitter (UART) Clocks unsychronizd btw sender and receiver Uses the TX (transmit) and RX (receive) line on the pies Signaling in units of baud instead of bits/sec since 8 data bits are sent using 10 symbols (a start and stop bit) 9600 baud rate = 9600 symbols /sec = 960 bytes(chars)/sec Slow compared to modern standards Universal Serial Bus (USB) Ethernet Many embedded systems use analog I/O. Therefore they use analog-to-digital converters (ADCs) to turn analog signals (voltages) to digital values (bits) and they use digital-to-analog converters (DACs) to turn bits to voltages. ADCs are built into many microcontrollers but few have built-in DACs. Motors Motors draw a very high current that can cause glitches on the power supply that disturb the digital logic Problem is mitigated by using different power supply for motor DC and stepper motors require a high drive current so a powerful driver such as an H-bridge must be connected between the microcontroller and the motor Stepper Motors accept a sequence of pulses that each rotate the motor by a fixed angle called a step More precise position control DC Motors tend to spin at thousands of RPM at very low torque so gear trains are added at cost of decreased RPM but benefit of higher torque Reversing the current makes the motor spin in the opposite direction Changing the current abruptly will result in a large potentially damagaging voltage spike from the inductance of the motor's electromagnet H-bridges handle all the these current related details Requires a seperate logic and motor power supply Supports coast, brake, reverse, and forward for DC motors Servo Motor A DC motor integrated with a gear train and shaft encoder Limited rotation (unless you get a continuous rotation servo)","title":"IO Systems"},{"location":"dig_sys/ch9-io-sys/#io-systems","text":"Input/Output (I/O) systems are used to connect a computer with external devices caled peripherals. Example devices for a personal computer include keyboards, monitors, printers, and wireless networks. Example devices for an embedded system include toaster's heating element, a toy's speech synthesizer, an engine's fuel injector, and a satellite's panel motors.","title":"I/O Systems"},{"location":"dig_sys/ch9-io-sys/#memory-mapped-io","text":"A method of communicating with input-output devices such as printers. Memory-mapped I/O involves dedicating a portion of the address space to I/O devices instead of memory. This allows a store to the specified address to send data to the device while a load from the address will receive data from the device. The blow program writes the value 7 to a an I/O device at a specified memory address. MOV R1, #7 LDR R2, =ioadr STR R1, [R2] ioadr DCD 0x20001000 To read from the the same device: LDR R1, [R2] A device driver is software that communicates with an I/O device. They are often downloaded or installed for things such as printers since writing a device driver requires detailed knowledge about the I/O device hardware including the addresses and behavior of the memory mapped I/O registers. Other programs can access the device by making calls to functions in the device driver, therefore avoiding the need to understand the low-level device hardware.","title":"Memory-mapped I/O"},{"location":"dig_sys/ch9-io-sys/#programmed-io","text":"Certain architectures, such as x86, use specialzied instructions instead of memory-mapped I/O to communicate with I/O devices. LDRIO R1, device1 STRIO R2, device2","title":"Programmed I/O"},{"location":"dig_sys/ch9-io-sys/#serial-io","text":"When a microcontroller needs to send more bits than free pins so it breaks the message into bits that it sends at each step. There are different standards for serial I/O: Serial Peripheral Interface (SPI) Clocks synchronized btw sender and receiver Universal Asynchronous Receiver/Transmitter (UART) Clocks unsychronizd btw sender and receiver Uses the TX (transmit) and RX (receive) line on the pies Signaling in units of baud instead of bits/sec since 8 data bits are sent using 10 symbols (a start and stop bit) 9600 baud rate = 9600 symbols /sec = 960 bytes(chars)/sec Slow compared to modern standards Universal Serial Bus (USB) Ethernet Many embedded systems use analog I/O. Therefore they use analog-to-digital converters (ADCs) to turn analog signals (voltages) to digital values (bits) and they use digital-to-analog converters (DACs) to turn bits to voltages. ADCs are built into many microcontrollers but few have built-in DACs.","title":"Serial I/O"},{"location":"dig_sys/ch9-io-sys/#motors","text":"Motors draw a very high current that can cause glitches on the power supply that disturb the digital logic Problem is mitigated by using different power supply for motor DC and stepper motors require a high drive current so a powerful driver such as an H-bridge must be connected between the microcontroller and the motor Stepper Motors accept a sequence of pulses that each rotate the motor by a fixed angle called a step More precise position control DC Motors tend to spin at thousands of RPM at very low torque so gear trains are added at cost of decreased RPM but benefit of higher torque Reversing the current makes the motor spin in the opposite direction Changing the current abruptly will result in a large potentially damagaging voltage spike from the inductance of the motor's electromagnet H-bridges handle all the these current related details Requires a seperate logic and motor power supply Supports coast, brake, reverse, and forward for DC motors Servo Motor A DC motor integrated with a gear train and shaft encoder Limited rotation (unless you get a continuous rotation servo)","title":"Motors"},{"location":"general/git/","text":"git reference undoing things git commit --ammend will add any staged changes to previous commit (technically 2nd commit replaces the previous one) only ammend local commits git restore replaces git reset . Unstaging changes: git reset HEAD <file-name> git restore --staged <file-name> Unmodifying an unstaged modified file: git restore <file> source diff unadded changes: git diff <file/folder-name> added changes: git diff --cached <file/folder-name> also works with --staged changes from commit 1 to commit 2: git diff <commit-1-hash> <commit-2-hash> --stats list changed files + insertions/deletions --name-only lists name of changed files --name-status list status of added/deleted/modified/renamed files changes from previous commit to current commit: git diff HEAD^ ( HEAD^ is previous commit) generate output to .diff file: git diff -output=patch.diff git diff > patch.diff git diff > changes.patch apply a diff/patch: git apply changes.patch (only performs the changes-- they still need to be added/commited) changes from one branch to another: git diff main <file-name> (comparing cur branch to main) adding ~ after branch name will use the previous commit (multiple ~ goes multiple commits back) pull vs fetch git fetch will bring down any changes from remote repo but won't change any of your local branchs Only updates .git/ directory with an updated version of the remote repo To integrate the fetched commits, need to run git merge git pull essentially does a fetch followed by a merge into the current branch git fetch is the command that says \"bring my local copy of the remote repository up to date.\" git pull says \"bring the changes in the remote repository to where I keep my own code.\" switch new version of checkout git switch <branch-name> use - as branch name to go back to original branch before from before switching create and switch to new branch: git switch -c <new-branch> switch to a remote branch (after fetching): git switch -c <branch> --track <remote>/<branch> branching add branch create local branch (doesn't checkout): git branch <new-branch> create and automatically checkout a new local-branch: git checkout -b <new-branch> add local branch to remote repo: git push --set-upstream origin <local-branch> -u is shorthand for upstream delete branch Local: git branch -d <local-branch> -d refuse to delete unmerged/unpushed changes -D force delete Remote: git push origin --delete <remote-branch-name> stash changes Stashing can be used to temporaliy store modified, tracked files in order to change branches git stash saves the modified and staged changes git stash list lists the stack of stashed file changes git stash pop writes working from the top of the stash stack git stash drop discards the changes from the top of the stash stack config preferences: Stored globally in ~/.gitconfig git config to update config settings --global for global config updates --local for project specific updates diff.noprefix true removes a/ and b/ prefixes in diff results credential.helper store and then type in your username and PAT the next time you login Will save and use your login credentials for any future remote requests can create git aliases git alias : [alias] unstaged = diff staged = diff --cached both = diff HEAD help.autocorrect <tenths-of-seconds> will auto run a mistyped command after specified tenths of a second More Config Settings how git works how git works from the bottom up - index = staging area = cache (all refer to same thing) - difference between git restore and git reset commit hashes Git generates a unique SHA-1 hash (40 char string of hex digits) for every commit and refers to commits by this ID (usually only displays first 7 digits) SHA-1 has been compromised (can spoof hashes) so they are moving to SHA-256 Making changes to previous commits in .git can be detected b/c each commit's hash is based on the previous commit's hash so the change to a previous commit would be easily detected Simple blockchain of basing commit hashes on previous commits and verifying chains of hashes","title":"Git"},{"location":"general/git/#git-reference","text":"","title":"git reference"},{"location":"general/git/#undoing-things","text":"git commit --ammend will add any staged changes to previous commit (technically 2nd commit replaces the previous one) only ammend local commits git restore replaces git reset . Unstaging changes: git reset HEAD <file-name> git restore --staged <file-name> Unmodifying an unstaged modified file: git restore <file> source","title":"undoing things"},{"location":"general/git/#diff","text":"unadded changes: git diff <file/folder-name> added changes: git diff --cached <file/folder-name> also works with --staged changes from commit 1 to commit 2: git diff <commit-1-hash> <commit-2-hash> --stats list changed files + insertions/deletions --name-only lists name of changed files --name-status list status of added/deleted/modified/renamed files changes from previous commit to current commit: git diff HEAD^ ( HEAD^ is previous commit) generate output to .diff file: git diff -output=patch.diff git diff > patch.diff git diff > changes.patch apply a diff/patch: git apply changes.patch (only performs the changes-- they still need to be added/commited) changes from one branch to another: git diff main <file-name> (comparing cur branch to main) adding ~ after branch name will use the previous commit (multiple ~ goes multiple commits back)","title":"diff"},{"location":"general/git/#pull-vs-fetch","text":"git fetch will bring down any changes from remote repo but won't change any of your local branchs Only updates .git/ directory with an updated version of the remote repo To integrate the fetched commits, need to run git merge git pull essentially does a fetch followed by a merge into the current branch git fetch is the command that says \"bring my local copy of the remote repository up to date.\" git pull says \"bring the changes in the remote repository to where I keep my own code.\"","title":"pull vs fetch"},{"location":"general/git/#switch","text":"new version of checkout git switch <branch-name> use - as branch name to go back to original branch before from before switching create and switch to new branch: git switch -c <new-branch> switch to a remote branch (after fetching): git switch -c <branch> --track <remote>/<branch>","title":"switch"},{"location":"general/git/#branching","text":"","title":"branching"},{"location":"general/git/#add-branch","text":"create local branch (doesn't checkout): git branch <new-branch> create and automatically checkout a new local-branch: git checkout -b <new-branch> add local branch to remote repo: git push --set-upstream origin <local-branch> -u is shorthand for upstream","title":"add branch"},{"location":"general/git/#delete-branch","text":"Local: git branch -d <local-branch> -d refuse to delete unmerged/unpushed changes -D force delete Remote: git push origin --delete <remote-branch-name>","title":"delete branch"},{"location":"general/git/#stash-changes","text":"Stashing can be used to temporaliy store modified, tracked files in order to change branches git stash saves the modified and staged changes git stash list lists the stack of stashed file changes git stash pop writes working from the top of the stash stack git stash drop discards the changes from the top of the stash stack","title":"stash changes"},{"location":"general/git/#config-preferences","text":"Stored globally in ~/.gitconfig git config to update config settings --global for global config updates --local for project specific updates diff.noprefix true removes a/ and b/ prefixes in diff results credential.helper store and then type in your username and PAT the next time you login Will save and use your login credentials for any future remote requests can create git aliases git alias : [alias] unstaged = diff staged = diff --cached both = diff HEAD help.autocorrect <tenths-of-seconds> will auto run a mistyped command after specified tenths of a second More Config Settings","title":"config preferences:"},{"location":"general/git/#how-git-works","text":"how git works from the bottom up - index = staging area = cache (all refer to same thing) - difference between git restore and git reset","title":"how git works"},{"location":"general/git/#commit-hashes","text":"Git generates a unique SHA-1 hash (40 char string of hex digits) for every commit and refers to commits by this ID (usually only displays first 7 digits) SHA-1 has been compromised (can spoof hashes) so they are moving to SHA-256 Making changes to previous commits in .git can be detected b/c each commit's hash is based on the previous commit's hash so the change to a previous commit would be easily detected Simple blockchain of basing commit hashes on previous commits and verifying chains of hashes","title":"commit hashes"},{"location":"general/hardware/","text":"3D Modeling and Printing Process Design or download a model (.stl file) Import the stl file(s) to slicing software (e.g. IdeaMaker) Slice the object Slicing takes the model and does the math on it to create gcode instructions for the 3D printer Export the gcode instructions to a usb drive or SD card depending on the printer Plug in drive to printer and begin the 3D print Notes PLA is a common plastic used b/c it is softer (less wear & tear on printer) and needs less heat to be melted ABS is a harder plastic that is used and thus requires more heat to melt it A variety of different filaments can be used to print things Tiny errors in a 3D printer\u2019s movement results in big errors with the print b/c movements are done hundreds of times Raspberry Pi Board Structure Set of GPIO pins (General purpose input-output pins) Read More Serial pin on TX (GPIO14) and RX (GPIO15) Can print out this and place on pi for reference Interactive GPIO Guide Pi Camera Watch out, static can kill it FIX PI CAMERA DETECTION ERROR by enabling the I2C Interface in preferences --> raspberry pi configuration","title":"Hardware"},{"location":"general/hardware/#3d-modeling-and-printing","text":"","title":"3D Modeling and Printing"},{"location":"general/hardware/#process","text":"Design or download a model (.stl file) Import the stl file(s) to slicing software (e.g. IdeaMaker) Slice the object Slicing takes the model and does the math on it to create gcode instructions for the 3D printer Export the gcode instructions to a usb drive or SD card depending on the printer Plug in drive to printer and begin the 3D print","title":"Process"},{"location":"general/hardware/#notes","text":"PLA is a common plastic used b/c it is softer (less wear & tear on printer) and needs less heat to be melted ABS is a harder plastic that is used and thus requires more heat to melt it A variety of different filaments can be used to print things Tiny errors in a 3D printer\u2019s movement results in big errors with the print b/c movements are done hundreds of times","title":"Notes"},{"location":"general/hardware/#raspberry-pi","text":"","title":"Raspberry Pi"},{"location":"general/hardware/#board-structure","text":"Set of GPIO pins (General purpose input-output pins) Read More Serial pin on TX (GPIO14) and RX (GPIO15) Can print out this and place on pi for reference Interactive GPIO Guide","title":"Board Structure"},{"location":"general/hardware/#pi-camera","text":"Watch out, static can kill it FIX PI CAMERA DETECTION ERROR by enabling the I2C Interface in preferences --> raspberry pi configuration","title":"Pi Camera"},{"location":"general/macos/","text":"MacOS Overview Executable PATH PATH is an environment variable that contains a colon-seperated list of directories where your shell will look for executables that are called by name on the command line without an explicit path to them Ex: /usr/bin:/bin:/home/bin Any executable called by name will be searched for in these directories in the order from left to right if an executable exists in 2 directories, the one that is found first is executed If no executable is found in any of the directories on the path, the shell will not execute the command and will throw a command not recognized error /etc/paths sets the PATH system wide for all users (macOS specific) .~/zsh_profile sets per-user preferences ( ~ is the user's home directory) PATH , $PATH , and ${PATH} all reference the same variable just in different contexts PATH is for setting the variable (e.g. PATH=/usr/bin ) $ denotes an environment variable variable names are case sensitive so PATH is different than Path Bash/zsh Profile vs RC: .bash_profile is executed for login shells (e.g. logging into machine via console or via ssh) .bashrc is executed for interactive non-login shells (e.g. already logged in and open a new terminal window) Also run when starting a new bash instance by typing /bin/bash such as the shebang at the top of some python scripts In OSX, terminal runs a login shell every time by default unlike other operating systems Filesystem Does not follow the Filesystem Hierarchy Standard that Linux operating systems do so there are some similarities and differences / is the root of the MacOS filesystem /System/Library/Kernels : Contains the OS kernel (replaces /boot folder in FHS) /Users : replaces the /home folder in FHS /var/root/ : replaces the /root folder in FHS /usr contains user installed utilities and apps user commands: /usr/bin for normal users /usr/sbin for admin users shared libraries: /usr/lib Man pages (manual page- software documentation) /usr/share/man executables that shouldn't directly be run by users /usr/libexec a subdirectory to place programs, libraries, and other files that don't come with the base OS /usr/local /dev contains device files /etc contains system configuration files and scripts /etc/paths contains a list of paths used by path_helper to build and set the PATH to search for commands along /bin contians executables to provide essential user utilities (e.g common command line commands like ls or pwd or cd) man hier : / root directory of the filesystem /bin/ user utilities fundamental to both single-user and multi-user environments /dev/ block and character device files /etc/ system configuration files and scripts /mach_kernel kernel executable (the operating system loaded into memory at boot time). /sbin/ system programs and administration utilities fundamental to both single-user and multi- user environments /tmp/ temporary files /usr/ contains the majority of user utilities and applications bin/ common utilities, programming tools, and apps include/ standard C include files arpa/ C include files for Internet service protocols hfs/ C include files for HFS machine/ machine specific C include files net/ misc network C include files netinet/ C include files for Internet standard protocols; see inet(4) nfs/ C include files for NFS (Network File System) objc/ C include files for Objective-C protocols/ C include files for Berkeley service protocols sys/ system C include files (kernel data structures) ufs/ C include files for UFS lib/ archive libraries libexec/ system daemons & system utilities (executed by other programs) local/ executables, libraries, etc. not included by the basic OS sbin/ system daemons & system utilities (executed by users) share/ architecture-independent data files calendar/ a variety of pre-fab calendar files dict/ word lists man/ manual pages misc/ misc system-wide ascii text files mk/ templates for make skel/ example . (dot) files for new accounts tabset/ tab description files zoneinfo/ timezone configuration information /var/ multi-purpose log, temporary, transient, and spool files at/ timed command scheduling files; see at(1) backups/ misc. backup files db/ misc. automatically generated system-specific database files log/ misc. system log files mail/ user mailbox files run/ system information files describing various info about system since it was booted rwho/ rwho data files spool/ misc. printer and mail system spooling directories tmp/ temporary files that are kept between system reboots folders/ per-user temporary files and caches Useful Commands man cmd will display the manual page for the terminal command (useful for getting the flag descriptions for commands like ls ) | pipe operator is great for doing additional commands to the output of the first command echo \"source /opt/ros/foxy/setup.zsh\" >> .zshrc is useful for adding things to the .zshrc without opening it up in an editor which python3 is usefull for figuring out where commands/executables are installed on the PATH compaudit | xargs chmod g-w basically runs an audit for insecure directories (usually related to read-write permissions) and removes any write permissions that should not be on directories ( Source ) needed to use this to fix a compaudit warning when sourcing ros2-foxy-base Resources MacOS Filesystem PATH Explanation Bash Profile vs RC Homebrew symlinks in /usr/local/opt to /usr/local/Cellar","title":"MacOS"},{"location":"general/macos/#macos-overview","text":"","title":"MacOS Overview"},{"location":"general/macos/#executable-path","text":"PATH is an environment variable that contains a colon-seperated list of directories where your shell will look for executables that are called by name on the command line without an explicit path to them Ex: /usr/bin:/bin:/home/bin Any executable called by name will be searched for in these directories in the order from left to right if an executable exists in 2 directories, the one that is found first is executed If no executable is found in any of the directories on the path, the shell will not execute the command and will throw a command not recognized error /etc/paths sets the PATH system wide for all users (macOS specific) .~/zsh_profile sets per-user preferences ( ~ is the user's home directory) PATH , $PATH , and ${PATH} all reference the same variable just in different contexts PATH is for setting the variable (e.g. PATH=/usr/bin ) $ denotes an environment variable variable names are case sensitive so PATH is different than Path","title":"Executable PATH"},{"location":"general/macos/#bashzsh-profile-vs-rc","text":".bash_profile is executed for login shells (e.g. logging into machine via console or via ssh) .bashrc is executed for interactive non-login shells (e.g. already logged in and open a new terminal window) Also run when starting a new bash instance by typing /bin/bash such as the shebang at the top of some python scripts In OSX, terminal runs a login shell every time by default unlike other operating systems","title":"Bash/zsh Profile vs RC:"},{"location":"general/macos/#filesystem","text":"Does not follow the Filesystem Hierarchy Standard that Linux operating systems do so there are some similarities and differences / is the root of the MacOS filesystem /System/Library/Kernels : Contains the OS kernel (replaces /boot folder in FHS) /Users : replaces the /home folder in FHS /var/root/ : replaces the /root folder in FHS /usr contains user installed utilities and apps user commands: /usr/bin for normal users /usr/sbin for admin users shared libraries: /usr/lib Man pages (manual page- software documentation) /usr/share/man executables that shouldn't directly be run by users /usr/libexec a subdirectory to place programs, libraries, and other files that don't come with the base OS /usr/local /dev contains device files /etc contains system configuration files and scripts /etc/paths contains a list of paths used by path_helper to build and set the PATH to search for commands along /bin contians executables to provide essential user utilities (e.g common command line commands like ls or pwd or cd) man hier : / root directory of the filesystem /bin/ user utilities fundamental to both single-user and multi-user environments /dev/ block and character device files /etc/ system configuration files and scripts /mach_kernel kernel executable (the operating system loaded into memory at boot time). /sbin/ system programs and administration utilities fundamental to both single-user and multi- user environments /tmp/ temporary files /usr/ contains the majority of user utilities and applications bin/ common utilities, programming tools, and apps include/ standard C include files arpa/ C include files for Internet service protocols hfs/ C include files for HFS machine/ machine specific C include files net/ misc network C include files netinet/ C include files for Internet standard protocols; see inet(4) nfs/ C include files for NFS (Network File System) objc/ C include files for Objective-C protocols/ C include files for Berkeley service protocols sys/ system C include files (kernel data structures) ufs/ C include files for UFS lib/ archive libraries libexec/ system daemons & system utilities (executed by other programs) local/ executables, libraries, etc. not included by the basic OS sbin/ system daemons & system utilities (executed by users) share/ architecture-independent data files calendar/ a variety of pre-fab calendar files dict/ word lists man/ manual pages misc/ misc system-wide ascii text files mk/ templates for make skel/ example . (dot) files for new accounts tabset/ tab description files zoneinfo/ timezone configuration information /var/ multi-purpose log, temporary, transient, and spool files at/ timed command scheduling files; see at(1) backups/ misc. backup files db/ misc. automatically generated system-specific database files log/ misc. system log files mail/ user mailbox files run/ system information files describing various info about system since it was booted rwho/ rwho data files spool/ misc. printer and mail system spooling directories tmp/ temporary files that are kept between system reboots folders/ per-user temporary files and caches","title":"Filesystem"},{"location":"general/macos/#useful-commands","text":"man cmd will display the manual page for the terminal command (useful for getting the flag descriptions for commands like ls ) | pipe operator is great for doing additional commands to the output of the first command echo \"source /opt/ros/foxy/setup.zsh\" >> .zshrc is useful for adding things to the .zshrc without opening it up in an editor which python3 is usefull for figuring out where commands/executables are installed on the PATH compaudit | xargs chmod g-w basically runs an audit for insecure directories (usually related to read-write permissions) and removes any write permissions that should not be on directories ( Source ) needed to use this to fix a compaudit warning when sourcing ros2-foxy-base","title":"Useful Commands"},{"location":"general/macos/#resources","text":"MacOS Filesystem PATH Explanation Bash Profile vs RC Homebrew symlinks in /usr/local/opt to /usr/local/Cellar","title":"Resources"},{"location":"general/oop/","text":"Object Oriented Programming: What is a Class: A blueprint Fields (instance variables) What an object knows Methods(Functions) What an object does What is Inheritance: Parent/Super class that shares fields/methods with its subclasses that also have their own fields & methods Subclasses abstract out the super class's features Subclasses can override or extend methods that don't work Subclasses only define the changes since the super's fields & methods are already defined when you extend the super class Use is A? principle to decide whether to extend a class Ex: Is a Dog an Animal? Yes, so Dog extends Animal Ex: Is a Dog a cat? No, so Dog doesn't extend Cat Use inheritance when a subclass needs most of the methods in the superclass Do not use inheritance just to reuse code if is A? doesn't work class Animal{ private String name; private double height; private int weight; private String sound; public void setName(String newName){ name = newName; } public void setSound(String newSound){ sound = newSound; } } class Dog extends Animal{ public Dog(){ super(); //Calls super constructor setSound(\"Bark\"); } public void digHole(){ System.out.println(\"Hole dug\"); } } What is Encapsulation: Protects data Use private fields Do not set fields directly Use public getter & setter functions to access & change the data Setter = Mutator Getter = Accessor class Dog{ private double height; public void setHeight(newHeight){ if(newHeight > 0){ height = newHeight; } else{ //Throw an Error } } } Instance vs. Local Variables: Instance Variable(AKA fields) are declared in a class Local Variables are declared in a method What is Polymorphism: Allows you to write methods that don't need to change if new subclasses are created Ex: Dog can add a new method w/o changing Animal Allows you to put diff subclasses in one array Animal doggy = new Dog(); Animal kitty = new Cat(); Animal[] animals = [doggy,kitty]; kitty.getSound(); //Returns Meow doggy.digHole(); //Would not work ((Dog)doggy).digHole(); //Would Work You can't access methods this way if they are only in the subclass Need to cast the object to the subclass that contains that method Cannot reference non-static variables or non-static-methods(w/o an object) in a static method Cannot access private methods outside of a subclass/class What is an Abstract Class: Gives power of polymorphism w/o all the work There are no abstract fields but can have protected variables that are rewritten as private fields in subclasses All methods do not have to be abstract w/in an abstract class You can have static methods w/in abstract classes Cannot create objects from abstract classes but subclasses can extend them and be made into objects Have to override abstract methods in the subclass in order to extend the class abstract public Class Creature{ protected String name; public abstract void setName(newName); } What is an Interface: A class w/ only abstract methods Can implement as many interfaces to a class as you want Can only use public static and final fields Provide the ultimate flexibility Classes from different inheritance trees can use a common interface Avoid using interfaces just to force the creation of a method public interface Living { public void setName(String newName); } public class Monkey implements Living{ private name; public void setName(String newName){ name = newName; } }","title":"Oop"},{"location":"general/oop/#object-oriented-programming","text":"","title":"Object Oriented Programming:"},{"location":"general/oop/#what-is-a-class","text":"A blueprint Fields (instance variables) What an object knows Methods(Functions) What an object does","title":"What is a Class:"},{"location":"general/oop/#what-is-inheritance","text":"Parent/Super class that shares fields/methods with its subclasses that also have their own fields & methods Subclasses abstract out the super class's features Subclasses can override or extend methods that don't work Subclasses only define the changes since the super's fields & methods are already defined when you extend the super class Use is A? principle to decide whether to extend a class Ex: Is a Dog an Animal? Yes, so Dog extends Animal Ex: Is a Dog a cat? No, so Dog doesn't extend Cat Use inheritance when a subclass needs most of the methods in the superclass Do not use inheritance just to reuse code if is A? doesn't work class Animal{ private String name; private double height; private int weight; private String sound; public void setName(String newName){ name = newName; } public void setSound(String newSound){ sound = newSound; } } class Dog extends Animal{ public Dog(){ super(); //Calls super constructor setSound(\"Bark\"); } public void digHole(){ System.out.println(\"Hole dug\"); } }","title":"What is Inheritance:"},{"location":"general/oop/#what-is-encapsulation","text":"Protects data Use private fields Do not set fields directly Use public getter & setter functions to access & change the data Setter = Mutator Getter = Accessor class Dog{ private double height; public void setHeight(newHeight){ if(newHeight > 0){ height = newHeight; } else{ //Throw an Error } } }","title":"What is Encapsulation:"},{"location":"general/oop/#instance-vs-local-variables","text":"Instance Variable(AKA fields) are declared in a class Local Variables are declared in a method","title":"Instance vs. Local Variables:"},{"location":"general/oop/#what-is-polymorphism","text":"Allows you to write methods that don't need to change if new subclasses are created Ex: Dog can add a new method w/o changing Animal Allows you to put diff subclasses in one array Animal doggy = new Dog(); Animal kitty = new Cat(); Animal[] animals = [doggy,kitty]; kitty.getSound(); //Returns Meow doggy.digHole(); //Would not work ((Dog)doggy).digHole(); //Would Work You can't access methods this way if they are only in the subclass Need to cast the object to the subclass that contains that method Cannot reference non-static variables or non-static-methods(w/o an object) in a static method Cannot access private methods outside of a subclass/class","title":"What is Polymorphism:"},{"location":"general/oop/#what-is-an-abstract-class","text":"Gives power of polymorphism w/o all the work There are no abstract fields but can have protected variables that are rewritten as private fields in subclasses All methods do not have to be abstract w/in an abstract class You can have static methods w/in abstract classes Cannot create objects from abstract classes but subclasses can extend them and be made into objects Have to override abstract methods in the subclass in order to extend the class abstract public Class Creature{ protected String name; public abstract void setName(newName); }","title":"What is an Abstract Class:"},{"location":"general/oop/#what-is-an-interface","text":"A class w/ only abstract methods Can implement as many interfaces to a class as you want Can only use public static and final fields Provide the ultimate flexibility Classes from different inheritance trees can use a common interface Avoid using interfaces just to force the creation of a method public interface Living { public void setName(String newName); } public class Monkey implements Living{ private name; public void setName(String newName){ name = newName; } }","title":"What is an Interface:"},{"location":"general/paradigms/","text":"What is a Programming Paradigm? A style of programming/way of thinking about software architecture A way/methodology, not a language Some languages are better for some paradigms than others Functional Programming (FP): Treats computation as the the evaluation of math functions and avoids changing-state and mutable data Passing data from function to function to get a result Functions are threatened as data (you can use them as parameters, return them, build functions from other functions, and build custom functions Have to be pure functions- not dependent on local/global states Good for modularity since each function will return the same output given the same input Object Oriented Programming (OOP): Based on the concept of \u201cobjects\u201d which may contain data in the form of fields/attributes and code in the form of procedures/methods Encapsulating data & behavior into objects that interact with other elements and can perform certain actions Read more here Procedural Programming (PP): Based on the concept of procedure call where procedures/routines/subroutines/functions simply contain a series of computational steps to be carried out \u2022 AKA inline programming and it takes a top-down approach \u2022 Writing a list of instructions to tell the computer what to do step by step Relies on procedures/routines Resource","title":"Programming Paradigms"},{"location":"general/paradigms/#what-is-a-programming-paradigm","text":"A style of programming/way of thinking about software architecture A way/methodology, not a language Some languages are better for some paradigms than others","title":"What is a Programming Paradigm?"},{"location":"general/paradigms/#functional-programming-fp","text":"Treats computation as the the evaluation of math functions and avoids changing-state and mutable data Passing data from function to function to get a result Functions are threatened as data (you can use them as parameters, return them, build functions from other functions, and build custom functions Have to be pure functions- not dependent on local/global states Good for modularity since each function will return the same output given the same input","title":"Functional Programming (FP):"},{"location":"general/paradigms/#object-oriented-programming-oop","text":"Based on the concept of \u201cobjects\u201d which may contain data in the form of fields/attributes and code in the form of procedures/methods Encapsulating data & behavior into objects that interact with other elements and can perform certain actions Read more here","title":"Object Oriented Programming (OOP):"},{"location":"general/paradigms/#procedural-programming-pp","text":"Based on the concept of procedure call where procedures/routines/subroutines/functions simply contain a series of computational steps to be carried out \u2022 AKA inline programming and it takes a top-down approach \u2022 Writing a list of instructions to tell the computer what to do step by step Relies on procedures/routines Resource","title":"Procedural Programming (PP):"},{"location":"general/python/","text":"Python Ternary Conditionals condition = True x = 1 if condition else 0 Number Formatting num1 = 1_000_000_000 num2 = 10_000_000 total = num1 + num2 print(f'{total:,}') #Uses f-string to format output w/ commas Context Managers Manage resources such as IO connections, threads, db connections, etc. by opening & closing resources automatically with open('test.txt','r') as f: file_contents = f.read() Enumerate Functions names = ['Bob','Steve','Jim'] for index,name in enumerate(names): print(index,name) for index,name in enumerate(names, start=1): #Can specify starting index value print(index,name) Zip Function Loops over n lists at once. When lists are different lengths, it stops at the end of the shortest list for name, hero, universe in zip(names, heroes, universes): print(name,hero) for value in zip(names, heroes, universes): print(value) #Value is a tuple of the results of the 3 lists Unpacking a,b = (1,2) print(a) #1 print(b) #2 c,_ = (4,5) #use underscore when you don't want to use a variable print(c) #4 x,y,*z = (1,2,3,5,6,7) print(x) #1 print(y) #2 print(z) #[3,5,6,7] x,y,*_, z = (1,2,3,4,6,7,) #ignores all values after 1 & 2 but until 7, which is stored in z Requests Library import requests url_params = {'page' : 2, 'count' : 25} r = requests.get(\"https://httpbin.org/get\", params=url_params) body = {'username' : 'corey', 'password' : 'testing'} r = requests.post(\"https://httpbin.org/post\", data=body, timeout=3) #include the timeout argument to Raise a ReadTimeout Error if the website does not respond in time r_dict = r.json() Environment Variables MacOS terminal: - export <var-name>=<var-value> (add new env var) - export <existing-var-name>=<var-value>:$<existing-var-name> (prepend values to an existing env var) - unset <var-name> (remove env var) os.environ acts like a python dictionary If you have other scripts updating the environment while your python script is running, calling os.environ again will not reflect the latest values since the mapping is only read when the python script is initially run. import os os.environ['DB_USER'] = str(123) # env vars must always be strings db_user = os.environ['DB_USER'] db_user = os.environ.get('DB_USER') # safe way of accessing potentially undefined env vars Memoization/Caching Examples calculate the nth term of the fibonacci sequence Basic implementation with dictionary fibonacci_cache = {} def fibonacci(n): if n in fibonacci_cache: return fibonacci_cache[n] elif n == 1 or n == 2: value = 1 else: value = fibonacci(n-1) + fibonacci(n-2) fibonacci_cache[n] = value return value Optimized implementation with function tools from functools import lru_cache @lru_cache(maxsize=1000) def fibonacci(n): if n == 1 or n ==2: return 1 else: return fibonacci(n-1)+fibonacci(n-2) Config Parser Documentation . Configuration file format: [section] option1 = value1 option2 = value2 Reading the configuration file: from configparser import ConfigParser parser = ConfigParser() parser.read('file.ini') if parser.has_section('database'): items = parser.items('database') Its good to store things that could change in the configuration file (e.g. endpoints, db logins/tables/sprocs) CSV Files import csv with open(file1, 'r'), open(file2, 'w') as f1, f2: csv_read = csv.reader(f1) csv_writer = csv.writer(f2) next(csv_read) # Skip header row for line in csv_reader: csv_writer.writerow([line[0],\"extra col\"]) Python Executable MacOS installs python 2.7 by default and should not be deleted /usr/bin/python and /usr/bin/python2 are symlinks to default install: System/Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7 Python 3+ versions are installed in /usr/local/bin/python3 is a symlink to version 3.5 installed in /Library/Frameworks/Python.framework/Versions/3.5 by downloading python from internet /usr/local/bin/python3.9 is a symlink to version 3.9 installed in /usr/local/Cellar by homebrew (same goes for pip3.9 ) /usr/bin/python3 is the actual install of version 3.8. Note sure how it got there but it is currently looked at on the path after the other version of python3 in the local/bin so it is not found unless the version is being explicitly looked for All 3 versions of python3 are needed for ROS stuff so thats fun python3 -m module_name Searches the path for the module and excecutes its contents as the main module (Runs the specified module even if it isnt in the cwd) Note: find symlinks using ls -l","title":"Python"},{"location":"general/python/#python","text":"","title":"Python"},{"location":"general/python/#ternary-conditionals","text":"condition = True x = 1 if condition else 0","title":"Ternary Conditionals"},{"location":"general/python/#number-formatting","text":"num1 = 1_000_000_000 num2 = 10_000_000 total = num1 + num2 print(f'{total:,}') #Uses f-string to format output w/ commas","title":"Number Formatting"},{"location":"general/python/#context-managers","text":"Manage resources such as IO connections, threads, db connections, etc. by opening & closing resources automatically with open('test.txt','r') as f: file_contents = f.read()","title":"Context Managers"},{"location":"general/python/#enumerate-functions","text":"names = ['Bob','Steve','Jim'] for index,name in enumerate(names): print(index,name) for index,name in enumerate(names, start=1): #Can specify starting index value print(index,name)","title":"Enumerate Functions"},{"location":"general/python/#zip-function","text":"Loops over n lists at once. When lists are different lengths, it stops at the end of the shortest list for name, hero, universe in zip(names, heroes, universes): print(name,hero) for value in zip(names, heroes, universes): print(value) #Value is a tuple of the results of the 3 lists","title":"Zip Function"},{"location":"general/python/#unpacking","text":"a,b = (1,2) print(a) #1 print(b) #2 c,_ = (4,5) #use underscore when you don't want to use a variable print(c) #4 x,y,*z = (1,2,3,5,6,7) print(x) #1 print(y) #2 print(z) #[3,5,6,7] x,y,*_, z = (1,2,3,4,6,7,) #ignores all values after 1 & 2 but until 7, which is stored in z","title":"Unpacking"},{"location":"general/python/#requests-library","text":"import requests url_params = {'page' : 2, 'count' : 25} r = requests.get(\"https://httpbin.org/get\", params=url_params) body = {'username' : 'corey', 'password' : 'testing'} r = requests.post(\"https://httpbin.org/post\", data=body, timeout=3) #include the timeout argument to Raise a ReadTimeout Error if the website does not respond in time r_dict = r.json()","title":"Requests Library"},{"location":"general/python/#environment-variables","text":"MacOS terminal: - export <var-name>=<var-value> (add new env var) - export <existing-var-name>=<var-value>:$<existing-var-name> (prepend values to an existing env var) - unset <var-name> (remove env var) os.environ acts like a python dictionary If you have other scripts updating the environment while your python script is running, calling os.environ again will not reflect the latest values since the mapping is only read when the python script is initially run. import os os.environ['DB_USER'] = str(123) # env vars must always be strings db_user = os.environ['DB_USER'] db_user = os.environ.get('DB_USER') # safe way of accessing potentially undefined env vars","title":"Environment Variables"},{"location":"general/python/#memoizationcaching","text":"Examples calculate the nth term of the fibonacci sequence Basic implementation with dictionary fibonacci_cache = {} def fibonacci(n): if n in fibonacci_cache: return fibonacci_cache[n] elif n == 1 or n == 2: value = 1 else: value = fibonacci(n-1) + fibonacci(n-2) fibonacci_cache[n] = value return value Optimized implementation with function tools from functools import lru_cache @lru_cache(maxsize=1000) def fibonacci(n): if n == 1 or n ==2: return 1 else: return fibonacci(n-1)+fibonacci(n-2)","title":"Memoization/Caching"},{"location":"general/python/#config-parser","text":"Documentation . Configuration file format: [section] option1 = value1 option2 = value2 Reading the configuration file: from configparser import ConfigParser parser = ConfigParser() parser.read('file.ini') if parser.has_section('database'): items = parser.items('database') Its good to store things that could change in the configuration file (e.g. endpoints, db logins/tables/sprocs)","title":"Config Parser"},{"location":"general/python/#csv-files","text":"import csv with open(file1, 'r'), open(file2, 'w') as f1, f2: csv_read = csv.reader(f1) csv_writer = csv.writer(f2) next(csv_read) # Skip header row for line in csv_reader: csv_writer.writerow([line[0],\"extra col\"])","title":"CSV Files"},{"location":"general/python/#python-executable","text":"MacOS installs python 2.7 by default and should not be deleted /usr/bin/python and /usr/bin/python2 are symlinks to default install: System/Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7 Python 3+ versions are installed in /usr/local/bin/python3 is a symlink to version 3.5 installed in /Library/Frameworks/Python.framework/Versions/3.5 by downloading python from internet /usr/local/bin/python3.9 is a symlink to version 3.9 installed in /usr/local/Cellar by homebrew (same goes for pip3.9 ) /usr/bin/python3 is the actual install of version 3.8. Note sure how it got there but it is currently looked at on the path after the other version of python3 in the local/bin so it is not found unless the version is being explicitly looked for All 3 versions of python3 are needed for ROS stuff so thats fun python3 -m module_name Searches the path for the module and excecutes its contents as the main module (Runs the specified module even if it isnt in the cwd) Note: find symlinks using ls -l","title":"Python Executable"},{"location":"general/regex/","text":"Regular expressions operate by moving character by character, from left to right, through a piece of text. When the regular expression finds a character that matches the first piece of the expression, it looks to find a continuous sequence of matching characters. Alternation is performed in regular expressions with the pipe symbol, | , allowing us to match either the characters preceding the | OR the characters after the | . Grouping , denoted with the open parenthesis ( and the closing parenthesis ) , lets us group parts of a regular expression together, and allows us to limit alternation to part of the regex. Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters, allowing for matches with incorrect or different spellings. Negated Character Sets : at the front of a character set, the ^ negates the set, matching any character that is not stated. Thus the regex [^cat] will match any character that is not c , a , or t , and would completely match each character d , o or g . Wildcards . will match any single character (letter, number, symbol or whitespace) in a piece of text. We can use the escape character, \\ , to escape the wildcard functionality of the . and match an actual period. Ranges allow us to specify a range of characters in which we can make a match without having to type out each individual character. The - character allows us to specify that we are interested in matching a range of characters. Shorthand Character Classes represent common ranges and make writing regular expressions much simpler: \\w : the \u201cword character\u201d class represents the regex range [A-Za-z0-9_] , and it matches a single uppercase character, lowercase character, digit or underscore \\d : the \u201cdigit character\u201d class represents the regex range [0-9] , and it matches a single digit character \\s : the \u201cwhitespace character\u201d class represents the regex range [ \\t\\r\\n\\f\\v] , matching a single space, tab, carriage return, line break, form feed, or vertical tab Negated Character Classes are shorthands that match any character not in the regular shorthand classes: \\W : the \u201cnon-word character\u201d class represents the regex range [^A-Za-z0-9_] , matching any character that is not included in the range represented by \\w \\D : the \u201cnon-digit character\u201d class represents the regex range [^0-9] , matching any character that is not included in the range represented by \\d \\S : the \u201cnon-whitespace character\u201d class represents the regex range [^ \\t\\r\\n\\f\\v] , matching any character that is not included in the range represented by \\s Fixed quantifiers , denoted with curly braces {} , let us indicate the exact quantity of a character we wish to match, or allow us to provide a quantity range to match on. \\w{3} will match exactly 3 word characters \\w{4,7} will match at minimum 4 word characters and at maximum 7 word characters An important note is that quantifiers are considered to be greedy . This means that they will match the greatest quantity of characters they possibly can. For example, the regex mo{2,4} will match the text moooo in the string moooo , and not return a match of moo , or mooo . Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time. The ? only applies to the character/grouping directly before it. Use the escape character in your regex in order to match a question mark ? in a piece of text. The Kleene star , denoted with the asterisk * , is also a quantifier, and matches the preceding character 0 or more times. This means that the character doesn\u2019t need to appear, can appear once, or can appear many many times. The Kleene plus , denoted by the plus + matches the preceding character 1 or more times. The anchors hat ^ and dollar sign $ are used to match text at the start and the end of a string, respectively. The regex ^Monkeys: my mortal enemy$ will completely match the text Monkeys: my mortal enemy but not match Spider Monkeys: my mortal enemy in the wild Summary: Regular expressions are special sequences of characters that describe a pattern of text that is to be matched We can use literals to match the exact characters that we desire Alternation , using the pipe symbol | , allows us to match the text preceding or following the | Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters Wildcards , represented by the period or dot . , will match any single character (letter, number, symbol or whitespace) Ranges allow us to specify a range of characters in which we can make a match Shorthand character classes like \\w , \\d and \\s represent the ranges representing word characters, digit characters, and whitespace characters, respectively Groupings , denoted with parentheses () , group parts of a regular expression together, and allows us to limit alternation to part of a regex Fixed quantifiers , represented with curly braces {} , let us indicate the exact quantity or a range of quantity of a character we wish to match Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time The Kleene star , denoted with the asterisk * , is a quantifier that matches the preceding character 0 or more times The Kleene plus , denoted by the plus + , matches the preceding character 1 or more times The anchor symbols hat ^ and dollar sign $ are used to match text at the start and end of a string, respectively","title":"Regex"},{"location":"general/regex/#summary","text":"Regular expressions are special sequences of characters that describe a pattern of text that is to be matched We can use literals to match the exact characters that we desire Alternation , using the pipe symbol | , allows us to match the text preceding or following the | Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters Wildcards , represented by the period or dot . , will match any single character (letter, number, symbol or whitespace) Ranges allow us to specify a range of characters in which we can make a match Shorthand character classes like \\w , \\d and \\s represent the ranges representing word characters, digit characters, and whitespace characters, respectively Groupings , denoted with parentheses () , group parts of a regular expression together, and allows us to limit alternation to part of a regex Fixed quantifiers , represented with curly braces {} , let us indicate the exact quantity or a range of quantity of a character we wish to match Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time The Kleene star , denoted with the asterisk * , is a quantifier that matches the preceding character 0 or more times The Kleene plus , denoted by the plus + , matches the preceding character 1 or more times The anchor symbols hat ^ and dollar sign $ are used to match text at the start and end of a string, respectively","title":"Summary:"},{"location":"general/swe-notes/","text":"Software Engineering Notebook UML Class Diagram Visual diagram used to demonstrate classes, their attributes/functions, and the relationships between classes Useful to start one before a large project to see how all the components interact Youtube Tutorial Lucid Chart (Online software used by numerous Fortune 500 companies for creating visual workspaces w/ things like UML diagrams) Class Construction Declare all fields as private/protected whenever possible Use getter and setter functions to access and update class fields Initialize the fields in the constructor Code Readability Readability and maintainability separate coders from good coders Focus on being able to read and understand parts of parts of code (e.g. modules/functions) without having to read entire rest of codebase Code should be Intuitive and self-documenting Readability > Cleverness/Shortness If you write the code as clever as possible, you will not be smart enough to debug it Consistency in style (e.g. spacing, braces) Commenting/Documentation Learning to write good comments is a skill Any good developer can figure out what your code does so your comments should explain why it does it that way Comment on why you made the decisions you did in your code Software Design Patterns Use encapsulation in order to separate concerns (i.e. possible points of breakdown in locally important assumptions such as object types) Try to limit managing global states (e.g. updating/referencing) since that can easily get messy, complicated, and buggy Clarity of a codebase greatly improves when pure functions that access no external state are used Functional languages like Haskell do this really well Don\u2019t switch between programming designs (e.g. pub/sub, actors, MVC) in connected parts of a codebase Create Data Abstraction Layers Ex: Don\u2019t have queries for your database in your application code. Instead create a separate library between the database and application that handles all the queries and provides easy to use getter functions like load_users(). Creates consistent styles in queries Limits the number of places to change queries if the DB schema changes Building a Software Stack Don\u2019t reinvent the wheel when not necessary Reliance on 3rd-party/open source software does leave you vulnerable to their security issues and makes you reliant on other people\u2019s maintenance of the dependencies Choose Appropriate Database: SQL: Postgres / MySQL / MariaDB / MemSQL / Amazon RDS Key Value Stores: Redis / Memcache / Riak NoSQL: MongoDB / Cassandra Hosted DBs: AWS RDS / DynamoDB / AppEngine Datastore Heavy Lifting: Amazon MR / Hadoop (Hive/Pig) / Cloudera / Google Big Query Debugging Come up w/ a hypothesis and test it (repeat until you fix the bug) Think like a scientist when debugging Record hypothesis and result Reproduce the bug locally rather than on a server (if convenient) Once you can fix it locally (which is faster & easier) you can change it on the server version Read the source code carefully and make minor alterations according to your hypothesis Use debuggers instead of messy print statements Problem Solving Define the problem Brainstorm (no idea is a bad idea) Pseudo-Code (don\u2019t worry about syntax- get the ideas down) Whiteboarding/writing is useful Implement (test as you go and make sure each component works before moving on) Avoid building out a whole solution w/o testing any of the parts Optimize efficiency (Go back and try to condense code, make more efficient, etc.) Time, memory, etc. Don't optimize too soon or overoptimize something that is fine Transition solution to another language if learning a new language General Tips You are responsible for code quality Use meaningful names Write code that expresses intent Code should speak for itself (Less comments = Less maintenance) Leave the code better than you found it Single-responsibility code Function does one thing well Less arguments = better function Tests! (Test Driven Development) Work on the big picture skeleton for the program and then fill in the details later Interface first, implementation later Independent components that can be used in different places Master your craft Create a minimum viable product (MVP) with the base functionality and then iterate by adding more features Notes on SWE Not an industry, it\u2019s a skill achieved with lots of practice Applicable to all industries available today (i.e. software runs everything) Solving problems is an art form-- you get better with lifelong practice Resources Readability & Software Design Practices Clean Code (Book) Commenting Less REST API Design","title":"Software Engineering Notebook"},{"location":"general/swe-notes/#software-engineering-notebook","text":"","title":"Software Engineering Notebook"},{"location":"general/swe-notes/#uml-class-diagram","text":"Visual diagram used to demonstrate classes, their attributes/functions, and the relationships between classes Useful to start one before a large project to see how all the components interact Youtube Tutorial Lucid Chart (Online software used by numerous Fortune 500 companies for creating visual workspaces w/ things like UML diagrams)","title":"UML Class Diagram"},{"location":"general/swe-notes/#class-construction","text":"Declare all fields as private/protected whenever possible Use getter and setter functions to access and update class fields Initialize the fields in the constructor","title":"Class Construction"},{"location":"general/swe-notes/#code-readability","text":"Readability and maintainability separate coders from good coders Focus on being able to read and understand parts of parts of code (e.g. modules/functions) without having to read entire rest of codebase Code should be Intuitive and self-documenting Readability > Cleverness/Shortness If you write the code as clever as possible, you will not be smart enough to debug it Consistency in style (e.g. spacing, braces)","title":"Code Readability"},{"location":"general/swe-notes/#commentingdocumentation","text":"Learning to write good comments is a skill Any good developer can figure out what your code does so your comments should explain why it does it that way Comment on why you made the decisions you did in your code","title":"Commenting/Documentation"},{"location":"general/swe-notes/#software-design-patterns","text":"Use encapsulation in order to separate concerns (i.e. possible points of breakdown in locally important assumptions such as object types) Try to limit managing global states (e.g. updating/referencing) since that can easily get messy, complicated, and buggy Clarity of a codebase greatly improves when pure functions that access no external state are used Functional languages like Haskell do this really well Don\u2019t switch between programming designs (e.g. pub/sub, actors, MVC) in connected parts of a codebase Create Data Abstraction Layers Ex: Don\u2019t have queries for your database in your application code. Instead create a separate library between the database and application that handles all the queries and provides easy to use getter functions like load_users(). Creates consistent styles in queries Limits the number of places to change queries if the DB schema changes","title":"Software Design Patterns"},{"location":"general/swe-notes/#building-a-software-stack","text":"Don\u2019t reinvent the wheel when not necessary Reliance on 3rd-party/open source software does leave you vulnerable to their security issues and makes you reliant on other people\u2019s maintenance of the dependencies Choose Appropriate Database: SQL: Postgres / MySQL / MariaDB / MemSQL / Amazon RDS Key Value Stores: Redis / Memcache / Riak NoSQL: MongoDB / Cassandra Hosted DBs: AWS RDS / DynamoDB / AppEngine Datastore Heavy Lifting: Amazon MR / Hadoop (Hive/Pig) / Cloudera / Google Big Query","title":"Building a Software Stack"},{"location":"general/swe-notes/#debugging","text":"Come up w/ a hypothesis and test it (repeat until you fix the bug) Think like a scientist when debugging Record hypothesis and result Reproduce the bug locally rather than on a server (if convenient) Once you can fix it locally (which is faster & easier) you can change it on the server version Read the source code carefully and make minor alterations according to your hypothesis Use debuggers instead of messy print statements","title":"Debugging"},{"location":"general/swe-notes/#problem-solving","text":"Define the problem Brainstorm (no idea is a bad idea) Pseudo-Code (don\u2019t worry about syntax- get the ideas down) Whiteboarding/writing is useful Implement (test as you go and make sure each component works before moving on) Avoid building out a whole solution w/o testing any of the parts Optimize efficiency (Go back and try to condense code, make more efficient, etc.) Time, memory, etc. Don't optimize too soon or overoptimize something that is fine Transition solution to another language if learning a new language","title":"Problem Solving"},{"location":"general/swe-notes/#general-tips","text":"You are responsible for code quality Use meaningful names Write code that expresses intent Code should speak for itself (Less comments = Less maintenance) Leave the code better than you found it Single-responsibility code Function does one thing well Less arguments = better function Tests! (Test Driven Development) Work on the big picture skeleton for the program and then fill in the details later Interface first, implementation later Independent components that can be used in different places Master your craft Create a minimum viable product (MVP) with the base functionality and then iterate by adding more features","title":"General Tips"},{"location":"general/swe-notes/#notes-on-swe","text":"Not an industry, it\u2019s a skill achieved with lots of practice Applicable to all industries available today (i.e. software runs everything) Solving problems is an art form-- you get better with lifelong practice","title":"Notes on SWE"},{"location":"general/swe-notes/#resources","text":"Readability & Software Design Practices Clean Code (Book) Commenting Less REST API Design","title":"Resources"},{"location":"general/terminal-cmds/","text":"Terminal Commands (Mac) Navigation: cd {/path/to/folder} : changes directory to specified path cd / : goes to root directory cd ~ : goes to user directory ls : lists all files/folders in the current working directory pwd : prints the path to the current working directory| Creating & Deleting: mkdir {foldername} : makes a folder with the specified nam rm {filename} : removes the specified file rm -r {foldername} : removes the specified folder recursively touch {filename} : creates the specified file| mv {filename} {new filename} : renames the file/folder to the 2nd name Opening Files/Folders: open {filename} : opens the file with the default program open {filename} -a \"{program name}\" : opens the file in the specified application open . : opens the current folder in finder open . -a \"{program name}\" opens the folder in the specified application Terminal Commands Different in Windows: dir - list files echo > {filename} - create an empty file del {filename} - remove a file rmdir {directory name} - remove a directory and all files within rename {filename} {new filename} - rename a file or folder start {filename} - open file in default program start . - open current directory cls - clear the terminal screen Vim Commands Command Function i insert/typing mode esc leave insert mode :w save additions :wq save & quit :q! quit & discard changes Key Movement w front of next word b front of previous word 0 start of line $ end of line g last line a append to final line","title":"Terminal Commands (Mac)"},{"location":"general/terminal-cmds/#terminal-commands-mac","text":"","title":"Terminal Commands (Mac)"},{"location":"general/terminal-cmds/#navigation","text":"cd {/path/to/folder} : changes directory to specified path cd / : goes to root directory cd ~ : goes to user directory ls : lists all files/folders in the current working directory pwd : prints the path to the current working directory|","title":"Navigation:"},{"location":"general/terminal-cmds/#creating-deleting","text":"mkdir {foldername} : makes a folder with the specified nam rm {filename} : removes the specified file rm -r {foldername} : removes the specified folder recursively touch {filename} : creates the specified file| mv {filename} {new filename} : renames the file/folder to the 2nd name","title":"Creating &amp; Deleting:"},{"location":"general/terminal-cmds/#opening-filesfolders","text":"open {filename} : opens the file with the default program open {filename} -a \"{program name}\" : opens the file in the specified application open . : opens the current folder in finder open . -a \"{program name}\" opens the folder in the specified application","title":"Opening Files/Folders:"},{"location":"general/terminal-cmds/#terminal-commands-different-in-windows","text":"dir - list files echo > {filename} - create an empty file del {filename} - remove a file rmdir {directory name} - remove a directory and all files within rename {filename} {new filename} - rename a file or folder start {filename} - open file in default program start . - open current directory cls - clear the terminal screen","title":"Terminal Commands Different in Windows:"},{"location":"general/terminal-cmds/#vim-commands","text":"Command Function i insert/typing mode esc leave insert mode :w save additions :wq save & quit :q! quit & discard changes Key Movement w front of next word b front of previous word 0 start of line $ end of line g last line a append to final line","title":"Vim Commands"},{"location":"math_science/brain/","text":"The average adult brain weighs about 3 lbs which is roughly 2% of total body weight. However it requires 20% of the total amount of energy our bodies spend in a day of no activity. This means it takes roughly 13 watts to power the brain. To put things in perspective, this is 1/5 of the power required by a standard 60 watt lightbulb. When compared to even the most impressive computers-- IBM's Watson which runs on a supercomputer that requires around 1,000 watts-- the brains ability computational ability compared to power consumption is remarkable. The Neuron Our brain is comprised of an estimated 100 billion neurons that operate together in order to produce behavior by transmitting and integrating information at the individual level. Each neuron is connected to roughly 50,000 others. A neuron is comprised of 3 main parts: 1. Dendrites- \"input\" side that receives signals from many other neurons 2. Cell Body- contains the nucleus and all elements needed for normal metabolic activities of these cells 3. Axon- \"output\" side that transmitts neural impulses to other neurons There are many varities of neurons that range in size from 5 microns in diameter to 100 microns-- the size of a human hair in diameter. The 3 main types of neurons are the following: Efferent Neurons- carry information outward from the central nervous system Afferent Neurons- carry information from the external world and body's internal environment inward to the central nervous system Interneurons- carry information from one neuron to another and comprise 99% of neurons in the brain How are signals transferrred? The science behind how electrical signals are transferred in the brain involves some physics and biology. Cells have a higher concentration of positive ions on the outside than the inside which creates a higher potential on the outside. The V_{out} = 0 mV while V_{in} = -70 mV . At the peak of the potential inside the nerve cell, the positive charges begin moving down the axon in order to maximize the distance between positive ions. This is the start of an electrical signal being transmitted. The myelin sheath which has a high resisitvity and covers the axon keeps the positive ions trapped, preventing the signal from disappating. Gaps in the myelin sheath called nodes of ranvier contain voltage gated sodium pumps that repeat the same process as above with the action potential when the electrical charge signal, helping to push the electrical signal further down the axon. The myelin sheath combined with nodes of ranvier allow for the electrical signal to be transmitted at very high speeds. These transmissions of electrical signals form the basis for all activity and computation done by the brain. While there are always things to further understand such as why sodium pumps work or the quantum mechanics behind the movement of electrons, we use layers of abstraction to allow us to build up understanding of certain aspects without having to understand every single thing that makes something occur. Abstraction is the key to making things understandable to humans and is critical in many fields outside of CS/EE in areas such as bio where complex phenomena can be studied at varying levels of abstraction in order to gain different insights. Its pretty meta when you think about how a brain is creating these layers of abstraction just so it can think about how itself works and begin to have an understanding of what it means to think. Brain Diseases Multiple Sclerosis (MS) is a disease where damage is done to the myelin sheaths in the brain, making it difficult for signals to travel, thus causing a breakdown in many critical functions such as muscle control. Sources PSY-PC 1205 PHYS 1602 Brain Power","title":"The Brain"},{"location":"math_science/brain/#the-neuron","text":"Our brain is comprised of an estimated 100 billion neurons that operate together in order to produce behavior by transmitting and integrating information at the individual level. Each neuron is connected to roughly 50,000 others. A neuron is comprised of 3 main parts: 1. Dendrites- \"input\" side that receives signals from many other neurons 2. Cell Body- contains the nucleus and all elements needed for normal metabolic activities of these cells 3. Axon- \"output\" side that transmitts neural impulses to other neurons There are many varities of neurons that range in size from 5 microns in diameter to 100 microns-- the size of a human hair in diameter. The 3 main types of neurons are the following: Efferent Neurons- carry information outward from the central nervous system Afferent Neurons- carry information from the external world and body's internal environment inward to the central nervous system Interneurons- carry information from one neuron to another and comprise 99% of neurons in the brain","title":"The Neuron"},{"location":"math_science/brain/#how-are-signals-transferrred","text":"The science behind how electrical signals are transferred in the brain involves some physics and biology. Cells have a higher concentration of positive ions on the outside than the inside which creates a higher potential on the outside. The V_{out} = 0 mV while V_{in} = -70 mV . At the peak of the potential inside the nerve cell, the positive charges begin moving down the axon in order to maximize the distance between positive ions. This is the start of an electrical signal being transmitted. The myelin sheath which has a high resisitvity and covers the axon keeps the positive ions trapped, preventing the signal from disappating. Gaps in the myelin sheath called nodes of ranvier contain voltage gated sodium pumps that repeat the same process as above with the action potential when the electrical charge signal, helping to push the electrical signal further down the axon. The myelin sheath combined with nodes of ranvier allow for the electrical signal to be transmitted at very high speeds. These transmissions of electrical signals form the basis for all activity and computation done by the brain. While there are always things to further understand such as why sodium pumps work or the quantum mechanics behind the movement of electrons, we use layers of abstraction to allow us to build up understanding of certain aspects without having to understand every single thing that makes something occur. Abstraction is the key to making things understandable to humans and is critical in many fields outside of CS/EE in areas such as bio where complex phenomena can be studied at varying levels of abstraction in order to gain different insights. Its pretty meta when you think about how a brain is creating these layers of abstraction just so it can think about how itself works and begin to have an understanding of what it means to think.","title":"How are signals transferrred?"},{"location":"math_science/brain/#brain-diseases","text":"Multiple Sclerosis (MS) is a disease where damage is done to the myelin sheaths in the brain, making it difficult for signals to travel, thus causing a breakdown in many critical functions such as muscle control.","title":"Brain Diseases"},{"location":"math_science/brain/#sources","text":"PSY-PC 1205 PHYS 1602 Brain Power","title":"Sources"},{"location":"math_science/physics/ch25/","text":"Current Current is the movement of net charges. More formally it is defined as the rate at which net charge flows past any section of a conductor. The unit of current is the ampere (1 A = 1 C/sec) Current density is the amount of net charge flowing through a unit area. J = nev_d The relation between current density and current is intuitively going to be the sum of the current density at each point times the area of each point. This can be expressed in general using a surface integral: I = \\int \\int J \\cdot dA If the current density J is uniform and the area A is flat, we get a simplified I = J \\cdot A which for simple wires where the angle between the flow and the area is 0, yields the equation I = JA . Resistance Voltage and current are observed to be proportional in most materials. The constant that relates the voltage and current for a given material is called the resistance R : V = RI . The resistance can be thought of as a measure of how difficult it is for current to flow. When free electrons are flowing through a material, they will inevitably collide with the nuclei of the materials' atoms. Certain materials will have nuclei arrangmenets that will result in more collisions, corresponding to lower current flow and a higher resistance value. This relationship of V = RI is known as Ohm's law after being discovered by George Ohm in 1827. Materials that are observed to follow Ohm's law are known as ohmic materials while ones that do not are known as nonohmic materials. Resistance has numerous applications such as being used to design circuit boards as well as its use in the myelin sheaths of our nerves to transmit electrical signals. Factors affecting Resistance Resistance depends on the material and details/geometry of the sample . Resistivity is the resistance of a unit cube of a given material and depends on the material only. \\rho = \\frac{E}{J} Note that conductivtiy is simply the inverse of resistivity. Resistivity and thus resistance, depends on temperature. Higher temperatures will increase the resistivity and thus increase the resistance and vice versa.","title":"Current & Resistance"},{"location":"math_science/physics/ch25/#current","text":"Current is the movement of net charges. More formally it is defined as the rate at which net charge flows past any section of a conductor. The unit of current is the ampere (1 A = 1 C/sec) Current density is the amount of net charge flowing through a unit area. J = nev_d The relation between current density and current is intuitively going to be the sum of the current density at each point times the area of each point. This can be expressed in general using a surface integral: I = \\int \\int J \\cdot dA If the current density J is uniform and the area A is flat, we get a simplified I = J \\cdot A which for simple wires where the angle between the flow and the area is 0, yields the equation I = JA .","title":"Current"},{"location":"math_science/physics/ch25/#resistance","text":"Voltage and current are observed to be proportional in most materials. The constant that relates the voltage and current for a given material is called the resistance R : V = RI . The resistance can be thought of as a measure of how difficult it is for current to flow. When free electrons are flowing through a material, they will inevitably collide with the nuclei of the materials' atoms. Certain materials will have nuclei arrangmenets that will result in more collisions, corresponding to lower current flow and a higher resistance value. This relationship of V = RI is known as Ohm's law after being discovered by George Ohm in 1827. Materials that are observed to follow Ohm's law are known as ohmic materials while ones that do not are known as nonohmic materials. Resistance has numerous applications such as being used to design circuit boards as well as its use in the myelin sheaths of our nerves to transmit electrical signals.","title":"Resistance"},{"location":"math_science/physics/ch25/#factors-affecting-resistance","text":"Resistance depends on the material and details/geometry of the sample . Resistivity is the resistance of a unit cube of a given material and depends on the material only. \\rho = \\frac{E}{J} Note that conductivtiy is simply the inverse of resistivity. Resistivity and thus resistance, depends on temperature. Higher temperatures will increase the resistivity and thus increase the resistance and vice versa.","title":"Factors affecting Resistance"},{"location":"math_science/physics/notes/","text":"Voltage The electric potential energy difference per unit charge. 1 volt = 1 J / 1 C. 1 volt represents 1 Joule of electric potential energy per 1 Coloumb of charge. 5 volts represent 5 joules of potential energy per coloumb meaning each charge carries 5 joules of potential energy higher voltage means the electrons have more energy final - initial current is the flow of charge per unit charge 1 Amp = 1 C / 1 s 5 Amp = 5 C / 1s meaning 5 coloumbs of charge are flowing per second analogous rate of flow of water resistance measure of materials' ability to resist the flow of charges (current) longer wire will have a greater resistance than a shorter wire because the electrons will have to travel through more material, meaning they will run into more obstacles thin wire will have larger resistance than thick wire since more electrons can get through a thicker wire resistance and current are inversely relateed ohm's law Relates voltage, resistance, and current V = IR current flows from high potential to low potential electrons actually travel in the opposite direction of current (direction of current travel can be thought of as the direction of travel of imaginary positive charges) increasing the voltage will increase the current increasing the resistance will decrease the current capacitors capacitors in parallel Equivalent capcitance is the sum of individual capacitances Voltage is same across all capacitors in parallel Follows that the total charge is the equivalent capacitance times the voltage potential energy in a capacitor is U = 1/2 CV^2 capacitors in series inverses for equivalent capacitance series => diff voltage across capacitor if diff capacitance charge stored on each capacitor is the same for capacitors in series dielectrics and capacitors when a circuit is not connected to a battery , inserting a dielectric will increase capacitance by a factor of K and decrease potential by a factor of K meaning charge remains the same due to Q = KV. Since E = V/l, decreasing V by a factor of K also decreases E by a factor of K When a circuit is connected to a battery , inserting a dielectric will increase the capacitane by a factor of K.= Voltage will remain the same as before due to the battery recharging the initial decrease in voltage so that it stays consistent with the potential supplied by the battery. Therefore, electric field will also be the same since voltae remains the same. In this case, charge will increase with the increase in capacitance. The increase in charge by factor of K will result in an increase of potential energy by a factor of K since U = 1/2 Q V .","title":"Voltage"},{"location":"math_science/physics/notes/#voltage","text":"The electric potential energy difference per unit charge. 1 volt = 1 J / 1 C. 1 volt represents 1 Joule of electric potential energy per 1 Coloumb of charge. 5 volts represent 5 joules of potential energy per coloumb meaning each charge carries 5 joules of potential energy higher voltage means the electrons have more energy final - initial","title":"Voltage"},{"location":"math_science/physics/notes/#current","text":"is the flow of charge per unit charge 1 Amp = 1 C / 1 s 5 Amp = 5 C / 1s meaning 5 coloumbs of charge are flowing per second analogous rate of flow of water","title":"current"},{"location":"math_science/physics/notes/#resistance","text":"measure of materials' ability to resist the flow of charges (current) longer wire will have a greater resistance than a shorter wire because the electrons will have to travel through more material, meaning they will run into more obstacles thin wire will have larger resistance than thick wire since more electrons can get through a thicker wire resistance and current are inversely relateed","title":"resistance"},{"location":"math_science/physics/notes/#ohms-law","text":"Relates voltage, resistance, and current V = IR current flows from high potential to low potential electrons actually travel in the opposite direction of current (direction of current travel can be thought of as the direction of travel of imaginary positive charges) increasing the voltage will increase the current increasing the resistance will decrease the current","title":"ohm's law"},{"location":"math_science/physics/notes/#capacitors","text":"","title":"capacitors"},{"location":"math_science/physics/notes/#capacitors-in-parallel","text":"Equivalent capcitance is the sum of individual capacitances Voltage is same across all capacitors in parallel Follows that the total charge is the equivalent capacitance times the voltage potential energy in a capacitor is U = 1/2 CV^2","title":"capacitors in parallel"},{"location":"math_science/physics/notes/#capacitors-in-series","text":"inverses for equivalent capacitance series => diff voltage across capacitor if diff capacitance charge stored on each capacitor is the same for capacitors in series","title":"capacitors in series"},{"location":"math_science/physics/notes/#dielectrics-and-capacitors","text":"when a circuit is not connected to a battery , inserting a dielectric will increase capacitance by a factor of K and decrease potential by a factor of K meaning charge remains the same due to Q = KV. Since E = V/l, decreasing V by a factor of K also decreases E by a factor of K When a circuit is connected to a battery , inserting a dielectric will increase the capacitane by a factor of K.= Voltage will remain the same as before due to the battery recharging the initial decrease in voltage so that it stays consistent with the potential supplied by the battery. Therefore, electric field will also be the same since voltae remains the same. In this case, charge will increase with the increase in capacitance. The increase in charge by factor of K will result in an increase of potential energy by a factor of K since U = 1/2 Q V .","title":"dielectrics and capacitors"},{"location":"math_science/prob_stats/crvs/","text":"Continuous Random Variables A CRV X satisifes: 1) Possible values of X make up an interval or union of disjoint intervals 2) P(X = c) = 0) for any c that is a possible value of X Probability Density Function DEF: Let X be a CRV. Then a probability density function of X is a function f s.t. P(a \\leq X \\leq b) = \\int_a^b f(x) dx This can be interpreted as the probability that X takes on a value in the interval [a,b] is the area above the interval and under the graph of the density function. Properties of pdfs: 1) f(x) \\geq 0 for all x 2) \\int_{-\\infty}^\\infty f(x)dx = 1 (area under the entire graph of f(x) ) Cumulative Distribution Function F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(y) dy This can be interpreted as the area under the density curve to the left of x . Propositions P(x > a) = 1 - F(a) P(a \\leq X \\leq b) = F(b) - F(a) The (100p) th percentile of a CRV X : p = F[n(p)] = \\int_{-\\infty}^{n(p)} f(y) dy where n(p) is the value on the measurement axis s.t. 100p % of the area under the density curve is to left of n(p) Ex: n(.75) stands for the 75% percentile where 75% of the area is to the left of n(.75) PDFs and CDFs PDFs measure how much the mass changes per unit of length (aka contribution to mass per unit length) CDFs measure the total mass up to a pt x (achieves this my taking the integral on the desired interval to get the mass of that interval) F(x) = \\int_{-\\infty}^x f(y) dy In the cdf's formula, the dy is a tiny length so f(y)dy is the contribution of mass by the point y so integrating (summing over an uncountable interval) the interval gives the total mass of probability. To get the cdf from the pdf, we integrate the pdf over the desired interval. To get the pdf from the cdf, we take the derivative of the cdf and evaluate it at the desired point. At every x which F'(x) exists, F'(x) = f(x) Variance \\sigma_X^2 = V(X)= \\int_{-\\infty}^\\infty (x - \\mu)^2 f(x) dx = E[(X - \\mu)^2] V(X) = E(X^2) - [E(X)]^2 V(aX + b) = a^2\\sigma_X^2 Expected Value E(aX + b) = aE(X) + b If X is largely concentrated on an interval of values close to \\mu , the mean value and variance of Y = h(X) can be approximated using the assumption that h(x) is differentiable. Approximating E[h(X)] \\approx h(\\mu) V[h(X)] \\approx [h'(\\mu)]^2 \\sigma^2 These follow from approximating h(X) using a first order taylor series expansion about (\\mu,h(\\mu)) : Y = h(X) \\approx h(\\mu) + h'(\\mu)(X - \\mu) Moment Generating Functions M_X(t) = E(e^{tX}) = \\int_{-\\infty}^{\\infty} e^{tx}f(x)dx Properties: M_X(0) = E(e^0) = \\int_{-\\infty}^{\\infty} e^{0x}(fx)dx = \\int_{-\\infty}^{\\infty} f(x)dx = 1 Let Y = aX +b . Then M_Y(t) = e^{bt}M_X(at) .","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/crvs/#continuous-random-variables","text":"A CRV X satisifes: 1) Possible values of X make up an interval or union of disjoint intervals 2) P(X = c) = 0) for any c that is a possible value of X","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/crvs/#probability-density-function","text":"DEF: Let X be a CRV. Then a probability density function of X is a function f s.t. P(a \\leq X \\leq b) = \\int_a^b f(x) dx This can be interpreted as the probability that X takes on a value in the interval [a,b] is the area above the interval and under the graph of the density function. Properties of pdfs: 1) f(x) \\geq 0 for all x 2) \\int_{-\\infty}^\\infty f(x)dx = 1 (area under the entire graph of f(x) )","title":"Probability Density Function"},{"location":"math_science/prob_stats/crvs/#cumulative-distribution-function","text":"F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(y) dy This can be interpreted as the area under the density curve to the left of x .","title":"Cumulative Distribution Function"},{"location":"math_science/prob_stats/crvs/#propositions","text":"P(x > a) = 1 - F(a) P(a \\leq X \\leq b) = F(b) - F(a) The (100p) th percentile of a CRV X : p = F[n(p)] = \\int_{-\\infty}^{n(p)} f(y) dy where n(p) is the value on the measurement axis s.t. 100p % of the area under the density curve is to left of n(p) Ex: n(.75) stands for the 75% percentile where 75% of the area is to the left of n(.75)","title":"Propositions"},{"location":"math_science/prob_stats/crvs/#pdfs-and-cdfs","text":"PDFs measure how much the mass changes per unit of length (aka contribution to mass per unit length) CDFs measure the total mass up to a pt x (achieves this my taking the integral on the desired interval to get the mass of that interval) F(x) = \\int_{-\\infty}^x f(y) dy In the cdf's formula, the dy is a tiny length so f(y)dy is the contribution of mass by the point y so integrating (summing over an uncountable interval) the interval gives the total mass of probability. To get the cdf from the pdf, we integrate the pdf over the desired interval. To get the pdf from the cdf, we take the derivative of the cdf and evaluate it at the desired point. At every x which F'(x) exists, F'(x) = f(x)","title":"PDFs and CDFs"},{"location":"math_science/prob_stats/crvs/#variance","text":"\\sigma_X^2 = V(X)= \\int_{-\\infty}^\\infty (x - \\mu)^2 f(x) dx = E[(X - \\mu)^2] V(X) = E(X^2) - [E(X)]^2 V(aX + b) = a^2\\sigma_X^2","title":"Variance"},{"location":"math_science/prob_stats/crvs/#expected-value","text":"E(aX + b) = aE(X) + b If X is largely concentrated on an interval of values close to \\mu , the mean value and variance of Y = h(X) can be approximated using the assumption that h(x) is differentiable.","title":"Expected Value"},{"location":"math_science/prob_stats/crvs/#approximating","text":"E[h(X)] \\approx h(\\mu) V[h(X)] \\approx [h'(\\mu)]^2 \\sigma^2 These follow from approximating h(X) using a first order taylor series expansion about (\\mu,h(\\mu)) : Y = h(X) \\approx h(\\mu) + h'(\\mu)(X - \\mu)","title":"Approximating"},{"location":"math_science/prob_stats/crvs/#moment-generating-functions","text":"M_X(t) = E(e^{tX}) = \\int_{-\\infty}^{\\infty} e^{tx}f(x)dx Properties: M_X(0) = E(e^0) = \\int_{-\\infty}^{\\infty} e^{0x}(fx)dx = \\int_{-\\infty}^{\\infty} f(x)dx = 1 Let Y = aX +b . Then M_Y(t) = e^{bt}M_X(at) .","title":"Moment Generating Functions"},{"location":"math_science/prob_stats/joint-distributions/","text":"Joint Probability Distributions Many problems involves several random variables, thus it is useful to have models for the joint behavior of several random variables, especially the case where the variables are independent of each other. Joint PMF for 2 DRVs A single pmf for a DRV X specifies the amount of mass for each possible value of X . The joint pmf of DRVs X and Y describes the amount of mass for each possible pair of values (x,y) . Let X and Y be two DRVs defined on sample space S of an experiment: p(x,y) = P(X = x \\cap Y = y) = \\sum_x \\sum_y p(x,y) The marginal pmfs of X and Y : p_X(x) = \\sum_y p(x,y) p_Y(y) = \\sum_x p(x,y) This makes sense since order to get the probability of a certain value of x, we take its probability as the sum over all possible y values. The marginal pmfs are useful for computing probabilites of events involving only one of the RVs. Joint PDF for 2 CRVs A single pdf for a CRV X specifies the amount of mass per unit length for each possible value of X on an interval/set. A joint pdf of CRVs X and Y specifies the amount of mass per unit area for each possible pair of values (x,y) . Let X and Y be two CRVs and A a two-dimensional set. P[(X,Y) \\in A] = \\int_A \\int f(x,y)dx dy Then f(x,y) is the joint pdf with properties: 1) f(x,y) \\geq 0 2) \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x,y) dx dy = 1 If A is a two-dimensional rectangle: P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f(x,y)dy dx The marginal pdfs for X and Y : f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) dy f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) dx Independence of 2 RV DEF: Two RVs X and Y are independent if \\forall (x,y) p(x,y) = p_X(x)*p_Y(y) for DRVs f(x,y) = f_X(x)*f_Y(y) for CRVs Independence of n RV Def: x_1 ... x_n are independent RV if (for any subset a_1 to a_r ) for DRV P(x_{a_1}, ..., x_{a_r}) = P(x_{a_1}) * ... *P(x_{a_r}) for CRV f(x_{a_1}, ..., x_{a_r}) = f(x_{a_1}) * ... *f(x_{a_r}) Multinomial Distribution Model: n independent trials with replacement with r possible outcomes each. P_i = prob of getting ith outcome i = 1, ..., r . X_i = # times the ith outcome appears The jpmf of X_1 ,... X_r has a multinomial distribution. P(X_1, \\cdots , X_r) = \\frac{n!}{X_1!X_2! \\cdots X_r!}P_1^{X_1}P_2^{X_2} \\cdots P_r^{X_r} Divide by the number of permutations of each element to remove permutations from the total number of ways the elements can be arranged Expected Value for Functions of 2 RV X, Y are RV and Z = h(X,Y) . Remeber that the expected value can be thought of as a weighted average so the same idea extends to functions of 2 RV: DRV: E(Z) = \\sum_X \\sum_Y h(X,Y)P(X,Y) CRV: E(Z) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} h(x,y) dy dx Note: You can change the order of summation/integration when the series is convergent (i dont really understand why) Propositions: 1) E(aX + Y) = aE(X) + E(Y) 2) If X,Y are independent, then E(X,Y) = E(X)E(Y) A counterexample s can be found such that the reverse of 2) does not hold meaning E(X,Y) = E(X)E(Y) does not imply independence of X and Y . Proof of 1) \\begin{aligned} E(aX+Y) &= \\sum_X \\sum_Y (aX+Y)P(X,Y) \\\\ &= a \\sum_X \\sum_Y X P(X,Y) + \\sum_X \\sum_Y YP(X,Y) \\\\ &= a \\sum_X X \\sum_Y P(X,Y) + \\sum_Y Y \\sum_X P(X,Y) \\\\ &= a \\sum_X X \\sum_Y P_X(X) + \\sum_Y Y \\sum_X P_Y(Y) \\\\ &= aE(X) + E(Y) \\end{aligned} Covariance DEF: X,Y are RV. Then Cov(X,Y) = E((x- \\mu_x)(Y-\\mu_y)) = E(X,Y) - E(X)E(Y) Interpretations Covariance measures how much X and Y are spread since Cov(X,X) = \\sigma^2 How much are X and Y related How much X and Y fail to be independent Cov(X,Y) = 0 does not imply independence as demonstrated by the counterexample to proposition 2 above. How linear is the relation between X and Y Examples The leftmost graph reprsents X and Y variables highly related in an inversely proportional way meaning when X increases, Y decreases and when X decresases, Y increases. The rightmost graph represents X and Y variables highly related in a directly proprtional way. Properties Cov(aX,Z) = aCov(X,Z) This implies Cov(aX,aX) = a^2Cov(X,X) . Cov(aX + bY, Z) = aCov(X,Z) + bCov(Y,Z) Correlation DEF: X and Y are random vars. Corr(X,Y) = \\delta_{x,y} = \\frac{Cov(X,Y)}{\\sigma_x \\sigma_y} Properties: 1) a,c > 0 or a, c <0 implies Corr(aX+b, cY+d) = Corr(X,Y) 2) -1 \\leq Corr(X,Y) \\leq 1 3) Corr(X,Y) = \\pm 1 iff Y = aX +b for some a \\neq 0 Correlation is unrelated to the value of the slope. Simply means when it is one, the slope is positive/increasing. WHen it is negative one, the slope is negative/decreasing. Correlation of 0 means no relation between the points (points are distributed roughly as a circle/sphere). As the correlation approaches -1 or 1, the circle of points flattens, with the spread increasing. Independent random variables will have a correlation of 0. However, uncorrelated random variables do not imply independence. Correlation does not imply causation! From a dataset we can compute correlation with the following formula: \\delta_{x,y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(n-1)s_x s_y} Transformations of RVs X is a CRV and Y = h(X) . Goal: Find the pdf of Y from the pdf of X . Assume h has an inverse. F_Y(y) = P(Y \\leq y) = P(h(X) \\leq y) = P(X \\leq h^{-1}(y) = F_X(h^{-1}(y) Therefore, f_Y(y) = f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) If h has a decreasing inverse, f_Y(y) = -f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) P(h(X) \\leq y) = P(X \\leq h^{-1}(y) only holds if h^{-1} is increasing. If h^{-1} is decreasing then P(h(X) \\leq y) = P(X \\geq h^{-1}(y) f_Y(h(x)) = f_X(x) \\lvert \\frac{1}{h'(x)} \\rvert Change of Variables Formula for 2 RVs X and Y are CRV. U, V = h(X, Y) f_{(u,v)}(h(x,y)) = f_{x,y}(x,y)\\lvert \\frac{1}{\\frac{\\partial u,v}{\\partial x,y}} \\rvert In the equation above, the denominator is the determinant of the jacobian. This represents the change in areas from X,Y to U,V (remember 3Blue1Brown determinant visualization intuition of differencec between areas). Conditional Distributions DEF: the condititonal pmf of Y given X = x P_{Y|X}(Y|X) = \\frac{P(X,Y)}{P_X(x)} = \\frac{f_{x,y}(x,y)}{f_x(x)} Warning: notice that for 1 fixed x , P_{Y|X}(Y | X = x) are pdfs and pmfs resp P_{Y|X}(Y | X = x) = \\sum_y P_{Y|X}(Y|X =x) = \\sum_y \\frac{P(X = x,Y)}{P_X(x)} = \\frac{1}{P_X(x)} \\sum_y P(X,Y) = \\frac{P_X(X)}{P_X(X)} = 1 DEF: E(Y|X=x) = \\sum_y y P(Y|X=x) E(g(Y) | X = x) = \\sum_y g(y) P(Y|X=x) V(Y) = \\sum_y [y - E(Y|X=x)]^2 P(Y|X=x) For CRV: similar formula with integrals instead of summation THM: 1) E(Y) = E(E(Y|X)) 2) V(Y) = E(V(Y|X)) + V(E(Y|X)) Intuition for 1: E(Y|X) is a curve/RV since you evaluate it for all X to give each x and expceted value of Y . So to get an expected value for Y , we simply take the weighted average (expected value) of all the possible values for the RV E(Y|X) . Intuition for 2: Varaiance of Y can be thought of as Avg(spreads) + Spread(avgs) Proof for 1: Assume E(Y) is finite so we can flip the order of summation \\begin{aligned} E(E(Y|X))) &= \\sum_x E(Y|X=x) P_X(x) \\\\ &= \\sum_x \\sum_y y P(Y|X=x)P_X(x) \\\\ &= \\sum_y y \\sum_x P(Y | X=x) P_X(x) \\\\ &= \\sum_y y P_Y(y) \\\\ &= E(Y) \\end{aligned}","title":"Joint Probability Distributions"},{"location":"math_science/prob_stats/joint-distributions/#joint-probability-distributions","text":"Many problems involves several random variables, thus it is useful to have models for the joint behavior of several random variables, especially the case where the variables are independent of each other.","title":"Joint Probability Distributions"},{"location":"math_science/prob_stats/joint-distributions/#joint-pmf-for-2-drvs","text":"A single pmf for a DRV X specifies the amount of mass for each possible value of X . The joint pmf of DRVs X and Y describes the amount of mass for each possible pair of values (x,y) . Let X and Y be two DRVs defined on sample space S of an experiment: p(x,y) = P(X = x \\cap Y = y) = \\sum_x \\sum_y p(x,y) The marginal pmfs of X and Y : p_X(x) = \\sum_y p(x,y) p_Y(y) = \\sum_x p(x,y) This makes sense since order to get the probability of a certain value of x, we take its probability as the sum over all possible y values. The marginal pmfs are useful for computing probabilites of events involving only one of the RVs.","title":"Joint PMF for 2 DRVs"},{"location":"math_science/prob_stats/joint-distributions/#joint-pdf-for-2-crvs","text":"A single pdf for a CRV X specifies the amount of mass per unit length for each possible value of X on an interval/set. A joint pdf of CRVs X and Y specifies the amount of mass per unit area for each possible pair of values (x,y) . Let X and Y be two CRVs and A a two-dimensional set. P[(X,Y) \\in A] = \\int_A \\int f(x,y)dx dy Then f(x,y) is the joint pdf with properties: 1) f(x,y) \\geq 0 2) \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x,y) dx dy = 1 If A is a two-dimensional rectangle: P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f(x,y)dy dx The marginal pdfs for X and Y : f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) dy f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) dx","title":"Joint PDF for 2 CRVs"},{"location":"math_science/prob_stats/joint-distributions/#independence-of-2-rv","text":"DEF: Two RVs X and Y are independent if \\forall (x,y) p(x,y) = p_X(x)*p_Y(y) for DRVs f(x,y) = f_X(x)*f_Y(y) for CRVs","title":"Independence of 2 RV"},{"location":"math_science/prob_stats/joint-distributions/#independence-of-n-rv","text":"Def: x_1 ... x_n are independent RV if (for any subset a_1 to a_r ) for DRV P(x_{a_1}, ..., x_{a_r}) = P(x_{a_1}) * ... *P(x_{a_r}) for CRV f(x_{a_1}, ..., x_{a_r}) = f(x_{a_1}) * ... *f(x_{a_r})","title":"Independence of n RV"},{"location":"math_science/prob_stats/joint-distributions/#multinomial-distribution","text":"Model: n independent trials with replacement with r possible outcomes each. P_i = prob of getting ith outcome i = 1, ..., r . X_i = # times the ith outcome appears The jpmf of X_1 ,... X_r has a multinomial distribution. P(X_1, \\cdots , X_r) = \\frac{n!}{X_1!X_2! \\cdots X_r!}P_1^{X_1}P_2^{X_2} \\cdots P_r^{X_r} Divide by the number of permutations of each element to remove permutations from the total number of ways the elements can be arranged","title":"Multinomial Distribution"},{"location":"math_science/prob_stats/joint-distributions/#expected-value-for-functions-of-2-rv","text":"X, Y are RV and Z = h(X,Y) . Remeber that the expected value can be thought of as a weighted average so the same idea extends to functions of 2 RV: DRV: E(Z) = \\sum_X \\sum_Y h(X,Y)P(X,Y) CRV: E(Z) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} h(x,y) dy dx Note: You can change the order of summation/integration when the series is convergent (i dont really understand why) Propositions: 1) E(aX + Y) = aE(X) + E(Y) 2) If X,Y are independent, then E(X,Y) = E(X)E(Y) A counterexample s can be found such that the reverse of 2) does not hold meaning E(X,Y) = E(X)E(Y) does not imply independence of X and Y . Proof of 1) \\begin{aligned} E(aX+Y) &= \\sum_X \\sum_Y (aX+Y)P(X,Y) \\\\ &= a \\sum_X \\sum_Y X P(X,Y) + \\sum_X \\sum_Y YP(X,Y) \\\\ &= a \\sum_X X \\sum_Y P(X,Y) + \\sum_Y Y \\sum_X P(X,Y) \\\\ &= a \\sum_X X \\sum_Y P_X(X) + \\sum_Y Y \\sum_X P_Y(Y) \\\\ &= aE(X) + E(Y) \\end{aligned}","title":"Expected Value for Functions of 2 RV"},{"location":"math_science/prob_stats/joint-distributions/#covariance","text":"DEF: X,Y are RV. Then Cov(X,Y) = E((x- \\mu_x)(Y-\\mu_y)) = E(X,Y) - E(X)E(Y)","title":"Covariance"},{"location":"math_science/prob_stats/joint-distributions/#interpretations","text":"Covariance measures how much X and Y are spread since Cov(X,X) = \\sigma^2 How much are X and Y related How much X and Y fail to be independent Cov(X,Y) = 0 does not imply independence as demonstrated by the counterexample to proposition 2 above. How linear is the relation between X and Y","title":"Interpretations"},{"location":"math_science/prob_stats/joint-distributions/#examples","text":"The leftmost graph reprsents X and Y variables highly related in an inversely proportional way meaning when X increases, Y decreases and when X decresases, Y increases. The rightmost graph represents X and Y variables highly related in a directly proprtional way.","title":"Examples"},{"location":"math_science/prob_stats/joint-distributions/#properties","text":"Cov(aX,Z) = aCov(X,Z) This implies Cov(aX,aX) = a^2Cov(X,X) . Cov(aX + bY, Z) = aCov(X,Z) + bCov(Y,Z)","title":"Properties"},{"location":"math_science/prob_stats/joint-distributions/#correlation","text":"DEF: X and Y are random vars. Corr(X,Y) = \\delta_{x,y} = \\frac{Cov(X,Y)}{\\sigma_x \\sigma_y} Properties: 1) a,c > 0 or a, c <0 implies Corr(aX+b, cY+d) = Corr(X,Y) 2) -1 \\leq Corr(X,Y) \\leq 1 3) Corr(X,Y) = \\pm 1 iff Y = aX +b for some a \\neq 0 Correlation is unrelated to the value of the slope. Simply means when it is one, the slope is positive/increasing. WHen it is negative one, the slope is negative/decreasing. Correlation of 0 means no relation between the points (points are distributed roughly as a circle/sphere). As the correlation approaches -1 or 1, the circle of points flattens, with the spread increasing. Independent random variables will have a correlation of 0. However, uncorrelated random variables do not imply independence. Correlation does not imply causation! From a dataset we can compute correlation with the following formula: \\delta_{x,y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(n-1)s_x s_y}","title":"Correlation"},{"location":"math_science/prob_stats/joint-distributions/#transformations-of-rvs","text":"X is a CRV and Y = h(X) . Goal: Find the pdf of Y from the pdf of X . Assume h has an inverse. F_Y(y) = P(Y \\leq y) = P(h(X) \\leq y) = P(X \\leq h^{-1}(y) = F_X(h^{-1}(y) Therefore, f_Y(y) = f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) If h has a decreasing inverse, f_Y(y) = -f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) P(h(X) \\leq y) = P(X \\leq h^{-1}(y) only holds if h^{-1} is increasing. If h^{-1} is decreasing then P(h(X) \\leq y) = P(X \\geq h^{-1}(y) f_Y(h(x)) = f_X(x) \\lvert \\frac{1}{h'(x)} \\rvert","title":"Transformations of RVs"},{"location":"math_science/prob_stats/joint-distributions/#change-of-variables-formula-for-2-rvs","text":"X and Y are CRV. U, V = h(X, Y) f_{(u,v)}(h(x,y)) = f_{x,y}(x,y)\\lvert \\frac{1}{\\frac{\\partial u,v}{\\partial x,y}} \\rvert In the equation above, the denominator is the determinant of the jacobian. This represents the change in areas from X,Y to U,V (remember 3Blue1Brown determinant visualization intuition of differencec between areas).","title":"Change of Variables Formula for 2 RVs"},{"location":"math_science/prob_stats/joint-distributions/#conditional-distributions","text":"DEF: the condititonal pmf of Y given X = x P_{Y|X}(Y|X) = \\frac{P(X,Y)}{P_X(x)} = \\frac{f_{x,y}(x,y)}{f_x(x)} Warning: notice that for 1 fixed x , P_{Y|X}(Y | X = x) are pdfs and pmfs resp P_{Y|X}(Y | X = x) = \\sum_y P_{Y|X}(Y|X =x) = \\sum_y \\frac{P(X = x,Y)}{P_X(x)} = \\frac{1}{P_X(x)} \\sum_y P(X,Y) = \\frac{P_X(X)}{P_X(X)} = 1 DEF: E(Y|X=x) = \\sum_y y P(Y|X=x) E(g(Y) | X = x) = \\sum_y g(y) P(Y|X=x) V(Y) = \\sum_y [y - E(Y|X=x)]^2 P(Y|X=x) For CRV: similar formula with integrals instead of summation THM: 1) E(Y) = E(E(Y|X)) 2) V(Y) = E(V(Y|X)) + V(E(Y|X)) Intuition for 1: E(Y|X) is a curve/RV since you evaluate it for all X to give each x and expceted value of Y . So to get an expected value for Y , we simply take the weighted average (expected value) of all the possible values for the RV E(Y|X) . Intuition for 2: Varaiance of Y can be thought of as Avg(spreads) + Spread(avgs) Proof for 1: Assume E(Y) is finite so we can flip the order of summation \\begin{aligned} E(E(Y|X))) &= \\sum_x E(Y|X=x) P_X(x) \\\\ &= \\sum_x \\sum_y y P(Y|X=x)P_X(x) \\\\ &= \\sum_y y \\sum_x P(Y | X=x) P_X(x) \\\\ &= \\sum_y y P_Y(y) \\\\ &= E(Y) \\end{aligned}","title":"Conditional Distributions"},{"location":"math_science/prob_stats/rv/","text":"Discrete Random Variables Binomial Negative Binomial Hypergeometric Geometric Poisson Continuous Random Variables Uniform DEF: A CRV X has a uniform distribution on the interval [A,B] if the pdf for A \\leq X \\leq B is: f(x; A,B) = \\frac{1}{B-A} E(X) = \\frac{A + B}{2} V(X) = \\frac{(B-A)^2}{12} M_X(t) = E(e^{tx}) = \\frac{e^{tb} - e^{ta}}{t(b-a)} Normal DEF: A CRV X has a normal/gaussian distribution with parameters \\mu and \\sigma (or \\sigma^2 ) where -\\infty < \\mu < \\infty and 0 < \\sigma if the pdf is: f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} X \\sim N(\\mu,\\sigma^2) A large \\sigma implies a value far from \\mu is well observed whereas such a value is unlikely when \\sigma is small. Standard Normal Distribution Since standard integration techniques cannot be used to evaluate the cdf of a normal distribution, the standard normal distribution ( \\mu = 0 and \\sigma = 1 ) has been tabulated and can be used to compute probabilities for any other values of \\mu and \\sigma . The PDF: f(z;0,1) = \\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}} The CDF: \\Phi(z) = P(Z \\leq z) = \\int_{-\\infty}^z f(y;0,1)dy Non Standard Normal Distributions To compute probabilities for X \\sim N(\\mu,\\sigma^2) we create a standardized random variable: Z = \\frac{X - \\mu}{\\sigma} Thus, P(a\\leq X \\leq b) = P(\\frac{a-\\mu}{\\sigma} \\leq Z \\leq \\frac{b - \\mu}{\\sigma}) = \\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma}) P(X \\leq a) = \\Phi(\\frac{a - \\mu}{\\sigma}) This results in expected values, variances, and mgfs of the following form: E(X) = E(\\sigma Z + \\mu) = \\sigma E(Z) + \\mu = \\sigma(0) + \\mu = \\mu V(X) = V(\\sigma Z + \\mu) = \\sigma^2V(Z) = \\sigma^2(1) = \\sigma^2 M_X(t) = e^{\\frac{\\mu t + \\sigma^2 t^2}{2}} Normal Approximation of Binomial Distribution Normal distributions can approximate binomial distributions quite well as long as they are not too skewed meaning their probabaility of success p is roughly around 0.5 . X \\sim N(np, \\sqrt{np(1-p)}) P(X \\leq x) = \\Phi(\\frac{x + 0.5 - np}{\\sqrt{np(1-p)}}) 0.5 is the continuity correction that basically corrects for the discreteness of the underyling binomial distribution. The approximation is adequate provided that np \\geq 10 and n(1-p) \\geq 10 . Otherwise, the binomial distribution may be too skewed for the symmetric normal curve to give accurate approximations. Z Critical Values In statistical inference, we need values on the measurement axis that capture small tail areas under the standard normal curve. z_\\alpha denotes the value on the measurement axis for which \\alpha of the area under the z curve lies to the right of z_\\alpha . Also is the 100(1-\\alpha) th percentile of the standard normal distribution. Gamma The gamma family of pdfs yield a wide variety of skewed distributional shapes that can be used for situations in which the symmetric normal disitrubtion does not accurately represent the skewed random variable. In order to define the family of gama distributions we first must define an important function in many areas of mathematics. Gamma Function DEF: For \\alpha > 0 , the gamma function \\Gamma(\\alpha) is defined by: \\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha - 1}e^{-x}dx 1) For any \\alpha > 1 , \\Gamma(\\alpha) = (\\alpha - 1) * \\Gamma(\\alpha - 1) 2) For any positive integer n, \\Gamma(n) = (n - 1)! 3) \\Gamma(\\frac{1}{2}) = \\sqrt{\\pi} Distribution With the gamma function, we can then define the gamma distribution for a CRV X : f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\frac{1}{\\beta^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1}e^{-x/\\beta} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} where \\alpha > 0 and \\beta > 0 . The Standard Gamma Distribution has \\beta = 1 . \\beta is known as the scale parameter because values less than one compress the pdf in the x direction, and values greater than one stretch the pdf in the x direction \\alpha determines how far to the right the distribution's center is, with larger values making it centered more to the right. E(X) = \\alpha \\beta V(X) = \\alpha \\beta^2 M_X(t) = \\frac{1}{(1- \\beta t)^\\alpha} Incomplete Gamma Function The cdf when X is a standard gamma rv (for x >0 ), F(x; \\alpha) = \\int_0^x \\frac{y^{\\alpha - 1}e^{-y}}{\\Gamma(\\alpha)}dy The incomplete gamma can be used to compute any non standard gamma distibution's probabilities since it has been tabulated. For X \\sim G(\\alpha,\\beta) , the cdf of X is the incomplete gamma function evaluated at x/\\beta : F_X(x; \\alpha,\\beta) = F(\\frac{x}{\\beta};\\alpha) Exponential Often used to model the time elapsed between events DEF: A CRV X has an exponential distribution with parameter \\lambda where \\lambda > 0 if the pdf of X is: f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\lambda e^{-\\lambda x} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} Exponential pdf is special case of the gamma pdf where \\alpha = 1 and \\beta = \\frac{1}{\\lambda} . So we can use the expected value and variance formula for the gamma distribution to derive the mean and variance of the exponential distribution: E(X) = \\alpha \\beta = \\frac{1}{\\lambda} V(X) = \\alpha \\beta^2 = \\frac{1}{\\lambda^2} The pdf can be easily integrated unlike the general gamma pdf so the cdf is: F_X(x; \\lambda) = \\int_0^x \\lambda e^{-\\lambda x} dx = 1 - e^{-\\lambda x} Memoryless Property P(X \\geq t + t_0 | X \\geq t_0) = P(X \\geq t_0) The above can be thought of through analogy: If we toss a coin several times until we observe heads, not getting heads for several tosses does not affect the probability of the next toss since they are independent. Memorylessness of the exponential distribution is basically this idea. Read More about memorylessness and approximating the geometric distribution here .","title":"Random Variables"},{"location":"math_science/prob_stats/rv/#discrete-random-variables","text":"","title":"Discrete Random Variables"},{"location":"math_science/prob_stats/rv/#binomial","text":"","title":"Binomial"},{"location":"math_science/prob_stats/rv/#negative-binomial","text":"","title":"Negative Binomial"},{"location":"math_science/prob_stats/rv/#hypergeometric","text":"","title":"Hypergeometric"},{"location":"math_science/prob_stats/rv/#geometric","text":"","title":"Geometric"},{"location":"math_science/prob_stats/rv/#poisson","text":"","title":"Poisson"},{"location":"math_science/prob_stats/rv/#continuous-random-variables","text":"","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/rv/#uniform","text":"DEF: A CRV X has a uniform distribution on the interval [A,B] if the pdf for A \\leq X \\leq B is: f(x; A,B) = \\frac{1}{B-A} E(X) = \\frac{A + B}{2} V(X) = \\frac{(B-A)^2}{12} M_X(t) = E(e^{tx}) = \\frac{e^{tb} - e^{ta}}{t(b-a)}","title":"Uniform"},{"location":"math_science/prob_stats/rv/#normal","text":"DEF: A CRV X has a normal/gaussian distribution with parameters \\mu and \\sigma (or \\sigma^2 ) where -\\infty < \\mu < \\infty and 0 < \\sigma if the pdf is: f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} X \\sim N(\\mu,\\sigma^2) A large \\sigma implies a value far from \\mu is well observed whereas such a value is unlikely when \\sigma is small.","title":"Normal"},{"location":"math_science/prob_stats/rv/#standard-normal-distribution","text":"Since standard integration techniques cannot be used to evaluate the cdf of a normal distribution, the standard normal distribution ( \\mu = 0 and \\sigma = 1 ) has been tabulated and can be used to compute probabilities for any other values of \\mu and \\sigma . The PDF: f(z;0,1) = \\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}} The CDF: \\Phi(z) = P(Z \\leq z) = \\int_{-\\infty}^z f(y;0,1)dy","title":"Standard Normal Distribution"},{"location":"math_science/prob_stats/rv/#non-standard-normal-distributions","text":"To compute probabilities for X \\sim N(\\mu,\\sigma^2) we create a standardized random variable: Z = \\frac{X - \\mu}{\\sigma} Thus, P(a\\leq X \\leq b) = P(\\frac{a-\\mu}{\\sigma} \\leq Z \\leq \\frac{b - \\mu}{\\sigma}) = \\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma}) P(X \\leq a) = \\Phi(\\frac{a - \\mu}{\\sigma}) This results in expected values, variances, and mgfs of the following form: E(X) = E(\\sigma Z + \\mu) = \\sigma E(Z) + \\mu = \\sigma(0) + \\mu = \\mu V(X) = V(\\sigma Z + \\mu) = \\sigma^2V(Z) = \\sigma^2(1) = \\sigma^2 M_X(t) = e^{\\frac{\\mu t + \\sigma^2 t^2}{2}}","title":"Non Standard Normal Distributions"},{"location":"math_science/prob_stats/rv/#normal-approximation-of-binomial-distribution","text":"Normal distributions can approximate binomial distributions quite well as long as they are not too skewed meaning their probabaility of success p is roughly around 0.5 . X \\sim N(np, \\sqrt{np(1-p)}) P(X \\leq x) = \\Phi(\\frac{x + 0.5 - np}{\\sqrt{np(1-p)}}) 0.5 is the continuity correction that basically corrects for the discreteness of the underyling binomial distribution. The approximation is adequate provided that np \\geq 10 and n(1-p) \\geq 10 . Otherwise, the binomial distribution may be too skewed for the symmetric normal curve to give accurate approximations.","title":"Normal Approximation of Binomial Distribution"},{"location":"math_science/prob_stats/rv/#z-critical-values","text":"In statistical inference, we need values on the measurement axis that capture small tail areas under the standard normal curve. z_\\alpha denotes the value on the measurement axis for which \\alpha of the area under the z curve lies to the right of z_\\alpha . Also is the 100(1-\\alpha) th percentile of the standard normal distribution.","title":"Z Critical Values"},{"location":"math_science/prob_stats/rv/#gamma","text":"The gamma family of pdfs yield a wide variety of skewed distributional shapes that can be used for situations in which the symmetric normal disitrubtion does not accurately represent the skewed random variable. In order to define the family of gama distributions we first must define an important function in many areas of mathematics.","title":"Gamma"},{"location":"math_science/prob_stats/rv/#gamma-function","text":"DEF: For \\alpha > 0 , the gamma function \\Gamma(\\alpha) is defined by: \\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha - 1}e^{-x}dx 1) For any \\alpha > 1 , \\Gamma(\\alpha) = (\\alpha - 1) * \\Gamma(\\alpha - 1) 2) For any positive integer n, \\Gamma(n) = (n - 1)! 3) \\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}","title":"Gamma Function"},{"location":"math_science/prob_stats/rv/#distribution","text":"With the gamma function, we can then define the gamma distribution for a CRV X : f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\frac{1}{\\beta^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1}e^{-x/\\beta} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} where \\alpha > 0 and \\beta > 0 . The Standard Gamma Distribution has \\beta = 1 . \\beta is known as the scale parameter because values less than one compress the pdf in the x direction, and values greater than one stretch the pdf in the x direction \\alpha determines how far to the right the distribution's center is, with larger values making it centered more to the right. E(X) = \\alpha \\beta V(X) = \\alpha \\beta^2 M_X(t) = \\frac{1}{(1- \\beta t)^\\alpha}","title":"Distribution"},{"location":"math_science/prob_stats/rv/#incomplete-gamma-function","text":"The cdf when X is a standard gamma rv (for x >0 ), F(x; \\alpha) = \\int_0^x \\frac{y^{\\alpha - 1}e^{-y}}{\\Gamma(\\alpha)}dy The incomplete gamma can be used to compute any non standard gamma distibution's probabilities since it has been tabulated. For X \\sim G(\\alpha,\\beta) , the cdf of X is the incomplete gamma function evaluated at x/\\beta : F_X(x; \\alpha,\\beta) = F(\\frac{x}{\\beta};\\alpha)","title":"Incomplete Gamma Function"},{"location":"math_science/prob_stats/rv/#exponential","text":"Often used to model the time elapsed between events DEF: A CRV X has an exponential distribution with parameter \\lambda where \\lambda > 0 if the pdf of X is: f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\lambda e^{-\\lambda x} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} Exponential pdf is special case of the gamma pdf where \\alpha = 1 and \\beta = \\frac{1}{\\lambda} . So we can use the expected value and variance formula for the gamma distribution to derive the mean and variance of the exponential distribution: E(X) = \\alpha \\beta = \\frac{1}{\\lambda} V(X) = \\alpha \\beta^2 = \\frac{1}{\\lambda^2} The pdf can be easily integrated unlike the general gamma pdf so the cdf is: F_X(x; \\lambda) = \\int_0^x \\lambda e^{-\\lambda x} dx = 1 - e^{-\\lambda x}","title":"Exponential"},{"location":"math_science/prob_stats/rv/#memoryless-property","text":"P(X \\geq t + t_0 | X \\geq t_0) = P(X \\geq t_0) The above can be thought of through analogy: If we toss a coin several times until we observe heads, not getting heads for several tosses does not affect the probability of the next toss since they are independent. Memorylessness of the exponential distribution is basically this idea. Read More about memorylessness and approximating the geometric distribution here .","title":"Memoryless Property"},{"location":"math_science/prob_stats/stats/","text":"Statistics and Sampling Distributions A sample mean will have variance since each new sample from the population will result in slightly different observed values. This uncertainty in the observed values means the resulting sample mean will also have uncertainty. This uncertainty means the sample mean can be represented with a distribution. DEF: a statistic is any quantity that can be calculated from sampled data. Prior to obtaining data, there is uncertainty as to what the value of the statistic will be so the statistic is a special case of a random variable. The probability distribution of a statistic is known as its sampling distribution to emphasize how its value varies across all possible samples. The probability distribution of a statistic depends not only on the population distribution (normal, uniform, etc.) and sample size n , but also on the method of sampling. The random variables X_1, ... X_n are said to form a simple random sample of size n if 1) X_i 's are independent 2) Every X_i has the same probability distribution The above properties are summarized by saying that X_i 's are iid (independent and identically distributed random variables). If we sample without replacement, we can assume X_i 's are iid if the sample size n is much smaller than the population size N (i.e. population size is so big that not replacing the sampled values does not really change the probability too much of what is sampeled next). In practice if \\frac{n}{N} \\leq 0.05 (at most 5% of the population is sampeled), we can proceed as if the X_i 's form a random sample. There are two methods for obtaining information about a statistic's sampling distribution: 1) Calculations based on info about X_i 's 2) Simulation experiment Deriving the Sampling Distribution Example 6.3 : (in book) X_i \\sim Exp(\\lambda) is iid for all i in range 1 to n where X_i represents the service time for customer i . The total service time could then be represented as T_n = \\sum_{i = i}^n X_i . Set up the cdf using double integrals and a region of integration Differentiating the cdf to get the pdf of T_n will then yield an equation in the form of a gamma pdf with \\alpha = n and \\beta = \\frac{1}{\\lambda} . T_n \\sim Gamma(n, \\frac{1}{\\alpha}) With the distribution for T_n , we can easily find the expected value, variance, etc. for the statistic. Simulation Experiment When we cannot derive the distribution of a statistic, we run experiments programmatically: We need the: 1. Statistic of interest ( \\bar{X}, S, , etc.) 2. Population Distribution (i.e. distribution of the X_i 's) - Ex: normal with \\mu = 100 and \\sigma = 15 3. Number of samples n 4. Number of repetitions k A computer then obtains k different random samples, each of size n , from the designated population distribution. For each of the k random samples, the value of the statistic is calculated and added to a histogram. The histogram gives the approximate sampling distribution of the statistic. Kernel density estimators perform a similer function except instead of using bins to approximate the pdf, it outputs a smooth line to approximate the pdf. This helps reduce information loss due to the width of bins. The more repetitions k , the better the approximation since as k \\to \\infty the actual sampling distribution emerges. As you increase the number of samples n , the resulting normal distribution of the statistic will converge to the true value of the statistic. This is the idea behind the central limit theorem- As n increases, the spread decreases since the effect of one outlier is less when there are more data points being sampeled. Sample Mean's Distribution Let X_1, ..., X_n be iid from a distribution with mean \\mu and standard deviation \\sigma . Then, E(\\bar{X}) = \\mu_{\\bar{X}} = \\mu V(\\bar{X}) = \\sigma_{\\bar{X}}^2 = \\sigma^2/n So the standard deviation \\sigma_{\\bar{X}} = \\sigma/\\sqrt{n} In addition where the sample total T_n = X_1 + \\dots + X_n , E(T_n) = n \\mu and V(T_n) = n\\sigma^2 . These results show that the \\bar{X} distribution becomes more concentrated about the population mean as the sample size increases while the sample total's distribution spreads out more as sample size increases. Rough proof for property 1: E(\\bar{x}) = \\sum E(x_i) / n = n \\mu /n = \\mu where \\mu is the average of X_i . Lemma: X_1, ..., X_n independent random variables: E(a_1X_1 + ... + a_nX_n) = a_1E(X_1) + ... + a_nE(X_n) V(a_1X_1 + ... + a_nX_n) = a_1^2V(X_1) + ... + a_n^2V(X_n) M_{a_1X_1 + ... + a_nX_n}(t) = M_{X_1}(a_1t) * ... * M_{X_n}(a_nt) This property is the motivating idea behind moment generating function. Its the change of basis that diaglonizes the linear statistics. This is a probabilistic laplace transform. \\begin{aligned} M_{a_1x_1 + a_2x_2}(t) &= E(e^{t(a_1x_1 + a_2x_2)}) \\\\ &= \\int \\int e^{t(a_1x_1 + a_2x_2)} * f_{X_1,X_2}(X_1,X_2) dX_1 dX_2 \\\\ &= \\int \\int e^{ta_1x_1} * f_{X_1}(X_1) e^{ta_2x_2} * f_{X_2}(X_2) dX_1 dX_2 \\\\ &= E(e^{ta_1x_1}) E(e^{ta_2x_2}) \\end{aligned} Summing Distributions: X_i \\sim N(\\mu_i, \\sigma_i^2) L = a_1X_1 + ... a_nX_n M_{X_i} = e^{t\\mu_i + t^2a_1^2\\sigma^2/2} = e^{t(a_1\\mu_1 + ... a_n\\mu_n) + 0.5 t^2 (a_1^2\\sigma_1^2 + ... ++ a_n^2\\sigma_n^2)} So X \\sim N(\\sum a_i \\mu_i, \\sum a_i^2\\sigma_i^2) Central Limit Theorem If X_i indepednent and identically distributed with mean \\mu and variance \\sigma^2 , then \\lim_{n \\to \\infty} P(\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z) = P(Z \\leq z) = \\Phi(z) and \\lim_{n \\to \\infty}P(\\frac{T_n - n\\mu}{\\sqrt{n}\\sigma} \\leq z) = P( Z \\leq z) = \\Phi(z) where Z is a standard normal random variable. NOTE: If n >> 0 ( n > 30 is enough) then you can approximate the distribution of the mean by a normal distribution meaning the above central limit theorem holds. INTERPRETATION: When n is sufficiently large, \\bar{X} has an approximately normal distribution with mean \\mu and variance \\sigma^2/n . The CLT is useful as a shortcut in computing probabilities involving the sample mean since it allows us to use a standard normal such that we don't have to actually find the sample mean distribution. Appling the CLT: X \\sim Gamma(\\alpha, \\beta) . If \\alpha >> 0 then X is approximately normally distributed. This is true because X = \\sum_{i = 1}^\\alpha X_i where X_i \\sim Exp(\\frac{1}{\\beta}) . So X = T_\\alpha of X_i 's so X is approximately normal according to the central limit theorem. Y \\sim Bi(n,p) where n >> 0 . Then Y is normally distributed since Y = \\sum_{i = 1}^n Y_i where Y_i is 1 if success, 0 if failure. Y \\approx NormaL(np, \\sqrt{n}\\sqrt{p(1-p)}) Law of Large Numbers Two forms with different interpretations/strengths in their proof of convergence. The mean square of the variance of the mean approaches 0 as the number of samples increases. This requires afinite variance to demonstrate convergence of the mean. Chebyshev's inequality is stronger in demonstrating convergance as it does not require a finite variance. Take an interval around \\mu of [\\mu - \\epsilon, \\mu + \\epsilon] . Summary LLN tells us the average tends to the mean with increased number of observations CLT tells us the average tends to the mean in the shape of a normal distribution For linear statistics we can find the expected value, variance, and cdf from the sampled random variables using the mgf property","title":"Statistics"},{"location":"math_science/prob_stats/stats/#statistics-and-sampling-distributions","text":"A sample mean will have variance since each new sample from the population will result in slightly different observed values. This uncertainty in the observed values means the resulting sample mean will also have uncertainty. This uncertainty means the sample mean can be represented with a distribution. DEF: a statistic is any quantity that can be calculated from sampled data. Prior to obtaining data, there is uncertainty as to what the value of the statistic will be so the statistic is a special case of a random variable. The probability distribution of a statistic is known as its sampling distribution to emphasize how its value varies across all possible samples. The probability distribution of a statistic depends not only on the population distribution (normal, uniform, etc.) and sample size n , but also on the method of sampling. The random variables X_1, ... X_n are said to form a simple random sample of size n if 1) X_i 's are independent 2) Every X_i has the same probability distribution The above properties are summarized by saying that X_i 's are iid (independent and identically distributed random variables). If we sample without replacement, we can assume X_i 's are iid if the sample size n is much smaller than the population size N (i.e. population size is so big that not replacing the sampled values does not really change the probability too much of what is sampeled next). In practice if \\frac{n}{N} \\leq 0.05 (at most 5% of the population is sampeled), we can proceed as if the X_i 's form a random sample. There are two methods for obtaining information about a statistic's sampling distribution: 1) Calculations based on info about X_i 's 2) Simulation experiment","title":"Statistics and Sampling Distributions"},{"location":"math_science/prob_stats/stats/#deriving-the-sampling-distribution","text":"Example 6.3 : (in book) X_i \\sim Exp(\\lambda) is iid for all i in range 1 to n where X_i represents the service time for customer i . The total service time could then be represented as T_n = \\sum_{i = i}^n X_i . Set up the cdf using double integrals and a region of integration Differentiating the cdf to get the pdf of T_n will then yield an equation in the form of a gamma pdf with \\alpha = n and \\beta = \\frac{1}{\\lambda} . T_n \\sim Gamma(n, \\frac{1}{\\alpha}) With the distribution for T_n , we can easily find the expected value, variance, etc. for the statistic.","title":"Deriving the Sampling Distribution"},{"location":"math_science/prob_stats/stats/#simulation-experiment","text":"When we cannot derive the distribution of a statistic, we run experiments programmatically: We need the: 1. Statistic of interest ( \\bar{X}, S, , etc.) 2. Population Distribution (i.e. distribution of the X_i 's) - Ex: normal with \\mu = 100 and \\sigma = 15 3. Number of samples n 4. Number of repetitions k A computer then obtains k different random samples, each of size n , from the designated population distribution. For each of the k random samples, the value of the statistic is calculated and added to a histogram. The histogram gives the approximate sampling distribution of the statistic. Kernel density estimators perform a similer function except instead of using bins to approximate the pdf, it outputs a smooth line to approximate the pdf. This helps reduce information loss due to the width of bins. The more repetitions k , the better the approximation since as k \\to \\infty the actual sampling distribution emerges. As you increase the number of samples n , the resulting normal distribution of the statistic will converge to the true value of the statistic. This is the idea behind the central limit theorem- As n increases, the spread decreases since the effect of one outlier is less when there are more data points being sampeled.","title":"Simulation Experiment"},{"location":"math_science/prob_stats/stats/#sample-means-distribution","text":"Let X_1, ..., X_n be iid from a distribution with mean \\mu and standard deviation \\sigma . Then, E(\\bar{X}) = \\mu_{\\bar{X}} = \\mu V(\\bar{X}) = \\sigma_{\\bar{X}}^2 = \\sigma^2/n So the standard deviation \\sigma_{\\bar{X}} = \\sigma/\\sqrt{n} In addition where the sample total T_n = X_1 + \\dots + X_n , E(T_n) = n \\mu and V(T_n) = n\\sigma^2 . These results show that the \\bar{X} distribution becomes more concentrated about the population mean as the sample size increases while the sample total's distribution spreads out more as sample size increases. Rough proof for property 1: E(\\bar{x}) = \\sum E(x_i) / n = n \\mu /n = \\mu where \\mu is the average of X_i . Lemma: X_1, ..., X_n independent random variables: E(a_1X_1 + ... + a_nX_n) = a_1E(X_1) + ... + a_nE(X_n) V(a_1X_1 + ... + a_nX_n) = a_1^2V(X_1) + ... + a_n^2V(X_n) M_{a_1X_1 + ... + a_nX_n}(t) = M_{X_1}(a_1t) * ... * M_{X_n}(a_nt) This property is the motivating idea behind moment generating function. Its the change of basis that diaglonizes the linear statistics. This is a probabilistic laplace transform. \\begin{aligned} M_{a_1x_1 + a_2x_2}(t) &= E(e^{t(a_1x_1 + a_2x_2)}) \\\\ &= \\int \\int e^{t(a_1x_1 + a_2x_2)} * f_{X_1,X_2}(X_1,X_2) dX_1 dX_2 \\\\ &= \\int \\int e^{ta_1x_1} * f_{X_1}(X_1) e^{ta_2x_2} * f_{X_2}(X_2) dX_1 dX_2 \\\\ &= E(e^{ta_1x_1}) E(e^{ta_2x_2}) \\end{aligned} Summing Distributions: X_i \\sim N(\\mu_i, \\sigma_i^2) L = a_1X_1 + ... a_nX_n M_{X_i} = e^{t\\mu_i + t^2a_1^2\\sigma^2/2} = e^{t(a_1\\mu_1 + ... a_n\\mu_n) + 0.5 t^2 (a_1^2\\sigma_1^2 + ... ++ a_n^2\\sigma_n^2)} So X \\sim N(\\sum a_i \\mu_i, \\sum a_i^2\\sigma_i^2)","title":"Sample Mean's Distribution"},{"location":"math_science/prob_stats/stats/#central-limit-theorem","text":"If X_i indepednent and identically distributed with mean \\mu and variance \\sigma^2 , then \\lim_{n \\to \\infty} P(\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z) = P(Z \\leq z) = \\Phi(z) and \\lim_{n \\to \\infty}P(\\frac{T_n - n\\mu}{\\sqrt{n}\\sigma} \\leq z) = P( Z \\leq z) = \\Phi(z) where Z is a standard normal random variable. NOTE: If n >> 0 ( n > 30 is enough) then you can approximate the distribution of the mean by a normal distribution meaning the above central limit theorem holds. INTERPRETATION: When n is sufficiently large, \\bar{X} has an approximately normal distribution with mean \\mu and variance \\sigma^2/n . The CLT is useful as a shortcut in computing probabilities involving the sample mean since it allows us to use a standard normal such that we don't have to actually find the sample mean distribution.","title":"Central Limit Theorem"},{"location":"math_science/prob_stats/stats/#appling-the-clt","text":"X \\sim Gamma(\\alpha, \\beta) . If \\alpha >> 0 then X is approximately normally distributed. This is true because X = \\sum_{i = 1}^\\alpha X_i where X_i \\sim Exp(\\frac{1}{\\beta}) . So X = T_\\alpha of X_i 's so X is approximately normal according to the central limit theorem. Y \\sim Bi(n,p) where n >> 0 . Then Y is normally distributed since Y = \\sum_{i = 1}^n Y_i where Y_i is 1 if success, 0 if failure. Y \\approx NormaL(np, \\sqrt{n}\\sqrt{p(1-p)})","title":"Appling the CLT:"},{"location":"math_science/prob_stats/stats/#law-of-large-numbers","text":"Two forms with different interpretations/strengths in their proof of convergence. The mean square of the variance of the mean approaches 0 as the number of samples increases. This requires afinite variance to demonstrate convergence of the mean. Chebyshev's inequality is stronger in demonstrating convergance as it does not require a finite variance. Take an interval around \\mu of [\\mu - \\epsilon, \\mu + \\epsilon] .","title":"Law of Large Numbers"},{"location":"math_science/prob_stats/stats/#summary","text":"LLN tells us the average tends to the mean with increased number of observations CLT tells us the average tends to the mean in the shape of a normal distribution For linear statistics we can find the expected value, variance, and cdf from the sampled random variables using the mgf property","title":"Summary"},{"location":"software_design/cpp/big3/","text":"Classes Separate the public interface from the specifics of the implementation Everything is private by default (public in a struct) public interface provides the abstraction Encapsulation separates the implementation details from the public interface Data Hiding- one of type of encapsulation where we use private data members/functions Base Member Initialization List Every variable will be constructed before getting into the body of the constructor as a result of the compiler. Therefore we want to use the BMI to prevent doubling the work. Initialize all variables in the BMI (lots of things are able to be initialized including arrays). Order of initialization in BMI should be the same as order declared in the header (compiler doesn't care but good for consistency). Note the upper most base class is always initialized first. Initialization is the process of turning raw storage into an object. Assignment is the process of replacing the existing state of a well-defined object with a new state (never performed on raw storage). Big 3 Destructor Copy Constructor Copy Assignment Operator When one of the big 3 needs custom behavior, all of them probably will. Best practice to explicitly define the behavior of the big 3 even if it uses default functionality (serves as documentation). Resource Destructor Purpose: destroy items that are allocated onto the heap Default destructor does not cause memory leaks for primitve data types. Default destructor causes memory leaks when using pointers in complex data types because the data at the allocated memory address is not freed up (memory leak) Should not be called explicitly Called by compiler when object goes out of scope or when delete is called on an object Called in reverse order of the constructors for a heierachy of base classes Copy Constructor Purpose: Creates a new object instance with same values as existing object Different from the assignment operator in that it creates a new object instead of just setting existing objects to be equal to another Copying involves allocating memory for the data members and then initializing the data members to be the same as those of the referenced object. Called in 3 instances: 1. Traditional use c++ SomeClass a; SomeClass b(a); 2. Assignment operator is not called because b hasn't been initialized c++ SomeClass a; SomeClass b = a; 3. Passing or returning an object by value creates a copy of that object Default copy constructor does member wise copy which results in a shallow copies when dealing with pointers. Therefore, we define our own copy ctor for most classes we write Example Copy Constructor: An object of the same type is passed by constant (don't want to change existing object) reference (can't be passed by value since that would require copy constructor). SomeClass(const SomeClass &rhs ) { // Any pointer manipulation to prevent shallow copies } Copy Assignment Operator Purpose: set an existing object to be the same as another existing object of the same type Often overloaded to eliminate the problems caused by memberwise assignment when using pointers. Assignment involves: 1. Check for self assignment (assignining an object to itself) 2. Deleting the original items stored in the object's data members 3. Allocating memory for new items 4. Copying the other object's data members to the current object - Best practice to use copy constructor to keep code DRY 5. Return the object (allows for chaining assignment operators) Specifying Default and Delete Behavior Set copy ctor or assignment operatort to equal delete in the header to make it clear the user should not use them Will generate a compiler error if used Prevents the compiler from generating default implementations Certain cases (e.g. cout and files) its not acceptable to make copies or assignments Stack(const Stack &rhs) = delete; Stack &operator=(const Stack &rhs) = delete; Set copy ctor or assignment operatort to equal default in the header to make it clear the compiler will generate default implementations Serves as good documentation for user of the class Stack(const Stack &rhs) = default; Stack &operator=(const Stack &rhs) = default; Garbage Collection A program's executable includes automatic behavior that at various intervals finds all unreachable allocated memory locations (e.g., by comparing all reachable memory with all previously-allocated memory), and automatically frees such unreachable memory Can reduce the impact of memory leaks at the expense of runtime overhead Not implemented in standard C++ but is used in higher-level languages like Python and Java All C++ does is call destructor when variables/objects go out of the scope they were initialized in Therefore, C++ doesn't call the destructor on reference variables passed into functions when that function's scope ends Destructors for primitive data types works fine but destructors for more complex objects must be defined by user","title":"The Big 3"},{"location":"software_design/cpp/big3/#classes","text":"Separate the public interface from the specifics of the implementation Everything is private by default (public in a struct) public interface provides the abstraction Encapsulation separates the implementation details from the public interface Data Hiding- one of type of encapsulation where we use private data members/functions","title":"Classes"},{"location":"software_design/cpp/big3/#base-member-initialization-list","text":"Every variable will be constructed before getting into the body of the constructor as a result of the compiler. Therefore we want to use the BMI to prevent doubling the work. Initialize all variables in the BMI (lots of things are able to be initialized including arrays). Order of initialization in BMI should be the same as order declared in the header (compiler doesn't care but good for consistency). Note the upper most base class is always initialized first. Initialization is the process of turning raw storage into an object. Assignment is the process of replacing the existing state of a well-defined object with a new state (never performed on raw storage).","title":"Base Member Initialization List"},{"location":"software_design/cpp/big3/#big-3","text":"Destructor Copy Constructor Copy Assignment Operator When one of the big 3 needs custom behavior, all of them probably will. Best practice to explicitly define the behavior of the big 3 even if it uses default functionality (serves as documentation). Resource","title":"Big 3"},{"location":"software_design/cpp/big3/#destructor","text":"Purpose: destroy items that are allocated onto the heap Default destructor does not cause memory leaks for primitve data types. Default destructor causes memory leaks when using pointers in complex data types because the data at the allocated memory address is not freed up (memory leak) Should not be called explicitly Called by compiler when object goes out of scope or when delete is called on an object Called in reverse order of the constructors for a heierachy of base classes","title":"Destructor"},{"location":"software_design/cpp/big3/#copy-constructor","text":"Purpose: Creates a new object instance with same values as existing object Different from the assignment operator in that it creates a new object instead of just setting existing objects to be equal to another Copying involves allocating memory for the data members and then initializing the data members to be the same as those of the referenced object. Called in 3 instances: 1. Traditional use c++ SomeClass a; SomeClass b(a); 2. Assignment operator is not called because b hasn't been initialized c++ SomeClass a; SomeClass b = a; 3. Passing or returning an object by value creates a copy of that object Default copy constructor does member wise copy which results in a shallow copies when dealing with pointers. Therefore, we define our own copy ctor for most classes we write Example Copy Constructor: An object of the same type is passed by constant (don't want to change existing object) reference (can't be passed by value since that would require copy constructor). SomeClass(const SomeClass &rhs ) { // Any pointer manipulation to prevent shallow copies }","title":"Copy Constructor"},{"location":"software_design/cpp/big3/#copy-assignment-operator","text":"Purpose: set an existing object to be the same as another existing object of the same type Often overloaded to eliminate the problems caused by memberwise assignment when using pointers. Assignment involves: 1. Check for self assignment (assignining an object to itself) 2. Deleting the original items stored in the object's data members 3. Allocating memory for new items 4. Copying the other object's data members to the current object - Best practice to use copy constructor to keep code DRY 5. Return the object (allows for chaining assignment operators)","title":"Copy Assignment Operator"},{"location":"software_design/cpp/big3/#specifying-default-and-delete-behavior","text":"Set copy ctor or assignment operatort to equal delete in the header to make it clear the user should not use them Will generate a compiler error if used Prevents the compiler from generating default implementations Certain cases (e.g. cout and files) its not acceptable to make copies or assignments Stack(const Stack &rhs) = delete; Stack &operator=(const Stack &rhs) = delete; Set copy ctor or assignment operatort to equal default in the header to make it clear the compiler will generate default implementations Serves as good documentation for user of the class Stack(const Stack &rhs) = default; Stack &operator=(const Stack &rhs) = default;","title":"Specifying Default and Delete Behavior"},{"location":"software_design/cpp/big3/#garbage-collection","text":"A program's executable includes automatic behavior that at various intervals finds all unreachable allocated memory locations (e.g., by comparing all reachable memory with all previously-allocated memory), and automatically frees such unreachable memory Can reduce the impact of memory leaks at the expense of runtime overhead Not implemented in standard C++ but is used in higher-level languages like Python and Java All C++ does is call destructor when variables/objects go out of the scope they were initialized in Therefore, C++ doesn't call the destructor on reference variables passed into functions when that function's scope ends Destructors for primitive data types works fine but destructors for more complex objects must be defined by user","title":"Garbage Collection"},{"location":"software_design/cpp/exceptions/","text":"Exception Handling Purpose: permit the program to catch and handle errors rather than let it occur and suffer the consequences Used when system can recover from the error causing the exception Exception Handler- recovery procedure If no catch function, the terminate function is called (terminate calls abort function that aborts the program) Properly written exception safe code employs relatively few try blocks try { throw std::overflow_error(\"overflow error in push\") } catch (std::overflow_error &excep) { // exception handler is here std::cout << excep.what() << std::endl; } catch (...) { std::cout << \"Unknown exception\" << std::endl; } Throw Can throw anything but error types in standard library are typically used If a function throws a const object, the catch handler argument type must be declared const Throw lists for functions are bad practice but you will see them in legacy code Unwinding the stack refers to when an expection is thrown void func(int x) { char* fizz = new char[1024]; std::string s(\"Test\"); if(x) throw std::runtime_error(\"explosion\"); delete[] test; } In the above example, memory allocated for fizz will be leaked if an exception is thrown b/c delete[] fizz is never reached. However, memory allocated for s will be properly destructed b/c throwing an exception unwinds the stack meaning the destructor will be called on objects in each of the stack frames until a try catch block is reached. Since std::string has a properly defined destructor, s will not create a memory leak when an exception is thrown. Constructors & Destructors Exceptions thrown in constructors will cause the destructors to be called for any objects built as part of the object being constructed before the exception is thrown Don't throw exceptions in a destructor","title":"Exception Handling"},{"location":"software_design/cpp/exceptions/#exception-handling","text":"Purpose: permit the program to catch and handle errors rather than let it occur and suffer the consequences Used when system can recover from the error causing the exception Exception Handler- recovery procedure If no catch function, the terminate function is called (terminate calls abort function that aborts the program) Properly written exception safe code employs relatively few try blocks try { throw std::overflow_error(\"overflow error in push\") } catch (std::overflow_error &excep) { // exception handler is here std::cout << excep.what() << std::endl; } catch (...) { std::cout << \"Unknown exception\" << std::endl; }","title":"Exception Handling"},{"location":"software_design/cpp/exceptions/#throw","text":"Can throw anything but error types in standard library are typically used If a function throws a const object, the catch handler argument type must be declared const Throw lists for functions are bad practice but you will see them in legacy code Unwinding the stack refers to when an expection is thrown void func(int x) { char* fizz = new char[1024]; std::string s(\"Test\"); if(x) throw std::runtime_error(\"explosion\"); delete[] test; } In the above example, memory allocated for fizz will be leaked if an exception is thrown b/c delete[] fizz is never reached. However, memory allocated for s will be properly destructed b/c throwing an exception unwinds the stack meaning the destructor will be called on objects in each of the stack frames until a try catch block is reached. Since std::string has a properly defined destructor, s will not create a memory leak when an exception is thrown.","title":"Throw"},{"location":"software_design/cpp/exceptions/#constructors-destructors","text":"Exceptions thrown in constructors will cause the destructors to be called for any objects built as part of the object being constructed before the exception is thrown Don't throw exceptions in a destructor","title":"Constructors &amp; Destructors"},{"location":"software_design/cpp/functors/","text":"Functors Any class that has overriden the parens/function operator operator() Allows an instance of the class to be called as a function Can do multiple overridings of operator() as long as they have different signatures Functors are just regular classes Can have constructors & destructores Can have private member variables and functions Can be a template class STL algorithms will return a copy of the functor being passed in so that we can access the final state after all iterations Functions vs Functors The below code demonstrates how the same functionality would be implemented differently between just using a function and using a functor void printIt(int i) { std::cout << i << \":\"; } std::for_each(intArray.begin(), intArray.end(), printIt()); std::cout << std::endl; class PrintIt { public: // overloading the parens operator lets us treat an instance of this class as a function void operator() (int i) { std::cout << i << \":\"; } }; // creates instance of PrintIt for each integer in the array and call it as a function std::for_each(intArray.begin(), intArray.end(), PrintIt()); std::cout << std::endl; Maintaining State Functors allow us to better maintain state through an STL algorithm's iteration compared to regular functions Encapsulates the state within a class, preventing pollution of the global namespace with global state variables All state is encapsulated in normal class instance lifecycle: 1) Constructor: initial state 2) operator(): state mutation 3) Accessor methods: state querying 4) Destructor: state cleanup (as needed)","title":"Functors"},{"location":"software_design/cpp/functors/#functors","text":"Any class that has overriden the parens/function operator operator() Allows an instance of the class to be called as a function Can do multiple overridings of operator() as long as they have different signatures Functors are just regular classes Can have constructors & destructores Can have private member variables and functions Can be a template class STL algorithms will return a copy of the functor being passed in so that we can access the final state after all iterations","title":"Functors"},{"location":"software_design/cpp/functors/#functions-vs-functors","text":"The below code demonstrates how the same functionality would be implemented differently between just using a function and using a functor void printIt(int i) { std::cout << i << \":\"; } std::for_each(intArray.begin(), intArray.end(), printIt()); std::cout << std::endl; class PrintIt { public: // overloading the parens operator lets us treat an instance of this class as a function void operator() (int i) { std::cout << i << \":\"; } }; // creates instance of PrintIt for each integer in the array and call it as a function std::for_each(intArray.begin(), intArray.end(), PrintIt()); std::cout << std::endl;","title":"Functions vs Functors"},{"location":"software_design/cpp/functors/#maintaining-state","text":"Functors allow us to better maintain state through an STL algorithm's iteration compared to regular functions Encapsulates the state within a class, preventing pollution of the global namespace with global state variables All state is encapsulated in normal class instance lifecycle: 1) Constructor: initial state 2) operator(): state mutation 3) Accessor methods: state querying 4) Destructor: state cleanup (as needed)","title":"Maintaining State"},{"location":"software_design/cpp/inheritance/","text":"Inheritance Single Inheritance: occurs when a derived class inherits from only one parent class Multiple Inheritance: allows a class to inherit from multiple classes Error prone and should be avoided Big 3 are not inherited from a base class by a derived class Assignment operator is not inherited from the base class Will be provided with compiler generated one if used and not implemented by the user B publicly inheriting A creates the relationship: B is an instance of A private and protected inheritance do not create the same \"is a\" relationship Derived Classes Have access to base class' public and protected behaviors Protected- used for inheritance. Allows derived class access to something not public class A{ } class B: protected A { // everything public in A becomes protected in B } class C: private A { // everything public/private in A becomes private in B } Defines new attributes and behaviors may override the behaviors of the base class intended to be more specific than the base class constructor for the base class must be called from the derived class constructor in order to initialzie the base class members in the derived class Non explicitly calling it will result in the default constructor being called implicitly DerviedClass::DerivedClass(parameters) : BaseClass(parameters) {} virtual double func1() const { return 0.0; } default returns 0.0 virtual void func() const = 0; forces the derived class to implement the function Example implementation: void func() const override { //do something } Constructor & Destructor When derived class constructor is called 1) Base Class constructor is called to create an instance of the base class (done implicitly or explicitly) 2) Constructor for the derived class is executed Think of an onion (build up dervied object, layer by layer) When derived class destructor is called 1) Derived class destructor is executed 2) Base class destructor function is executed Reverse order of ctor, destroy the onion layer by layer Overriding Dervied version must have same function signature as base version Dervied version may include a call to the base version Provides more functionality specific to the derived class Abstract Class A base class that will never have an object instantiated from it Provides a generic interface Defined as any class that contains at least one pure virtual function (declare but provide no implementation of) Pure virtual function: virtual void func() const = 0; The equals zero makes the func pure virtual instead of just virtual Virtual Function A function that is expected to be overriden by a derived class Incudes full method signature, return type, and may provide default implementation Declared in public portion of the class Must not be static or a friend of another class Pure virtual functions must be overridden If derived class doesn't implement a pure virtual function, the derived class is also an abstract base class Non-pure virtual functions can be overidden but do not have to be A function defined as virtual in the base class makes it virutal for all classes derived from the base class Class with virtual functions should contain a virtual destructor Ensures the correct sequence of destructors is called Base class dtor must be virtual Should be accessed using pointer or reference of base class type to achieve run time polymorphism Why use Virtual Functions? Basic inheritance and overriding gives us the expected behavior with concrete instances Virtual functions allow us to work with a pointer to the base class Virtual functions defined in the base classes permit dynamic binding allowing runtime polymorphism Dynamic Binding A virtual function invoked using a reference to an objcet Allows program to choose appropraite method designed to identify the method for a particular object type at runtime Static binding requires object type to be defined at compile time Achieved using vtables Polymorphism Occurs whens multiple objects from different classes are related by inheritance from the same base class Most useful when there are a series of related objects that need to be treated in a uniform manner Polymorphic means having many forms Can have multiple behaviors for the same function depending on the context Achieved by using virtual functions and overriding these methods in derived classes Virtual Function Table Created at compile time and put in static memory Used at runtime to achieve dynamic binding and runtime polymorphism Compiler generates a vtable for each class with at least one method marked as virtual Only virtual methods are included in the vtable Example vtable for the shape example code from lecture 9: Shape Class ~Shape local or {} local implementation area() const {} local implementation volume() const {} local implementation pShapeName() const =0 pure virtual print() const = 0 pure virtual Shape class is abstract since there are pure virtual methods in the vtable Point Class ~Point local {} local implementation area() const Shape::area implementation in shape class volume() const Shape::volume implementation in shape class pShapeName() const {} own implementation print() const {} own implementation Point class is concrete since there are no pure virtual methods in the vtable Circle Class ~Circle local {} local implementation area() const {} local implementation volume() const Shape::volume implementation in shape class pShapeName() const {} local implementation print() const {} local implementation Point class is concrete since there are no pure virtual methods in the vtable When an object of a class containing virtual functions is instantiated, the compiler attaches a pointer to the class's vtable at the front of the object Memory and processing costs associated with virtual functions Increased size of object to hold vtable's address Increased compile time to create the vtable for each class with virtual functions More efficient to compute lookup table at compile time rather than determining these relationships at runtime For each function call, there is an extra step of looking up the address in the table to the correct implementation If marked virtual but not pure virtual, the class will provide its own implementation for it Derived class inherits all of the virtual functions from base class Polymorphism and use of vtable will be used when the method is marked as virtual and the method is called via a pointer or reference. This means functions in base class with same name will not be hidden like they are when doing override and using concrete instances Design Considerations Only use inheritance where additional layers of abstraction makes sense Class hierarchies promote code reuse Stand alone class --> bsase classes can make refactoring difficult Can create issues with slicing as a result of concrete base classes being able to be instantiated Should make base classes abstract Clarifications Overloading is creating a method with the same name as an existing method but with different parameters Overriding is creating a method in a derived class with the same name and parameters (same signature) as an existing method in its base class Polymorphism- ability of different object to be accessed by a common interface Polymorphism and overloading are related but not the same Standard hiding of methods of the same name in the base class will occur when the derived class has a concrete instance created Dynamic binding and runtime polymorphism occurs when using pointers/references of the base class to point to instances of the derived classes (gives standard interface to access different, but related objects --> definition of polymorphism)","title":"Inheritance"},{"location":"software_design/cpp/inheritance/#inheritance","text":"Single Inheritance: occurs when a derived class inherits from only one parent class Multiple Inheritance: allows a class to inherit from multiple classes Error prone and should be avoided Big 3 are not inherited from a base class by a derived class Assignment operator is not inherited from the base class Will be provided with compiler generated one if used and not implemented by the user B publicly inheriting A creates the relationship: B is an instance of A private and protected inheritance do not create the same \"is a\" relationship","title":"Inheritance"},{"location":"software_design/cpp/inheritance/#derived-classes","text":"Have access to base class' public and protected behaviors Protected- used for inheritance. Allows derived class access to something not public class A{ } class B: protected A { // everything public in A becomes protected in B } class C: private A { // everything public/private in A becomes private in B } Defines new attributes and behaviors may override the behaviors of the base class intended to be more specific than the base class constructor for the base class must be called from the derived class constructor in order to initialzie the base class members in the derived class Non explicitly calling it will result in the default constructor being called implicitly DerviedClass::DerivedClass(parameters) : BaseClass(parameters) {} virtual double func1() const { return 0.0; } default returns 0.0 virtual void func() const = 0; forces the derived class to implement the function Example implementation: void func() const override { //do something }","title":"Derived Classes"},{"location":"software_design/cpp/inheritance/#constructor-destructor","text":"When derived class constructor is called 1) Base Class constructor is called to create an instance of the base class (done implicitly or explicitly) 2) Constructor for the derived class is executed Think of an onion (build up dervied object, layer by layer) When derived class destructor is called 1) Derived class destructor is executed 2) Base class destructor function is executed Reverse order of ctor, destroy the onion layer by layer","title":"Constructor &amp; Destructor"},{"location":"software_design/cpp/inheritance/#overriding","text":"Dervied version must have same function signature as base version Dervied version may include a call to the base version Provides more functionality specific to the derived class","title":"Overriding"},{"location":"software_design/cpp/inheritance/#abstract-class","text":"A base class that will never have an object instantiated from it Provides a generic interface Defined as any class that contains at least one pure virtual function (declare but provide no implementation of) Pure virtual function: virtual void func() const = 0; The equals zero makes the func pure virtual instead of just virtual","title":"Abstract Class"},{"location":"software_design/cpp/inheritance/#virtual-function","text":"A function that is expected to be overriden by a derived class Incudes full method signature, return type, and may provide default implementation Declared in public portion of the class Must not be static or a friend of another class Pure virtual functions must be overridden If derived class doesn't implement a pure virtual function, the derived class is also an abstract base class Non-pure virtual functions can be overidden but do not have to be A function defined as virtual in the base class makes it virutal for all classes derived from the base class Class with virtual functions should contain a virtual destructor Ensures the correct sequence of destructors is called Base class dtor must be virtual Should be accessed using pointer or reference of base class type to achieve run time polymorphism","title":"Virtual Function"},{"location":"software_design/cpp/inheritance/#why-use-virtual-functions","text":"Basic inheritance and overriding gives us the expected behavior with concrete instances Virtual functions allow us to work with a pointer to the base class Virtual functions defined in the base classes permit dynamic binding allowing runtime polymorphism","title":"Why use Virtual Functions?"},{"location":"software_design/cpp/inheritance/#dynamic-binding","text":"A virtual function invoked using a reference to an objcet Allows program to choose appropraite method designed to identify the method for a particular object type at runtime Static binding requires object type to be defined at compile time Achieved using vtables","title":"Dynamic Binding"},{"location":"software_design/cpp/inheritance/#polymorphism","text":"Occurs whens multiple objects from different classes are related by inheritance from the same base class Most useful when there are a series of related objects that need to be treated in a uniform manner Polymorphic means having many forms Can have multiple behaviors for the same function depending on the context Achieved by using virtual functions and overriding these methods in derived classes","title":"Polymorphism"},{"location":"software_design/cpp/inheritance/#virtual-function-table","text":"Created at compile time and put in static memory Used at runtime to achieve dynamic binding and runtime polymorphism Compiler generates a vtable for each class with at least one method marked as virtual Only virtual methods are included in the vtable Example vtable for the shape example code from lecture 9: Shape Class ~Shape local or {} local implementation area() const {} local implementation volume() const {} local implementation pShapeName() const =0 pure virtual print() const = 0 pure virtual Shape class is abstract since there are pure virtual methods in the vtable Point Class ~Point local {} local implementation area() const Shape::area implementation in shape class volume() const Shape::volume implementation in shape class pShapeName() const {} own implementation print() const {} own implementation Point class is concrete since there are no pure virtual methods in the vtable Circle Class ~Circle local {} local implementation area() const {} local implementation volume() const Shape::volume implementation in shape class pShapeName() const {} local implementation print() const {} local implementation Point class is concrete since there are no pure virtual methods in the vtable When an object of a class containing virtual functions is instantiated, the compiler attaches a pointer to the class's vtable at the front of the object Memory and processing costs associated with virtual functions Increased size of object to hold vtable's address Increased compile time to create the vtable for each class with virtual functions More efficient to compute lookup table at compile time rather than determining these relationships at runtime For each function call, there is an extra step of looking up the address in the table to the correct implementation If marked virtual but not pure virtual, the class will provide its own implementation for it Derived class inherits all of the virtual functions from base class Polymorphism and use of vtable will be used when the method is marked as virtual and the method is called via a pointer or reference. This means functions in base class with same name will not be hidden like they are when doing override and using concrete instances","title":"Virtual Function Table"},{"location":"software_design/cpp/inheritance/#design-considerations","text":"Only use inheritance where additional layers of abstraction makes sense Class hierarchies promote code reuse Stand alone class --> bsase classes can make refactoring difficult Can create issues with slicing as a result of concrete base classes being able to be instantiated Should make base classes abstract","title":"Design Considerations"},{"location":"software_design/cpp/inheritance/#clarifications","text":"Overloading is creating a method with the same name as an existing method but with different parameters Overriding is creating a method in a derived class with the same name and parameters (same signature) as an existing method in its base class Polymorphism- ability of different object to be accessed by a common interface Polymorphism and overloading are related but not the same Standard hiding of methods of the same name in the base class will occur when the derived class has a concrete instance created Dynamic binding and runtime polymorphism occurs when using pointers/references of the base class to point to instances of the derived classes (gives standard interface to access different, but related objects --> definition of polymorphism)","title":"Clarifications"},{"location":"software_design/cpp/iterators/","text":"Iterators Allow a program to access aggregated data in a container Allow us to write programs that do not depend on the type of container (e.g. array, vector, tree, etc.) The details of accessing the aggregated data iis hidden via the iterator interface Our code then interacts with the iterator, not the container directly Every container has its own class for its iterator Iterator Design Pattern Intent Access elements of a container (aggregate) without exposing its representation Applicability Require multiple traversal algorthims over a container Require a uniform traversal interface over different containers When container classes and traversal algorithms must vary independently Structure Aggregate is an abstract base class used for creating containers. ConcreteAggregate is a derived class that is a specific type of container (e.g. tree, hash map, list, etc.) Iterator is an abstract base class used for creating iterators on containers ConcreteIterator is a derived class that is a specific iterator implementation corresponding to the strucutre of a concrete container The use of Aggregate and Iterator abstract base classes lets client code be written against any generic container with an iterator Looping directly over linear containers like arrays make assumption on the subscript operators definition meaning it interacts directly with the container Using iterators makes algorithms more general and independent of the container since the iterators handle differencs between data structures such as linear vs tree STL Iterators C++ implementation of the iterator pattern Generalization of pointers since they are objects that point to other objects Central to generic programming b/c they are an interface btw containers and algorithms STL algorithms typically take iterators as arugments A container only needs to provide a way to access its elements using iterators Useful to add iterators to your own classes so they can be used with STL algorithms Not all containers support random-access (e.g. specifying the ith item to access) Containers that support random-access iterators can be used with all STL algos Input Iterators Used to read from a container Dereferenced to refer to some object Incremented to obtain next iterator in a sequence Must allow following operations: Copy Ctor and assignment operator == and != for comparison with other iterators of the same type * and ++ for incrementing which object is being pointed to Can be const prefix and postfix Output Iterators Used to write to a container More restrictive interface: = , == , and != don't need to be defined Must support non-const operator* Iterator Types Iterator categories depend on type parameterization rather than inheritance Iterator categories are hierarchical with more refined categories adding constraints Forward - start to end of container (supports ++ ) Bidirectional - iterate through elements forward and backward (supports ++ , -- ) list, set, multiset, map, & multimap Random Access - go forward n elements, get nth element (supports [] ) vector and deque Using Iterators begin() is the first element end() is whatever it means to be just after the last element begin()/end() are used to traverse front to back rbegin()/rend() are used to traverse back to front Range based for loops use iterators to easily go through containers: vector<int> = {1,2,3,4}; for(int i : v) { std::cout << i << std::endl; }","title":"Iterators"},{"location":"software_design/cpp/iterators/#iterators","text":"Allow a program to access aggregated data in a container Allow us to write programs that do not depend on the type of container (e.g. array, vector, tree, etc.) The details of accessing the aggregated data iis hidden via the iterator interface Our code then interacts with the iterator, not the container directly Every container has its own class for its iterator","title":"Iterators"},{"location":"software_design/cpp/iterators/#iterator-design-pattern","text":"","title":"Iterator Design Pattern"},{"location":"software_design/cpp/iterators/#intent","text":"Access elements of a container (aggregate) without exposing its representation","title":"Intent"},{"location":"software_design/cpp/iterators/#applicability","text":"Require multiple traversal algorthims over a container Require a uniform traversal interface over different containers When container classes and traversal algorithms must vary independently","title":"Applicability"},{"location":"software_design/cpp/iterators/#structure","text":"Aggregate is an abstract base class used for creating containers. ConcreteAggregate is a derived class that is a specific type of container (e.g. tree, hash map, list, etc.) Iterator is an abstract base class used for creating iterators on containers ConcreteIterator is a derived class that is a specific iterator implementation corresponding to the strucutre of a concrete container The use of Aggregate and Iterator abstract base classes lets client code be written against any generic container with an iterator Looping directly over linear containers like arrays make assumption on the subscript operators definition meaning it interacts directly with the container Using iterators makes algorithms more general and independent of the container since the iterators handle differencs between data structures such as linear vs tree","title":"Structure"},{"location":"software_design/cpp/iterators/#stl-iterators","text":"C++ implementation of the iterator pattern Generalization of pointers since they are objects that point to other objects Central to generic programming b/c they are an interface btw containers and algorithms STL algorithms typically take iterators as arugments A container only needs to provide a way to access its elements using iterators Useful to add iterators to your own classes so they can be used with STL algorithms Not all containers support random-access (e.g. specifying the ith item to access) Containers that support random-access iterators can be used with all STL algos","title":"STL Iterators"},{"location":"software_design/cpp/iterators/#input-iterators","text":"Used to read from a container Dereferenced to refer to some object Incremented to obtain next iterator in a sequence Must allow following operations: Copy Ctor and assignment operator == and != for comparison with other iterators of the same type * and ++ for incrementing which object is being pointed to Can be const prefix and postfix","title":"Input Iterators"},{"location":"software_design/cpp/iterators/#output-iterators","text":"Used to write to a container More restrictive interface: = , == , and != don't need to be defined Must support non-const operator*","title":"Output Iterators"},{"location":"software_design/cpp/iterators/#iterator-types","text":"Iterator categories depend on type parameterization rather than inheritance Iterator categories are hierarchical with more refined categories adding constraints Forward - start to end of container (supports ++ ) Bidirectional - iterate through elements forward and backward (supports ++ , -- ) list, set, multiset, map, & multimap Random Access - go forward n elements, get nth element (supports [] ) vector and deque","title":"Iterator Types"},{"location":"software_design/cpp/iterators/#using-iterators","text":"begin() is the first element end() is whatever it means to be just after the last element begin()/end() are used to traverse front to back rbegin()/rend() are used to traverse back to front Range based for loops use iterators to easily go through containers: vector<int> = {1,2,3,4}; for(int i : v) { std::cout << i << std::endl; }","title":"Using Iterators"},{"location":"software_design/cpp/lambda/","text":"Lambda Functions Introduced in C++11 Create light-weight functions in place Designed to replace functors Behind the scenes, the compiler rewrites the lambda to be a functor (so lambdas are just syntax simplification of functors) Easy to use with STL std::for_each(int_list, int_list+8, [](int i) { std::cout << i << \":\"; }); Generic Lambdas Introduced in C++14 Compiler can infer input types Allows generic lambdas (since we don't have templates for lambdas) Variable Capture Can bring in variables from an external scope into the lambda scope Can be done by copy or reference Should be done by reference if we want the updated variables outside the scope of the lambda (use by reference to persist state) [int_var, dbl_var] () { int i = 7; cout << int_var << ' ' << dbl_var << ' ' << i << endl; } (); Lambdaas and Member Functions Bring this into scope, not class member variables Lets you use the class member variables with the implicit this->","title":"Lambda Functions"},{"location":"software_design/cpp/lambda/#lambda-functions","text":"Introduced in C++11 Create light-weight functions in place Designed to replace functors Behind the scenes, the compiler rewrites the lambda to be a functor (so lambdas are just syntax simplification of functors) Easy to use with STL std::for_each(int_list, int_list+8, [](int i) { std::cout << i << \":\"; });","title":"Lambda Functions"},{"location":"software_design/cpp/lambda/#generic-lambdas","text":"Introduced in C++14 Compiler can infer input types Allows generic lambdas (since we don't have templates for lambdas)","title":"Generic Lambdas"},{"location":"software_design/cpp/lambda/#variable-capture","text":"Can bring in variables from an external scope into the lambda scope Can be done by copy or reference Should be done by reference if we want the updated variables outside the scope of the lambda (use by reference to persist state) [int_var, dbl_var] () { int i = 7; cout << int_var << ' ' << dbl_var << ' ' << i << endl; } ();","title":"Variable Capture"},{"location":"software_design/cpp/lambda/#lambdaas-and-member-functions","text":"Bring this into scope, not class member variables Lets you use the class member variables with the implicit this->","title":"Lambdaas and Member Functions"},{"location":"software_design/cpp/misc/","text":"C++ Compiler 4 Steps: 1. Preprocessor: deletes comments, expands macros (anything with # prefix), replace file includes and constants with the values - #include brings in lots of files to create a larger temp file with everything needed - Summary: Pull together all needed code 2. Compiler: takes the code and produces architecture dependent assembly code (type, syntax, grammar rules are applied here) 3. Assembler: takes the assembly code and translates it to machine code - No commnon errors at this step 4. Linker: takes all seperate translation units and tries to link them together - Common Errors: symbol missing (declare and call a method but never define it), couldn't open output file (tried to build while debugger was running on the old executable) Clang and Gcc compiler will be used. Undefined behaviors are different between C++ compilers Forward Declarations LinkedList will often depend on LinkedListIter which itself depends on LinkedList . This mutual depenedency causes an issue when trying to compile doing the standard #include 'LinkedList.h' at the top. Forward declarations help get around this issue by declaring the dependency class exists without providing any of the details yet. The class's details are provided later to the compiler by moving #include to the bottom of the file so that the compiler will go back into the placeholder and fill in the missing symbols. Here is what LinkedList.h that depends on the LinkedListIter class would look like: class LinkedListIter; class LinkedList { ... } #include 'LinkedListIter.h' Command Line Arguments int main(int argc, char **argv) { } argc is the number of command line arguments (strings) **argv is a pointer to an array (a pointer) containing pointers to the command line strings Always one argument (the name of your program itself) When running a program the OS loader finds the executable on disk and passes in any additional arguments from the command line to the main function Explicit vs. Automatic Conversions A single argument constructor provides the ability to convert the value of the argument to the clas type. Implicit conversion converts the statement to a Class A { public: A(); A(int); A(const char*, int=0); } // implicit conversion: A c = 1; // same as A c = A(1) A c = \"someword\" // same as A c = A(\"someword\") Class A { public: A(); // don't need to give params names in the header but its helpful, only required in the cpp implementation explicit A(int); explicit A(const char*, int=0); } // implicit conversion no longer allowed A c = 1; // will now throw compiler errors A c = \"someword\" // same as A c = A(\"someword\") // allows: A a1; A a2 = A(1); A a3(1); A a4 = A(\"Test\"); A a6 = static_cast<A>(1); A* p = new A(1); Reference Another name for an existing object Not a pointer and doesn't behave like a pointer 3 Major differences from a pointer: 1) No null references 2) All references require initialization when they are declared 3) A reference always refers to the object with which it is initialized (cannot be made to refer to a different object later) References and Const reference to a non const cannot be initialized with a literal or temporary value a refernce to a const can be initialized with a literal or a temporary value double &cd = 12.3; // error! const double &cd = 12.3; //no error Function Calls: 1) Pass by value: calls copy constructor 2) Pass by pointer: Function call must send address of the variable: f(&<var-name>) Function def must use * to create an alias for the variable: <return-type> f(<data-type>* <var-name>) { ... } int test(char* letter) { return int(*letter) } char testLetter = 'a'; std::cout << test(&testLetter) << std::endl; // prints a 3) Pass by reference: allow Types not matching causes an attempt to implicitly cast to the correct type which effectively causes a copy call when making a temp copy Debugger Can set breakpoints to run the program until a certain line Can set watch points to run the program until a certain condition LLVM/GDB debuggers can be used from the terminal","title":"Misc"},{"location":"software_design/cpp/misc/#c-compiler","text":"4 Steps: 1. Preprocessor: deletes comments, expands macros (anything with # prefix), replace file includes and constants with the values - #include brings in lots of files to create a larger temp file with everything needed - Summary: Pull together all needed code 2. Compiler: takes the code and produces architecture dependent assembly code (type, syntax, grammar rules are applied here) 3. Assembler: takes the assembly code and translates it to machine code - No commnon errors at this step 4. Linker: takes all seperate translation units and tries to link them together - Common Errors: symbol missing (declare and call a method but never define it), couldn't open output file (tried to build while debugger was running on the old executable) Clang and Gcc compiler will be used. Undefined behaviors are different between C++ compilers","title":"C++ Compiler"},{"location":"software_design/cpp/misc/#forward-declarations","text":"LinkedList will often depend on LinkedListIter which itself depends on LinkedList . This mutual depenedency causes an issue when trying to compile doing the standard #include 'LinkedList.h' at the top. Forward declarations help get around this issue by declaring the dependency class exists without providing any of the details yet. The class's details are provided later to the compiler by moving #include to the bottom of the file so that the compiler will go back into the placeholder and fill in the missing symbols. Here is what LinkedList.h that depends on the LinkedListIter class would look like: class LinkedListIter; class LinkedList { ... } #include 'LinkedListIter.h'","title":"Forward Declarations"},{"location":"software_design/cpp/misc/#command-line-arguments","text":"int main(int argc, char **argv) { } argc is the number of command line arguments (strings) **argv is a pointer to an array (a pointer) containing pointers to the command line strings Always one argument (the name of your program itself) When running a program the OS loader finds the executable on disk and passes in any additional arguments from the command line to the main function","title":"Command Line Arguments"},{"location":"software_design/cpp/misc/#explicit-vs-automatic-conversions","text":"A single argument constructor provides the ability to convert the value of the argument to the clas type. Implicit conversion converts the statement to a Class A { public: A(); A(int); A(const char*, int=0); } // implicit conversion: A c = 1; // same as A c = A(1) A c = \"someword\" // same as A c = A(\"someword\") Class A { public: A(); // don't need to give params names in the header but its helpful, only required in the cpp implementation explicit A(int); explicit A(const char*, int=0); } // implicit conversion no longer allowed A c = 1; // will now throw compiler errors A c = \"someword\" // same as A c = A(\"someword\") // allows: A a1; A a2 = A(1); A a3(1); A a4 = A(\"Test\"); A a6 = static_cast<A>(1); A* p = new A(1);","title":"Explicit vs. Automatic Conversions"},{"location":"software_design/cpp/misc/#reference","text":"Another name for an existing object Not a pointer and doesn't behave like a pointer 3 Major differences from a pointer: 1) No null references 2) All references require initialization when they are declared 3) A reference always refers to the object with which it is initialized (cannot be made to refer to a different object later)","title":"Reference"},{"location":"software_design/cpp/misc/#references-and-const","text":"reference to a non const cannot be initialized with a literal or temporary value a refernce to a const can be initialized with a literal or a temporary value double &cd = 12.3; // error! const double &cd = 12.3; //no error","title":"References and Const"},{"location":"software_design/cpp/misc/#function-calls","text":"1) Pass by value: calls copy constructor 2) Pass by pointer: Function call must send address of the variable: f(&<var-name>) Function def must use * to create an alias for the variable: <return-type> f(<data-type>* <var-name>) { ... } int test(char* letter) { return int(*letter) } char testLetter = 'a'; std::cout << test(&testLetter) << std::endl; // prints a 3) Pass by reference: allow Types not matching causes an attempt to implicitly cast to the correct type which effectively causes a copy call when making a temp copy","title":"Function Calls:"},{"location":"software_design/cpp/misc/#debugger","text":"Can set breakpoints to run the program until a certain line Can set watch points to run the program until a certain condition LLVM/GDB debuggers can be used from the terminal","title":"Debugger"},{"location":"software_design/cpp/move-semantics/","text":"Move Semantics makes code faster by adding to code rvalue references Allow programmers to avoid unnecessary copying and to provide perfect forwarding functions Move constructor: MyClass::MyClass(MyClass&& other); does not allocate new resources, simply takes the resources from other and sets other to its default ctor state much faster than a copy ctor b/c it doesn't allocate memory and doesn't copy memory buffers only a handful of machine instructions compared to possibly thousands of machine instructions to allocate new memory any temp or unnamed variables will be rvalues (determined by compiler) assignment of the result of a function is would be 2 copies if move semantics were not used (very costly) move ctor is more exception safe than copy ctor move semantics are safe since we are not grabbing more resources","title":"Move Semantics"},{"location":"software_design/cpp/move-semantics/#move-semantics","text":"makes code faster by adding to code","title":"Move Semantics"},{"location":"software_design/cpp/move-semantics/#rvalue-references","text":"Allow programmers to avoid unnecessary copying and to provide perfect forwarding functions Move constructor: MyClass::MyClass(MyClass&& other); does not allocate new resources, simply takes the resources from other and sets other to its default ctor state much faster than a copy ctor b/c it doesn't allocate memory and doesn't copy memory buffers only a handful of machine instructions compared to possibly thousands of machine instructions to allocate new memory any temp or unnamed variables will be rvalues (determined by compiler) assignment of the result of a function is would be 2 copies if move semantics were not used (very costly) move ctor is more exception safe than copy ctor move semantics are safe since we are not grabbing more resources","title":"rvalue references"},{"location":"software_design/cpp/operator-overloading/","text":"Operator Overloading Allows a programmer to define behaviors when built-in operators are applied to user defined types operator<symbol> is used for the function name of the operator to be overloaded class String { public: String &operator=(const String &); // assignment: returns by referenceto allow chaining/compounding assignments String operator+(const String &) const; // addition: const method b/c it does not alter the object, but returns a new one String operator-() const; // unary negator ... }; a = b // equivalent a.operator=(b) Compiler generates default implementation for assignment ( = ) and address ( & ) operator Cannot overload . , .* , :: , ?: , and sizeof operators Overloading an operator does not change: Operator precedence Associativity of the operator (important for unary operator) Arity of the operator (can't turn unary operator into a binary operator or vice versa) Meaning of how the operator works on objects of built-in types Overloading = and - operators does not overload -= operator An overloaded operator must have at least one operand that is a user defined type Cannot be used to create new operator symbols Overloaded oeprators must adhere to syntax of original operator Operator functions: 1) Member functions- usually use the this pointer implicity 2) Non-member functions- made friends so they have access to internal state of the user defined object Friendship Used for sharing private data members between classes class A{ public: int operator+(const B &rhs) { return this->foo + } private: int foo; } class B { public: friend class A; // any object A and all of its functions have access to private members in class B friend int A::operator+(const B &rhs); // grants only this method in class A access to private member variables in class B private: int bar; } Implementing an operator function as a non-member function of a class (e.g. overloading the insertion/extraction operator): // .h class A{ public: A(std::string a, std::string b, std::string c); friend std::ostream &operator<<(std::ostream &lhs, const A &rhs); // gives method access to the private member variables private: std::string a, b, c; } std::ostream &operator<<(std::ostream &lhs, const A &rhs); // .cpp A:A(std::string a, std::string b, std::string c): a(a), b(b), c(c) {} // returns a reference to the ostream that was passed in and modified by adding the data from the rhs object which is not modified in the process std::ostream &operator<<(std::ostream &lhs, const A &rhs) { lhs << rhs.a << \" \" << rhs.b << \" \" << rhs.c <<std::endl; return lhs; } Overloading Unary Operators Preference is to make the operator functions class members rather than non-member friend functions Prefix (increment and return the incremented value) and postfix (increment and return the value before it was incremented) Prefix is faster b/c it doesn't have to make a temp copy class A { public: A &operator++(); // prefix const A operator++(int) // postfix- called as A.operator(0); A &operator--(); // prefix const A operator--(int) // postfix } A &A::operator++() { ++*this; return this; } const A A::operator++(int) { A temp(*this); ++*this; return temp; } ++ and -- are often overloaded to support iterators and smart pointers When overloading ++ and -- , both prefix and postfix must be overloaded and each version will have a distinct signature due to the use of dummy parameters in the postfix operators Subscript Operator operator [] can be overloadded to return an object of a new class or return an element of the original array Usually a const and non-const version for reading and writing Can use const_cast to reduce code duplication and increase maintainability class TextBlock { public: ... const char& operator[](std::size_t position) const { // bounds checking // log access data // verify data integrity return text[position]; } char& operator[](std::size_t position) { return const_cast<char&>( const_cast<const TextBlock&>(*this)][position] ); // 1) adds const to *this // 2) calls const operator[] // 3) cast away const from returned value } ... } Overloading vs. Overriding Overloading - multiple functions w/ same name in same scope, but different signatures (e.g. different argument/return types, different parameters, etc.) When overloading functions, use the copy constructor to create new objects Overriding - derived class function has the same name and signature as a base class virtual function Overrriden mthods in a derived class will cause any methods of the same name (regardless of signature) in the base class to be hidden meaning they can't be used by the derived class Can override this default hiding behavior with a using class::method; line inside the derived class class A { public: bool process(Credit &); bool process(Acceptance &); } class B : public A{ public: using A::process; // no hiding of A's process methods bool process(Rejection &) }","title":"Operator Overloading"},{"location":"software_design/cpp/operator-overloading/#operator-overloading","text":"Allows a programmer to define behaviors when built-in operators are applied to user defined types operator<symbol> is used for the function name of the operator to be overloaded class String { public: String &operator=(const String &); // assignment: returns by referenceto allow chaining/compounding assignments String operator+(const String &) const; // addition: const method b/c it does not alter the object, but returns a new one String operator-() const; // unary negator ... }; a = b // equivalent a.operator=(b) Compiler generates default implementation for assignment ( = ) and address ( & ) operator Cannot overload . , .* , :: , ?: , and sizeof operators Overloading an operator does not change: Operator precedence Associativity of the operator (important for unary operator) Arity of the operator (can't turn unary operator into a binary operator or vice versa) Meaning of how the operator works on objects of built-in types Overloading = and - operators does not overload -= operator An overloaded operator must have at least one operand that is a user defined type Cannot be used to create new operator symbols Overloaded oeprators must adhere to syntax of original operator Operator functions: 1) Member functions- usually use the this pointer implicity 2) Non-member functions- made friends so they have access to internal state of the user defined object","title":"Operator Overloading"},{"location":"software_design/cpp/operator-overloading/#friendship","text":"Used for sharing private data members between classes class A{ public: int operator+(const B &rhs) { return this->foo + } private: int foo; } class B { public: friend class A; // any object A and all of its functions have access to private members in class B friend int A::operator+(const B &rhs); // grants only this method in class A access to private member variables in class B private: int bar; } Implementing an operator function as a non-member function of a class (e.g. overloading the insertion/extraction operator): // .h class A{ public: A(std::string a, std::string b, std::string c); friend std::ostream &operator<<(std::ostream &lhs, const A &rhs); // gives method access to the private member variables private: std::string a, b, c; } std::ostream &operator<<(std::ostream &lhs, const A &rhs); // .cpp A:A(std::string a, std::string b, std::string c): a(a), b(b), c(c) {} // returns a reference to the ostream that was passed in and modified by adding the data from the rhs object which is not modified in the process std::ostream &operator<<(std::ostream &lhs, const A &rhs) { lhs << rhs.a << \" \" << rhs.b << \" \" << rhs.c <<std::endl; return lhs; }","title":"Friendship"},{"location":"software_design/cpp/operator-overloading/#overloading-unary-operators","text":"Preference is to make the operator functions class members rather than non-member friend functions Prefix (increment and return the incremented value) and postfix (increment and return the value before it was incremented) Prefix is faster b/c it doesn't have to make a temp copy class A { public: A &operator++(); // prefix const A operator++(int) // postfix- called as A.operator(0); A &operator--(); // prefix const A operator--(int) // postfix } A &A::operator++() { ++*this; return this; } const A A::operator++(int) { A temp(*this); ++*this; return temp; } ++ and -- are often overloaded to support iterators and smart pointers When overloading ++ and -- , both prefix and postfix must be overloaded and each version will have a distinct signature due to the use of dummy parameters in the postfix operators","title":"Overloading Unary Operators"},{"location":"software_design/cpp/operator-overloading/#subscript-operator","text":"operator [] can be overloadded to return an object of a new class or return an element of the original array Usually a const and non-const version for reading and writing Can use const_cast to reduce code duplication and increase maintainability class TextBlock { public: ... const char& operator[](std::size_t position) const { // bounds checking // log access data // verify data integrity return text[position]; } char& operator[](std::size_t position) { return const_cast<char&>( const_cast<const TextBlock&>(*this)][position] ); // 1) adds const to *this // 2) calls const operator[] // 3) cast away const from returned value } ... }","title":"Subscript Operator"},{"location":"software_design/cpp/operator-overloading/#overloading-vs-overriding","text":"Overloading - multiple functions w/ same name in same scope, but different signatures (e.g. different argument/return types, different parameters, etc.) When overloading functions, use the copy constructor to create new objects Overriding - derived class function has the same name and signature as a base class virtual function Overrriden mthods in a derived class will cause any methods of the same name (regardless of signature) in the base class to be hidden meaning they can't be used by the derived class Can override this default hiding behavior with a using class::method; line inside the derived class class A { public: bool process(Credit &); bool process(Acceptance &); } class B : public A{ public: using A::process; // no hiding of A's process methods bool process(Rejection &) }","title":"Overloading vs. Overriding"},{"location":"software_design/cpp/pointers/","text":"Pointers A pointer is a variable that contains a memory address as its value Memory address points to the actual data Has a data type that indicates the type of data being stored at the memory address Declared using * operator like: int* a; Refrence/Address Operator: & obtains a variable's memory address Dereference Operator: * retrieves the data at the memory address a pointer stores When declared, pointers hold an unknown address until initialized To indicate pointing at nothing, use nullptr Why use them? Pointers are all 8-bytes (64-bits on 64-bit machines, 32-bits on 32-bit) so it is much more efficient to use memory addresses of large objects like images or videos than to actually move around the object and make copies of it when doing things like passing them to a function. Common Errors Syntax Using the dereference operator when initializing a pointer int* a; int b = 20; *a = &b; // error b/c using derefence operator a = &b // correct The 3rd line is an error b/c *a refers to data being stored at the unknown memory address a was initialized to. This will set the data at a to the memory address of b instead of making a point at b 's memory address. Note this will note cause a compiler error, just a tricky to find bug. However, this is valid and perform the desired functionality because * is not being used for dereferencing but rather declaring a pointer: int b = 20; int *a = &b; Forgetting the * before each pointer when declaring multiple on the same line int* ptr1, ptr2; // ptr1 will be an int pointer but ptr2 will just be an int int *ptr1, *ptr2; // makes both of them int pointers Good practice to declare one pointer per line to avoid this. Runtime Using a derefence operator * when the pointer has not been intialized. This causes undefined behavior meaning the program could crash if the pointer holds an address the program is not allowed to access. Dereferencing a null pointer. This causes the program to crash. Memory overflow can be dangerous b/c it results in overwriting data anywhere in memory (can be OS, other programs, etc.) Aliasing- changing the memory address a pointer points to Dereferencing Derefencing a pointer means accessing the value stored at the memory address the pointer contains char* p = \"abc\" // stores 'a', 'b', 'c' in 3 continuous chunks of memory and p points to the location of a // Pointer arithmetic can be used to access b and c assert(*p == 'a'); // The first character at address p will be 'a' assert(p[1] == 'b'); // p[1] actually dereferences the pointer: p + 1 * (size of p in memory) assert(*(p + 1) == 'b'); // Another notation for p[1] Change data at the address pointed to by derferencing the pointer: *p = 'z' // now the string of chars is zbc assert(*p = 'z') Move pointers through the data: ++p; // Increment p so now it points to 'b' assert(*p == 'b'); Member Access Operator struct SomeStruct {int a;}; SomeStruct s; SomeStruct* structPtr = s; structPtr->a = 1; // is cleaner than: (*structPtr).a = 1; Arrays Represented internally as a pointer to the first element Accessing elements using indexing is actually just using pointer arithmetic A variable declared as an array is the same as a variable declared as a pointer When passing an array to a function, only the address of the array is copied into the parameter so any changes to the array in the function will cause a change to the original array b/c its shared void f1(int array[]) = void f1(int *array) [] and * are effectively the same but [] provides better documentation/readability Array of pointers (multi-dimensional arrays): ** or *[] can be used to declare arrays of pointers Allows a program to contain elements that vary in size (saves memory which is important for programs using large data objects) Strings represented internally as a character array ending with the null character \\0 since it is a character array, pointer arithmetic and everything can be done on strings Const const ensures data cannot be modified and the compiler will enforce this constraint Use as much as possible const int num; num = 10; // error! const char let = 'a'; // good! let = 'b'; // error New and Delete Operators new allocates memory for the given type and returns a pointer to the allocated memory If the type is a class, it calls the constructor after allocating memory for the class's data members Can pass arguments to the constructor by passing them in parentheses after the class name (ex: ClassA a = new ClassA(\"Test\") ) To allocate a continuous chunk of memory for an array of objects use new SomeClass[size] Default constructor called for each object in array (class must have a constructor that can take 0 arguments otherwise a compiler error will occur) delete deallocates/frees a block of memory allocated with new No effect if used on nullptr Dereferencing after using delete will cause undefined behavior if pointer is not set to nullptr Calling delete on pointer not allocated with new has undefined behavior and is a logic error Must be called on a pointer to memory allocated using new Doesn't set a pointer to nullptr just frees the memory (must be done manually) To delete an array of objects use delete[] array Calling destructor instead of delete fails to actually free up the memory Memory Regions Memory has 3 different regions: data, stack, and heap. There are 3 types of memory allocation: static, dynamic, and automatic A program's memory usage includes 3 different regions: Static - global & static local variables are allocated at compilation time (fixed size) Reserved at compile time in the program's data segment Allocated as a fixed block of memory Stores any global and static local variables Stores the actual code Allocated when program starts and deallocated when program exists Automatic - each function call allocates a new block of memory called a stack frame to holds its local variables. The stack frames are part of the stack Starts where static memory ends and grows towards the end of memory Allocated on the program's execution stack Allocated at run time as control flow enters and deallocated as flow exits Managed by the run-time system Dynamic Memory - where the new operator allocates memory and the delete operator deallocates memory during runtime Managed by the programmer (aka the free store) Dynamic memory is stored on the heap Can only have as much physical memory as the machine or OS can make available (mismanaged memory in large programs can lead to it running out of memory and crashing) In classical architectures, the stack and heap grow toward each other to maximize the available space Memory Leaks Occur when a program that allocates memory loses the ability to access the allocated memory Typically due to failure to properly destroy/free dynamically allocated memory that is no longer being used Can cause a program to occupy more and more memory as the program runs, slowing its runtime Can cause a program to fail if memory becomes completely full and additional memory cannot be allocated Programs left running for long periods such as web browsers suffer from known memory leaks Occur at the program level so when the program terminates, all the memory allocated by the program is freed const and pointers A const pointer cannot be changed to point at something else const data cannot be modified char greeting[] = \"Hello\"; char *p = greeting; // non-const pointer, non-const data (unfixed at what it points to & read/write) const char *p = greeting; // non-const pointer, const data (unfixed at what it points to & readonly) const * char p = greeting; // const pointerm, non-const data (fixed at what it points to & read/write) const char * const p = greeting // const pointer, const data (fixed at what it points & readonly) // const anywhere to the left of * means its const data void f1(const Widget *pw) // preferred void f2(Widget const *pw ) // same as above non-const --> const is common const --> non-const is bad and should be avoided this pointer this pointer in a non-const member function of a class X is type: X * const (can change the data of the class but can't change where this is pointing) constant pointer to non-constant object returning objects Objects can be returned from functions Resources (Stack Overflow) Dereferencing Pointers (Reference) Access Operators (Slides) Pointers (Article) Weird Pointer Expressions","title":"Pointers"},{"location":"software_design/cpp/pointers/#pointers","text":"A pointer is a variable that contains a memory address as its value Memory address points to the actual data Has a data type that indicates the type of data being stored at the memory address Declared using * operator like: int* a; Refrence/Address Operator: & obtains a variable's memory address Dereference Operator: * retrieves the data at the memory address a pointer stores When declared, pointers hold an unknown address until initialized To indicate pointing at nothing, use nullptr","title":"Pointers"},{"location":"software_design/cpp/pointers/#why-use-them","text":"Pointers are all 8-bytes (64-bits on 64-bit machines, 32-bits on 32-bit) so it is much more efficient to use memory addresses of large objects like images or videos than to actually move around the object and make copies of it when doing things like passing them to a function.","title":"Why use them?"},{"location":"software_design/cpp/pointers/#common-errors","text":"","title":"Common Errors"},{"location":"software_design/cpp/pointers/#syntax","text":"Using the dereference operator when initializing a pointer int* a; int b = 20; *a = &b; // error b/c using derefence operator a = &b // correct The 3rd line is an error b/c *a refers to data being stored at the unknown memory address a was initialized to. This will set the data at a to the memory address of b instead of making a point at b 's memory address. Note this will note cause a compiler error, just a tricky to find bug. However, this is valid and perform the desired functionality because * is not being used for dereferencing but rather declaring a pointer: int b = 20; int *a = &b; Forgetting the * before each pointer when declaring multiple on the same line int* ptr1, ptr2; // ptr1 will be an int pointer but ptr2 will just be an int int *ptr1, *ptr2; // makes both of them int pointers Good practice to declare one pointer per line to avoid this.","title":"Syntax"},{"location":"software_design/cpp/pointers/#runtime","text":"Using a derefence operator * when the pointer has not been intialized. This causes undefined behavior meaning the program could crash if the pointer holds an address the program is not allowed to access. Dereferencing a null pointer. This causes the program to crash. Memory overflow can be dangerous b/c it results in overwriting data anywhere in memory (can be OS, other programs, etc.) Aliasing- changing the memory address a pointer points to","title":"Runtime"},{"location":"software_design/cpp/pointers/#dereferencing","text":"Derefencing a pointer means accessing the value stored at the memory address the pointer contains char* p = \"abc\" // stores 'a', 'b', 'c' in 3 continuous chunks of memory and p points to the location of a // Pointer arithmetic can be used to access b and c assert(*p == 'a'); // The first character at address p will be 'a' assert(p[1] == 'b'); // p[1] actually dereferences the pointer: p + 1 * (size of p in memory) assert(*(p + 1) == 'b'); // Another notation for p[1] Change data at the address pointed to by derferencing the pointer: *p = 'z' // now the string of chars is zbc assert(*p = 'z') Move pointers through the data: ++p; // Increment p so now it points to 'b' assert(*p == 'b');","title":"Dereferencing"},{"location":"software_design/cpp/pointers/#member-access-operator","text":"struct SomeStruct {int a;}; SomeStruct s; SomeStruct* structPtr = s; structPtr->a = 1; // is cleaner than: (*structPtr).a = 1;","title":"Member Access Operator"},{"location":"software_design/cpp/pointers/#arrays","text":"Represented internally as a pointer to the first element Accessing elements using indexing is actually just using pointer arithmetic A variable declared as an array is the same as a variable declared as a pointer When passing an array to a function, only the address of the array is copied into the parameter so any changes to the array in the function will cause a change to the original array b/c its shared void f1(int array[]) = void f1(int *array) [] and * are effectively the same but [] provides better documentation/readability Array of pointers (multi-dimensional arrays): ** or *[] can be used to declare arrays of pointers Allows a program to contain elements that vary in size (saves memory which is important for programs using large data objects)","title":"Arrays"},{"location":"software_design/cpp/pointers/#strings","text":"represented internally as a character array ending with the null character \\0 since it is a character array, pointer arithmetic and everything can be done on strings","title":"Strings"},{"location":"software_design/cpp/pointers/#const","text":"const ensures data cannot be modified and the compiler will enforce this constraint Use as much as possible const int num; num = 10; // error! const char let = 'a'; // good! let = 'b'; // error","title":"Const"},{"location":"software_design/cpp/pointers/#new-and-delete-operators","text":"new allocates memory for the given type and returns a pointer to the allocated memory If the type is a class, it calls the constructor after allocating memory for the class's data members Can pass arguments to the constructor by passing them in parentheses after the class name (ex: ClassA a = new ClassA(\"Test\") ) To allocate a continuous chunk of memory for an array of objects use new SomeClass[size] Default constructor called for each object in array (class must have a constructor that can take 0 arguments otherwise a compiler error will occur) delete deallocates/frees a block of memory allocated with new No effect if used on nullptr Dereferencing after using delete will cause undefined behavior if pointer is not set to nullptr Calling delete on pointer not allocated with new has undefined behavior and is a logic error Must be called on a pointer to memory allocated using new Doesn't set a pointer to nullptr just frees the memory (must be done manually) To delete an array of objects use delete[] array Calling destructor instead of delete fails to actually free up the memory","title":"New and Delete Operators"},{"location":"software_design/cpp/pointers/#memory-regions","text":"Memory has 3 different regions: data, stack, and heap. There are 3 types of memory allocation: static, dynamic, and automatic A program's memory usage includes 3 different regions: Static - global & static local variables are allocated at compilation time (fixed size) Reserved at compile time in the program's data segment Allocated as a fixed block of memory Stores any global and static local variables Stores the actual code Allocated when program starts and deallocated when program exists Automatic - each function call allocates a new block of memory called a stack frame to holds its local variables. The stack frames are part of the stack Starts where static memory ends and grows towards the end of memory Allocated on the program's execution stack Allocated at run time as control flow enters and deallocated as flow exits Managed by the run-time system Dynamic Memory - where the new operator allocates memory and the delete operator deallocates memory during runtime Managed by the programmer (aka the free store) Dynamic memory is stored on the heap Can only have as much physical memory as the machine or OS can make available (mismanaged memory in large programs can lead to it running out of memory and crashing) In classical architectures, the stack and heap grow toward each other to maximize the available space","title":"Memory Regions"},{"location":"software_design/cpp/pointers/#memory-leaks","text":"Occur when a program that allocates memory loses the ability to access the allocated memory Typically due to failure to properly destroy/free dynamically allocated memory that is no longer being used Can cause a program to occupy more and more memory as the program runs, slowing its runtime Can cause a program to fail if memory becomes completely full and additional memory cannot be allocated Programs left running for long periods such as web browsers suffer from known memory leaks Occur at the program level so when the program terminates, all the memory allocated by the program is freed","title":"Memory Leaks"},{"location":"software_design/cpp/pointers/#const-and-pointers","text":"A const pointer cannot be changed to point at something else const data cannot be modified char greeting[] = \"Hello\"; char *p = greeting; // non-const pointer, non-const data (unfixed at what it points to & read/write) const char *p = greeting; // non-const pointer, const data (unfixed at what it points to & readonly) const * char p = greeting; // const pointerm, non-const data (fixed at what it points to & read/write) const char * const p = greeting // const pointer, const data (fixed at what it points & readonly) // const anywhere to the left of * means its const data void f1(const Widget *pw) // preferred void f2(Widget const *pw ) // same as above non-const --> const is common const --> non-const is bad and should be avoided","title":"const and pointers"},{"location":"software_design/cpp/pointers/#this-pointer","text":"this pointer in a non-const member function of a class X is type: X * const (can change the data of the class but can't change where this is pointing) constant pointer to non-constant object","title":"this pointer"},{"location":"software_design/cpp/pointers/#returning-objects","text":"Objects can be returned from functions","title":"returning objects"},{"location":"software_design/cpp/pointers/#resources","text":"(Stack Overflow) Dereferencing Pointers (Reference) Access Operators (Slides) Pointers (Article) Weird Pointer Expressions","title":"Resources"},{"location":"software_design/cpp/smart-pointers/","text":"Smart Pointers Class type that look and act like a raw pointer but with additional capabilities Allows programmer to control the following pointer behaviors: Construction and Destruction: Copy and assignment Shallow copy, deep copy, or no copy Dereferencing Primarily used for RAII to make programs using pointers exception safe unique_ptr Smart pointer that cleans up after itself Advantages: Very efficient When it goes out of scope, the destructor frees pointed to object Disadvantages: Retains sole ownership of an objct Cannot copy or copy-assign Two instances cannot manage the same object Typical uses: Guarantees deletion (helpful for exception safety) Passing ownership of uniquely-owned objects into methods Acquiring ownership of uniquely-owned objects from methods Managing ownership: release() reset() swap() Can be used w/ arrays shared_ptr reference-counting smart pointer Track how many objects point to a particular resource Deletes the resource when no pointers point to the resource anymore assignment and copy construction are how shared_ptrs keep track of the number of references constructing the pointers seperately would result in two different shared_ptrs using std::shared_ptr; Circle *foo = new Circle(); shared_ptr<Shape> aShape(foo); shared_ptr<Shape> aNewShape(aShape) // copy constructor creates new smart pointer and increments reference count aShape = aNewShape; // nothing changes shared_ptr<Shape> aNewPtr(foo); // creates an entirely new shared_ptr with seperate reference count than the above shared_ptrs","title":"Smart Pointers"},{"location":"software_design/cpp/smart-pointers/#smart-pointers","text":"Class type that look and act like a raw pointer but with additional capabilities Allows programmer to control the following pointer behaviors: Construction and Destruction: Copy and assignment Shallow copy, deep copy, or no copy Dereferencing Primarily used for RAII to make programs using pointers exception safe","title":"Smart Pointers"},{"location":"software_design/cpp/smart-pointers/#unique_ptr","text":"Smart pointer that cleans up after itself Advantages: Very efficient When it goes out of scope, the destructor frees pointed to object Disadvantages: Retains sole ownership of an objct Cannot copy or copy-assign Two instances cannot manage the same object Typical uses: Guarantees deletion (helpful for exception safety) Passing ownership of uniquely-owned objects into methods Acquiring ownership of uniquely-owned objects from methods Managing ownership: release() reset() swap() Can be used w/ arrays","title":"unique_ptr"},{"location":"software_design/cpp/smart-pointers/#shared_ptr","text":"reference-counting smart pointer Track how many objects point to a particular resource Deletes the resource when no pointers point to the resource anymore assignment and copy construction are how shared_ptrs keep track of the number of references constructing the pointers seperately would result in two different shared_ptrs using std::shared_ptr; Circle *foo = new Circle(); shared_ptr<Shape> aShape(foo); shared_ptr<Shape> aNewShape(aShape) // copy constructor creates new smart pointer and increments reference count aShape = aNewShape; // nothing changes shared_ptr<Shape> aNewPtr(foo); // creates an entirely new shared_ptr with seperate reference count than the above shared_ptrs","title":"shared_ptr"},{"location":"software_design/cpp/stl/","text":"Standard Template Library Contains generic template classes and functions for containers, iterators, & algorithms Allows for development of generic programs that are independent of the underlying container STL Containers Are abstract data types (ADTs) that hold data for manipulation 3 types 1) Sequential - arrange data in a linear manner vector, deque, list 2) Associative - maintain data in structures suitable for fast associative operations set, multiset, map, multimap Implemented as balanced binary trees Supports efficient operations on elements using keys ordered by operator< Provide efficient, direct accessto store and retrieve elements via a key Keys are maintained in ascending order 3) Adaptors - provide different ways to access sequential and associative containers stack, queue, priority queue vector Can change size dynamically (resizable array) Provides best random-access performance Supports random access iterator Insertions/deletions at the back of the vector ( push_back() and pop_back() ) push_back - used when we can only copy emplace_back - used when we do not need to copy for speed increase Pros: Const time access elements by index Linear time iteration over all elements Const amortized (avg) time for adding/removing elements from the end O(N)/N Cons: consume more memory than arrays due to automatic resizing Memory is gauranteed to be contiguous so can use pointer arithmetic deque Pronounced \"deck\" Double ended queue Advantages: Provides efficient index access to data Efficient insertions/deletions at both front and back of queue push_back() , push_front() , pop_back() , pop_front() Uses a index lookup table to optimize memory and lookup efficiency Vector will be slightly faster b/c it doesnt need the lookup table due to only pushing back Elements not guaranteeed to be in contiguous storage locations so pointer arithmetic not safe list Implements a doubly linked-list Advantages: Const time insertion/removal of elements anywhere in the container Const time moving elements and blocks of elements within the container or even between different containers It just requires pointer assignments instead of copying values and allocating new arrays Disadvantages: No support for random-access iterator set provides rapid look-up but does not permit duplicates O(logn) amortized time complexity for insertion and deletion Because its stored as a balanced binary tree- usually a red-black tree // Create an output stream iterator with \" \" as a delimeter std::ostream_iterator<double> output(std::cout, \" \"); std::set<double> doubleSet; // insert on a set returns a pair: an iterator to the value and T if it was inserted, F if it already existed std::pair<std::set<double>::const_iterator, bool> pairValue; pairValue = doubleSet.insert(13.2) // or simply use auto to infer the type auto pairValue = doubleSet.insert(13.2) std::cout << *(pairValue.first) << (pairValue.second ? \"was\" : \"was not\") << \"inserted\" << std::endl; std::cout << \"Set contains: \"; std::copy(doubleSet.begin(),doubleSet.end(),output); multiset provides rapid look-up but permits duplicates Order of data determined by a comparator function std::multiset<int> intMultiSet; // insert on a multiset just returns an iterator intMultiSet.insert(1); // check for an item if (intMultiSet.find(2) == intMultiSet.end()) std::cout << \"Not found\" map Provides lookup using a rapid key based lookup Each value is associated with a unique key (no duplicate keys) AKA associative array Implemented as either a hashtable or red-black tree depending on the compiler multimap Allows duplicate keys No index operator notation since ambiguity in which key is being referred to STL Algorithms Operate over iterators, not containers Composing an algorithm with a container by invoking the algorithm with the iterators for that container Templates provide compile-time type safety when combining containers, iterators, algorithms Primary categories: Non-mutating Mutating Sorting and Sets : sort or search ranges of elements and act on sorted ranges by testing values Ex: sort() , nth_element() , binary_search() Numeric : produce generally numeric results Ex: min() min_element() , next_permutation() Mutating Remove packs all the valid elements to the front of the container Doesn't actually remove the element Must be followed by a container specific call to actually remove the element and change the size of the container Generate calls the passed in function to create a new value and then puts it into the container (does this for a range) generate_n does this n times instead of for a range remove transform() is an important and commonly used algo takes from one domain to another domain applies a function (takes in type of input container and returns type of output container) to elements int the input container and adds them to an output container expects there to be space in the output container (space must be preallocated which can be done since its a 1:1 mapping from the input container to the output container) many algorithms we don't know the output of so we cant presize/preallocate back_inserter is a adaptor that grows the size of the container by calling push_back (more flexible in that we don't need to presize anything) corresponds to MapReduce another version has a function that takes two inputs and returns 1 output to write back to the same input container understand 4 and 5 parameter versions bind prob not on quiz random notes boolean/predicate function- returns T/F based on a condition. usually passed to STL algorithms such as find_if() sort() is performed inplace. can pass a different operator than < for the comparator erase is just doing smush copying (behavior is not what you would expect)","title":"STL"},{"location":"software_design/cpp/stl/#standard-template-library","text":"Contains generic template classes and functions for containers, iterators, & algorithms Allows for development of generic programs that are independent of the underlying container","title":"Standard Template Library"},{"location":"software_design/cpp/stl/#stl-containers","text":"Are abstract data types (ADTs) that hold data for manipulation 3 types 1) Sequential - arrange data in a linear manner vector, deque, list 2) Associative - maintain data in structures suitable for fast associative operations set, multiset, map, multimap Implemented as balanced binary trees Supports efficient operations on elements using keys ordered by operator< Provide efficient, direct accessto store and retrieve elements via a key Keys are maintained in ascending order 3) Adaptors - provide different ways to access sequential and associative containers stack, queue, priority queue","title":"STL Containers"},{"location":"software_design/cpp/stl/#vector","text":"Can change size dynamically (resizable array) Provides best random-access performance Supports random access iterator Insertions/deletions at the back of the vector ( push_back() and pop_back() ) push_back - used when we can only copy emplace_back - used when we do not need to copy for speed increase Pros: Const time access elements by index Linear time iteration over all elements Const amortized (avg) time for adding/removing elements from the end O(N)/N Cons: consume more memory than arrays due to automatic resizing Memory is gauranteed to be contiguous so can use pointer arithmetic","title":"vector"},{"location":"software_design/cpp/stl/#deque","text":"Pronounced \"deck\" Double ended queue Advantages: Provides efficient index access to data Efficient insertions/deletions at both front and back of queue push_back() , push_front() , pop_back() , pop_front() Uses a index lookup table to optimize memory and lookup efficiency Vector will be slightly faster b/c it doesnt need the lookup table due to only pushing back Elements not guaranteeed to be in contiguous storage locations so pointer arithmetic not safe","title":"deque"},{"location":"software_design/cpp/stl/#list","text":"Implements a doubly linked-list Advantages: Const time insertion/removal of elements anywhere in the container Const time moving elements and blocks of elements within the container or even between different containers It just requires pointer assignments instead of copying values and allocating new arrays Disadvantages: No support for random-access iterator","title":"list"},{"location":"software_design/cpp/stl/#set","text":"provides rapid look-up but does not permit duplicates O(logn) amortized time complexity for insertion and deletion Because its stored as a balanced binary tree- usually a red-black tree // Create an output stream iterator with \" \" as a delimeter std::ostream_iterator<double> output(std::cout, \" \"); std::set<double> doubleSet; // insert on a set returns a pair: an iterator to the value and T if it was inserted, F if it already existed std::pair<std::set<double>::const_iterator, bool> pairValue; pairValue = doubleSet.insert(13.2) // or simply use auto to infer the type auto pairValue = doubleSet.insert(13.2) std::cout << *(pairValue.first) << (pairValue.second ? \"was\" : \"was not\") << \"inserted\" << std::endl; std::cout << \"Set contains: \"; std::copy(doubleSet.begin(),doubleSet.end(),output);","title":"set"},{"location":"software_design/cpp/stl/#multiset","text":"provides rapid look-up but permits duplicates Order of data determined by a comparator function std::multiset<int> intMultiSet; // insert on a multiset just returns an iterator intMultiSet.insert(1); // check for an item if (intMultiSet.find(2) == intMultiSet.end()) std::cout << \"Not found\"","title":"multiset"},{"location":"software_design/cpp/stl/#map","text":"Provides lookup using a rapid key based lookup Each value is associated with a unique key (no duplicate keys) AKA associative array Implemented as either a hashtable or red-black tree depending on the compiler","title":"map"},{"location":"software_design/cpp/stl/#multimap","text":"Allows duplicate keys No index operator notation since ambiguity in which key is being referred to","title":"multimap"},{"location":"software_design/cpp/stl/#stl-algorithms","text":"Operate over iterators, not containers Composing an algorithm with a container by invoking the algorithm with the iterators for that container Templates provide compile-time type safety when combining containers, iterators, algorithms Primary categories: Non-mutating Mutating Sorting and Sets : sort or search ranges of elements and act on sorted ranges by testing values Ex: sort() , nth_element() , binary_search() Numeric : produce generally numeric results Ex: min() min_element() , next_permutation()","title":"STL Algorithms"},{"location":"software_design/cpp/stl/#mutating","text":"Remove packs all the valid elements to the front of the container Doesn't actually remove the element Must be followed by a container specific call to actually remove the element and change the size of the container Generate calls the passed in function to create a new value and then puts it into the container (does this for a range) generate_n does this n times instead of for a range remove transform() is an important and commonly used algo takes from one domain to another domain applies a function (takes in type of input container and returns type of output container) to elements int the input container and adds them to an output container expects there to be space in the output container (space must be preallocated which can be done since its a 1:1 mapping from the input container to the output container) many algorithms we don't know the output of so we cant presize/preallocate back_inserter is a adaptor that grows the size of the container by calling push_back (more flexible in that we don't need to presize anything) corresponds to MapReduce another version has a function that takes two inputs and returns 1 output to write back to the same input container understand 4 and 5 parameter versions bind prob not on quiz","title":"Mutating"},{"location":"software_design/cpp/stl/#random-notes","text":"boolean/predicate function- returns T/F based on a condition. usually passed to STL algorithms such as find_if() sort() is performed inplace. can pass a different operator than < for the comparator erase is just doing smush copying (behavior is not what you would expect)","title":"random notes"},{"location":"software_design/cpp/strong-exception-safety/","text":"Strong Exception Safety Very large and old software systems with ad hoc resource managment cannot use exceptions Noexcept Specfication Functions that guarantee they will not throw an exception should specify that like so: void foo (...) noexcept; Can also be used as an operator that returns true at compile time if a given expression is guaranteed to not throw an exception delete , return and std::swap are all noexcept General Principles Can design every function to: 1) Complete successfully 2) Fail in a well-defined manner Assume every function that can throw an exception will throw one and incorporate it into your code/design Never delete a peice of information before the replacement info is ready for use Basic Tools: Try-blocks Support from Resource Acquisition Is Initialization (RAII) technique Throw and catch exceptions only when absolutely necessary When exception is thrown: Leak no resources Don't permit data structures to become corrupted Golden Rule: when an exception is propagated, try to leave the object in the state it had when the function was called Avoid side effects in expressions that may propagate exceptions Standard Exception Class Heierarchy exception logic_error domain_error length_error invalid_argument out_of_range runtime_error range_error overflow_error underflow_error Mutex Mu tual ex clusion object An object that allows multiple program threads to share the same resource (e.g. file access) but not simultaneously Mutex is locked when being used and unlocked when no longer needed std::lock_guard<std::mutex> mutex(exMutex) will automatically lock and unlock the mutex when Strong exception safety because mutex will be unlocked if exception is thrown and will not freeze program b/c of never reaching the unlock call Example of using RAII to destroy local variables when they go out of scope Exception Safety Exception safe functions provide one of four guarantees for if an exception is thrown: No Safety- code is in bad place Weak/Basic- everything in function remains in a valid state, but exact state may be unknown Strong- state of program is unchanged Nothrow- function always works and never throws an exception Arithmetic operations on primitive types do not throw exceptions delete is no throw because we need to be able to reliably delete things For same reason, destructors should be nothrow Operating overloading can cause exceptions on user defined types because they are function calls Combining operating overloading with templates makes things very complicated since depending on whether the type is a primitive or user defined, exceptions may be possible with simple operator calls Resource Acquisition Is Initialization (RAII) Only code guaranteed to be executed after an exception is thrown are the destructors of objects residing on the stack (local variables) Vital to writing exception safe C++ code Required so that resources are released before permitting exceptions to propagate (in order to avoid resource leaks) Source code of std::lock_gaurd demonstrating wrapping a resource in a class that can be used as a local variable so that its destructor is called when exceptions are thrown and the resource is properly dealt with: namespace std{ template <typename MUTEX> class lock_gaurd { public: lock_guard(MUTEX &m) : m(m) {m.lock();} ~lock_guard() {m.unlock();} private: MUTEX &m; } } RAII is used with strings, vectors, list, etc. std::shared_ptr and std::unique_ptr is the same concept and is a local variable that destroys what is being pointed to when they go out of scope Exception Handling Guidlines always rethrow an exception caught in catch(...) if another catch can deal with the exception Don't strip info from the exception and","title":"Strong Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#strong-exception-safety","text":"Very large and old software systems with ad hoc resource managment cannot use exceptions","title":"Strong Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#noexcept-specfication","text":"Functions that guarantee they will not throw an exception should specify that like so: void foo (...) noexcept; Can also be used as an operator that returns true at compile time if a given expression is guaranteed to not throw an exception delete , return and std::swap are all noexcept","title":"Noexcept Specfication"},{"location":"software_design/cpp/strong-exception-safety/#general-principles","text":"Can design every function to: 1) Complete successfully 2) Fail in a well-defined manner Assume every function that can throw an exception will throw one and incorporate it into your code/design Never delete a peice of information before the replacement info is ready for use Basic Tools: Try-blocks Support from Resource Acquisition Is Initialization (RAII) technique Throw and catch exceptions only when absolutely necessary When exception is thrown: Leak no resources Don't permit data structures to become corrupted Golden Rule: when an exception is propagated, try to leave the object in the state it had when the function was called Avoid side effects in expressions that may propagate exceptions","title":"General Principles"},{"location":"software_design/cpp/strong-exception-safety/#standard-exception-class-heierarchy","text":"exception logic_error domain_error length_error invalid_argument out_of_range runtime_error range_error overflow_error underflow_error","title":"Standard Exception Class Heierarchy"},{"location":"software_design/cpp/strong-exception-safety/#mutex","text":"Mu tual ex clusion object An object that allows multiple program threads to share the same resource (e.g. file access) but not simultaneously Mutex is locked when being used and unlocked when no longer needed std::lock_guard<std::mutex> mutex(exMutex) will automatically lock and unlock the mutex when Strong exception safety because mutex will be unlocked if exception is thrown and will not freeze program b/c of never reaching the unlock call Example of using RAII to destroy local variables when they go out of scope","title":"Mutex"},{"location":"software_design/cpp/strong-exception-safety/#exception-safety","text":"Exception safe functions provide one of four guarantees for if an exception is thrown: No Safety- code is in bad place Weak/Basic- everything in function remains in a valid state, but exact state may be unknown Strong- state of program is unchanged Nothrow- function always works and never throws an exception Arithmetic operations on primitive types do not throw exceptions delete is no throw because we need to be able to reliably delete things For same reason, destructors should be nothrow Operating overloading can cause exceptions on user defined types because they are function calls Combining operating overloading with templates makes things very complicated since depending on whether the type is a primitive or user defined, exceptions may be possible with simple operator calls","title":"Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#resource-acquisition-is-initialization-raii","text":"Only code guaranteed to be executed after an exception is thrown are the destructors of objects residing on the stack (local variables) Vital to writing exception safe C++ code Required so that resources are released before permitting exceptions to propagate (in order to avoid resource leaks) Source code of std::lock_gaurd demonstrating wrapping a resource in a class that can be used as a local variable so that its destructor is called when exceptions are thrown and the resource is properly dealt with: namespace std{ template <typename MUTEX> class lock_gaurd { public: lock_guard(MUTEX &m) : m(m) {m.lock();} ~lock_guard() {m.unlock();} private: MUTEX &m; } } RAII is used with strings, vectors, list, etc. std::shared_ptr and std::unique_ptr is the same concept and is a local variable that destroys what is being pointed to when they go out of scope","title":"Resource Acquisition Is Initialization (RAII)"},{"location":"software_design/cpp/strong-exception-safety/#exception-handling-guidlines","text":"always rethrow an exception caught in catch(...) if another catch can deal with the exception Don't strip info from the exception and","title":"Exception Handling Guidlines"},{"location":"software_design/cpp/templates/","text":"Templates Permit the definition of a template class or template function that can be used with multiple data types Requires only a single definition Permits reuse Compiler will create specific versions when functions are used with specific types Save time and avoid code replication One class template that is instantiated for N specific classes with X associated member functions Instead of writing N * X member functions, you only write X Can result in code bloat (source code looks small but object code/binaries are large) Need to be recompiled for each translation unit (can dramatically increase compile time) Need to do a commonality and variability analysis Look for replication to idenfity when a template could instead be instantiated multiple times Example A.h for templatized A class: template <typename T> class A { ... } #include '../src/A.cpp' Function Templates Define a specific behavior that can be applied to any data type Method overloading can be used to provide functionality for each data type Parameters and return type may be template types template <typename T> void functionName(T paramName, ...){ ... } When program runs and a call to the function template is encountered: 1) compiler substitutes the appropriate type(s) for the template params 2) compiler compiles this version of the function Multiple copies of function templates are created (one for each data type used) Function templates : specify a range of related functinos with a single code segment Written by programmer Template functions : the individually compiled versions of the function tempalte Generated by compiler Class Templates Allow the program to contain a generic class definition that can be instantiated into a type specific object cpp files for template classes cannot be compiled on their own Need to have types inserted to be compiled (must create an object to compile a template class) .h file for the template class will #include '<name>.cpp' So the template's cpp file should be left out of the CMake list Seperating interface from the implementation is good practice Common way is to implement everything in the .h for template classes (will see this in libraries often) Can pass a literal as a template parameter such as the int parameter below: // ClassName.h file template<typename T, typename T2, int x> class ClassName { public: ... private: ... } // ClassName.cpp file template<typename T, typename T2, > ClassName<T, T2, X>::ClassName(...) { .. } ... // main.cpp file int main() { ClassName<datatype, datatypeT2, int> objectName(); ... } Class templates : specify a range of related classes with a single definition (not compileable) Defined by programmer Template classes : the individual instantiated versions of the class template that are compileable Created by compiler Can set defaults types or values for template parameters: template<typename T=int, int x=10> Template classes Can be used as arguments to other templates since they are valid types once compiled Compiler doesn't evaluate class templates unless they are used (methods could be uncompiled if class not instantiated) Specialization In the below version, a seperate version of sum() is provided for string types while the generic template version of sum() is provided for other types. This reduces code bloat b/c only the necessary implementation will be compiled if a class of that type is instantiated You can specialize a method as many times as needed A non-specialized version should still be provided as well template <> std::string Stack<std::string>::sum() const { std::string value; for (uint32_t i = 0; i < stackTop; ++i) { value = stack[i] + value; } return value; } template <typename T> T Stack<T>::sum() const { T value = T(); for (uint32_t i = 0; i < stackTop; ++i) { value += stack[i]; } return value; }","title":"Templates"},{"location":"software_design/cpp/templates/#templates","text":"Permit the definition of a template class or template function that can be used with multiple data types Requires only a single definition Permits reuse Compiler will create specific versions when functions are used with specific types Save time and avoid code replication One class template that is instantiated for N specific classes with X associated member functions Instead of writing N * X member functions, you only write X Can result in code bloat (source code looks small but object code/binaries are large) Need to be recompiled for each translation unit (can dramatically increase compile time) Need to do a commonality and variability analysis Look for replication to idenfity when a template could instead be instantiated multiple times Example A.h for templatized A class: template <typename T> class A { ... } #include '../src/A.cpp'","title":"Templates"},{"location":"software_design/cpp/templates/#function-templates","text":"Define a specific behavior that can be applied to any data type Method overloading can be used to provide functionality for each data type Parameters and return type may be template types template <typename T> void functionName(T paramName, ...){ ... } When program runs and a call to the function template is encountered: 1) compiler substitutes the appropriate type(s) for the template params 2) compiler compiles this version of the function Multiple copies of function templates are created (one for each data type used) Function templates : specify a range of related functinos with a single code segment Written by programmer Template functions : the individually compiled versions of the function tempalte Generated by compiler","title":"Function Templates"},{"location":"software_design/cpp/templates/#class-templates","text":"Allow the program to contain a generic class definition that can be instantiated into a type specific object cpp files for template classes cannot be compiled on their own Need to have types inserted to be compiled (must create an object to compile a template class) .h file for the template class will #include '<name>.cpp' So the template's cpp file should be left out of the CMake list Seperating interface from the implementation is good practice Common way is to implement everything in the .h for template classes (will see this in libraries often) Can pass a literal as a template parameter such as the int parameter below: // ClassName.h file template<typename T, typename T2, int x> class ClassName { public: ... private: ... } // ClassName.cpp file template<typename T, typename T2, > ClassName<T, T2, X>::ClassName(...) { .. } ... // main.cpp file int main() { ClassName<datatype, datatypeT2, int> objectName(); ... } Class templates : specify a range of related classes with a single definition (not compileable) Defined by programmer Template classes : the individual instantiated versions of the class template that are compileable Created by compiler Can set defaults types or values for template parameters: template<typename T=int, int x=10> Template classes Can be used as arguments to other templates since they are valid types once compiled Compiler doesn't evaluate class templates unless they are used (methods could be uncompiled if class not instantiated)","title":"Class Templates"},{"location":"software_design/cpp/templates/#specialization","text":"In the below version, a seperate version of sum() is provided for string types while the generic template version of sum() is provided for other types. This reduces code bloat b/c only the necessary implementation will be compiled if a class of that type is instantiated You can specialize a method as many times as needed A non-specialized version should still be provided as well template <> std::string Stack<std::string>::sum() const { std::string value; for (uint32_t i = 0; i < stackTop; ++i) { value = stack[i] + value; } return value; } template <typename T> T Stack<T>::sum() const { T value = T(); for (uint32_t i = 0; i < stackTop; ++i) { value += stack[i]; } return value; }","title":"Specialization"},{"location":"software_design/patterns/adapter/","text":"Adapter Pattern Also known as wrapper. Intent Convert a class interface into an interface expected by the cleints Allows classes to work together that cannot otherwise work together due to incompatible interfaces Applicability When there is a need to use an existing class, but its interface doesn't match the one needed When a class should be reusable so that it can cooperate with unrelated and unforeseen classes When there is a need to use several existing subclasses, but its not practical to adapt their interfaces by subclassing each one Structure Participants Target - the domain specific interface a client uses Adaptee - the existing interface that needs adapting Adapter - class that adapts the existing interface to the target interface Collaborations Clients will call operations on an Adapter instance which in turn calls adaptee operations to carry out the request Consequences (+) A single adapter can work with multiple adaptees (-) Can make it harder to override adaptee behavior Implementation Considerations: How much adapting to do? Focus on a good client experience Pluggable adapters- dynamically create and change different types of adapters at runtime Sample Code Legacy Interface: class Alpha { public: // No hope of polymorphism ~Alpha() { std::cout << \"Alpha::dtor\" << std::endl; } void doThis() { std::cout << \"Alpha::doThis()\" << std::endl; } }; class Beta { public: ~Beta() { std::cout << \"Beta::dtor\" << std::endl; } void doThat() { std::cout << \"Beta::doThat()\" << std::endl; } }; class Gamma { public: ~Gamma() { std::cout << \"Gamma::dtor\" << std::endl; } void doTheOther() { std::cout << \"Gamma::doTheOther()\" << std::endl; } }; Target Interface: - Client will only see an interface with an execute method // Abstract base class acts as the target interface class TargetInterface { public: virtual ~TargetInterface() = default; // The new interface that clients will call virtual void execute() = 0; }; Poor Adapter: - (-) Client has to know the mapping (very difficult to use) // Design a \"wrapper\" or \"adapter\" class template <typename T> class SimpleAdapter : public TargetInterface { public: // Constructor accepts an instance and a method pointer SimpleAdapter(T *o, void (T::*m)()) : object(o), method(m) {} ~SimpleAdapter() override { delete object; } // The adapter/wrapper \"maps\" the new to the legacy implementation void execute() override { (object->*method)(); } private: T *object; // ptr-to-object void (T::*method)(); // ptr-to-member-function }; // client code that uses the adpater: // client has to have a lot of insight into how the mapping works int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new SimpleAdapter<Alpha>(new Alpha(), &Alpha::doThis); objects[1] = new SimpleAdapter<Beta>(new Beta(), &Beta::doThat); objects[2] = new SimpleAdapter<Gamma>(new Gamma(), &Gamma::doTheOther); for (int i = 0; i < count; i++) { // Client doesn't have to know which legacy type it is calling - just calls // execute objects[i]->execute(); } // Again, client uses the new interface // polymorphic destruction for (int i = 0; i < 3; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Outputs: Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Better Adapter: - (+) Easier client experience since they don't need to know the mapping (the adapter takes care of it) - (-) Have to modify the adapter to include any new adaptees - Usually a good tradeoff since main focus is better client experience template <typename T> class BetterAdapter : public TargetInterface { public: explicit BetterAdapter(T *obj) : object(obj) {}; ~BetterAdapter() override { delete object; }; void execute() override { // using runtime type information (RTTI) and the typeid part of the vtable to determine the type of object at runtime if (typeid(*object) == typeid(Alpha)) { // need the cast to pass compile time type checking // reinterpret_cast gives compile time errors while a strict cast would force the cast and not do additional checks reinterpret_cast<Alpha *>(object)->doThis(); } else if (typeid(*object) == typeid(Beta)) { reinterpret_cast<Beta *>(object)->doThat(); } else if (typeid(*object) == typeid(Gamma)) { reinterpret_cast<Gamma *>(object)->doTheOther(); } else { throw; } } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new BetterAdapter<Alpha>(new Alpha()); objects[1] = new BetterAdapter<Beta>(new Beta()); objects[2] = new BetterAdapter<Gamma>(new Gamma()); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Best Adapter: - (+) Default adaptees - (+) Easy to use client experience - (+) Compile time execution and code synthesis (all work is done at compile time) - (+) Fast and lightweight - (+) Adding new adaptees would not require too much work template <typename T = Alpha> class BestAdapter : public TargetInterface { public: explicit BestAdapter() : object(new T()){}; ~BestAdapter() override { delete object; }; void execute() override { if constexpr (std::is_same<T, Alpha>::value) object->doThis(); else if constexpr (std::is_same<T, Beta>::value) object->doThat(); else if constexpr (std::is_same<T, Gamma>::value) object->doTheOther(); // could use a compile time assert here to raise type issues at compilation else std::cout << \"Unknown type\\n\"; } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; // can use defaults if adaptee not specified objects[0] = new BestAdapter<>(); objects[1] = new BestAdapter<Beta>(); objects[2] = new BestAdapter<Gamma>(); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ constexpr ( ) code can be executed at compile time meaning the else ifs in the block above will get evaluated at compile time and the appropriate line of code will get inserted/synthesized. Lots of the STL can be executed at compile time (e.g. allocating vectors, sorting containers, etc.) std::is_same<> is for compile time type checking Known Uses New interfaces to legacy code Stack and Queue in the STL are adapters of vector and list class Related Patterns Bridge has a similar structure but has a different intent of separating an interface from its implementation so they can vary independently Adapter is meant to change the interface of an existing object","title":"Adapter"},{"location":"software_design/patterns/adapter/#adapter-pattern","text":"Also known as wrapper.","title":"Adapter Pattern"},{"location":"software_design/patterns/adapter/#intent","text":"Convert a class interface into an interface expected by the cleints Allows classes to work together that cannot otherwise work together due to incompatible interfaces","title":"Intent"},{"location":"software_design/patterns/adapter/#applicability","text":"When there is a need to use an existing class, but its interface doesn't match the one needed When a class should be reusable so that it can cooperate with unrelated and unforeseen classes When there is a need to use several existing subclasses, but its not practical to adapt their interfaces by subclassing each one","title":"Applicability"},{"location":"software_design/patterns/adapter/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/adapter/#participants","text":"Target - the domain specific interface a client uses Adaptee - the existing interface that needs adapting Adapter - class that adapts the existing interface to the target interface","title":"Participants"},{"location":"software_design/patterns/adapter/#collaborations","text":"Clients will call operations on an Adapter instance which in turn calls adaptee operations to carry out the request","title":"Collaborations"},{"location":"software_design/patterns/adapter/#consequences","text":"(+) A single adapter can work with multiple adaptees (-) Can make it harder to override adaptee behavior","title":"Consequences"},{"location":"software_design/patterns/adapter/#implementation","text":"Considerations: How much adapting to do? Focus on a good client experience Pluggable adapters- dynamically create and change different types of adapters at runtime","title":"Implementation"},{"location":"software_design/patterns/adapter/#sample-code","text":"Legacy Interface: class Alpha { public: // No hope of polymorphism ~Alpha() { std::cout << \"Alpha::dtor\" << std::endl; } void doThis() { std::cout << \"Alpha::doThis()\" << std::endl; } }; class Beta { public: ~Beta() { std::cout << \"Beta::dtor\" << std::endl; } void doThat() { std::cout << \"Beta::doThat()\" << std::endl; } }; class Gamma { public: ~Gamma() { std::cout << \"Gamma::dtor\" << std::endl; } void doTheOther() { std::cout << \"Gamma::doTheOther()\" << std::endl; } }; Target Interface: - Client will only see an interface with an execute method // Abstract base class acts as the target interface class TargetInterface { public: virtual ~TargetInterface() = default; // The new interface that clients will call virtual void execute() = 0; }; Poor Adapter: - (-) Client has to know the mapping (very difficult to use) // Design a \"wrapper\" or \"adapter\" class template <typename T> class SimpleAdapter : public TargetInterface { public: // Constructor accepts an instance and a method pointer SimpleAdapter(T *o, void (T::*m)()) : object(o), method(m) {} ~SimpleAdapter() override { delete object; } // The adapter/wrapper \"maps\" the new to the legacy implementation void execute() override { (object->*method)(); } private: T *object; // ptr-to-object void (T::*method)(); // ptr-to-member-function }; // client code that uses the adpater: // client has to have a lot of insight into how the mapping works int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new SimpleAdapter<Alpha>(new Alpha(), &Alpha::doThis); objects[1] = new SimpleAdapter<Beta>(new Beta(), &Beta::doThat); objects[2] = new SimpleAdapter<Gamma>(new Gamma(), &Gamma::doTheOther); for (int i = 0; i < count; i++) { // Client doesn't have to know which legacy type it is calling - just calls // execute objects[i]->execute(); } // Again, client uses the new interface // polymorphic destruction for (int i = 0; i < 3; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Outputs: Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Better Adapter: - (+) Easier client experience since they don't need to know the mapping (the adapter takes care of it) - (-) Have to modify the adapter to include any new adaptees - Usually a good tradeoff since main focus is better client experience template <typename T> class BetterAdapter : public TargetInterface { public: explicit BetterAdapter(T *obj) : object(obj) {}; ~BetterAdapter() override { delete object; }; void execute() override { // using runtime type information (RTTI) and the typeid part of the vtable to determine the type of object at runtime if (typeid(*object) == typeid(Alpha)) { // need the cast to pass compile time type checking // reinterpret_cast gives compile time errors while a strict cast would force the cast and not do additional checks reinterpret_cast<Alpha *>(object)->doThis(); } else if (typeid(*object) == typeid(Beta)) { reinterpret_cast<Beta *>(object)->doThat(); } else if (typeid(*object) == typeid(Gamma)) { reinterpret_cast<Gamma *>(object)->doTheOther(); } else { throw; } } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new BetterAdapter<Alpha>(new Alpha()); objects[1] = new BetterAdapter<Beta>(new Beta()); objects[2] = new BetterAdapter<Gamma>(new Gamma()); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Best Adapter: - (+) Default adaptees - (+) Easy to use client experience - (+) Compile time execution and code synthesis (all work is done at compile time) - (+) Fast and lightweight - (+) Adding new adaptees would not require too much work template <typename T = Alpha> class BestAdapter : public TargetInterface { public: explicit BestAdapter() : object(new T()){}; ~BestAdapter() override { delete object; }; void execute() override { if constexpr (std::is_same<T, Alpha>::value) object->doThis(); else if constexpr (std::is_same<T, Beta>::value) object->doThat(); else if constexpr (std::is_same<T, Gamma>::value) object->doTheOther(); // could use a compile time assert here to raise type issues at compilation else std::cout << \"Unknown type\\n\"; } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; // can use defaults if adaptee not specified objects[0] = new BestAdapter<>(); objects[1] = new BestAdapter<Beta>(); objects[2] = new BestAdapter<Gamma>(); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ constexpr ( ) code can be executed at compile time meaning the else ifs in the block above will get evaluated at compile time and the appropriate line of code will get inserted/synthesized. Lots of the STL can be executed at compile time (e.g. allocating vectors, sorting containers, etc.) std::is_same<> is for compile time type checking","title":"Sample Code"},{"location":"software_design/patterns/adapter/#known-uses","text":"New interfaces to legacy code Stack and Queue in the STL are adapters of vector and list class","title":"Known Uses"},{"location":"software_design/patterns/adapter/#related-patterns","text":"Bridge has a similar structure but has a different intent of separating an interface from its implementation so they can vary independently Adapter is meant to change the interface of an existing object","title":"Related Patterns"},{"location":"software_design/patterns/bridge/","text":"Bridge Pattern Also known as Handle/Body Intent Decouple an abstraction interface from its physical implementation(s) so that the two can vary independently Motivation When an abstraction can have multiple implementations, a common approach is to use inheritance. An abstract class defines the interface to the abstraction and the concrete subclasses implement it in different ways. However, using inheritance is not always the best solution since it can be cumbersome to modify, extend, and reuse abstractions and implementations independently. Bridge pattern addresses the problems of strict inheritance by putting the abstract interface and the implmentation in their own class hierarchies. The relationship between the abstraction and the implementation is known as the bridge. Applicability Use the bridge pattern when: You want to avoid permanent binding between an abstraction and its implementation e.g. when the implementation must be selected/switched at runtime Both the abstractions and their implementations should be extensible by subclassing Changes in the implementation should have no impact on the abstraction interface and client code that uses the interface You need a uniform interface to interchangeable class hierarchies Structure Participants Abstraction defines the abstraction's interface maintains a reference to an object of type Implementor RefinedAbstraction Extends the interface defined by Abstraction Implementor defines the interface for implementation classes does not have to correspond exactly to Abstraction's interface (can be quite different) Implementor interface provides only primitive operations and Abstraction defines higher-level operations based on these primitives ConcreteImplementor implements the Implementor interface and defines its concrete implementation Collaborations Abstraction forwards client requests to its Implementor object Consequences (+) Decoupled abstract interface and implementation (+) Implementations can vary dynamically (i.e. at runtime) (+) Eliminates compile-time dependencies on the implementation (e.g. changing implementation class doesn't require recompiling abstraction class and its clients) (+) Improved extensibility- can extend the Abstraction and Implementor hierarchies independently (+) Hiding implementation details from clients- you can shield clients from implmentation details (+) Can be used transparently with STL algorithms and containers Implementation The following implementation issues should be considered when applying the bridge pattern: Creating an abstract implementor class is unnecessary when there is only one implementation If sharing implementors a form of reference counting needs to be implemented Determining the right implementor to create for the use case Decision can be made in constructor based on passed in params Decision can also be made by outside object such as a factory Sample Code class Abstraction { public: Abstraction(); virtual void doSomething(); ... protected: Implementor* getImp(); private: Implementor* _imp; } class Implementor { public: virtual void someFunc(); ... protected: Implementor(); } Related Patterns an abstract factory can create and configure a bridge the adapter pattern is geared toward making unrelated classes work together (usually applied to systems after they are designed) bridge is used up-front in a design","title":"Bridge"},{"location":"software_design/patterns/bridge/#bridge-pattern","text":"Also known as Handle/Body","title":"Bridge Pattern"},{"location":"software_design/patterns/bridge/#intent","text":"Decouple an abstraction interface from its physical implementation(s) so that the two can vary independently","title":"Intent"},{"location":"software_design/patterns/bridge/#motivation","text":"When an abstraction can have multiple implementations, a common approach is to use inheritance. An abstract class defines the interface to the abstraction and the concrete subclasses implement it in different ways. However, using inheritance is not always the best solution since it can be cumbersome to modify, extend, and reuse abstractions and implementations independently. Bridge pattern addresses the problems of strict inheritance by putting the abstract interface and the implmentation in their own class hierarchies. The relationship between the abstraction and the implementation is known as the bridge.","title":"Motivation"},{"location":"software_design/patterns/bridge/#applicability","text":"Use the bridge pattern when: You want to avoid permanent binding between an abstraction and its implementation e.g. when the implementation must be selected/switched at runtime Both the abstractions and their implementations should be extensible by subclassing Changes in the implementation should have no impact on the abstraction interface and client code that uses the interface You need a uniform interface to interchangeable class hierarchies","title":"Applicability"},{"location":"software_design/patterns/bridge/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/bridge/#participants","text":"Abstraction defines the abstraction's interface maintains a reference to an object of type Implementor RefinedAbstraction Extends the interface defined by Abstraction Implementor defines the interface for implementation classes does not have to correspond exactly to Abstraction's interface (can be quite different) Implementor interface provides only primitive operations and Abstraction defines higher-level operations based on these primitives ConcreteImplementor implements the Implementor interface and defines its concrete implementation","title":"Participants"},{"location":"software_design/patterns/bridge/#collaborations","text":"Abstraction forwards client requests to its Implementor object","title":"Collaborations"},{"location":"software_design/patterns/bridge/#consequences","text":"(+) Decoupled abstract interface and implementation (+) Implementations can vary dynamically (i.e. at runtime) (+) Eliminates compile-time dependencies on the implementation (e.g. changing implementation class doesn't require recompiling abstraction class and its clients) (+) Improved extensibility- can extend the Abstraction and Implementor hierarchies independently (+) Hiding implementation details from clients- you can shield clients from implmentation details (+) Can be used transparently with STL algorithms and containers","title":"Consequences"},{"location":"software_design/patterns/bridge/#implementation","text":"The following implementation issues should be considered when applying the bridge pattern: Creating an abstract implementor class is unnecessary when there is only one implementation If sharing implementors a form of reference counting needs to be implemented Determining the right implementor to create for the use case Decision can be made in constructor based on passed in params Decision can also be made by outside object such as a factory","title":"Implementation"},{"location":"software_design/patterns/bridge/#sample-code","text":"class Abstraction { public: Abstraction(); virtual void doSomething(); ... protected: Implementor* getImp(); private: Implementor* _imp; } class Implementor { public: virtual void someFunc(); ... protected: Implementor(); }","title":"Sample Code"},{"location":"software_design/patterns/bridge/#related-patterns","text":"an abstract factory can create and configure a bridge the adapter pattern is geared toward making unrelated classes work together (usually applied to systems after they are designed) bridge is used up-front in a design","title":"Related Patterns"},{"location":"software_design/patterns/builder/","text":"Builder Pattern Intent Separate the construction of a complex object from its representation so that the same construction process can create different representations Applicability When the algorthim for creating a complex object should be independent of the parts that make up the object When the construction process must allow different representations for the object that's constructed Ex: multiplication in an expression tree can also be represented as repeated addtion Structure Participants Builder -specifies an abstract interface for creating parts of a product object ConcreteBuilder - constructs and assembles parts of the product by implementing the Builder interface Director - constructs an object using the Builder interface Product - represents the complex object under construction Collaborations Client creates the Director object and configures it with the desired builder object Director notifies the builder whenever a part of the product should be built Builder handles requests from the director and adds parts to the product Client retrieves the product from the builder Consequences (+) Can vary a product's internal representation (all you need to do is define a new builder) (+) Isolates code for construction and representation (+) Finer control over the construction process (-) May involve lots of classes Implementation Usually no abstract class for products since they each may differ so much in their representation Related Patterns Abstract Factory also creates complex objects but the difference is that builder pattern focuses on creting the complex object step by step while the abstract factory's focus is on families of product objects Builder often builds a Composite","title":"Builder"},{"location":"software_design/patterns/builder/#builder-pattern","text":"","title":"Builder Pattern"},{"location":"software_design/patterns/builder/#intent","text":"Separate the construction of a complex object from its representation so that the same construction process can create different representations","title":"Intent"},{"location":"software_design/patterns/builder/#applicability","text":"When the algorthim for creating a complex object should be independent of the parts that make up the object When the construction process must allow different representations for the object that's constructed Ex: multiplication in an expression tree can also be represented as repeated addtion","title":"Applicability"},{"location":"software_design/patterns/builder/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/builder/#participants","text":"Builder -specifies an abstract interface for creating parts of a product object ConcreteBuilder - constructs and assembles parts of the product by implementing the Builder interface Director - constructs an object using the Builder interface Product - represents the complex object under construction","title":"Participants"},{"location":"software_design/patterns/builder/#collaborations","text":"Client creates the Director object and configures it with the desired builder object Director notifies the builder whenever a part of the product should be built Builder handles requests from the director and adds parts to the product Client retrieves the product from the builder","title":"Collaborations"},{"location":"software_design/patterns/builder/#consequences","text":"(+) Can vary a product's internal representation (all you need to do is define a new builder) (+) Isolates code for construction and representation (+) Finer control over the construction process (-) May involve lots of classes","title":"Consequences"},{"location":"software_design/patterns/builder/#implementation","text":"Usually no abstract class for products since they each may differ so much in their representation","title":"Implementation"},{"location":"software_design/patterns/builder/#related-patterns","text":"Abstract Factory also creates complex objects but the difference is that builder pattern focuses on creting the complex object step by step while the abstract factory's focus is on families of product objects Builder often builds a Composite","title":"Related Patterns"},{"location":"software_design/patterns/command/","text":"Command Pattern Also known as Action or Transaction Intent Encapsulate a request for a service as an object Motivation Part of an application that may issue a command (e.g. a button click) might not be able to execute the command itself (e.g. performing the action of the button click would be done by a different part of the application). The comand pattern allows commands to be created and passed around as objects so that a receiver/target with the proper scope can execute commands issued by any part of the application. Applicability To parameterize objects with an action to perform To specify, queue, and execute requests at different times Command object can have a lifetime independent of the original request so if the receiver/target can be stored indepedently of the caller, then command object can be transfered to a different process and executed there are the proper time For multilevel undo/redo The execute operation can store state for reversing its effects Can log changes to be reapplied in case of a system crash Structure Participants Command declares an interface for executing an operation ConcreteCommand (ex: PasteCommand, OpenCommand) defines a binding between a receiver object and an action implements Execute by invoking the corresponding operations on Target Client (ex: Application) Creates a ConcreteCommand object and sets its target Invoker (ex: MenuItem) asks the command to carry out the request Receiver/Target (ex: Document, Application) knows how to perform the operations associated with carrying out a request (e.g. Document knows how to handle the paste command by adding the contents of the clipboard to the document) Any class may serve as a target/receiver The diagram below shows the interactions between the objects and how Command decouples the invoker from the receiver and the request it carries out Collaborations The client creates a ConcreteCommand object and specifies its receiver An Invoker object stores the ConcreteCommand object The invoker issues a request by calling execute on the command The ConcreteCommand object invokes operations on its receiver to carry out the request Consequences (+) Decouple the object that invokes the operation from the one that knows how to perform it (+) Commands are first-class objects that can be manipulated and extended like any other object (+) Can assemble commands into a composite command (e.g macros) (+) Can easily add new commands (+) Supports arbitrary-level undo/redo (-) May result in lots of trivial command subclasses --> doesn't scale well to hundreds or thousands of commands (-) Excessive memory may be needed to support long time horizons of undo/redo operations Implementation Supporting undo and redo requires a ConcreteCommand to store additional state Possible state: The receiver, thearguments to the operation, and/or original values in the receiver that changed due to the command Place each executed command onto a stack Each command has the required state to restore a previous version of the application (the state can be light or heavy depending on the application) Popping from the stack restores other versions of the application Handling hysteresis Want to watch out for the accumulation of error in the undo/redo process that causes the application's state to diverge from its original value The pattern can be used to support transactions Sample Code class Command { public: virtual ~Command(); virtual void execute() = 0; protected: Command(); } class ConcreteCommand : public Command { public: ConcreteCommand(Client*); virtual void execute(); private: Target* _target; } ConcreteCommand::ConcreteCommand(Target* target) : _target(target) {} ConcreteCommand::execute() { _target->doSomething(); } Related Patterns Composite pattern can be used to implement MacroCommands A Memento can keep state the command requires to undo its effect A command that must be copied before being placed on the history list acts as a prototype","title":"Command"},{"location":"software_design/patterns/command/#command-pattern","text":"Also known as Action or Transaction","title":"Command Pattern"},{"location":"software_design/patterns/command/#intent","text":"Encapsulate a request for a service as an object","title":"Intent"},{"location":"software_design/patterns/command/#motivation","text":"Part of an application that may issue a command (e.g. a button click) might not be able to execute the command itself (e.g. performing the action of the button click would be done by a different part of the application). The comand pattern allows commands to be created and passed around as objects so that a receiver/target with the proper scope can execute commands issued by any part of the application.","title":"Motivation"},{"location":"software_design/patterns/command/#applicability","text":"To parameterize objects with an action to perform To specify, queue, and execute requests at different times Command object can have a lifetime independent of the original request so if the receiver/target can be stored indepedently of the caller, then command object can be transfered to a different process and executed there are the proper time For multilevel undo/redo The execute operation can store state for reversing its effects Can log changes to be reapplied in case of a system crash","title":"Applicability"},{"location":"software_design/patterns/command/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/command/#participants","text":"Command declares an interface for executing an operation ConcreteCommand (ex: PasteCommand, OpenCommand) defines a binding between a receiver object and an action implements Execute by invoking the corresponding operations on Target Client (ex: Application) Creates a ConcreteCommand object and sets its target Invoker (ex: MenuItem) asks the command to carry out the request Receiver/Target (ex: Document, Application) knows how to perform the operations associated with carrying out a request (e.g. Document knows how to handle the paste command by adding the contents of the clipboard to the document) Any class may serve as a target/receiver The diagram below shows the interactions between the objects and how Command decouples the invoker from the receiver and the request it carries out","title":"Participants"},{"location":"software_design/patterns/command/#collaborations","text":"The client creates a ConcreteCommand object and specifies its receiver An Invoker object stores the ConcreteCommand object The invoker issues a request by calling execute on the command The ConcreteCommand object invokes operations on its receiver to carry out the request","title":"Collaborations"},{"location":"software_design/patterns/command/#consequences","text":"(+) Decouple the object that invokes the operation from the one that knows how to perform it (+) Commands are first-class objects that can be manipulated and extended like any other object (+) Can assemble commands into a composite command (e.g macros) (+) Can easily add new commands (+) Supports arbitrary-level undo/redo (-) May result in lots of trivial command subclasses --> doesn't scale well to hundreds or thousands of commands (-) Excessive memory may be needed to support long time horizons of undo/redo operations","title":"Consequences"},{"location":"software_design/patterns/command/#implementation","text":"Supporting undo and redo requires a ConcreteCommand to store additional state Possible state: The receiver, thearguments to the operation, and/or original values in the receiver that changed due to the command Place each executed command onto a stack Each command has the required state to restore a previous version of the application (the state can be light or heavy depending on the application) Popping from the stack restores other versions of the application Handling hysteresis Want to watch out for the accumulation of error in the undo/redo process that causes the application's state to diverge from its original value The pattern can be used to support transactions","title":"Implementation"},{"location":"software_design/patterns/command/#sample-code","text":"class Command { public: virtual ~Command(); virtual void execute() = 0; protected: Command(); } class ConcreteCommand : public Command { public: ConcreteCommand(Client*); virtual void execute(); private: Target* _target; } ConcreteCommand::ConcreteCommand(Target* target) : _target(target) {} ConcreteCommand::execute() { _target->doSomething(); }","title":"Sample Code"},{"location":"software_design/patterns/command/#related-patterns","text":"Composite pattern can be used to implement MacroCommands A Memento can keep state the command requires to undo its effect A command that must be copied before being placed on the history list acts as a prototype","title":"Related Patterns"},{"location":"software_design/patterns/composite/","text":"Composite Pattern Intent Compose objects into tree structures to represent part-whole hierarchies. Allows clients to treat individual objects and multiple, recursively-composed objects uniformly. Applicability Tree structure Objects must be composed recursively No distinction between individual and composed elements (root node is itself a tree) Objects in strcutre can be treated uniformly Structure Participants Component - declares the interface for objects in the composition implements any default behavior common for all classes declares an interface for accessing and managing its child components Leaf - represents leaf objects in the composition (no children) Composite - defines behavior for components having children stores child components implements child-related operations Client - manipulates objects in the composition through the component interface Collaborations Requests are usually forwarded through composite components to the leaves where the requests are handled. Consequences (+) Easy to use for the client (+) Easy to add new components (-) Overhead: might be prohibitive as the number of objects increases (e.g. impractical for linux kernel with 30+ million lines of code) (-) Awkward designs: may need to treat leaves as lobotomized composites Implementation Do components need to know their parents? If so, add a parent pointer to components Does there need to be a uniform interface for both leaves and composites? Need to decide who has the responsibility for deleting children Do we allocate storage for children in component base class In the expression tree, someone outside the tree will do this actual creation of children nodes (i.e. the interpreter) Related Patterns Iterator pattern can be used to traverse composites Visitor pattern can be used to localize operations/behavior that would otherwise be distributed across composite and leaf classes","title":"Composite"},{"location":"software_design/patterns/composite/#composite-pattern","text":"","title":"Composite Pattern"},{"location":"software_design/patterns/composite/#intent","text":"Compose objects into tree structures to represent part-whole hierarchies. Allows clients to treat individual objects and multiple, recursively-composed objects uniformly.","title":"Intent"},{"location":"software_design/patterns/composite/#applicability","text":"Tree structure Objects must be composed recursively No distinction between individual and composed elements (root node is itself a tree) Objects in strcutre can be treated uniformly","title":"Applicability"},{"location":"software_design/patterns/composite/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/composite/#participants","text":"Component - declares the interface for objects in the composition implements any default behavior common for all classes declares an interface for accessing and managing its child components Leaf - represents leaf objects in the composition (no children) Composite - defines behavior for components having children stores child components implements child-related operations Client - manipulates objects in the composition through the component interface","title":"Participants"},{"location":"software_design/patterns/composite/#collaborations","text":"Requests are usually forwarded through composite components to the leaves where the requests are handled.","title":"Collaborations"},{"location":"software_design/patterns/composite/#consequences","text":"(+) Easy to use for the client (+) Easy to add new components (-) Overhead: might be prohibitive as the number of objects increases (e.g. impractical for linux kernel with 30+ million lines of code) (-) Awkward designs: may need to treat leaves as lobotomized composites","title":"Consequences"},{"location":"software_design/patterns/composite/#implementation","text":"Do components need to know their parents? If so, add a parent pointer to components Does there need to be a uniform interface for both leaves and composites? Need to decide who has the responsibility for deleting children Do we allocate storage for children in component base class In the expression tree, someone outside the tree will do this actual creation of children nodes (i.e. the interpreter)","title":"Implementation"},{"location":"software_design/patterns/composite/#related-patterns","text":"Iterator pattern can be used to traverse composites Visitor pattern can be used to localize operations/behavior that would otherwise be distributed across composite and leaf classes","title":"Related Patterns"},{"location":"software_design/patterns/factory/","text":"Factory Method Pattern Intent Provide an interface for creating an object, but let subclasses decide which class to instantiate. Applicability When a class cannot anticipate the objects it must create When a class wants its subclasses to specify the objects it creates When a standard interface for creating objects is useful in enforcing rules on how objects are created Structure Participants Product (ex: Document) defines the interface of objects the factory method cretes ConcreteProduct (ex: MyDocument) implements the product interface Creator (Ex: Application) declares the factory method which returns an object of type Product (may also provide default implementation that returns a default ConcreteProduct) may call the factory method to create a Product object ConcreteCreator (ex: MyApplication) overrides the factory method to return an instance of a ConcreteProduct Collaborations Creator relies on its subclasses to define the factory method so that it returns the appropriate ConcreteProduct instance Consequences (+) Client code becomes more flexible since we avoid specifying the class name of the concerete class Resilient to adding more objects or changing how objects are made (+) Client is only dependent on the interface Remove burden of knowing how to create things from the user and give user a simple interface for making new objects (-) Construction of objects requires one additional class in some cases Implementation 2 choices: 1) Creator class is abstract and doesn't implement creation methods meaning it must be subclassed 2) Creator class is concrete and provides a default implementation meaning it can optionally be subclassed Can create multiple types of products by parameterizing the factory method Should be parameterized if a factory method needs to be able to create different variants Known Uses All STL containers are factories Database connectors (a standard way of creating a database connection that only has to be changed in one place instead of across the application) Related Patterns Abstract Factory is often implemented with factory methods Abstract Factory Pattern Intent Provide an interface for creating families of related or dependent objects without specifying their concrete classes Applicability When a system should be independent of how its products are created, composed, and represented When a system should be configured with one of multiple families of products When a family of related product objects is designed to be used together and you need to enforce this constraint When you want to provide a class library of products without revealing their implementations Structure Participants AbstractFactory declares an interface for operations that create abstract product objects ConcreteFactory implements the operations to create concrete product objects Abstract Product declares an interface for a type of product object Concrete Product implements the AbstractProduct interface and defines a product object to be created by the corresponding ConcreteFactory Client uses only the interfaces defined by AbstractFactory and AbstractProduct classes Collaborations Normally a single instance of a ConcreteFactory is created at runtime AbstractFactory defers creation of product objects to its ConcreteFactory subclasses Consequences (+) Flexibility: remove type/subclass dependencies from clients (+) Abstraction and semantic checking: hides product's composition (-) Hard to extend interface to create new products Implementation Factories are usually best implemented as a singleton Parameterization as a way of controlling the interface's size Configuration with Prototypes (i.e. determines who creates the factories) Essentially groups of factory methods","title":"Factory"},{"location":"software_design/patterns/factory/#factory-method-pattern","text":"","title":"Factory Method Pattern"},{"location":"software_design/patterns/factory/#intent","text":"Provide an interface for creating an object, but let subclasses decide which class to instantiate.","title":"Intent"},{"location":"software_design/patterns/factory/#applicability","text":"When a class cannot anticipate the objects it must create When a class wants its subclasses to specify the objects it creates When a standard interface for creating objects is useful in enforcing rules on how objects are created","title":"Applicability"},{"location":"software_design/patterns/factory/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/factory/#participants","text":"Product (ex: Document) defines the interface of objects the factory method cretes ConcreteProduct (ex: MyDocument) implements the product interface Creator (Ex: Application) declares the factory method which returns an object of type Product (may also provide default implementation that returns a default ConcreteProduct) may call the factory method to create a Product object ConcreteCreator (ex: MyApplication) overrides the factory method to return an instance of a ConcreteProduct","title":"Participants"},{"location":"software_design/patterns/factory/#collaborations","text":"Creator relies on its subclasses to define the factory method so that it returns the appropriate ConcreteProduct instance","title":"Collaborations"},{"location":"software_design/patterns/factory/#consequences","text":"(+) Client code becomes more flexible since we avoid specifying the class name of the concerete class Resilient to adding more objects or changing how objects are made (+) Client is only dependent on the interface Remove burden of knowing how to create things from the user and give user a simple interface for making new objects (-) Construction of objects requires one additional class in some cases","title":"Consequences"},{"location":"software_design/patterns/factory/#implementation","text":"2 choices: 1) Creator class is abstract and doesn't implement creation methods meaning it must be subclassed 2) Creator class is concrete and provides a default implementation meaning it can optionally be subclassed Can create multiple types of products by parameterizing the factory method Should be parameterized if a factory method needs to be able to create different variants","title":"Implementation"},{"location":"software_design/patterns/factory/#known-uses","text":"All STL containers are factories Database connectors (a standard way of creating a database connection that only has to be changed in one place instead of across the application)","title":"Known Uses"},{"location":"software_design/patterns/factory/#related-patterns","text":"Abstract Factory is often implemented with factory methods","title":"Related Patterns"},{"location":"software_design/patterns/factory/#abstract-factory-pattern","text":"","title":"Abstract Factory Pattern"},{"location":"software_design/patterns/factory/#intent_1","text":"Provide an interface for creating families of related or dependent objects without specifying their concrete classes","title":"Intent"},{"location":"software_design/patterns/factory/#applicability_1","text":"When a system should be independent of how its products are created, composed, and represented When a system should be configured with one of multiple families of products When a family of related product objects is designed to be used together and you need to enforce this constraint When you want to provide a class library of products without revealing their implementations","title":"Applicability"},{"location":"software_design/patterns/factory/#structure_1","text":"","title":"Structure"},{"location":"software_design/patterns/factory/#participants_1","text":"AbstractFactory declares an interface for operations that create abstract product objects ConcreteFactory implements the operations to create concrete product objects Abstract Product declares an interface for a type of product object Concrete Product implements the AbstractProduct interface and defines a product object to be created by the corresponding ConcreteFactory Client uses only the interfaces defined by AbstractFactory and AbstractProduct classes","title":"Participants"},{"location":"software_design/patterns/factory/#collaborations_1","text":"Normally a single instance of a ConcreteFactory is created at runtime AbstractFactory defers creation of product objects to its ConcreteFactory subclasses","title":"Collaborations"},{"location":"software_design/patterns/factory/#consequences_1","text":"(+) Flexibility: remove type/subclass dependencies from clients (+) Abstraction and semantic checking: hides product's composition (-) Hard to extend interface to create new products","title":"Consequences"},{"location":"software_design/patterns/factory/#implementation_1","text":"Factories are usually best implemented as a singleton Parameterization as a way of controlling the interface's size Configuration with Prototypes (i.e. determines who creates the factories) Essentially groups of factory methods","title":"Implementation"},{"location":"software_design/patterns/interpreter/","text":"Interpreter Pattern Intent Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences in the languages Applicability When there is a language to interpret and statements in the language can be represented as abstract syntax trees Works best when: The grammar is simple and relatively stable (e.g. don't use for a programming language like C++) Expression can be interpreted without building abstract syntax trees (saves space and time) Efficiency is not a critical concern (other techniques for efficient interpreters) Structure Participants AbstractExpression - declares an abstract Interpret operation that is common to all nodes in the abstract syntax tree TerminalExpression - implements an Interpret operation associated with terminal symbols in the grammar NonTerminalExpression - one such class is required for every rule in the grammar Maintains references to other AbstractExpressions to represent the remaining subexpressions to be interpreted Interpret operation typically calls itself recursively on the variables representing each of the rules Context - contains information that is global to the interpreter Client - calls the Interpret operation in order to build an abstract syntax tree representing a particular sentence in the language defined by the grammar Collaborations The client builds the sentence as an abstract syntax tree of Terminal and Nonterminal expression instances. The client then initializes the content and invokes the Interpret operation NonTerminal expressions define Interpret in term of Interpret on each subexpression Interpret operations use the context to store and access the state of the interpreter Consequences (+) Simple grammars are easy to change and extend All rules are represented by distinct classes in an orderly manner (+) Adding another rule adds another class (-) Complex grammars are hard to maintain More interdependent rules yield more interdependent classes Parser or compiler generators are more appropriate for complex grammars Implementation Doesn't explain how to create an abstract syntax tree (doesn't address parsing) Express the language rules, one per class Alternations, repetitions, or sequences expressed as nonterminal expressions Literal translations expressed as terminal expressions Create interpret method to lead the context through the interpretation classes Sample Code Known Uses Regular expression (regex) is a language for searching for patterns in strings so that custom algorithms are not needed for each proble (the problem is so often occuring that it made sense to develop a simple grammar and interpeter that can parse sentences of the language) Related Patterns The abstract syntax tree is an instance of the composite pattern An iterator can be used to traverse the structure The visitor pattern can be used to maintain the behavior in each node in the syntax tree in one class","title":"Interpreter"},{"location":"software_design/patterns/interpreter/#interpreter-pattern","text":"","title":"Interpreter Pattern"},{"location":"software_design/patterns/interpreter/#intent","text":"Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences in the languages","title":"Intent"},{"location":"software_design/patterns/interpreter/#applicability","text":"When there is a language to interpret and statements in the language can be represented as abstract syntax trees Works best when: The grammar is simple and relatively stable (e.g. don't use for a programming language like C++) Expression can be interpreted without building abstract syntax trees (saves space and time) Efficiency is not a critical concern (other techniques for efficient interpreters)","title":"Applicability"},{"location":"software_design/patterns/interpreter/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/interpreter/#participants","text":"AbstractExpression - declares an abstract Interpret operation that is common to all nodes in the abstract syntax tree TerminalExpression - implements an Interpret operation associated with terminal symbols in the grammar NonTerminalExpression - one such class is required for every rule in the grammar Maintains references to other AbstractExpressions to represent the remaining subexpressions to be interpreted Interpret operation typically calls itself recursively on the variables representing each of the rules Context - contains information that is global to the interpreter Client - calls the Interpret operation in order to build an abstract syntax tree representing a particular sentence in the language defined by the grammar","title":"Participants"},{"location":"software_design/patterns/interpreter/#collaborations","text":"The client builds the sentence as an abstract syntax tree of Terminal and Nonterminal expression instances. The client then initializes the content and invokes the Interpret operation NonTerminal expressions define Interpret in term of Interpret on each subexpression Interpret operations use the context to store and access the state of the interpreter","title":"Collaborations"},{"location":"software_design/patterns/interpreter/#consequences","text":"(+) Simple grammars are easy to change and extend All rules are represented by distinct classes in an orderly manner (+) Adding another rule adds another class (-) Complex grammars are hard to maintain More interdependent rules yield more interdependent classes Parser or compiler generators are more appropriate for complex grammars","title":"Consequences"},{"location":"software_design/patterns/interpreter/#implementation","text":"Doesn't explain how to create an abstract syntax tree (doesn't address parsing) Express the language rules, one per class Alternations, repetitions, or sequences expressed as nonterminal expressions Literal translations expressed as terminal expressions Create interpret method to lead the context through the interpretation classes","title":"Implementation"},{"location":"software_design/patterns/interpreter/#sample-code","text":"","title":"Sample Code"},{"location":"software_design/patterns/interpreter/#known-uses","text":"Regular expression (regex) is a language for searching for patterns in strings so that custom algorithms are not needed for each proble (the problem is so often occuring that it made sense to develop a simple grammar and interpeter that can parse sentences of the language)","title":"Known Uses"},{"location":"software_design/patterns/interpreter/#related-patterns","text":"The abstract syntax tree is an instance of the composite pattern An iterator can be used to traverse the structure The visitor pattern can be used to maintain the behavior in each node in the syntax tree in one class","title":"Related Patterns"},{"location":"software_design/patterns/iterator/","text":"Iterator Pattern Also known as cursor Intent Access elements of a container without exposing its representation Applicability Require multiple traversal algorithms over a container Require a uniform traversal interface over different containers When container classes and traversal algorithm must vary independently Structure Participants Iterator - defines an interface for accessing and traversing elements ConcreteIterator - implements the Iterator interface and a specific type of traversal Aggregate - container interface that defines method for creating an Iterator object ConcreteAggregate - specific container implementation that implements the create iterator method to return an instance of the correct ConcreteIterator Collaborations ConcreteIterator keeps track of the current object in the Aggregate and can compute the succeeding object in the traversal Consequences (+) Flexibility: container and traversal are independent (+) Multiple iterators and multiple traversal algorithms (-) Additional communication overhead between iterator and container Problematic for iterators in concurrent or distributed systems Implementation Internval versus external iterators Internal- when the iterator controls the iteration External- when the client controls the iteration (more flexible) Violating the object structure's encapsulation Robust iterators- ensure insertions/removals won't interfere with traversal Synchronization overhead in multi-threaded programs Batching in distributed and concurrent programs Related Patterns Iterators are often applied to Composite structures","title":"Iterator"},{"location":"software_design/patterns/iterator/#iterator-pattern","text":"Also known as cursor","title":"Iterator Pattern"},{"location":"software_design/patterns/iterator/#intent","text":"Access elements of a container without exposing its representation","title":"Intent"},{"location":"software_design/patterns/iterator/#applicability","text":"Require multiple traversal algorithms over a container Require a uniform traversal interface over different containers When container classes and traversal algorithm must vary independently","title":"Applicability"},{"location":"software_design/patterns/iterator/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/iterator/#participants","text":"Iterator - defines an interface for accessing and traversing elements ConcreteIterator - implements the Iterator interface and a specific type of traversal Aggregate - container interface that defines method for creating an Iterator object ConcreteAggregate - specific container implementation that implements the create iterator method to return an instance of the correct ConcreteIterator","title":"Participants"},{"location":"software_design/patterns/iterator/#collaborations","text":"ConcreteIterator keeps track of the current object in the Aggregate and can compute the succeeding object in the traversal","title":"Collaborations"},{"location":"software_design/patterns/iterator/#consequences","text":"(+) Flexibility: container and traversal are independent (+) Multiple iterators and multiple traversal algorithms (-) Additional communication overhead between iterator and container Problematic for iterators in concurrent or distributed systems","title":"Consequences"},{"location":"software_design/patterns/iterator/#implementation","text":"Internval versus external iterators Internal- when the iterator controls the iteration External- when the client controls the iteration (more flexible) Violating the object structure's encapsulation Robust iterators- ensure insertions/removals won't interfere with traversal Synchronization overhead in multi-threaded programs Batching in distributed and concurrent programs","title":"Implementation"},{"location":"software_design/patterns/iterator/#related-patterns","text":"Iterators are often applied to Composite structures","title":"Related Patterns"},{"location":"software_design/patterns/observer/","text":"Observer Pattern Also known as the pub/sub Intent Define a one-to-many dependency between objects so that when one object changes state, all dependents are notified and updated Applicability When an abstraction has two aspects, one dependent on the other When a change to one object requires changing untold others When an object should notify unknown other objects Structure Subject base class implements all interactions with observers This means it does not necessarily have to be an abstract base class Concrete subject class only needs to call notify to send updates to all the observers Can have multiple different concrete observers that use the subject's data in different ways Participants Subject - object being watched for state changes. Knows its observers and provides an interface for attaching and detaching observer objects Observer - defines an updating interface for objects that should be notified of changes in a subject Concrete Subject - stores the state of interest to ConcreteObserver objects Sends a notification to its observers when its state changes Concrete Observer - maintains a reference to a concrete subject Implements the Observer's updating interface to keep its state consistent with the subject's Collaborations The observers do not communicate with each other. A higher level of abstraction is thus required to keep track of things such as repeat observers. Consequences (+) Modularity- subject and observers can vary independently Subject only knows it has a list of Observers, doesn't know their concrete types (loosely coupled) (+) Extensibility- can define and add any number of different observers (+) Customizability- different observers offer different views of the subject (-) Unexpected updates- Observers don't know about each other (-) High update overhead (especially in large networks of observers) Can be reduced using hints or filtering Implementation Can filter the data an observer receives to decrease the update overhead Observers can register what data from the subject they are interested so not all the data needs to be sent to each observer An observer can be a subject that updates its own observers Can create large networks with high update overhead Can also create accidental update cycles (common in enterprise software) Need to handle dangling references left by observers that suddenly crash or get deleted Push vs. Pull models Pull model- subject sends message saying its data changed and observers can optionally request the updated data Allows observers to pull the data at varying rates Can implement both with pull model for certain observers and push for other observers Sample Code Below we define a simple abstract base class that has a method to be called when an event happens to the object being observed template <typename T> class Observer { public: virtual void handleEvent(const T &) = 0; }; Below we define a simple base class for any objects that we want to be subjects (observable) template <typename T> class Subject { public: /** * Default constructor */ Subject() = default; /** * Add an observer to this subject * @param ref New observer to notify of changes */ void add(Observer<T> &ref) { observers.insert(&ref); } /** * Remove an observer * @param ref Observer to stop notifying of changes */ void remove(Observer<T> &ref) { observers.erase(&ref); } protected: /** * Notify all observers of change * @param obj Object that has changed */ void Notify(T &obj) { for (auto observer : observers) observer->handleEvent(obj); } private: /** * Set of recorded observers */ std::set<Observer<T> *> observers; }; Here is the github repo with the example code from lecture. Known Uses MVC Smart phone event frameworks Pub/sub middleware (ROS, DDS, JAva Message Service, etc.) Mailing lists","title":"Observer"},{"location":"software_design/patterns/observer/#observer-pattern","text":"Also known as the pub/sub","title":"Observer Pattern"},{"location":"software_design/patterns/observer/#intent","text":"Define a one-to-many dependency between objects so that when one object changes state, all dependents are notified and updated","title":"Intent"},{"location":"software_design/patterns/observer/#applicability","text":"When an abstraction has two aspects, one dependent on the other When a change to one object requires changing untold others When an object should notify unknown other objects","title":"Applicability"},{"location":"software_design/patterns/observer/#structure","text":"Subject base class implements all interactions with observers This means it does not necessarily have to be an abstract base class Concrete subject class only needs to call notify to send updates to all the observers Can have multiple different concrete observers that use the subject's data in different ways","title":"Structure"},{"location":"software_design/patterns/observer/#participants","text":"Subject - object being watched for state changes. Knows its observers and provides an interface for attaching and detaching observer objects Observer - defines an updating interface for objects that should be notified of changes in a subject Concrete Subject - stores the state of interest to ConcreteObserver objects Sends a notification to its observers when its state changes Concrete Observer - maintains a reference to a concrete subject Implements the Observer's updating interface to keep its state consistent with the subject's","title":"Participants"},{"location":"software_design/patterns/observer/#collaborations","text":"The observers do not communicate with each other. A higher level of abstraction is thus required to keep track of things such as repeat observers.","title":"Collaborations"},{"location":"software_design/patterns/observer/#consequences","text":"(+) Modularity- subject and observers can vary independently Subject only knows it has a list of Observers, doesn't know their concrete types (loosely coupled) (+) Extensibility- can define and add any number of different observers (+) Customizability- different observers offer different views of the subject (-) Unexpected updates- Observers don't know about each other (-) High update overhead (especially in large networks of observers) Can be reduced using hints or filtering","title":"Consequences"},{"location":"software_design/patterns/observer/#implementation","text":"Can filter the data an observer receives to decrease the update overhead Observers can register what data from the subject they are interested so not all the data needs to be sent to each observer An observer can be a subject that updates its own observers Can create large networks with high update overhead Can also create accidental update cycles (common in enterprise software) Need to handle dangling references left by observers that suddenly crash or get deleted Push vs. Pull models Pull model- subject sends message saying its data changed and observers can optionally request the updated data Allows observers to pull the data at varying rates Can implement both with pull model for certain observers and push for other observers","title":"Implementation"},{"location":"software_design/patterns/observer/#sample-code","text":"Below we define a simple abstract base class that has a method to be called when an event happens to the object being observed template <typename T> class Observer { public: virtual void handleEvent(const T &) = 0; }; Below we define a simple base class for any objects that we want to be subjects (observable) template <typename T> class Subject { public: /** * Default constructor */ Subject() = default; /** * Add an observer to this subject * @param ref New observer to notify of changes */ void add(Observer<T> &ref) { observers.insert(&ref); } /** * Remove an observer * @param ref Observer to stop notifying of changes */ void remove(Observer<T> &ref) { observers.erase(&ref); } protected: /** * Notify all observers of change * @param obj Object that has changed */ void Notify(T &obj) { for (auto observer : observers) observer->handleEvent(obj); } private: /** * Set of recorded observers */ std::set<Observer<T> *> observers; }; Here is the github repo with the example code from lecture.","title":"Sample Code"},{"location":"software_design/patterns/observer/#known-uses","text":"MVC Smart phone event frameworks Pub/sub middleware (ROS, DDS, JAva Message Service, etc.) Mailing lists","title":"Known Uses"},{"location":"software_design/patterns/patterns/","text":"Design Patterns Design patterns are simply object oriented software designs that often recurr as the solution to certain problems when designing large and complex software. The commonality in these recurring designs is distilled into patterns that codify these good practices for solving common problems. Each design pattern systematically names, explains, and evaluates an important and recurring design in object-oriented systems. Design patterns help us decide what should be an object and what its responsibilities should be. Goals Codify good object oriented design and implementation practices Distill and generalize experience to aid novices and experts alike Design structures with explicit names create a common vocab & reduce complexity Capture/preserve design and implementation knowledge Articulate key decisions succintctly Improve documentation Facilitate restructuring/refactoring Types Purpose - what a pattern does Creational - concern the process of object creation Structural - deal with the composition of classes/objects Behavioral - characterize the ways in which classes/objects interact and distribute responsibility Scope - specifies whether the pattern applies primarily to classes or objects Class patterns - focus on relationships between classes and their subclasses which are defined through inheritance so they are fixed at compile time Object patterns - deal with object relationships which can be changed at runtime and are more dynamic Creational class patterns defer some part of object creation to subclasses, while Creational object patterns defer it to another object. The Structural class patterns use inheritance to compose classes, while the Structural object patterns describe ways to assemble objects. The Behavioral class patterns use inheritance to describe algorithms and flow of control, whereas the Behavioral object patterns describe how a group of objects cooperate to perform a task that no single object can carry out alone. Organization Patterns often reference each other so a graph can be another useful way of organizing the different patterns: Design aspects that design patterns let you vary: OMT Object Model Notation Used in the diagrams Precursor to UML dashed arrowhead line: class instantiates an object of the class being pointed to triangle: inheritance abstract class- italicized names filled triangle indicates a virtual base class plain arrowhead line: class keeps a reference to the class being pointed at diamond on one end, arrow on the other: aggregation of the class being pointed at filled black circle- multiplicity empty circle- optional multiplicity","title":"Overview"},{"location":"software_design/patterns/patterns/#design-patterns","text":"Design patterns are simply object oriented software designs that often recurr as the solution to certain problems when designing large and complex software. The commonality in these recurring designs is distilled into patterns that codify these good practices for solving common problems. Each design pattern systematically names, explains, and evaluates an important and recurring design in object-oriented systems. Design patterns help us decide what should be an object and what its responsibilities should be.","title":"Design Patterns"},{"location":"software_design/patterns/patterns/#goals","text":"Codify good object oriented design and implementation practices Distill and generalize experience to aid novices and experts alike Design structures with explicit names create a common vocab & reduce complexity Capture/preserve design and implementation knowledge Articulate key decisions succintctly Improve documentation Facilitate restructuring/refactoring","title":"Goals"},{"location":"software_design/patterns/patterns/#types","text":"Purpose - what a pattern does Creational - concern the process of object creation Structural - deal with the composition of classes/objects Behavioral - characterize the ways in which classes/objects interact and distribute responsibility Scope - specifies whether the pattern applies primarily to classes or objects Class patterns - focus on relationships between classes and their subclasses which are defined through inheritance so they are fixed at compile time Object patterns - deal with object relationships which can be changed at runtime and are more dynamic Creational class patterns defer some part of object creation to subclasses, while Creational object patterns defer it to another object. The Structural class patterns use inheritance to compose classes, while the Structural object patterns describe ways to assemble objects. The Behavioral class patterns use inheritance to describe algorithms and flow of control, whereas the Behavioral object patterns describe how a group of objects cooperate to perform a task that no single object can carry out alone.","title":"Types"},{"location":"software_design/patterns/patterns/#organization","text":"Patterns often reference each other so a graph can be another useful way of organizing the different patterns: Design aspects that design patterns let you vary:","title":"Organization"},{"location":"software_design/patterns/patterns/#omt-object-model-notation","text":"Used in the diagrams Precursor to UML dashed arrowhead line: class instantiates an object of the class being pointed to triangle: inheritance abstract class- italicized names filled triangle indicates a virtual base class plain arrowhead line: class keeps a reference to the class being pointed at diamond on one end, arrow on the other: aggregation of the class being pointed at filled black circle- multiplicity empty circle- optional multiplicity","title":"OMT Object Model Notation"},{"location":"software_design/patterns/reactor/","text":"Reactor Pattern any aliases this pattern is known by Intent Allows event-driving applications to demultiplex and dispatch service requests that are delivered to an application from one or more clients. Applicability When you need to decouple event handling from event detecting/demuxing/dispatching When multiple sources of events must be handled in a single thread Structure Consequences (+) Separation of concerns and portability (+) Simplify concurrency control (-) Non-preemptive Implementation Decouple event demultiplexing mechanisms from event dispatching? Handle many idfferent types of events (e.g. input/output events, signals, timers, etc.)","title":"Reactor"},{"location":"software_design/patterns/reactor/#reactor-pattern","text":"any aliases this pattern is known by","title":"Reactor Pattern"},{"location":"software_design/patterns/reactor/#intent","text":"Allows event-driving applications to demultiplex and dispatch service requests that are delivered to an application from one or more clients.","title":"Intent"},{"location":"software_design/patterns/reactor/#applicability","text":"When you need to decouple event handling from event detecting/demuxing/dispatching When multiple sources of events must be handled in a single thread","title":"Applicability"},{"location":"software_design/patterns/reactor/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/reactor/#consequences","text":"(+) Separation of concerns and portability (+) Simplify concurrency control (-) Non-preemptive","title":"Consequences"},{"location":"software_design/patterns/reactor/#implementation","text":"Decouple event demultiplexing mechanisms from event dispatching? Handle many idfferent types of events (e.g. input/output events, signals, timers, etc.)","title":"Implementation"},{"location":"software_design/patterns/singleton/","text":"Singleton Pattern Intent Ensure a class only ever has one instance and provide a global point of access Applicability When there must be exactly one instance of a class and it must be accessible from a well-known access point When the sole instance should be extensible by subclassing, and clients should be able to use an extended instance without modifying their code Structure Participants Singleton - defines an Instance operation (static member function) that lets clients access its unique instance Collaborations Clients access a singleton instance soley though the singleton's Instance operation Consequences (+) Reduces namespace pollution (+) easy to change and allow multiple instances (+) allow extension by subclassing (-) Same drawbacks of a global if misused (-) Implementation may be less efficient than a global variable (-) Concurrency pitfalls and communication overhead Implementation Static instance operation Registering the singleton instance runtime though instead of compiletime Deleting singletons Not automatically destroyed by anything Usually use a shared pointer instead of raw pointer to deal with this Lifecycle is not as well defined as simple variables Sample Code class Singleton { public: static Singleton& getInstance() { if (inst == nullptr) inst = new Singleton(); return *inst; } Singleton(Singleton const&) = delete; void operator=(Singleton const&) = delete; private: static Singleton* inst; Singleton() {} }; // must provide initial value for static variable outside of class Singleton* Singleton::inst = nullptr; Then a singleton would be created like: int main() { Singleton& one = Singleton::getInstance(); Singleton& two = Singleton::getInstance(); return 0; } Known Uses Hardware interface access Logger: so everything is logged to same place in correct order using access protections Related Patterns Many patterns such as the Abstract Factory, Builder, and Prototype pattern can be implemented using the Singleton","title":"Singleton"},{"location":"software_design/patterns/singleton/#singleton-pattern","text":"","title":"Singleton Pattern"},{"location":"software_design/patterns/singleton/#intent","text":"Ensure a class only ever has one instance and provide a global point of access","title":"Intent"},{"location":"software_design/patterns/singleton/#applicability","text":"When there must be exactly one instance of a class and it must be accessible from a well-known access point When the sole instance should be extensible by subclassing, and clients should be able to use an extended instance without modifying their code","title":"Applicability"},{"location":"software_design/patterns/singleton/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/singleton/#participants","text":"Singleton - defines an Instance operation (static member function) that lets clients access its unique instance","title":"Participants"},{"location":"software_design/patterns/singleton/#collaborations","text":"Clients access a singleton instance soley though the singleton's Instance operation","title":"Collaborations"},{"location":"software_design/patterns/singleton/#consequences","text":"(+) Reduces namespace pollution (+) easy to change and allow multiple instances (+) allow extension by subclassing (-) Same drawbacks of a global if misused (-) Implementation may be less efficient than a global variable (-) Concurrency pitfalls and communication overhead","title":"Consequences"},{"location":"software_design/patterns/singleton/#implementation","text":"Static instance operation Registering the singleton instance runtime though instead of compiletime Deleting singletons Not automatically destroyed by anything Usually use a shared pointer instead of raw pointer to deal with this Lifecycle is not as well defined as simple variables","title":"Implementation"},{"location":"software_design/patterns/singleton/#sample-code","text":"class Singleton { public: static Singleton& getInstance() { if (inst == nullptr) inst = new Singleton(); return *inst; } Singleton(Singleton const&) = delete; void operator=(Singleton const&) = delete; private: static Singleton* inst; Singleton() {} }; // must provide initial value for static variable outside of class Singleton* Singleton::inst = nullptr; Then a singleton would be created like: int main() { Singleton& one = Singleton::getInstance(); Singleton& two = Singleton::getInstance(); return 0; }","title":"Sample Code"},{"location":"software_design/patterns/singleton/#known-uses","text":"Hardware interface access Logger: so everything is logged to same place in correct order using access protections","title":"Known Uses"},{"location":"software_design/patterns/singleton/#related-patterns","text":"Many patterns such as the Abstract Factory, Builder, and Prototype pattern can be implemented using the Singleton","title":"Related Patterns"},{"location":"software_design/patterns/state/","text":"State Pattern Intent Allow an object to alter its behavior when its internal state changes. The object will appear to change its class. Applicability When an object's behavior depends on its state, and it must change its behavior at runtime depending on that state When several operatio onal structure that depends on the object's state When its beneficial to treat the object's state as an object that can vary independently of everything else Structure Participants Context (ex: TCPConnection) defines the interface of interest to clients maintains an instance of a ConcreteState subclass that defines the current state State (ex: TCPState) defines an interface the behavior associated with a particular state of the Context ConcreteState subclasses (ex: TCPEstablished, TCPListen, TCPClosed) each subclass implments a behavior associated with a state of the context Collaborations Context delegates state-specific request to the curent ConcreteState object A context may pass itsself as an argument to the State object handling the request so that the State object can access the context if necessary Context is the primary interface for clients so they don't have to deal with State objects directly Either Context or the ConcreteState subclasses can decide which state succeeds another and under what circumstances Consequences (+) Localizes state-specific behavior and partitions behavior for different states (+) Makes state transitions explicit (also protects context from incosistent states) (+) State objects can be shared if they have no instance variables (-) Can result in many subclasses that are hard to understand Implementation Who defines the state transitions? Context or the ConcreteState subclasses Consider using table-based alternatives Creating and destroying state objects: do you create and destroy them as needed or create them ahead of time and never destroy 1st option preferable when contexts change state frequently and it is unknown what states will be entered 2nd option preferable when state changes occur rapidly and want to avoid overhead of repeated creation/deletion Related Patterns The flyweight patterns explains when and how State objects can be shared State objects are often singletons Finite State Machine A state is a distinguishable, disjoint (one state at a time), condition that persists for a significant period of time (FSMs spend all their time in states) A transition is the changing from one state to another represent responses to events (from external or internal sources) A finite state machine is a model of computation with state behavior defined by a set of states and set of transitions Useful for mathematically proving safety in critical systems Ex: add states that are unsafe and prove they can't be reached","title":"State"},{"location":"software_design/patterns/state/#state-pattern","text":"","title":"State Pattern"},{"location":"software_design/patterns/state/#intent","text":"Allow an object to alter its behavior when its internal state changes. The object will appear to change its class.","title":"Intent"},{"location":"software_design/patterns/state/#applicability","text":"When an object's behavior depends on its state, and it must change its behavior at runtime depending on that state When several operatio onal structure that depends on the object's state When its beneficial to treat the object's state as an object that can vary independently of everything else","title":"Applicability"},{"location":"software_design/patterns/state/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/state/#participants","text":"Context (ex: TCPConnection) defines the interface of interest to clients maintains an instance of a ConcreteState subclass that defines the current state State (ex: TCPState) defines an interface the behavior associated with a particular state of the Context ConcreteState subclasses (ex: TCPEstablished, TCPListen, TCPClosed) each subclass implments a behavior associated with a state of the context","title":"Participants"},{"location":"software_design/patterns/state/#collaborations","text":"Context delegates state-specific request to the curent ConcreteState object A context may pass itsself as an argument to the State object handling the request so that the State object can access the context if necessary Context is the primary interface for clients so they don't have to deal with State objects directly Either Context or the ConcreteState subclasses can decide which state succeeds another and under what circumstances","title":"Collaborations"},{"location":"software_design/patterns/state/#consequences","text":"(+) Localizes state-specific behavior and partitions behavior for different states (+) Makes state transitions explicit (also protects context from incosistent states) (+) State objects can be shared if they have no instance variables (-) Can result in many subclasses that are hard to understand","title":"Consequences"},{"location":"software_design/patterns/state/#implementation","text":"Who defines the state transitions? Context or the ConcreteState subclasses Consider using table-based alternatives Creating and destroying state objects: do you create and destroy them as needed or create them ahead of time and never destroy 1st option preferable when contexts change state frequently and it is unknown what states will be entered 2nd option preferable when state changes occur rapidly and want to avoid overhead of repeated creation/deletion","title":"Implementation"},{"location":"software_design/patterns/state/#related-patterns","text":"The flyweight patterns explains when and how State objects can be shared State objects are often singletons","title":"Related Patterns"},{"location":"software_design/patterns/state/#finite-state-machine","text":"A state is a distinguishable, disjoint (one state at a time), condition that persists for a significant period of time (FSMs spend all their time in states) A transition is the changing from one state to another represent responses to events (from external or internal sources) A finite state machine is a model of computation with state behavior defined by a set of states and set of transitions Useful for mathematically proving safety in critical systems Ex: add states that are unsafe and prove they can't be reached","title":"Finite State Machine"},{"location":"software_design/patterns/strategy/","text":"Strategy Pattern Also known as Policy pattern Intent Define a family of algorithms, encapsulate each one, and make them interchangeable. Lets the algorithm vary independenty from the clients that use it Applicability When many related classes differ only in their behavior Strategy pattern lets us configure a class with one of many behaviors When you need different variants of an algorithm When an algorithm uses data structures that should not be exposed to clients Structure Participants Strategy - declares an interface common to all supported algorithms Context uses this interface to call the algorithm defined by a ConcreteStrategy ConcreteStrategy - implements a variant of the algortihm using the Strategy interface Context - configured with a ConcreteStrategy object and matinains a reference to a Strategy object Might define an interface that lets Strategy access its data Collaborations Strategy and Content interact to implement the chosen algorithm Context may pass all data required by the algorithm to the strategy when the algorithm is called Alternatively, context can pass itself as an argument to the strategy allowing the strategy to call it as required Context forwards requests from its clients to its strategy Clients usually create and pass a ConcreteStrategy object to the context and then only interact with the context from there on out Consequences (+) Families of related algorithms An altertive (+) Eliminate conditional statements for selecting the desired behavior Encapsulating different behaviors in seperate strategy classes eliminates conditional statements (+) Can provide different implementations (size/speed tradeoffs) of the same behavior (-) Clients must be aware of different strategies (-) Communication overhead between strategy and context Implementation How will the strategy have access to data it needs in the context? Can use templates to configure a class with a strategy if it can be selected at compile-time and doesn't need to be changed at runtime","title":"Strategy"},{"location":"software_design/patterns/strategy/#strategy-pattern","text":"Also known as Policy pattern","title":"Strategy Pattern"},{"location":"software_design/patterns/strategy/#intent","text":"Define a family of algorithms, encapsulate each one, and make them interchangeable. Lets the algorithm vary independenty from the clients that use it","title":"Intent"},{"location":"software_design/patterns/strategy/#applicability","text":"When many related classes differ only in their behavior Strategy pattern lets us configure a class with one of many behaviors When you need different variants of an algorithm When an algorithm uses data structures that should not be exposed to clients","title":"Applicability"},{"location":"software_design/patterns/strategy/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/strategy/#participants","text":"Strategy - declares an interface common to all supported algorithms Context uses this interface to call the algorithm defined by a ConcreteStrategy ConcreteStrategy - implements a variant of the algortihm using the Strategy interface Context - configured with a ConcreteStrategy object and matinains a reference to a Strategy object Might define an interface that lets Strategy access its data","title":"Participants"},{"location":"software_design/patterns/strategy/#collaborations","text":"Strategy and Content interact to implement the chosen algorithm Context may pass all data required by the algorithm to the strategy when the algorithm is called Alternatively, context can pass itself as an argument to the strategy allowing the strategy to call it as required Context forwards requests from its clients to its strategy Clients usually create and pass a ConcreteStrategy object to the context and then only interact with the context from there on out","title":"Collaborations"},{"location":"software_design/patterns/strategy/#consequences","text":"(+) Families of related algorithms An altertive (+) Eliminate conditional statements for selecting the desired behavior Encapsulating different behaviors in seperate strategy classes eliminates conditional statements (+) Can provide different implementations (size/speed tradeoffs) of the same behavior (-) Clients must be aware of different strategies (-) Communication overhead between strategy and context","title":"Consequences"},{"location":"software_design/patterns/strategy/#implementation","text":"How will the strategy have access to data it needs in the context? Can use templates to configure a class with a strategy if it can be selected at compile-time and doesn't need to be changed at runtime","title":"Implementation"},{"location":"software_design/patterns/temp/","text":"Pattern any aliases this pattern is known by Intent short description of the pattern and its purpose Applicability circumstances in which pattern applies Structure graphical representation of pattern using modified UML notation Participants participatnig classes/objects and their responsibilities Collaborations How participants cooperate to carry out their responsibilities Consequences results of application, benefits, and liabilities Implementation pitfalls, hints, techiques, plus language dependent issues Sample Code Known Uses Related Patterns","title":"Pattern"},{"location":"software_design/patterns/temp/#pattern","text":"any aliases this pattern is known by","title":"Pattern"},{"location":"software_design/patterns/temp/#intent","text":"short description of the pattern and its purpose","title":"Intent"},{"location":"software_design/patterns/temp/#applicability","text":"circumstances in which pattern applies","title":"Applicability"},{"location":"software_design/patterns/temp/#structure","text":"graphical representation of pattern using modified UML notation","title":"Structure"},{"location":"software_design/patterns/temp/#participants","text":"participatnig classes/objects and their responsibilities","title":"Participants"},{"location":"software_design/patterns/temp/#collaborations","text":"How participants cooperate to carry out their responsibilities","title":"Collaborations"},{"location":"software_design/patterns/temp/#consequences","text":"results of application, benefits, and liabilities","title":"Consequences"},{"location":"software_design/patterns/temp/#implementation","text":"pitfalls, hints, techiques, plus language dependent issues","title":"Implementation"},{"location":"software_design/patterns/temp/#sample-code","text":"","title":"Sample Code"},{"location":"software_design/patterns/temp/#known-uses","text":"","title":"Known Uses"},{"location":"software_design/patterns/temp/#related-patterns","text":"","title":"Related Patterns"},{"location":"software_design/patterns/template/","text":"Template Pattern Intent Define a skeleton of an algorithm in an operation, deferring some steps to subclasses. Subclasses redefine certain steps of an algorithm without changing the algorithm's structure. Applicability Used to implement the invariant parts of an algorithm once and then leave it to the subclasses to implement the behavior that can vary When common behavior among subclasses should be factored and localizied in a common class to avoid code duplication Structure Participants AbstractClass - defines abstract primitive operations that concrete subclasses define to implement steps of an algorithm Implements a template method defining the skelton of an algorithm by calling primitive operations as well as other necessary methods ConcreteClass - implements the primitive operations to carry out subclass-specific steps of the algorithm Collaborations ConcreteClass relies on AbstractClass to implement the invariant steps of the algorithm Consequences (+) Inverted control principle- parent calls the operations of a subclass (not the other way) Implementation Goal is to minimize the number of primitive operations a subclass must override to flesh out the algorithm Related Patterns Factory Methods are often called by template methods Template methods use inheritance to vary part of an algorithm while strategies use delegation to vary the entire algorithm","title":"Template"},{"location":"software_design/patterns/template/#template-pattern","text":"","title":"Template Pattern"},{"location":"software_design/patterns/template/#intent","text":"Define a skeleton of an algorithm in an operation, deferring some steps to subclasses. Subclasses redefine certain steps of an algorithm without changing the algorithm's structure.","title":"Intent"},{"location":"software_design/patterns/template/#applicability","text":"Used to implement the invariant parts of an algorithm once and then leave it to the subclasses to implement the behavior that can vary When common behavior among subclasses should be factored and localizied in a common class to avoid code duplication","title":"Applicability"},{"location":"software_design/patterns/template/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/template/#participants","text":"AbstractClass - defines abstract primitive operations that concrete subclasses define to implement steps of an algorithm Implements a template method defining the skelton of an algorithm by calling primitive operations as well as other necessary methods ConcreteClass - implements the primitive operations to carry out subclass-specific steps of the algorithm","title":"Participants"},{"location":"software_design/patterns/template/#collaborations","text":"ConcreteClass relies on AbstractClass to implement the invariant steps of the algorithm","title":"Collaborations"},{"location":"software_design/patterns/template/#consequences","text":"(+) Inverted control principle- parent calls the operations of a subclass (not the other way)","title":"Consequences"},{"location":"software_design/patterns/template/#implementation","text":"Goal is to minimize the number of primitive operations a subclass must override to flesh out the algorithm","title":"Implementation"},{"location":"software_design/patterns/template/#related-patterns","text":"Factory Methods are often called by template methods Template methods use inheritance to vary part of an algorithm while strategies use delegation to vary the entire algorithm","title":"Related Patterns"},{"location":"software_design/patterns/visitor/","text":"Visitor Pattern Intent Centralize operations on an object structure so that they can vary independently but still behave polymorphically. Lets you define a new operation without changing the classes of the elements on which it operates. Applicability when classes define many unrelated operations when relationships of objects in the structure rarely change, but the operations on them change often algorithms keep state that is updated during traversal Structure Participants Visitor - declares a Visit operation for each class of the ConcreteElement in the object structure ConcreteVisitor - implements each operation declared by Visitor and stores local state of the algorithm that is acculumated during the traversal of the object Element - defines an accept operation that takes a visitor as an argument (e.g. Node) ConcreteElement - implements an accept operation that takes a visitor as an argument (e.g. AddNode, SubtractNode, .. ) ObjectStructure- can enumerate its elements Collaborations Client that uses a visitor pattern must create a ConcreteVisitor object and then traverse the object structure, visiting each element with the visitor When an element is visited, it calls the visitor operation that corresponds to its class by supplying itself as an argument. to the operation Consequences (+) Flexibility: visitor algorithm(s) and object structure are independent Easy to add new operations (+) Localized functionality in the visitor subclass instance (related behaviors are grouped together in a visitor and unrelated behaviors have a seperate visitor) (-) Circular dependency between Visitor and Element interfaces (-) Visitor brittle to new ConcreteElement classes Implementation Double dispatch- operations that is executed depends on the kind of request and the types of two receivers (the Visitor's and the Element's) visitor pattern lets you add operations to classes without changing them by using this General interface to elements of object structure Who is responsbile for traversing the object structure? Related Patterns Visitors can be used to apply an operation over an object structure defined by a composite Visitor can be applied to do the interpretation in the Interpreter pattern","title":"Visitor"},{"location":"software_design/patterns/visitor/#visitor-pattern","text":"","title":"Visitor Pattern"},{"location":"software_design/patterns/visitor/#intent","text":"Centralize operations on an object structure so that they can vary independently but still behave polymorphically. Lets you define a new operation without changing the classes of the elements on which it operates.","title":"Intent"},{"location":"software_design/patterns/visitor/#applicability","text":"when classes define many unrelated operations when relationships of objects in the structure rarely change, but the operations on them change often algorithms keep state that is updated during traversal","title":"Applicability"},{"location":"software_design/patterns/visitor/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/visitor/#participants","text":"Visitor - declares a Visit operation for each class of the ConcreteElement in the object structure ConcreteVisitor - implements each operation declared by Visitor and stores local state of the algorithm that is acculumated during the traversal of the object Element - defines an accept operation that takes a visitor as an argument (e.g. Node) ConcreteElement - implements an accept operation that takes a visitor as an argument (e.g. AddNode, SubtractNode, .. ) ObjectStructure- can enumerate its elements","title":"Participants"},{"location":"software_design/patterns/visitor/#collaborations","text":"Client that uses a visitor pattern must create a ConcreteVisitor object and then traverse the object structure, visiting each element with the visitor When an element is visited, it calls the visitor operation that corresponds to its class by supplying itself as an argument. to the operation","title":"Collaborations"},{"location":"software_design/patterns/visitor/#consequences","text":"(+) Flexibility: visitor algorithm(s) and object structure are independent Easy to add new operations (+) Localized functionality in the visitor subclass instance (related behaviors are grouped together in a visitor and unrelated behaviors have a seperate visitor) (-) Circular dependency between Visitor and Element interfaces (-) Visitor brittle to new ConcreteElement classes","title":"Consequences"},{"location":"software_design/patterns/visitor/#implementation","text":"Double dispatch- operations that is executed depends on the kind of request and the types of two receivers (the Visitor's and the Element's) visitor pattern lets you add operations to classes without changing them by using this General interface to elements of object structure Who is responsbile for traversing the object structure?","title":"Implementation"},{"location":"software_design/patterns/visitor/#related-patterns","text":"Visitors can be used to apply an operation over an object structure defined by a composite Visitor can be applied to do the interpretation in the Interpreter pattern","title":"Related Patterns"},{"location":"system_design/docker/","text":"Docker Tool for running applications in an isolated environment Advantages : Same environment (Works on all computers if it works on docker) Sandbox Projects (Keeps them separate: no conflicts & better security) Simple to get started on others' projects Containers : the building blocks of Docker Stop by themselves when the main process finishes/exits (e.g. php or node.js dies) Should be one process per container b/c the life of the container is tied to that process Lightweight so lots of containers can be run on a computer at a time Docker vs. Virutal Machines Docker is less resource heavy than a virtual machine so it is faster than a VM Docker Images A Dockerfile is a file with a list of steps to create the image A Docker Image is a template for creating a desired environment and includes an OS, software, and application code A Docker Container is a running instance of a docker image Setting up a Docker Project Create Dockerfile in the root of the project/services directory (outside src folder) Where we will start from an existing image and build on top of it Can find thousands of images on Dockerhub Write the instructions to build your image in the Dockerfile FROM specifies the starting/base image to be downloaded from Dockerhub (Must be the 1st line) COPY copies the files from the first directory to the second location inside the image (specified in image's documentation) EXPOSE tells running containers to listen on the specified port FROM php:7-0-apache COPY src/ /var/www/html EXPOSE 80 Build the docker image from the terminal -t image-name specifies the image's name location is the path to the Dockerfile which is . if in the same directory docker build -t image-name location Run the docker container from the terminal -p 80:80 forwards port 80 in the host to port 80 in the container which was exposed in the docker file, allowing it to accept the request so that the code in the container can handle the request docker run -p 80:80 image-name Volumes One type allows the sharing of data between containers The other type allows the sharing of folders between the host and the container Useful for development since any changes to source code doesn't require a new image to be built and new container to be spun up Will need to rebuild the image to deploy it to somewhere else b/c volumes just give the ability for a container to see files on the host's filesystem, volumes don't change the image Building an image from a Dockerfile copies the src code so that it can be deployed elsewhere Mounting a volume is done when running the container Must use absolute paths of folders to be mounted docker run -p80:80 -v /Users/admin/project/src/:/var/www/html/ image-name Extra: FROM python:3-onbuild COPY . /usr/src/app CMD [\"python\",\"api.py\"] Docker Compose Lets you define all you services/containers in a configuration file With one command, all the containers can be spun up The configuration files save the hassel of writing the docker run commands for each container with all their specifications for volumes and ports Creates a virtual network for all the containers allowing communication for all the containers specified in the docker-compose file The host names of the containers match the service names defined in docker-compose.yml Setting up a Project w/ Docker Compose Create docker-compose.yml in root directory of project Write the configuration instructions in docker-compose.yml Directories are relative to where the docker-compose file is version specifies the version of docker-compose file format that you will be writing in (the formats are often updated so this helps specify what syntax you will be using) build takes ther relative path to the Dockerfile for a container volumes & ports allows you to list the volumes and ports for that docker image depends_on allows you to specify other services necessary for the service to run version: '3' services: product-service: build: ./product volumes: - ./product:/usr/src/app ports: - 5001:80 website: image: php:apache volumes: - ./website:/var/www/html ports: - 5000:80 depends_on: - product-service Spin up the containers running docker-compose up from the terminal from the directory where the docker-compose file is located Will build all the images and then run all the containers Running docker-compose up -d will spin up the containers in detached mode meaning you can continue working on the terminal run docker ps to see the status of the containers in detached mode run docker-compose stop to stop the containers in detached mode (ctr + c works in nondetached mode)","title":"Docker"},{"location":"system_design/docker/#docker","text":"Tool for running applications in an isolated environment Advantages : Same environment (Works on all computers if it works on docker) Sandbox Projects (Keeps them separate: no conflicts & better security) Simple to get started on others' projects Containers : the building blocks of Docker Stop by themselves when the main process finishes/exits (e.g. php or node.js dies) Should be one process per container b/c the life of the container is tied to that process Lightweight so lots of containers can be run on a computer at a time","title":"Docker"},{"location":"system_design/docker/#docker-vs-virutal-machines","text":"Docker is less resource heavy than a virtual machine so it is faster than a VM","title":"Docker vs. Virutal Machines"},{"location":"system_design/docker/#docker-images","text":"A Dockerfile is a file with a list of steps to create the image A Docker Image is a template for creating a desired environment and includes an OS, software, and application code A Docker Container is a running instance of a docker image","title":"Docker Images"},{"location":"system_design/docker/#setting-up-a-docker-project","text":"Create Dockerfile in the root of the project/services directory (outside src folder) Where we will start from an existing image and build on top of it Can find thousands of images on Dockerhub Write the instructions to build your image in the Dockerfile FROM specifies the starting/base image to be downloaded from Dockerhub (Must be the 1st line) COPY copies the files from the first directory to the second location inside the image (specified in image's documentation) EXPOSE tells running containers to listen on the specified port FROM php:7-0-apache COPY src/ /var/www/html EXPOSE 80 Build the docker image from the terminal -t image-name specifies the image's name location is the path to the Dockerfile which is . if in the same directory docker build -t image-name location Run the docker container from the terminal -p 80:80 forwards port 80 in the host to port 80 in the container which was exposed in the docker file, allowing it to accept the request so that the code in the container can handle the request docker run -p 80:80 image-name","title":"Setting up a Docker Project"},{"location":"system_design/docker/#volumes","text":"One type allows the sharing of data between containers The other type allows the sharing of folders between the host and the container Useful for development since any changes to source code doesn't require a new image to be built and new container to be spun up Will need to rebuild the image to deploy it to somewhere else b/c volumes just give the ability for a container to see files on the host's filesystem, volumes don't change the image Building an image from a Dockerfile copies the src code so that it can be deployed elsewhere Mounting a volume is done when running the container Must use absolute paths of folders to be mounted docker run -p80:80 -v /Users/admin/project/src/:/var/www/html/ image-name","title":"Volumes"},{"location":"system_design/docker/#extra","text":"FROM python:3-onbuild COPY . /usr/src/app CMD [\"python\",\"api.py\"]","title":"Extra:"},{"location":"system_design/docker/#docker-compose","text":"Lets you define all you services/containers in a configuration file With one command, all the containers can be spun up The configuration files save the hassel of writing the docker run commands for each container with all their specifications for volumes and ports Creates a virtual network for all the containers allowing communication for all the containers specified in the docker-compose file The host names of the containers match the service names defined in docker-compose.yml","title":"Docker Compose"},{"location":"system_design/docker/#setting-up-a-project-w-docker-compose","text":"Create docker-compose.yml in root directory of project Write the configuration instructions in docker-compose.yml Directories are relative to where the docker-compose file is version specifies the version of docker-compose file format that you will be writing in (the formats are often updated so this helps specify what syntax you will be using) build takes ther relative path to the Dockerfile for a container volumes & ports allows you to list the volumes and ports for that docker image depends_on allows you to specify other services necessary for the service to run version: '3' services: product-service: build: ./product volumes: - ./product:/usr/src/app ports: - 5001:80 website: image: php:apache volumes: - ./website:/var/www/html ports: - 5000:80 depends_on: - product-service Spin up the containers running docker-compose up from the terminal from the directory where the docker-compose file is located Will build all the images and then run all the containers Running docker-compose up -d will spin up the containers in detached mode meaning you can continue working on the terminal run docker ps to see the status of the containers in detached mode run docker-compose stop to stop the containers in detached mode (ctr + c works in nondetached mode)","title":"Setting up a Project w/ Docker Compose"},{"location":"system_design/microservices/","text":"Microservice Architectual Style: Developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanics, often an HTTP resource API Encourages modularity and seperation of concerns ability to horizontally scale and partition the workload Microservices contain many aspects in reality: Clients, Caches, and Databases are all included in a microservice in conjuction with the service itself Stateless Service: Not a cache or database Frequently accessed metadata no instance affinity Losing a node is not a big deal and can be easily fixed Stateful Service: Databases & caches Custom apps which holds lots of data Losing a node is a notable event and it might take hours to get it fixed","title":"Microservices"},{"location":"system_design/microservices/#microservice-architectual-style","text":"Developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanics, often an HTTP resource API Encourages modularity and seperation of concerns ability to horizontally scale and partition the workload Microservices contain many aspects in reality: Clients, Caches, and Databases are all included in a microservice in conjuction with the service itself","title":"Microservice Architectual Style:"},{"location":"system_design/microservices/#stateless-service","text":"Not a cache or database Frequently accessed metadata no instance affinity Losing a node is not a big deal and can be easily fixed","title":"Stateless Service:"},{"location":"system_design/microservices/#stateful-service","text":"Databases & caches Custom apps which holds lots of data Losing a node is a notable event and it might take hours to get it fixed","title":"Stateful Service:"},{"location":"web_dev/html-css/sass/","text":"Sass h1, h2, h3 { //Equivalent to h1.lg-heading &.lg-heading{} //Affects any nested elements w/in h1/h2/h3 with the specified class name .lg-heading{} } 6rem is 6 times the rem unit rem unit is a multiplier of the html tag's font size (default is 16 pixels) z-index is how close an element is to you (layering) //Allows the same transition to be used uniformly throughout a file @mixin easeOut(){ transition: all 0.5s ease-out; } a { //& uses the element it is nested in &:hover { color: $secondary-color @include easeOut(); } } vh & vw slice the screen into numerous slices of height and width 100 vh and 100 vw takes up whole screen 10 vh takes 10 slices of the height rgba(color,opacity) Sets the color and opacity for a property stands for red green blue alpha","title":"Sass"},{"location":"web_dev/html-css/sass/#sass","text":"h1, h2, h3 { //Equivalent to h1.lg-heading &.lg-heading{} //Affects any nested elements w/in h1/h2/h3 with the specified class name .lg-heading{} } 6rem is 6 times the rem unit rem unit is a multiplier of the html tag's font size (default is 16 pixels) z-index is how close an element is to you (layering) //Allows the same transition to be used uniformly throughout a file @mixin easeOut(){ transition: all 0.5s ease-out; } a { //& uses the element it is nested in &:hover { color: $secondary-color @include easeOut(); } } vh & vw slice the screen into numerous slices of height and width 100 vh and 100 vw takes up whole screen 10 vh takes 10 slices of the height rgba(color,opacity) Sets the color and opacity for a property stands for red green blue alpha","title":"Sass"},{"location":"web_dev/js/basics/","text":"What is JavaScript Dynamic Programming Language (operations done at run-time) E.g. Possible to change variable type or add new properties/methods to an object while the program is running Dynamically-Typed Language (Interpreter assigns variables a type at runtime based on its current value) Can provide interactivity on websites when applied to an html document Interpreted language (Doesn't have to be compiled) Runs on the client's computer/browser Object Based Prototype based instead of class based like Java Scripting language (lightweight) Uses for JavaScript: Put content in an HTML page on the fly Make webpages responsive Detect a user's browser and other info Create cookies Validate forms Create animations, slideshows, scrollers, etc Build apps w/ JS frameworks (ex: angularJS, reactJS, etc) Primitive Data Types Number- integers and decimals String- use single or double quotes (single preferred) .length property Boolean- true or false Null- intentional absence of a value represnted by null Undefined- absence of a valuae represented by undefined and is different than null Symbol- unique identifiers and useful in more complex coding Variables When declaring variables without assigning a value, their inital value is set to undefined Prior to ES6, var was the only keyword to declare variables ( More Info ) Variables declared using var are created before any code is executed in a process known as hoisting A variable's initial value is undefined and its actual value is intialized when the assignment statement is reached in execution This means a variable can be used before it is declared in the code since hoisting results in the equivalent of all variables being declared at the top In ES6, let and const were introduced let signals that the variable can be reassigned a different value const signals that the variable is a constant and cannot be reassigned Reassigning a const will throw a TypeError Variables can be transformed using mathematical asignment operators ( += , *= , /= ) and increment/decrement operators ( ++ , -- ) In ES6, we can insert (or interpolate) variables into strings using template literals Uses backticks instead of single/double quotes const myPet = 'armadillo'; console.log(`I own a pet ${myPet}`); // Output: I own a pet armadillo. typeof operator will return a string of the data type of the value to its right (e.g. typeof 'hello' returns 'string') Conditional Statements if (greeting) { console.log('Hello World!') } else if (goodbye){ console.log('Bye World!') } else { console.log('IDK') } Comparison Operators: < , > , <= , >= , === , !== Don't use == or != b/c types are not considered (Read More) Logical Operators: and && , or || , not: ! Values that are not explicitly true/false but evaluate to true/false are called truthy/falsy Falsy: 0 ,empty strings, null , undefined , NaN Truthy: If a variable's value exists, it evaluates to true in a logical comparison let defaultName; if (username) { defaultName = username; } else { defaultName = 'Stranger'; } //Is equivalent to let defaultName = username || 'Stranger'; //Stranger is the default if usrname is falsy (DNE) A ternary operator can condense if...else statements If the condition before the ? is true, the 1st expression executes. If false, the 2nd expression executes let isNight = true; if (isNight){ console.log('Sleep') } else { console.log('Wakeup') } //Is equivalent to: isNight ? console.log('Sleep') : console.log('Wakeup'); Supports switch statements for easier syntax than numerous else if statements let item = 'Pie' switch (item) { case 'bread': //Do something break; case 'muffin': //Do something else break; default: //Last resort break; } Functions Hoisting applies to functions as well, allowing a function to be called before it is defined in the code Not good code practice though A function declaration binds a function to an identifier like getUser() using the function keyword ES6 added the ability to use default parameters function calcArea(width,height=10){ return width * height; } Helper functions- functions called within another function Function Expressions are another way to define a function The anonymous functions created by function expressions are stored in variables so they can be referenced const is used to declare the variable const calcArea = function(width,height){ return width * height; } ES6 introduced arrow function syntax as a shorter way to write functions (Documentation) Remove the need to type out the function keyword Include parameters inside the parentheses and add an arrow => pointing to the function body const calcArea = (width,height) => { return width * height; } Conscise Body Arrow Functions Functions taking 1 parameter don't need parentheses but 0 & 2+ parameters require parentheses Pushing the function to the single-line eliminates need for curly braces and return statement (implicitly returns the contents of the block) const sumNums = num => num + num; //Will return num + num Scope Defines where variablescan be accessed or referenced In block scope variables are declared inside a block (set of {} ) and are called local variables Local variables can only be accessed within the block In global scope variables are declared outside of a block and are called global variables Global variables can be accessed by any code in the program The global namespace is where global variables go and it allows them to be accessed anywhere in the program Scope Pollution occurs when too many global variables exist in the global namespace or when variables are reused across different scopes Best practice not to define variables in the global scope to avoid this proble Scope variables as tightly as possible using block scope Makes code more legible & understandable since blocks organize the code into discrete sections Easier to maintain the modular code Saves memory b/c the variables are automatically erased after the block is finished running Arrays Documentation Can store any combination of data types( const list = ['Hello',45,true] ) Traditional array access & updates( list[0] and list[1] = 56 ) Can change the contents of an array declared with const but cannot reassign a new array or different value to the variable .length property just like strings .push(item) adds items to the end of an array & .unshift(item) adds items to the beginning ofan array Can take multipe arguments to add multiple items at a time Changes/mutates the original array (Also classified as a destructive array method since it changes the initial array ) .pop() removes the last item of an array & .shift() removes the first item (Neither take any arguments) Changes/mutates the original array .indexOf(item) returns the index of an item in the array (not found = -1) .slice() copies an array ( let copy = og.slice(); ) .splice(pos,n) removes the item at pos n times Changes the original array and returns the removed items as another array Pass-by-Reference is when an array is passed into a function, if the array is mutated inside the function, that change will be maintained outside the function as well Works because the argument to the function is just a reference to where the variable is stored in memory, allowing the memory of the array to be changed Nested arrays can be accessed by chaining on more bracket notation with index values (e.g. arry[1][3] ) let nums = [1,5,7,3,9]; let num2 = new Array(1,3,6,'Hi',3,7); nums.push(10); nums.length num2.sort() //Strings come last nums.reverse() //Reverses order Loops for loop consists of an initialization, stopping condition, and iteration statement Do while loops run a piece of code then check the condition compared to while loops that check the condition and then run the code Do while loops run at least once whether or not the condition evaluates to true break keyword allows programs to break out of a loop within the loop's block for (let i = 0; i < 5, i++){} for (let i = items.length - 1; i >= 0; i--){} //Reverse through a list while (condition) {} //Avoid infinite loops! do {} while (condition) Higher-Order Functions Functions that accept other functions as arguments and/or return functions as output Callback Functions are functions that are passed as arguments and invoked Get called during the excution of the higher-order function To pass a callback function as ana argument, the name is typed w/o the parentheses so that the reference to the function is passed, not the value from invoking the function Anonymous functions can be passed as arguments as well (they are defined in the higher-order function's call) Adds another level of abstraction to a program to make it more modular & easier to read/debug JS functions are first class objects meaning that like other objects, JS functions can have properties and methods Functions are special b/c they can be invoked and treated like any other type of data Every JS function is actually a Function object ( Documentation ) Iterators These iterators take a callback function as an argument and execute the callback function for each element in the array .forEach() const fruits = ['mango', 'papaya', 'pineapple', 'apple']; fruits.forEach(elem=>console.log(`I want to eat a ${elem}`)); //I want to eat a mango...papaya...etc. .map() returns a new array unlike forEach which mutates the original array const nums = [1,2,3,4]; const bigNums = nums.map(number => number * 10); //[10,20,30,40] .filter() takes a boolean callback function (returns T/F) as an argument. Returns a new array const favoriteWords = ['nostalgia', 'hyperbole', 'fervent', 'esoteric', 'serene']; const longFavoriteWords = favoriteWords.filter(elem=> { return elem.length > 7; }); .findIndex() Returns the index of the first element that evaluates to true in the boolean callback function No element that satisfies the callback returns -1 ``` javascript const jumbledNums = [123, 25, 78, 5, 9]; const lessThanTen = jumbledNums.findIndex(num => { return num < 10; }); //3 - `.reduce()` returns a single value after iterating through the elements of an array (Consists of an accumulator and iterator) - The optional 2nd argument sets the initial value for accumulator ```javascript const nums = [1,2,3,4]; const summedNums = nums.reduce((accumulator,currentVal) => { console.log('The value of accumulator: ', accumulator); console.log('The value of currentValue: ', currentValue); return accumulator + currentVal; },100); //110","title":"Basics"},{"location":"web_dev/js/basics/#what-is-javascript","text":"Dynamic Programming Language (operations done at run-time) E.g. Possible to change variable type or add new properties/methods to an object while the program is running Dynamically-Typed Language (Interpreter assigns variables a type at runtime based on its current value) Can provide interactivity on websites when applied to an html document Interpreted language (Doesn't have to be compiled) Runs on the client's computer/browser Object Based Prototype based instead of class based like Java Scripting language (lightweight)","title":"What is JavaScript"},{"location":"web_dev/js/basics/#uses-for-javascript","text":"Put content in an HTML page on the fly Make webpages responsive Detect a user's browser and other info Create cookies Validate forms Create animations, slideshows, scrollers, etc Build apps w/ JS frameworks (ex: angularJS, reactJS, etc)","title":"Uses for JavaScript:"},{"location":"web_dev/js/basics/#primitive-data-types","text":"Number- integers and decimals String- use single or double quotes (single preferred) .length property Boolean- true or false Null- intentional absence of a value represnted by null Undefined- absence of a valuae represented by undefined and is different than null Symbol- unique identifiers and useful in more complex coding","title":"Primitive Data Types"},{"location":"web_dev/js/basics/#variables","text":"When declaring variables without assigning a value, their inital value is set to undefined Prior to ES6, var was the only keyword to declare variables ( More Info ) Variables declared using var are created before any code is executed in a process known as hoisting A variable's initial value is undefined and its actual value is intialized when the assignment statement is reached in execution This means a variable can be used before it is declared in the code since hoisting results in the equivalent of all variables being declared at the top In ES6, let and const were introduced let signals that the variable can be reassigned a different value const signals that the variable is a constant and cannot be reassigned Reassigning a const will throw a TypeError Variables can be transformed using mathematical asignment operators ( += , *= , /= ) and increment/decrement operators ( ++ , -- ) In ES6, we can insert (or interpolate) variables into strings using template literals Uses backticks instead of single/double quotes const myPet = 'armadillo'; console.log(`I own a pet ${myPet}`); // Output: I own a pet armadillo. typeof operator will return a string of the data type of the value to its right (e.g. typeof 'hello' returns 'string')","title":"Variables"},{"location":"web_dev/js/basics/#conditional-statements","text":"if (greeting) { console.log('Hello World!') } else if (goodbye){ console.log('Bye World!') } else { console.log('IDK') } Comparison Operators: < , > , <= , >= , === , !== Don't use == or != b/c types are not considered (Read More) Logical Operators: and && , or || , not: ! Values that are not explicitly true/false but evaluate to true/false are called truthy/falsy Falsy: 0 ,empty strings, null , undefined , NaN Truthy: If a variable's value exists, it evaluates to true in a logical comparison let defaultName; if (username) { defaultName = username; } else { defaultName = 'Stranger'; } //Is equivalent to let defaultName = username || 'Stranger'; //Stranger is the default if usrname is falsy (DNE) A ternary operator can condense if...else statements If the condition before the ? is true, the 1st expression executes. If false, the 2nd expression executes let isNight = true; if (isNight){ console.log('Sleep') } else { console.log('Wakeup') } //Is equivalent to: isNight ? console.log('Sleep') : console.log('Wakeup'); Supports switch statements for easier syntax than numerous else if statements let item = 'Pie' switch (item) { case 'bread': //Do something break; case 'muffin': //Do something else break; default: //Last resort break; }","title":"Conditional Statements"},{"location":"web_dev/js/basics/#functions","text":"Hoisting applies to functions as well, allowing a function to be called before it is defined in the code Not good code practice though A function declaration binds a function to an identifier like getUser() using the function keyword ES6 added the ability to use default parameters function calcArea(width,height=10){ return width * height; } Helper functions- functions called within another function Function Expressions are another way to define a function The anonymous functions created by function expressions are stored in variables so they can be referenced const is used to declare the variable const calcArea = function(width,height){ return width * height; } ES6 introduced arrow function syntax as a shorter way to write functions (Documentation) Remove the need to type out the function keyword Include parameters inside the parentheses and add an arrow => pointing to the function body const calcArea = (width,height) => { return width * height; } Conscise Body Arrow Functions Functions taking 1 parameter don't need parentheses but 0 & 2+ parameters require parentheses Pushing the function to the single-line eliminates need for curly braces and return statement (implicitly returns the contents of the block) const sumNums = num => num + num; //Will return num + num","title":"Functions"},{"location":"web_dev/js/basics/#scope","text":"Defines where variablescan be accessed or referenced In block scope variables are declared inside a block (set of {} ) and are called local variables Local variables can only be accessed within the block In global scope variables are declared outside of a block and are called global variables Global variables can be accessed by any code in the program The global namespace is where global variables go and it allows them to be accessed anywhere in the program Scope Pollution occurs when too many global variables exist in the global namespace or when variables are reused across different scopes Best practice not to define variables in the global scope to avoid this proble Scope variables as tightly as possible using block scope Makes code more legible & understandable since blocks organize the code into discrete sections Easier to maintain the modular code Saves memory b/c the variables are automatically erased after the block is finished running","title":"Scope"},{"location":"web_dev/js/basics/#arrays","text":"Documentation Can store any combination of data types( const list = ['Hello',45,true] ) Traditional array access & updates( list[0] and list[1] = 56 ) Can change the contents of an array declared with const but cannot reassign a new array or different value to the variable .length property just like strings .push(item) adds items to the end of an array & .unshift(item) adds items to the beginning ofan array Can take multipe arguments to add multiple items at a time Changes/mutates the original array (Also classified as a destructive array method since it changes the initial array ) .pop() removes the last item of an array & .shift() removes the first item (Neither take any arguments) Changes/mutates the original array .indexOf(item) returns the index of an item in the array (not found = -1) .slice() copies an array ( let copy = og.slice(); ) .splice(pos,n) removes the item at pos n times Changes the original array and returns the removed items as another array Pass-by-Reference is when an array is passed into a function, if the array is mutated inside the function, that change will be maintained outside the function as well Works because the argument to the function is just a reference to where the variable is stored in memory, allowing the memory of the array to be changed Nested arrays can be accessed by chaining on more bracket notation with index values (e.g. arry[1][3] ) let nums = [1,5,7,3,9]; let num2 = new Array(1,3,6,'Hi',3,7); nums.push(10); nums.length num2.sort() //Strings come last nums.reverse() //Reverses order","title":"Arrays"},{"location":"web_dev/js/basics/#loops","text":"for loop consists of an initialization, stopping condition, and iteration statement Do while loops run a piece of code then check the condition compared to while loops that check the condition and then run the code Do while loops run at least once whether or not the condition evaluates to true break keyword allows programs to break out of a loop within the loop's block for (let i = 0; i < 5, i++){} for (let i = items.length - 1; i >= 0; i--){} //Reverse through a list while (condition) {} //Avoid infinite loops! do {} while (condition)","title":"Loops"},{"location":"web_dev/js/basics/#higher-order-functions","text":"Functions that accept other functions as arguments and/or return functions as output Callback Functions are functions that are passed as arguments and invoked Get called during the excution of the higher-order function To pass a callback function as ana argument, the name is typed w/o the parentheses so that the reference to the function is passed, not the value from invoking the function Anonymous functions can be passed as arguments as well (they are defined in the higher-order function's call) Adds another level of abstraction to a program to make it more modular & easier to read/debug JS functions are first class objects meaning that like other objects, JS functions can have properties and methods Functions are special b/c they can be invoked and treated like any other type of data Every JS function is actually a Function object ( Documentation )","title":"Higher-Order Functions"},{"location":"web_dev/js/basics/#iterators","text":"These iterators take a callback function as an argument and execute the callback function for each element in the array .forEach() const fruits = ['mango', 'papaya', 'pineapple', 'apple']; fruits.forEach(elem=>console.log(`I want to eat a ${elem}`)); //I want to eat a mango...papaya...etc. .map() returns a new array unlike forEach which mutates the original array const nums = [1,2,3,4]; const bigNums = nums.map(number => number * 10); //[10,20,30,40] .filter() takes a boolean callback function (returns T/F) as an argument. Returns a new array const favoriteWords = ['nostalgia', 'hyperbole', 'fervent', 'esoteric', 'serene']; const longFavoriteWords = favoriteWords.filter(elem=> { return elem.length > 7; }); .findIndex() Returns the index of the first element that evaluates to true in the boolean callback function No element that satisfies the callback returns -1 ``` javascript const jumbledNums = [123, 25, 78, 5, 9]; const lessThanTen = jumbledNums.findIndex(num => { return num < 10; }); //3 - `.reduce()` returns a single value after iterating through the elements of an array (Consists of an accumulator and iterator) - The optional 2nd argument sets the initial value for accumulator ```javascript const nums = [1,2,3,4]; const summedNums = nums.reduce((accumulator,currentVal) => { console.log('The value of accumulator: ', accumulator); console.log('The value of currentValue: ', currentValue); return accumulator + currentVal; },100); //110","title":"Iterators"},{"location":"web_dev/js/browser_compatibility/","text":"Browser Compatibility Some ES6 features, like modules, are still not supported by most web browsers caniuse.com is the bset resource for finding browser compatiblity info on a feature-by-feature basis ES5 updated to ES6: Better readability and requires fewer characters Fixes ES5 bugs common from the syntax Syntax more similar to other OOP languages Ecma (Organization in charge of JS standards) made ES6 backwards compatible meaning it can be mapped to ES5 Backwards compatibility helps decrease browser compatibility issues Babel is a library that transpiles ES6 to ES5 JavaScript Transpilation- the process of converting one programming language to another babel-cli - Node package w/ command line tools for Babel babel-preset-env - Node package w/ ES6+ to ES5 syntax mapping information Transpilation (Detailed Notes) Setup the project using the specified file structure and npm bash project |_ src |___ main.js |_ package.json Run npm init to create a package.json file in the root directory that contains info about the current project: Metdata- Project Title, Description, Authors, etc List of Required Node Packages- npm downloads the packages in this list when other developers want to run your project Key-value pairs for command line scripts- can use npm to run these shorthand scripts to perform some process Install necessary Babel packages using node package manager (npm) bash npm install babel-cli -D npm install babel-preset-env -D install creates a folder called node_modules and copies the package files to it while also installing all the dependencies for the given package -D flag instructs npm to add each package to a property called devDependencies in package.json devDependencies allows other developers to run your project without installing each package separately Instead they can run npm install to instruct npm to look inside package.json and download all the packages listed in devDependencies New Directory Structure: ( ... indicates 100+ packages that npm installed) bash project |_ node_modules |___ .bin |___ ... |_ src |___ main.js |_ package.json Specify the initial JS version in .babelrc Run touch .babelrc in the root directory to create the file Define the preset for the source JS file ( [\"env\"] insrtucts Babel to transpile any code from ES6+) { \"presets\": [\"env\"] } Specify a script in package.json that initiates ES6+ to ES5 transpilation In the \"scripts\" object, add a property called \"build\" below \"test\" \"build\" 's value ( babel src -d lib ) is a command line method that trasnpiles ES6+ code to ES5 babel \u2014 The Babel command call responsible for transpiling code. src \u2014 Instructs Babel to transpile all JavaScript code inside the src directory. -d \u2014 Instructs Babel to write the transpiled code to a directory. lib \u2014 Babel writes the transpiled code to a directory called lib . json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"build\": \"babel src -d lib\" }, ... Type npm run build to build the transpile the code to ES5 where it is stored in a directory called lib as a file with the same name as the original file (./lib/main.js) The command runs the build script in package.json The one command transpiles all code in src - good for larger projects with numerous JS files Transpilation Process (Summary): Initialize your project using npm init and create a directory called src Install babel dependencies by running npm install babel-cli -D npm install babel-preset-env -D Create a .babelrc file inside your project and add the following code inside it: { \"presets\": [\"env\"] } Add the following script to your scripts object in package.json: json \"build\": \"babel src -d lib\" Run npm run build whenever you want to transpile your code from your src to lib directories","title":"Browser Compatibility"},{"location":"web_dev/js/browser_compatibility/#browser-compatibility","text":"Some ES6 features, like modules, are still not supported by most web browsers caniuse.com is the bset resource for finding browser compatiblity info on a feature-by-feature basis ES5 updated to ES6: Better readability and requires fewer characters Fixes ES5 bugs common from the syntax Syntax more similar to other OOP languages Ecma (Organization in charge of JS standards) made ES6 backwards compatible meaning it can be mapped to ES5 Backwards compatibility helps decrease browser compatibility issues Babel is a library that transpiles ES6 to ES5 JavaScript Transpilation- the process of converting one programming language to another babel-cli - Node package w/ command line tools for Babel babel-preset-env - Node package w/ ES6+ to ES5 syntax mapping information","title":"Browser Compatibility"},{"location":"web_dev/js/browser_compatibility/#transpilation-detailed-notes","text":"Setup the project using the specified file structure and npm bash project |_ src |___ main.js |_ package.json Run npm init to create a package.json file in the root directory that contains info about the current project: Metdata- Project Title, Description, Authors, etc List of Required Node Packages- npm downloads the packages in this list when other developers want to run your project Key-value pairs for command line scripts- can use npm to run these shorthand scripts to perform some process Install necessary Babel packages using node package manager (npm) bash npm install babel-cli -D npm install babel-preset-env -D install creates a folder called node_modules and copies the package files to it while also installing all the dependencies for the given package -D flag instructs npm to add each package to a property called devDependencies in package.json devDependencies allows other developers to run your project without installing each package separately Instead they can run npm install to instruct npm to look inside package.json and download all the packages listed in devDependencies New Directory Structure: ( ... indicates 100+ packages that npm installed) bash project |_ node_modules |___ .bin |___ ... |_ src |___ main.js |_ package.json Specify the initial JS version in .babelrc Run touch .babelrc in the root directory to create the file Define the preset for the source JS file ( [\"env\"] insrtucts Babel to transpile any code from ES6+) { \"presets\": [\"env\"] } Specify a script in package.json that initiates ES6+ to ES5 transpilation In the \"scripts\" object, add a property called \"build\" below \"test\" \"build\" 's value ( babel src -d lib ) is a command line method that trasnpiles ES6+ code to ES5 babel \u2014 The Babel command call responsible for transpiling code. src \u2014 Instructs Babel to transpile all JavaScript code inside the src directory. -d \u2014 Instructs Babel to write the transpiled code to a directory. lib \u2014 Babel writes the transpiled code to a directory called lib . json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"build\": \"babel src -d lib\" }, ... Type npm run build to build the transpile the code to ES5 where it is stored in a directory called lib as a file with the same name as the original file (./lib/main.js) The command runs the build script in package.json The one command transpiles all code in src - good for larger projects with numerous JS files","title":"Transpilation (Detailed Notes)"},{"location":"web_dev/js/browser_compatibility/#transpilation-process-summary","text":"Initialize your project using npm init and create a directory called src Install babel dependencies by running npm install babel-cli -D npm install babel-preset-env -D Create a .babelrc file inside your project and add the following code inside it: { \"presets\": [\"env\"] } Add the following script to your scripts object in package.json: json \"build\": \"babel src -d lib\" Run npm run build whenever you want to transpile your code from your src to lib directories","title":"Transpilation Process (Summary):"},{"location":"web_dev/js/classes/","text":"Classes Constructor JavaScript calls the constructor() method every time it creates a new instance of a class. class Dog { constructor(name) { this.name = name; this.behavior = 0; } } Instances An instance is an object that contains the property names and methods of a class, but with unique property values. const halley = new Dog('Halley'); console.log(halley.name); // Output: 'Halley' Methods Class method and getter syntax is the same as it is for objects except you can not include commas between methods. class Dog { constructor(name) { this._name = name; } get name() { return this._name; } incrementBehavior() { this._behavior++; } } Static Methods aren't available to instances and can only be called by the class Calling static methods from an instance throws a TypeError class Animal { constructor(name) { this._name = name; this._behavior = 0; } static generateName() { const names = ['Angel', 'Spike', 'Buffy', 'Willow', 'Tara']; const randomNumber = Math.floor(Math.random()*5); return names[randomNumber]; } } console.log(Animal.generateName()); // returns a name Inheritance Create a parent class (also known as a superclass) with properties and methods that multiple child classes (also known as subclasses) share Child classes inherit the properties and methods from their parent class Benefits (time saved, readability, efficiency) grow as the number and size of subclasses increase Adheres to DRY best practice JS uses extends keyword to extend the properties/methods of one clas to a subclass super() Calls the constructor of the parent class (with the appropriate parameters if necessary) super() must always be called before this can be used to define new properties (ReferenceError will be thrown otherwise) Best Practice: Always call super() on the first line of subclass constructors class Animal { constructor(name) { this._name = name; this._behavior = 0; } get name() { return this._name; } get behavior() { return this._behavior; } } class Cat extends Animal { constructor(name, usesLitter) { super(name); this._usesLitter = usesLitter; } }","title":"Classes"},{"location":"web_dev/js/classes/#classes","text":"","title":"Classes"},{"location":"web_dev/js/classes/#constructor","text":"JavaScript calls the constructor() method every time it creates a new instance of a class. class Dog { constructor(name) { this.name = name; this.behavior = 0; } }","title":"Constructor"},{"location":"web_dev/js/classes/#instances","text":"An instance is an object that contains the property names and methods of a class, but with unique property values. const halley = new Dog('Halley'); console.log(halley.name); // Output: 'Halley'","title":"Instances"},{"location":"web_dev/js/classes/#methods","text":"Class method and getter syntax is the same as it is for objects except you can not include commas between methods. class Dog { constructor(name) { this._name = name; } get name() { return this._name; } incrementBehavior() { this._behavior++; } } Static Methods aren't available to instances and can only be called by the class Calling static methods from an instance throws a TypeError class Animal { constructor(name) { this._name = name; this._behavior = 0; } static generateName() { const names = ['Angel', 'Spike', 'Buffy', 'Willow', 'Tara']; const randomNumber = Math.floor(Math.random()*5); return names[randomNumber]; } } console.log(Animal.generateName()); // returns a name","title":"Methods"},{"location":"web_dev/js/classes/#inheritance","text":"Create a parent class (also known as a superclass) with properties and methods that multiple child classes (also known as subclasses) share Child classes inherit the properties and methods from their parent class Benefits (time saved, readability, efficiency) grow as the number and size of subclasses increase Adheres to DRY best practice JS uses extends keyword to extend the properties/methods of one clas to a subclass super() Calls the constructor of the parent class (with the appropriate parameters if necessary) super() must always be called before this can be used to define new properties (ReferenceError will be thrown otherwise) Best Practice: Always call super() on the first line of subclass constructors class Animal { constructor(name) { this._name = name; this._behavior = 0; } get name() { return this._name; } get behavior() { return this._behavior; } } class Cat extends Animal { constructor(name, usesLitter) { super(name); this._usesLitter = usesLitter; } }","title":"Inheritance"},{"location":"web_dev/js/jQuery/","text":"jQuery An easy to learn JS library that simplifies JS web programming Wraps common, lengthy tasks into methods that can be called in a single line Simplifies complicated JS things such as AJAX calls & DOM manipulation Contains Following Features: HTML/DOM manipulation CSS manipulation HTML event methods Effects and animations AJAX Utilities Many other plugins for other tasks Add to Webpages: Download production or development version from jQuery.com into project folder and add it to your project file <head> <script src=\"jquery-3.5.1.min.js\"></script> </head> OR include it from a CDN (Content Delivery Network) such as google: Loaded from users cache when they visit your site and it uses google's CDN (faster loading) <head> <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script> </head> Syntax Tailor-made for selecting HTML elements and performing some action on the element(s). Basic syntax is: $(selector).action() A $ sign to define/access jQuery A (selector) to \"query (or find)\" HTML elements A jQuery action() to be performed on the element(s) Document Ready Event All jQuery methods are inside a document ready event to prevent any jQuery code from running before the document is finished loading (is ready) Actions on the DOM can fail if document is fully loaded before code is executed $(document).ready(function(){ // jQuery methods go here.. }); //or the shorter version: $(function(){ // jQuery methods go here... }); Selectors Allow you to select and manipulate HTML elements Used to \"find\" (or select) HTML elements based on their name, id, classes, types, attributes, values of attributes and much more. Based on the existing CSS Selectors andit has some own custom selectors Element: $(\"p\") Id: $(#ex_id) Class: $(\".ex_class\")","title":"jQuery"},{"location":"web_dev/js/jQuery/#jquery","text":"An easy to learn JS library that simplifies JS web programming Wraps common, lengthy tasks into methods that can be called in a single line Simplifies complicated JS things such as AJAX calls & DOM manipulation Contains Following Features: HTML/DOM manipulation CSS manipulation HTML event methods Effects and animations AJAX Utilities Many other plugins for other tasks","title":"jQuery"},{"location":"web_dev/js/jQuery/#add-to-webpages","text":"Download production or development version from jQuery.com into project folder and add it to your project file <head> <script src=\"jquery-3.5.1.min.js\"></script> </head> OR include it from a CDN (Content Delivery Network) such as google: Loaded from users cache when they visit your site and it uses google's CDN (faster loading) <head> <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script> </head>","title":"Add to Webpages:"},{"location":"web_dev/js/jQuery/#syntax","text":"Tailor-made for selecting HTML elements and performing some action on the element(s). Basic syntax is: $(selector).action() A $ sign to define/access jQuery A (selector) to \"query (or find)\" HTML elements A jQuery action() to be performed on the element(s)","title":"Syntax"},{"location":"web_dev/js/jQuery/#document-ready-event","text":"All jQuery methods are inside a document ready event to prevent any jQuery code from running before the document is finished loading (is ready) Actions on the DOM can fail if document is fully loaded before code is executed $(document).ready(function(){ // jQuery methods go here.. }); //or the shorter version: $(function(){ // jQuery methods go here... });","title":"Document Ready Event"},{"location":"web_dev/js/jQuery/#selectors","text":"Allow you to select and manipulate HTML elements Used to \"find\" (or select) HTML elements based on their name, id, classes, types, attributes, values of attributes and much more. Based on the existing CSS Selectors andit has some own custom selectors Element: $(\"p\") Id: $(#ex_id) Class: $(\".ex_class\")","title":"Selectors"},{"location":"web_dev/js/modules/","text":"Modules Overview Reusable pieces of code that can be exported from one program and imported for use in another program Benefits of Using Modules: Find, fix, and debug code more easily Reuse and recycle logic defined in different parts of our application Keep information private and protected from other modules Prevent pollution of the global namespace and potential naming collisions, by cautiously selecting variables and behavior we load into a program Two Ways of Implementing Modules: Node.js's module.exports and require() syntax ES6 import / export syntax Node.js Syntax module.exports Every JavaScript file run in Node has a local module object with an exports property used to define what should be exported from the file The pattern we use to export modules: Create an object to represent the module. Add properties or methods to the module object. Export the module with module.exports . let Menu = {}; Menu.specialty = \"Roasted Beet Burger with Mint Sauce\"; module.exports = Menu; Can also wrap any collection of data/functions in an object and export the object (Equivalent to above block) module.exports = { specialty: \"Roasted Beet Burger with Mint Sauce\", getSpecialty: function() { return this.specialty; } }; require() Used in Node to import the exported module into another file so its defined behavior can be used Takes a file path argument pointing to the original module file The .js extension in the file path is optional and will be assumed if not included The pattern to import a module: Import the module with require() and assign it to a local variable. Use the module and its properties within a program. const Menu = require('./menu.js'); function placeOrder() { console.log('My order is: ' + Menu.specialty); } placeOrder(); ES6 Syntax export default Works similarly to the module.exports syntax, allowing us to export 1 module per file Not supported in Node.js so this syntax is used for front-end development let Menu = {}; export default Menu; import The name following import specifies the name of the variable to store the default export in When specifying the path name after from , .js is left off because it specifically refers to the name of the file w/o the extension of the file when dealing with local files import Menu from './menu'; Named Exports Allow us to export data through the use of variables let specialty = ''; function isVegetarian() {}; export { specialty, isVegetarian }; Named exports can have their name changed when exported using as let specialty = ''; let isVegetarian = function() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; Variables can be exported as soon as they are declared by placing export in front of variable declarations export let specialty = ''; export function isVegetarian() {}; Named exports and default exports can be used together Best not to use both methods but can occasionally be useful Ex: If you suspect developers may only be interested in importing a specific function and won\u2019t need to import the entire default export. let specialty = ''; function isVegetarian() {}; function isGlutenFree() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; export default isGlutenFree; Named Imports To import objects stored in a variable, we use the import keyword and include the variables in a set of {} Don't have to import all the variables exported in the other module import { specialty, isVegetarian } from './menu'; console.log(specialty); Named exports can have their name changed when exported/imported using as import {speciality as chefsSpecial, isVegetarian as isVeg} from './menu'; //or import * as Carte from './menu'; Carte.speciality; Carte.isVegetarian(); Named imports and normal imports can be used together import { specialty, isVegetarian } from './menu'; import GlutenFree from './menu';","title":"Modules"},{"location":"web_dev/js/modules/#modules-overview","text":"Reusable pieces of code that can be exported from one program and imported for use in another program Benefits of Using Modules: Find, fix, and debug code more easily Reuse and recycle logic defined in different parts of our application Keep information private and protected from other modules Prevent pollution of the global namespace and potential naming collisions, by cautiously selecting variables and behavior we load into a program Two Ways of Implementing Modules: Node.js's module.exports and require() syntax ES6 import / export syntax","title":"Modules Overview"},{"location":"web_dev/js/modules/#nodejs-syntax","text":"","title":"Node.js Syntax"},{"location":"web_dev/js/modules/#moduleexports","text":"Every JavaScript file run in Node has a local module object with an exports property used to define what should be exported from the file The pattern we use to export modules: Create an object to represent the module. Add properties or methods to the module object. Export the module with module.exports . let Menu = {}; Menu.specialty = \"Roasted Beet Burger with Mint Sauce\"; module.exports = Menu; Can also wrap any collection of data/functions in an object and export the object (Equivalent to above block) module.exports = { specialty: \"Roasted Beet Burger with Mint Sauce\", getSpecialty: function() { return this.specialty; } };","title":"module.exports"},{"location":"web_dev/js/modules/#require","text":"Used in Node to import the exported module into another file so its defined behavior can be used Takes a file path argument pointing to the original module file The .js extension in the file path is optional and will be assumed if not included The pattern to import a module: Import the module with require() and assign it to a local variable. Use the module and its properties within a program. const Menu = require('./menu.js'); function placeOrder() { console.log('My order is: ' + Menu.specialty); } placeOrder();","title":"require()"},{"location":"web_dev/js/modules/#es6-syntax","text":"","title":"ES6 Syntax"},{"location":"web_dev/js/modules/#export-default","text":"Works similarly to the module.exports syntax, allowing us to export 1 module per file Not supported in Node.js so this syntax is used for front-end development let Menu = {}; export default Menu;","title":"export default"},{"location":"web_dev/js/modules/#import","text":"The name following import specifies the name of the variable to store the default export in When specifying the path name after from , .js is left off because it specifically refers to the name of the file w/o the extension of the file when dealing with local files import Menu from './menu';","title":"import"},{"location":"web_dev/js/modules/#named-exports","text":"Allow us to export data through the use of variables let specialty = ''; function isVegetarian() {}; export { specialty, isVegetarian }; Named exports can have their name changed when exported using as let specialty = ''; let isVegetarian = function() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; Variables can be exported as soon as they are declared by placing export in front of variable declarations export let specialty = ''; export function isVegetarian() {}; Named exports and default exports can be used together Best not to use both methods but can occasionally be useful Ex: If you suspect developers may only be interested in importing a specific function and won\u2019t need to import the entire default export. let specialty = ''; function isVegetarian() {}; function isGlutenFree() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; export default isGlutenFree;","title":"Named Exports"},{"location":"web_dev/js/modules/#named-imports","text":"To import objects stored in a variable, we use the import keyword and include the variables in a set of {} Don't have to import all the variables exported in the other module import { specialty, isVegetarian } from './menu'; console.log(specialty); Named exports can have their name changed when exported/imported using as import {speciality as chefsSpecial, isVegetarian as isVeg} from './menu'; //or import * as Carte from './menu'; Carte.speciality; Carte.isVegetarian(); Named imports and normal imports can be used together import { specialty, isVegetarian } from './menu'; import GlutenFree from './menu';","title":"Named Imports"},{"location":"web_dev/js/objects/","text":"Objects Are passed by reference meaning the variable assigned to an object points to the space in memory holding the object when passed into a function as an argument Functions that change object properties actually mutate the object permanently even when assigned to a const variable Can be iterated through using the for...in syntax that executes a given block of code for each property in an object ( Documentation ) for (let member in spaceship.crew) {} Object Literal Data is organized into key-value pairs where a key points to a location in memory that holds a value Keys are strings but values can be any data type When the keys don't have special characters, JS allows the quotation marks to be omitted Key serves as a method's name and the value is an anonymous function expression ES6 syntax allows omission of the colon and function keyword let person = { firstName: 'John', secondName: 'Doe', age: 30, children: ['Bob','Joe'] //Embedded Object address : { street: '555 Heaven Ave', city: 'Boston', state: 'MA' }, fullName: function(){ return this.firstname + ' ' + this.lastName; } //Same as fullName2 () { console.log(this.firstname) } } There are 2 notations used for accessing object properties: dot and bracket Braket notation must be used when accessing keys that have numbers, spaces, or special characters Also used for property assignment/creation Can't reassign an object declared with const delete operator is used to delete properties //Dot Notation person.age; person.children[0]; person.address.street; //Bracket Notation property = 'age'; person[property]; person['children'][0]; person['address']['street']; Object Constructor let apple = new Object(); apple.color = 'red'; apple.shape = 'round'; apple.describe = function(){ return \"Color: \" +this.color+' Shape: '+this.shape; } Constructor Pattern: function Fruit(name,color,shape){ this.name = name; this.color = color; this.shape = shape; this.describe = function(){ return \"This is \"+this.color; } } let apple = new Fruit('apple','red','round'); this Keyword Similar functionality to self keyword used for clases in python Used to reference other properties/methods of an object from within the object this references the calling object which provides access to the calling object's properties A ReferenceError is thrown if this is not used const goat = { dietType: 'herbivore', diet() { console.log(this.dietType); } }; goat.diet(); //Output: herbivore arrow functions bind/tie this to the function itself, not the calling object In the below example, the value of this is the global object (an object that exists in the global scope), which doesn't have a dietType property, therefore returnining undefined Avoid using arrow functions when using this in a method const goat = { dietType: 'herbivore', diet: () => { console.log(this.dietType); } }; goat.diet(); // Prints undefined Privacy Only certain properties should be mutable/able to change in value JS does not have privacy built-in for objects Naming conventions indicate how a developer should interact with a property Underscores _ before the name of a property: do not alter Getters are used to return internal properties of an object Syntax: get keyword followed by a function(){} Can perform an action on the data when getting a property Can return different values using conditionals Easier readability const person = { _firstName: 'John', _lastName: 'Doe', get fullName() { if (this._firstName && this._lastName){ return `${this._firstName} ${this._lastName}`; } else { return 'Missing a first name or a last name.'; } } } //Using a Getter person.fullName; // 'John Doe' Setters are used to reassign values of an object's properties const person = { _age: 37, set age(newAge){ if (typeof newAge === 'number'){ this._age = newAge; } else { console.log('You must assign a number to age'); } } }; //Using a Setter person.age = 40 console.log(person._age) //40 Factory Functions Returns an object that can be reused to make multiple object instances Simply returns an object Can have parameters allowing customization of the returned object const monsterFactory = (name, age, energySource, catchPhrase) => { return { name: name, age: age, energySource: energySource, scare() { console.log(catchPhrase); } } }; const ghost = monsterFactory('Ghouly', 251, 'ectoplasm', 'BOO!'); ghost.scare(); // 'BOO!' Destructuring An ES6 shortcut for assigning an object's properties to variables Property Value Shorthand can be used in creating factory functions where the property's name is the same as the variable it is being assigned to const monsterFactory = (name, age) => { return { name, age } }; Destructured Assignment is similar to unpacking in python where an object's properties can be concisely assigned to new variables const vampire = { name: 'Dracula', residence: 'Transylvania', preferences: { day: 'stay inside', night: 'satisfy appetite' } }; const {residence} = vampire; //Transylvania const {day} = vampire.preferences //Stay inside Built-In Object Methods Object Instance Methods: (Documentation) .hasOwnProperty() , .valueOf() Object Class Methods: Object.keys(name_of_obj) : Returns an array of the keys/property names of an object Object.entries(name_of_obj) : Returns an array containing arrays that have the key & value for each property Object.assign(target_obj,src_object) : Copies properties from the source object (s) to the target object and returns the target object","title":"Objects"},{"location":"web_dev/js/objects/#objects","text":"Are passed by reference meaning the variable assigned to an object points to the space in memory holding the object when passed into a function as an argument Functions that change object properties actually mutate the object permanently even when assigned to a const variable Can be iterated through using the for...in syntax that executes a given block of code for each property in an object ( Documentation ) for (let member in spaceship.crew) {}","title":"Objects"},{"location":"web_dev/js/objects/#object-literal","text":"Data is organized into key-value pairs where a key points to a location in memory that holds a value Keys are strings but values can be any data type When the keys don't have special characters, JS allows the quotation marks to be omitted Key serves as a method's name and the value is an anonymous function expression ES6 syntax allows omission of the colon and function keyword let person = { firstName: 'John', secondName: 'Doe', age: 30, children: ['Bob','Joe'] //Embedded Object address : { street: '555 Heaven Ave', city: 'Boston', state: 'MA' }, fullName: function(){ return this.firstname + ' ' + this.lastName; } //Same as fullName2 () { console.log(this.firstname) } } There are 2 notations used for accessing object properties: dot and bracket Braket notation must be used when accessing keys that have numbers, spaces, or special characters Also used for property assignment/creation Can't reassign an object declared with const delete operator is used to delete properties //Dot Notation person.age; person.children[0]; person.address.street; //Bracket Notation property = 'age'; person[property]; person['children'][0]; person['address']['street'];","title":"Object Literal"},{"location":"web_dev/js/objects/#object-constructor","text":"let apple = new Object(); apple.color = 'red'; apple.shape = 'round'; apple.describe = function(){ return \"Color: \" +this.color+' Shape: '+this.shape; }","title":"Object Constructor"},{"location":"web_dev/js/objects/#constructor-pattern","text":"function Fruit(name,color,shape){ this.name = name; this.color = color; this.shape = shape; this.describe = function(){ return \"This is \"+this.color; } } let apple = new Fruit('apple','red','round');","title":"Constructor Pattern:"},{"location":"web_dev/js/objects/#this-keyword","text":"Similar functionality to self keyword used for clases in python Used to reference other properties/methods of an object from within the object this references the calling object which provides access to the calling object's properties A ReferenceError is thrown if this is not used const goat = { dietType: 'herbivore', diet() { console.log(this.dietType); } }; goat.diet(); //Output: herbivore arrow functions bind/tie this to the function itself, not the calling object In the below example, the value of this is the global object (an object that exists in the global scope), which doesn't have a dietType property, therefore returnining undefined Avoid using arrow functions when using this in a method const goat = { dietType: 'herbivore', diet: () => { console.log(this.dietType); } }; goat.diet(); // Prints undefined","title":"this Keyword"},{"location":"web_dev/js/objects/#privacy","text":"Only certain properties should be mutable/able to change in value JS does not have privacy built-in for objects Naming conventions indicate how a developer should interact with a property Underscores _ before the name of a property: do not alter Getters are used to return internal properties of an object Syntax: get keyword followed by a function(){} Can perform an action on the data when getting a property Can return different values using conditionals Easier readability const person = { _firstName: 'John', _lastName: 'Doe', get fullName() { if (this._firstName && this._lastName){ return `${this._firstName} ${this._lastName}`; } else { return 'Missing a first name or a last name.'; } } } //Using a Getter person.fullName; // 'John Doe' Setters are used to reassign values of an object's properties const person = { _age: 37, set age(newAge){ if (typeof newAge === 'number'){ this._age = newAge; } else { console.log('You must assign a number to age'); } } }; //Using a Setter person.age = 40 console.log(person._age) //40","title":"Privacy"},{"location":"web_dev/js/objects/#factory-functions","text":"Returns an object that can be reused to make multiple object instances Simply returns an object Can have parameters allowing customization of the returned object const monsterFactory = (name, age, energySource, catchPhrase) => { return { name: name, age: age, energySource: energySource, scare() { console.log(catchPhrase); } } }; const ghost = monsterFactory('Ghouly', 251, 'ectoplasm', 'BOO!'); ghost.scare(); // 'BOO!'","title":"Factory Functions"},{"location":"web_dev/js/objects/#destructuring","text":"An ES6 shortcut for assigning an object's properties to variables Property Value Shorthand can be used in creating factory functions where the property's name is the same as the variable it is being assigned to const monsterFactory = (name, age) => { return { name, age } }; Destructured Assignment is similar to unpacking in python where an object's properties can be concisely assigned to new variables const vampire = { name: 'Dracula', residence: 'Transylvania', preferences: { day: 'stay inside', night: 'satisfy appetite' } }; const {residence} = vampire; //Transylvania const {day} = vampire.preferences //Stay inside","title":"Destructuring"},{"location":"web_dev/js/objects/#built-in-object-methods","text":"Object Instance Methods: (Documentation) .hasOwnProperty() , .valueOf() Object Class Methods: Object.keys(name_of_obj) : Returns an array of the keys/property names of an object Object.entries(name_of_obj) : Returns an array containing arrays that have the key & value for each property Object.assign(target_obj,src_object) : Copies properties from the source object (s) to the target object and returns the target object","title":"Built-In Object Methods"},{"location":"web_dev/js/promises/","text":"Ayscnhronous Programming An asynchronous operation is one that allows the computer to \u201cmove on\u201d to other tasks while waiting for the asynchronous operation to complete Asynchronous programming means that time-consuming operations don\u2019t have to bring everything else in our programs to a halt JS handles asynchronicity using the Promise object, introduced with ES6 What is a Promise? Promises are objects that represent the eventual outcome of an asynchronous operation A Promise object can be in one of three states: Pending : The initial state\u2014 the operation has not completed yet. Fulfilled : The operation has completed successfully and the promise now has a resolved value . For example, a request\u2019s promise might resolve with a JSON object as its value. Rejected : The operation has failed and the promise has a reason for the failure. This reason is usually an Error of some kind. A promise is settled if it is no longer pending (it is either fufilled or rejected) All promises eventually settle Enables us to write logic for what to do if the promise fulfills or is rejected Promises are returned from a asyncrhonous operations Constructing a Promise Object Promise constructor takes a function called the executor function as an argument Executor Function runs automatically when constructor is called, generally starts an asynchronous operation, and dictates how the promsie should be settled Has 2 function parameters: resolve() and reject() (These functions aren't defined by the progammer but are rather passed by JS into the executor function when the Promise constructor runs) resolve has one argument and will change the promise's status from pending to fulfilled if invoked and will set the resolved value to the argument passed in reject takes a reason or error as an argument and will change the promise's status from pending to rejected if invoked and will set the rejection's reason to the argument passed in Promises settle based on the results of an asynch operation (e.g. Database request is fulfilled with data from the query or is rejected with an error thrown) const executorFunction = (resolve,reject) => { if (condition){ resolve('Say Something') } else { reject('Say a different thing') } } const myPromise = new Promise(executorFunction) setTimeout() in Node: Takes a callback function and delay in milliseconds as arguments The callback function will execute in at least the passed in delay (Could be longer) This happens b/c after the delay, the line of code is added to be run but any synchronous code from the program will run before it, possibly delaying the callback functions execution","title":"Promises"},{"location":"web_dev/js/promises/#ayscnhronous-programming","text":"An asynchronous operation is one that allows the computer to \u201cmove on\u201d to other tasks while waiting for the asynchronous operation to complete Asynchronous programming means that time-consuming operations don\u2019t have to bring everything else in our programs to a halt JS handles asynchronicity using the Promise object, introduced with ES6","title":"Ayscnhronous Programming"},{"location":"web_dev/js/promises/#what-is-a-promise","text":"Promises are objects that represent the eventual outcome of an asynchronous operation A Promise object can be in one of three states: Pending : The initial state\u2014 the operation has not completed yet. Fulfilled : The operation has completed successfully and the promise now has a resolved value . For example, a request\u2019s promise might resolve with a JSON object as its value. Rejected : The operation has failed and the promise has a reason for the failure. This reason is usually an Error of some kind. A promise is settled if it is no longer pending (it is either fufilled or rejected) All promises eventually settle Enables us to write logic for what to do if the promise fulfills or is rejected Promises are returned from a asyncrhonous operations","title":"What is a Promise?"},{"location":"web_dev/js/promises/#constructing-a-promise-object","text":"Promise constructor takes a function called the executor function as an argument Executor Function runs automatically when constructor is called, generally starts an asynchronous operation, and dictates how the promsie should be settled Has 2 function parameters: resolve() and reject() (These functions aren't defined by the progammer but are rather passed by JS into the executor function when the Promise constructor runs) resolve has one argument and will change the promise's status from pending to fulfilled if invoked and will set the resolved value to the argument passed in reject takes a reason or error as an argument and will change the promise's status from pending to rejected if invoked and will set the rejection's reason to the argument passed in Promises settle based on the results of an asynch operation (e.g. Database request is fulfilled with data from the query or is rejected with an error thrown) const executorFunction = (resolve,reject) => { if (condition){ resolve('Say Something') } else { reject('Say a different thing') } } const myPromise = new Promise(executorFunction)","title":"Constructing a Promise Object"},{"location":"web_dev/js/promises/#settimeout-in-node","text":"Takes a callback function and delay in milliseconds as arguments The callback function will execute in at least the passed in delay (Could be longer) This happens b/c after the delay, the line of code is added to be run but any synchronous code from the program will run before it, possibly delaying the callback functions execution","title":"setTimeout() in Node:"},{"location":"web_dev/js/using_node_pkgs/","text":"Using Node Packages in a Project Initialize the project with npm init Install the desired packages with npm i package -D flag (Shorthand for --save-dev ) is used to save packages for necessary for development purposes (e.g. unit tests, minification, etc. ) Saves the package to \"devDependencies\" in package.json -S flag (Shorthand for --save) is used to save packages required for the application to run Saves them to \"dependencies\" in package.json Automatically saves new packages in npm 5+ Edit the \"scripts\" object in package.json to include necessary commands Run the scripts using npm run script_name Scripts: Sass (CSS Pre-Compiler): node-sass package should be saved to devDependencies \"sass\": \"node-sass -w scss/ -o dist/css/ --recursive\" Command watches (-w) the scss folder and outputs (-o) the compiled css to the css folder in the dist directory --recursive prevets issues with partials and auto-reloading Jest (JS Testing Framework): jest package should be saved to devDependencies \"test\": \"jest\" Babel (ES6+ to ES5 Transpilation): babel-cli and babel-preset-env packes should be saved to devDependencies \"build\": \"babel src -d lib\"","title":"Node Pkgs"},{"location":"web_dev/js/using_node_pkgs/#using-node-packages-in-a-project","text":"Initialize the project with npm init Install the desired packages with npm i package -D flag (Shorthand for --save-dev ) is used to save packages for necessary for development purposes (e.g. unit tests, minification, etc. ) Saves the package to \"devDependencies\" in package.json -S flag (Shorthand for --save) is used to save packages required for the application to run Saves them to \"dependencies\" in package.json Automatically saves new packages in npm 5+ Edit the \"scripts\" object in package.json to include necessary commands Run the scripts using npm run script_name","title":"Using Node Packages in a Project"},{"location":"web_dev/js/using_node_pkgs/#scripts","text":"","title":"Scripts:"},{"location":"web_dev/js/using_node_pkgs/#sass-css-pre-compiler","text":"node-sass package should be saved to devDependencies \"sass\": \"node-sass -w scss/ -o dist/css/ --recursive\" Command watches (-w) the scss folder and outputs (-o) the compiled css to the css folder in the dist directory --recursive prevets issues with partials and auto-reloading","title":"Sass (CSS Pre-Compiler):"},{"location":"web_dev/js/using_node_pkgs/#jest-js-testing-framework","text":"jest package should be saved to devDependencies \"test\": \"jest\"","title":"Jest (JS Testing Framework):"},{"location":"web_dev/js/using_node_pkgs/#babel-es6-to-es5-transpilation","text":"babel-cli and babel-preset-env packes should be saved to devDependencies \"build\": \"babel src -d lib\"","title":"Babel (ES6+ to ES5 Transpilation):"}]}