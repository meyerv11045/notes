{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Notes","title":"Notes"},{"location":"#notes","text":"","title":"Notes"},{"location":"ai/1-intro/","text":"Ch. 1 Introduction intelligence has a wide variety of definitions formal one is rationality (doing the \"right thing\" or making the optimal decision as defined by the objective provided to an agent) mathematical programming is a subfield concerned with rational decision making human vs. rational and thought vs. behavior agent- something that acts Rational agent- acts to achieve best outcome (or best expected outcome in the case of uncertainty) perfect rationality- always taking the exactly optimal action limited rationality- acting appropriately when there is not enough time to do all the computations for an exactly optimal/rational action (oftentimes in complex environments) Value alignment problem- achieving agreement btw our true preferences and the objective we give to a machine dualism- part of the mind outside nature, exempt from physical laws (proposed by descarte) materialism/physicalism/naturalism- the brain operates according to laws of physics and the perception of choices is simply a result of this empricism- concerned with establishing the source of knowledge decision theory- prob theory + utility theory in order to provide a framework for individual decisions made under uncertainty useful for large economies where each agent does not need to pay attention to other agents' actions game theory- framework for small economies where the actions of one player significantly affect the utility of another Multiagent systems- decisions involving multiple agents operations research- how to make rational decisions when payoffs are the result of several sequential actions led to markov decision processes and reinforcement learning Rolnick et al. (2019) present a 60-page catalog of ways in which machine learning can be used to tackle climate change. previous symbolic systems promoted by Newell and Simon used specific hard-coded facts about the world. what if future neuro-symbolic systems use learned representations of concepts in the world as the symbols and previous symbol manipulation techniques can be used on them","title":"Ch. 1 Introduction"},{"location":"ai/1-intro/#ch-1-introduction","text":"intelligence has a wide variety of definitions formal one is rationality (doing the \"right thing\" or making the optimal decision as defined by the objective provided to an agent) mathematical programming is a subfield concerned with rational decision making human vs. rational and thought vs. behavior agent- something that acts Rational agent- acts to achieve best outcome (or best expected outcome in the case of uncertainty) perfect rationality- always taking the exactly optimal action limited rationality- acting appropriately when there is not enough time to do all the computations for an exactly optimal/rational action (oftentimes in complex environments) Value alignment problem- achieving agreement btw our true preferences and the objective we give to a machine dualism- part of the mind outside nature, exempt from physical laws (proposed by descarte) materialism/physicalism/naturalism- the brain operates according to laws of physics and the perception of choices is simply a result of this empricism- concerned with establishing the source of knowledge decision theory- prob theory + utility theory in order to provide a framework for individual decisions made under uncertainty useful for large economies where each agent does not need to pay attention to other agents' actions game theory- framework for small economies where the actions of one player significantly affect the utility of another Multiagent systems- decisions involving multiple agents operations research- how to make rational decisions when payoffs are the result of several sequential actions led to markov decision processes and reinforcement learning Rolnick et al. (2019) present a 60-page catalog of ways in which machine learning can be used to tackle climate change. previous symbolic systems promoted by Newell and Simon used specific hard-coded facts about the world. what if future neuro-symbolic systems use learned representations of concepts in the world as the symbols and previous symbol manipulation techniques can be used on them","title":"Ch. 1 Introduction"},{"location":"ai/2-agents/","text":"Ch. 2 Intelligent Agents agent- anything that perceives its environments through sensors and acts upon that environment through actuators percept- content an agent's sensors are perceiving percept sequence- complete history of everything the agent has ever perceived agent function- maps any given percept sequence to an action As a general rule, it is better to design performance measures according to what one actually wants to be achieved in the environment, rather than according to how one thinks the agent should behave. rational agent- For each possible percept sequence, a rational agent should select an action that is ex- pected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has. Doing actions in order to modify future percepts \u2014sometimes called information gathering\u2014is an important part of rationality autonomy- agent does not rely on the prior knowledge of its designer and instead uses its own percepts and learning processes Just as evolution provides animals with enough built-in reflexes to survive long enough to learn for themselves, it would be reasonable to provide an artificial intelligent agent with some initial knowledge as well as an ability to learn. After sufficient experience of its environment, the behavior of a rational agent can become effectively independent of its prior knowledge. specify the task environment with performance metric, environemnt, actuators, and sensors fully oversvable environent- agent's sensors give it access to the complete state of the environment at each point in time effectively fully observable if sensors detect all relevant aspects to the choice of action (depends on the performance measure) partially observable environment- due to noisy or inaccurate sensors and because parts of the state are missing from the sensor data most environments multi-agent systems are defined by where other objects behavior can be described as maximizing a performance measure that is dependent on agent A's behavior ex: chess is competitive multiagent, driving is partially cooperative multiagent (trying to avoid collisions) has different rational behaviors than single-agent environments (e.g. communication and randomized behaviors) deterministic- next state of environment completely determined by current state and action executed by the agent(s) most cases are nondeterministic stochastic is slightly different and deals with probabilities instead of unquanitied possibilities The hardest case is partially observable , multiagent , nondeterministic , sequential , dynamic , continuous , and unknown agent = architecture + program programs will take current percept as input from sensors and return an action to the actuators (agent function may depend on entire percept history) Types of Agents Simple Reflex Agent - select actions on the basis of the current percept Model-based Reflex Agents - maintain an internal state that depends on the percept history and reflects some of the unobserved aspects of the current state uses a sensor model (knowledge of how the state of the world is reflected in the agent's percepts) and a transition model (how the world works/changes over time) does not eliminate uncertainty in some unobserved aspects of the world model-free agents can learn what action is best for a percept without ever learning how the action changes the environment Goal-based Agents - a model-based reflex agent with the addition of goal information to aid in decision making search and planning are subfields devoted to finding action sequences to achieve an agent's goals this involves imagining counterfactuals (what will happen if i perform this action) in order to achieve a goal in the future (unlike the simple reflex agent that directly maps a percept to an action) Utility-based Agents - uses a utility function (an internalization of the performance measure) to decide between multiple action sequences that achieve a goal more flexible than simpler agents (but not necessarily any more rational) Class Notes Environment perceived by agent through sensors acted on by agent through actuators rational agent- selects action to maximize the expected value of the performance measure rational \\neq knowing actual outcome Non-autonomous agent- relies on prior knowledge instead of percepts/experience prior knowledge helps decrease amount that needs to be learned in many cases ( Investigating Human Priors for Playing Video Games ) PEAS- describes a task env P erformance measure E nvironment A ctuators S ensors","title":"Ch. 2 Agents"},{"location":"ai/2-agents/#ch-2-intelligent-agents","text":"agent- anything that perceives its environments through sensors and acts upon that environment through actuators percept- content an agent's sensors are perceiving percept sequence- complete history of everything the agent has ever perceived agent function- maps any given percept sequence to an action As a general rule, it is better to design performance measures according to what one actually wants to be achieved in the environment, rather than according to how one thinks the agent should behave. rational agent- For each possible percept sequence, a rational agent should select an action that is ex- pected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has. Doing actions in order to modify future percepts \u2014sometimes called information gathering\u2014is an important part of rationality autonomy- agent does not rely on the prior knowledge of its designer and instead uses its own percepts and learning processes Just as evolution provides animals with enough built-in reflexes to survive long enough to learn for themselves, it would be reasonable to provide an artificial intelligent agent with some initial knowledge as well as an ability to learn. After sufficient experience of its environment, the behavior of a rational agent can become effectively independent of its prior knowledge. specify the task environment with performance metric, environemnt, actuators, and sensors fully oversvable environent- agent's sensors give it access to the complete state of the environment at each point in time effectively fully observable if sensors detect all relevant aspects to the choice of action (depends on the performance measure) partially observable environment- due to noisy or inaccurate sensors and because parts of the state are missing from the sensor data most environments multi-agent systems are defined by where other objects behavior can be described as maximizing a performance measure that is dependent on agent A's behavior ex: chess is competitive multiagent, driving is partially cooperative multiagent (trying to avoid collisions) has different rational behaviors than single-agent environments (e.g. communication and randomized behaviors) deterministic- next state of environment completely determined by current state and action executed by the agent(s) most cases are nondeterministic stochastic is slightly different and deals with probabilities instead of unquanitied possibilities The hardest case is partially observable , multiagent , nondeterministic , sequential , dynamic , continuous , and unknown agent = architecture + program programs will take current percept as input from sensors and return an action to the actuators (agent function may depend on entire percept history)","title":"Ch. 2 Intelligent Agents"},{"location":"ai/2-agents/#types-of-agents","text":"Simple Reflex Agent - select actions on the basis of the current percept Model-based Reflex Agents - maintain an internal state that depends on the percept history and reflects some of the unobserved aspects of the current state uses a sensor model (knowledge of how the state of the world is reflected in the agent's percepts) and a transition model (how the world works/changes over time) does not eliminate uncertainty in some unobserved aspects of the world model-free agents can learn what action is best for a percept without ever learning how the action changes the environment Goal-based Agents - a model-based reflex agent with the addition of goal information to aid in decision making search and planning are subfields devoted to finding action sequences to achieve an agent's goals this involves imagining counterfactuals (what will happen if i perform this action) in order to achieve a goal in the future (unlike the simple reflex agent that directly maps a percept to an action) Utility-based Agents - uses a utility function (an internalization of the performance measure) to decide between multiple action sequences that achieve a goal more flexible than simpler agents (but not necessarily any more rational)","title":"Types of Agents"},{"location":"ai/2-agents/#class-notes","text":"Environment perceived by agent through sensors acted on by agent through actuators rational agent- selects action to maximize the expected value of the performance measure rational \\neq knowing actual outcome Non-autonomous agent- relies on prior knowledge instead of percepts/experience prior knowledge helps decrease amount that needs to be learned in many cases ( Investigating Human Priors for Playing Video Games ) PEAS- describes a task env P erformance measure E nvironment A ctuators S ensors","title":"Class Notes"},{"location":"ai/3-search/","text":"Ch. 3 Solving Problems by Searching Search: how can an agent look ahead to find a sequence of actions that will eventually achieve its goal Search Algorithms Informed- agent can estimate distance from goal Uninformed- no estimate available This chapter assumes knowldege of the environment (ch. 4 deals with unknown env) Goals organize behavior by liiting the objectives and potential actions Fully observable, deterministic, known envs have a solution to any problem as a fixed sequence of actions Can ignore percepts (Open-loop system in control theory) with potentially incorrect models or nondeterministic envs, better to use closed-loop approach the monitors the perceps and adjusts accordingly My life as a search problem in a partially observable, nondeterministic, unknown env: I create a plan to achieve my goals but adjust to experience as I execute on the plan and make sure I have contingency plans for outcomes outside of my control Search problem: State space- set of possible states the env can be in can be represented as graph w/ vertices as state and directed edges as actions can be infinite as in the case of recursively defined objects (see Donald Knuth's example) Initial state the agent starts in Goal state (can be multiple or a property that applies to infinite states) Actions- set of actions that can be executed for given state Transition model-describes action -> state mapping T: S \\times A \\to S where S is state space A is action space s_0 \\in S is initial state G \\sub S is goal state(s) Action Cost Function- gives cost of applying action a to state s to reach state s' reflects the performance measure path- sequence of actions Solution- path from initial state to goal state optimal- lowest path cost among all solutions abstraction- removing detail from a representation to produce the minimally relevant model for a problem critical for allowing useful intelligent agents (too much detail could overwhelm) Example 3x3 Tile Game (8-puzzle) State Space has 9! unique states branching factor b = 3 b/c while 4 directions to move, we will never redo the action to get to the current state (only case it would be 4 is on the first state with the middle being empty, but every subsequent action will be 3) Search Algos Search Tree- nodes correspond to states and edges correspond to actions best-first search- choose a node n from frontier (unexplored) with a min value of some evaluation function f(n) . if it is the goal state, return it, otherwise expand it to generate the children nodes diff eval functions give diff specific algorithms Deciding which node from the frontier of the search tree to expand next is based on the evaluation function which the key difference between many search algos Datastructures: node has state, parent, action, and path cost fields queue of some kind is used to store the frontier priority- pops node w min cost for an eval fn fifo- bfs lifo (stack)- dfs can store reached states in a hash-table/lookup table algorithms that cannot remember the past are doomed to repeat it important for not traversing redundant paths which can result in computational explosion graph search- checks for redudant paths tree-like search- does not check for redudant paths to save memory since the structure of the problem does not pose the issue of redudant paths Measuring Performance Completeness- is algorithm gauranteed to find a solution given one exists and report a failure when one does not exist algo must be systematic in how it explores infinite search spaces so that it can eventually reach any state connected to the initial state can be complete without having an ubberbound on time to find Cost optimality Time complexity Space complexity Uninformed Search No info on how close a state is to the goal exponential complexity search problems cannot be solved with uninformed techniques for anything but the smallest instances Iterative deepening is the preferred uninformed search method when the search state space is larger than can fit in memory and the depth of the solution is not known. Breadth-First Search Cost optimal when all actions have = cost Systematic and thus complete on infinite search spaces Best-first search with node's depth as evaluation function O(b^d) time and space requirements where b is the branching factor and d is the depth in the search tree branching factor b means that expanding a node generates b additional nodes memory requirements are bigger issue than execution time (which are still an issue in themselves) Dijkstra's Algorithm / Uniform-Cost Search Cost optimal when actions have \\neq cost while breadth-first search spreads out in waves of uniform depth\u2014first depth 1, then depth 2, and so on\u2014uniform-cost search spreads out in waves of uniform path-cost Best-first search with Path-Cost as evaluation function O(b^{1 + C^*// \\epsilon}) is time and space complexity C^* is the cost of the optimal solution \\epsilon > 0 is a lower bound on the cost of each action Can be much greater than O(b^d) due to exploring large trees of actions with low costs before exploring paths with a high-cost and more useful action When all costs are equal, O(b^{d+1}) so its similar to BFS Considers all paths systematically in order of increasing cost, never getting caught going down a single infinite path (assuming that all action costs are > \\epsilon > 0 ) so its complete Depth-First Search expands deepest node in frontier first Best-first search with negative depth as eval function Not cost-optimal (returns first path it finds) and incomplete (can get stuck going down an infinite path) better for problems where tree-like search is feasible so DFS doesn't keep track of reached nodes and thus has smaller memory requirements O(bm) where m is max depth of tree backtracking search (a variant) uses even less memory Depth-limited and Iterative Deepening Search version of DFS where we supply a depth limit \\ell and treat all nodes at \\ell as if they have no successors O(b^{\\ell}) time complexity and O(b\\ell) space complexity depth limit requires knowledge of the problem, and is oftentimes not best determined till after solving the problem iterative deepening search solves the problem of picking a good value for \\ell by trying all values: first 0, then 1, then 2, and so on\u2014until either a solution is found, or the depth- limited search returns the failure value rather than the cutoff value. best of DFS and BFS (low memory but O(b^m) runtime and complete on acyclic state spaces with optimal cost) Bidirectional Search Simultaneously expand the frontiers from the start state and the goal state and hope they meet idea is that b^{d/2} + b^{d/2} << b^d (50k times less when b=d=10 ) complete and optimal cost Informed (Heuristic) Search Uses domain-specific hints about the location of goals to find solutions more efficiently than uninformed strategy uses heuristic function h(n) Ex: for route finding on a map, a good heuristic is the straight line distance from current node to the goal node note how the heuristic is good b/c of our knowledge of how the problem is structured (maps) Greedy Best-First Search First expands node with lowest h(n) (node that appears to be closest to goal) Best-first search with f(n) = h(n) Incomplete in infinite search spaces O(|V|) but a good heuristic can reduce it to O(bm) on certain problems","title":"Ch. 3 Search"},{"location":"ai/3-search/#ch-3-solving-problems-by-searching","text":"Search: how can an agent look ahead to find a sequence of actions that will eventually achieve its goal Search Algorithms Informed- agent can estimate distance from goal Uninformed- no estimate available This chapter assumes knowldege of the environment (ch. 4 deals with unknown env) Goals organize behavior by liiting the objectives and potential actions Fully observable, deterministic, known envs have a solution to any problem as a fixed sequence of actions Can ignore percepts (Open-loop system in control theory) with potentially incorrect models or nondeterministic envs, better to use closed-loop approach the monitors the perceps and adjusts accordingly My life as a search problem in a partially observable, nondeterministic, unknown env: I create a plan to achieve my goals but adjust to experience as I execute on the plan and make sure I have contingency plans for outcomes outside of my control Search problem: State space- set of possible states the env can be in can be represented as graph w/ vertices as state and directed edges as actions can be infinite as in the case of recursively defined objects (see Donald Knuth's example) Initial state the agent starts in Goal state (can be multiple or a property that applies to infinite states) Actions- set of actions that can be executed for given state Transition model-describes action -> state mapping T: S \\times A \\to S where S is state space A is action space s_0 \\in S is initial state G \\sub S is goal state(s) Action Cost Function- gives cost of applying action a to state s to reach state s' reflects the performance measure path- sequence of actions Solution- path from initial state to goal state optimal- lowest path cost among all solutions abstraction- removing detail from a representation to produce the minimally relevant model for a problem critical for allowing useful intelligent agents (too much detail could overwhelm)","title":"Ch. 3 Solving Problems by Searching"},{"location":"ai/3-search/#example-3x3-tile-game-8-puzzle","text":"State Space has 9! unique states branching factor b = 3 b/c while 4 directions to move, we will never redo the action to get to the current state (only case it would be 4 is on the first state with the middle being empty, but every subsequent action will be 3)","title":"Example 3x3 Tile Game (8-puzzle)"},{"location":"ai/3-search/#search-algos","text":"Search Tree- nodes correspond to states and edges correspond to actions best-first search- choose a node n from frontier (unexplored) with a min value of some evaluation function f(n) . if it is the goal state, return it, otherwise expand it to generate the children nodes diff eval functions give diff specific algorithms Deciding which node from the frontier of the search tree to expand next is based on the evaluation function which the key difference between many search algos Datastructures: node has state, parent, action, and path cost fields queue of some kind is used to store the frontier priority- pops node w min cost for an eval fn fifo- bfs lifo (stack)- dfs can store reached states in a hash-table/lookup table algorithms that cannot remember the past are doomed to repeat it important for not traversing redundant paths which can result in computational explosion graph search- checks for redudant paths tree-like search- does not check for redudant paths to save memory since the structure of the problem does not pose the issue of redudant paths","title":"Search Algos"},{"location":"ai/3-search/#measuring-performance","text":"Completeness- is algorithm gauranteed to find a solution given one exists and report a failure when one does not exist algo must be systematic in how it explores infinite search spaces so that it can eventually reach any state connected to the initial state can be complete without having an ubberbound on time to find Cost optimality Time complexity Space complexity","title":"Measuring Performance"},{"location":"ai/3-search/#uninformed-search","text":"No info on how close a state is to the goal exponential complexity search problems cannot be solved with uninformed techniques for anything but the smallest instances Iterative deepening is the preferred uninformed search method when the search state space is larger than can fit in memory and the depth of the solution is not known.","title":"Uninformed Search"},{"location":"ai/3-search/#breadth-first-search","text":"Cost optimal when all actions have = cost Systematic and thus complete on infinite search spaces Best-first search with node's depth as evaluation function O(b^d) time and space requirements where b is the branching factor and d is the depth in the search tree branching factor b means that expanding a node generates b additional nodes memory requirements are bigger issue than execution time (which are still an issue in themselves)","title":"Breadth-First Search"},{"location":"ai/3-search/#dijkstras-algorithm-uniform-cost-search","text":"Cost optimal when actions have \\neq cost while breadth-first search spreads out in waves of uniform depth\u2014first depth 1, then depth 2, and so on\u2014uniform-cost search spreads out in waves of uniform path-cost Best-first search with Path-Cost as evaluation function O(b^{1 + C^*// \\epsilon}) is time and space complexity C^* is the cost of the optimal solution \\epsilon > 0 is a lower bound on the cost of each action Can be much greater than O(b^d) due to exploring large trees of actions with low costs before exploring paths with a high-cost and more useful action When all costs are equal, O(b^{d+1}) so its similar to BFS Considers all paths systematically in order of increasing cost, never getting caught going down a single infinite path (assuming that all action costs are > \\epsilon > 0 ) so its complete","title":"Dijkstra's Algorithm / Uniform-Cost Search"},{"location":"ai/3-search/#depth-first-search","text":"expands deepest node in frontier first Best-first search with negative depth as eval function Not cost-optimal (returns first path it finds) and incomplete (can get stuck going down an infinite path) better for problems where tree-like search is feasible so DFS doesn't keep track of reached nodes and thus has smaller memory requirements O(bm) where m is max depth of tree backtracking search (a variant) uses even less memory","title":"Depth-First Search"},{"location":"ai/3-search/#depth-limited-and-iterative-deepening-search","text":"version of DFS where we supply a depth limit \\ell and treat all nodes at \\ell as if they have no successors O(b^{\\ell}) time complexity and O(b\\ell) space complexity depth limit requires knowledge of the problem, and is oftentimes not best determined till after solving the problem iterative deepening search solves the problem of picking a good value for \\ell by trying all values: first 0, then 1, then 2, and so on\u2014until either a solution is found, or the depth- limited search returns the failure value rather than the cutoff value. best of DFS and BFS (low memory but O(b^m) runtime and complete on acyclic state spaces with optimal cost)","title":"Depth-limited and Iterative Deepening Search"},{"location":"ai/3-search/#bidirectional-search","text":"Simultaneously expand the frontiers from the start state and the goal state and hope they meet idea is that b^{d/2} + b^{d/2} << b^d (50k times less when b=d=10 ) complete and optimal cost","title":"Bidirectional Search"},{"location":"ai/3-search/#informed-heuristic-search","text":"Uses domain-specific hints about the location of goals to find solutions more efficiently than uninformed strategy uses heuristic function h(n) Ex: for route finding on a map, a good heuristic is the straight line distance from current node to the goal node note how the heuristic is good b/c of our knowledge of how the problem is structured (maps)","title":"Informed (Heuristic) Search"},{"location":"ai/3-search/#greedy-best-first-search","text":"First expands node with lowest h(n) (node that appears to be closest to goal) Best-first search with f(n) = h(n) Incomplete in infinite search spaces O(|V|) but a good heuristic can reduce it to O(bm) on certain problems","title":"Greedy Best-First Search"},{"location":"ai/complexity/","text":"Complexity Reductionism- belief that a whole can be understood completely by understanding its parts and the nature of their sum Rene Descartes Opposed by phenomena like intelligencewhere complex behavior arrives from large collections of simple components Santa Fe Institute created for study of complex systems that require inherently interdisciplinary environment Founded on idea of antireductionism when solving important problems Melanie Mitchell Her adviser, cognitive scientist Douglas Hofstadter @ UMich Complex Systems ~ Emergent Computation How do we move beyond the traditional paradigm of reductionism toward a new understanding of seemingly irreducibly complex systems? four subject areas that are fundamental to the study of complex systems: information computation dynamics and chaos evolution \"Science has explored the microcosmos and the macrocosmos; we have a good sense of the lay of the land. The great unexplored frontier is complexity.\" - Heinz Pagels, The Dreams of Reason What we now call \u201ccomplex systems\u201d can trace its ancestry to cybernetics and the related field of systems science Ch. 1 What is Complexity? What if we are viewing intelligence from the wrong persepctive Its possible we see intelligence as too singular an end objective that we can engineer models to produce Maybe we need lots of smaller models with simple functionality that interact to create a collective intelligence we can view neural nets from this persepctive since they are made of lots of simple neurons interacting however the limitation of neural nets is that the neuron interactions are very rigid with predifined connections due to the model's architecture. this isn't quite the way the neurons in the brain are connected and could explain some of the shortcomings of neural nets when it comes to true intelligence Maybe a better persepective is that what we consider intelligence is an emergent property of complex systems and that it is not relegated to only a single animal/human brain but can rather include networks of simpler orgnisms such as ants or humans that form a collective \"intelligence\" Understading the mechanisms that allow ant colonys to express a collective intelligence is still an active area of research Ants have social organizations that allow a colony to collectively do things that increase the survival probability of the community as a whole. Humans are similar with the entire emergence of farming and cities and medicine. Without our social structures, human survival on our own, like ants on their own, is much harder and a lower probability Key aspect of complex systems is the lack of a central controller to organize the simple entities The word complex comes from the Latin root plectere : to weave, entwine complex system : a system in which large networks of components with no central control and simple rules of operation give rise to complex collective behavior, sophisticated information processing, and adaptation via learning or evolution Self-organizing Systems- organized behavior arises without an internal or exter- nal controller or leader Since simple rules produce complex behavior in hard-to-predict ways, the macroscopic behavior of such systems is sometimes called emergent . alternative definition of a complex system : a system that exhibits nontrivial emergent and self-organizing behaviors . The central question of the sciences of complexity is how this emergent self-organized behavior comes about The proper domain of computer science is information processing writ large across all of nature. \u2014Chris Langton (Quoted in Roger Lewin, Complexity: Life at the Edge of Chaos ) Insect Colonies An ant colony, for instance, can consist of hundreds to millions of individual ants, each one a rather simple creature that obeys its genetic imperatives to seek out food, respond in simple ways to the chemical signals of other ants in its colony, fight intruders, and so forth build sophisticated colonies, can even build bridges with their bodies for others in the colony to cross how did biological evolution produce creatures with such an enormous contrast between their individual simplicity and their collective sophistication? The Brain global behavior of the brain of perception and conciousness are due to the interactions of billions of simple neurons A neuron fires when it receives enough signals from other neurons through its dendrites. Firing consists of sending an electric pulse through the axon, which is then converted into a chemical signal via chemicals called neurotransmitters . This chemical signal in turn activates other neurons through their dendrites. The firing frequency and the resulting chemical output signals of a neuron can vary over time according to both its input and how much it has been firing recently. individuals (neurons or ants) perceive signals from other individuals, and a sufficient summed strength of these signals causes the individuals to act in certain ways that produce additional signals. The overall effects can be very complex. unsolved questions: what do neuronal signals mean? How do neurons interact to produce global cognitive behavior? How do the interactions cause the brain to think thoughts and learn new thigs? How did this all emerge from evolution? The Immune System Complex response to inaders caused by a cascade of signals once a independent cell detects an invader We do not yet know precisely how the system avoids attacking the body; or what gives rise to flaws in the system, such as autoimmune diseases, in which the system does attack the body; or the detailed strategies of the human immunodeficiency virus (HIV), which is able to get by the defenses by attacking the immune system itself Figuring out how complex systems like these work is the key to solving many health related issues AI could be critical to the future of healthcare with respect to understanding the body, how its cells work, and the interactions between the systems in the cells Economies Adam Smith's invisible hand that sef-corrects the markets is an example of a complex system at work self-interested individuals make buy/sell decisions that interact to form very hard to predict market behavior The Internet complex systems scientists have discovered that the network as a whole has many unexpected large-scale properties involving its overall structure, the way in which it grows, how information propagates over its links, and the coevolutionary relationships between the behavior of search engines and the Web\u2019s link structure, all of which lead to what could be called \u201cadaptive\u201d behavior for the system as a whole Ch. 2 Dynamics, Chaos, and Prediction \"It makes me so happy. To be at the beginning again, knowing almost nothing. . . . The ordinary-sized stuff which is our lives, the things people write poetry about\u2014clouds\u2014daffodils\u2014waterfalls...these things are full of mystery, as mysterious to us as the heavens were to the Greeks...It\u2019s the best possible time to be alive, when almost everything you thought you knew is wrong.\" \u2014Tom Stoppard, Arcadia Dynamical Systems Theory (dynamics)- describing and predicting behavior of systems with complex changing behavior at the macroscopic level, emerging from the collective actions of many interacting components describe the general ways systems can change, what types of macroscopic behavior are possible, and what kinds of predictions about that behavior can be made Chaos theory is a fasciating subfield of it Started with Artistotle Aristotle proposed a law of motion which stated that rest is the natural state of objects This seems to make intuitive sense based on our experience in the day to day world so it is no suprise that this dominated western thinking for hundreds of years until Galileo did experiments and proposed that rest is not the natural state of objects, rather it takes force to stop a moving object. this would be an unintuitive result without the knowledge of air resistance and other hard to see forces that affect all our observations on earth. galileo launched the scientific revolution with experimental observations at its core newton came right after galileo and invented the science of dynamics (also inventing calculus to describe motion and change along the way) Classical Mechanics: Newton's work Kinematics- describes how things move Dynamics- describes why things follow the laws of kinematics Newton's laws are foundation of dynamics: Constant motion: Any object not subject to a force moves with unchanging speed. Inertial mass: When an object is subject to a force, the resulting change in its motion is inversely proportional to its mass. Equal and opposite forces: If object A exerts a force on object B, then object B must exert an equal and opposite force on object A. Newtonian mechanics produced a picture of a \u201cclockwork universe,\u201d one that is wound up with the three laws and then runs its mechanical course. The mathematician Pierre Simon Laplace saw the implication of this clockwork view for prediction: in 1814 he asserted that, given Newton\u2019s laws and the current position and velocity of every particle in the universe, it was possible, in principle, to predict everything for all time. Discovery of quantum mechanics demonstrated this idea was not possible Understanding of chaotic systems (small changes in initial conditions = large changes in resulting behavior; aka sensitive dependence on initial conditions) further demonstrated the idea was not possible small errors in measurement of initial conditons would lead to large errors in long term predictions of behavior observed before quantum mechanics discovered: Poincare (founder of dynamical systems theory) in 19th century tried to solve 3 body problem of gravitation but was unsuccesful (invented algebraic topology in the process lol) predict the motion of 3 objects exerting gravitational force on one anothe Poincare prediccted sensitive depen- dence on initial conditions would make weather prediction impossible Meteorologist Edward Lorenz demonstrated in 60s that even simple computer models of weather were subject to sensitigve depedence on initial conditions even now, weather predicitions dont go beyond a week into the future very succesfully It is not yet known whether this limit is due to fundamental chaos in the weather, or how much this limit can be extended by collecting more data and building even better models. TODO: look into deepmind's paper on predicting the weather to see if more data and better models is able to overcome the perceived sensitve dependence on initial conditions Linearity vs. Nonlinearity a linear system can be understood by understanding its parts individually and then putting them together a reductionist's dream a nonlinear system's whole is different from the sum of its parts Logistic Map x_{t+1} = R x_t (1 - x_t) Type of attractor is one way of characterizing the behavior of a system The logistic map is an extremely simple equation and is completely deterministic: every x_t maps onto one and only one value of x_{t+1} . And yet the chaotic trajectories obtained from this map, at certain values of R , look very random\u2014enough so that the logistic map has been used as a basis for generating pseudo-random numbers on a computer. Thus apparent randomness can arise from very simple deterministic systems. In short, the presence of chaos in a system implies that perfect prediction a\u0300 la Laplace is impossible not only in practice but also in principle , since we can never know x 0 to infinitely many decimal places. This is a profound negative result that, along with quantum mechanics, helped wipe out the optimistic nineteenth-century view of a clockwork Newtonian universe that ticked along its predictable path. deeper studies of the logistic map and related maps have resulted in an equally surprising and profound positive result\u2014the discovery of universal characteristics of chaotic systems. even though \u201cprediction becomes impossible\u201d at the detailed level, there are some higher-level aspects of chaotic systems that are indeed predictable. The logistic map is a simplified model of population growth, but the detailed study of it and similar model systems resulted in a major revamp- ing of the scientific understanding of order, randomness, and predictability. This illustrates the power of idea models \u2014models that are simple enough to study via mathematics or computers but that nonetheless capture fundamental properties of natural complex systems Ch. 3 Information Why the second law should distinguish between past and future while all the other laws of nature do not is perhaps the greatest mystery in physics making a measurement to gain information entails an increase of entropy since acquiring info requires expending work In his 1948 paper \u201cA Mathematical Theory of Communication,\u201d Claude Shannon (working @ Bell labs) gave a narrow definition of information and proved a very important theorem, which gave the maximum possible transmission rate (channel capacity) of information over a given channel (wire or other medium), even if there are errors in transmission caused by noise on the channel Shannon Entropy- entropy of the message source that information content is defined in terms of a message can be any unit of communi- cation, be it a letter, a word, a sentence, or even a single bit the entropy (and thus information content) of a source is defined in terms of message probabilities Shannon's results led to the development of coding theory for data compression and was also applied to many other fields like crytography, bioinformatics, and ai Information , as narrowly defined by Shannon, concerns the predictability of a message source information theoretic notions such as entropy, information content, mutual information, information dynamics, and others have played central though controversial roles in attempts to define the notion of complexity and in characterizing different types of complex systems. Ch. 4 Computation 3 big questions on mathematics proposed by David Hilbertin 1900: Is mathematics complete? given a finite set of axioms, can every mathematical statement be proved/disproved Is mathematics consistent? can only true statements be proved (proving 1 + 1 = 3 would mean its inconsistent) Is every statement in mathematics decidable? there is an algorithm that can be applied to every statement that will tell us in finite time whether the statement is true/false decision problem connected to Gottfried Leibniz In 1930, Godel presented his incompleteness theorem stating if mathematics is consistent, then it is incomplete and if it is complete, then it is inconsistent Go\u0308del gave an example of a mathematical statement that can be translated into English as: \u201cThis statement is not provable.\u201d Let\u2019s call this statement \u201cStatement A .\u201d Now, suppose Statement A could indeed be proved. But then it would be false (since it states that it cannot be proved). That would mean a false statement could be proved\u2014arithmetic would be inconsistent. Okay, let\u2019s assume the opposite, that Statement A cannot be proved. That would mean that Statement A is true (because it asserts that it cannot be proved), but then there is a true statement that cannot be proved\u2014 arithmetic would be incomplete. Ergo, arithmetic is either inconsistent or incomplete. Godel essentially translated this statement into a mathematical proof This answered the first two questions proposed by Hilbert (shocking many mathematicians in the process) Turing demonstrated the answer is no to Hilbert's 3rd question by defining the Turing machine Turing Machines Consist of 3 parts: Tape divided into squares/cells on which symbols can be written on and read from (infinitely long in both directions) Movable read/write tape head that can read symbols from the tape and write symbols to the tape A set of rules that tell the head what to do next Head starts in a special start state and at a particular tape cell At each time step, the head reads the symbol at its current tape cell. The head then follows the rule that corresponds to that symbol and the head\u2019s current state. The rule tells the head what symbol to write on the current tape cell (replacing the previous symbol); whether the head should move to the right, move to the left, or stay put; and what the head\u2019s new state is. When the head goes into a special halt state, the machine is done and stops. The input to the machine is the set of symbols written on the tape before the machine starts. The output from the machine is the set of symbols written on the tape after the machine halts. Universal Turing Machines A universal turing machine U can emulate a Turing machine M running on an input I U starts with a tape that encodes the input I and the machine M At each step U reads the current symbol in I from the input part of the tape, decodes the appropriate rule from the M part of the tape, and carries it out on the input part, all the while keeping track (on some other part of its tape) of what state M would be in if M were actually running on the given input. When M would have reached the halt state, U also halts, with the input (now output) part of its tape now containing the symbols M would have on its tape after it was run on the given input I . Led to the development a decade later of programmable computers that developed into the modern computers we have today Turing's Solution to the Decision Problem Relies on fact that a turing machie M_1 (encoded on a tape) can be fed as input to another Turing machine M_2 By the assumption that the answer is yes to the decision problem, there is some definite procedure that, given M and I as input, will decide whether or not this particular statement is true. Turing\u2019s proof shows that this assumption leads to a contradiction. assuming answer is yes is equivalent to saying we can design a turing machine H to detect infinite loop (detect if a program halts, aka the halting problem) Turing proved by contradiction that there is no algorithm that can solve the halting problem wich demonstrates the answer to the decision problem (does every mathematical statement have an algorithm that can decide its truth value) is no Turing used similar techniques as Godel in his proof-- encoding mathematical statemenets. He encoded them as Turing machines so that they can run each other Summary of turing's accomplishments: he rigorously defined the notion of \u201cdefinite procedure.\u201d his definition, in the form of Turing machines, laid the groundwork for the invention of electronic programmable computers. he showed what few people ever expected: there are limits to what can be computed. Ch. 5 Evolution \"In a single stroke, the idea of evolution by natural selection unifies the realm of life, meaning, and purpose with the realm of space and time, cause and effect, mechanism and physical law.\" --Daniel Dennett Darwin did not come up with the idea of evolution all on his own George Louis Leclerc de Buffon proposed idea of evolution 100 years before Darwin Jean-Baptiste Lamarck was a prominent pre-darwin evolutionist, though his ideas were rejected by his contemporaries (including fellow evolutionists). they did turn out to be wrong but they influenced Darwin SImilarly, Darwin's grandfather also belived in evolution of species from a single ancestor Science is not an act of lone genius, rather we stand on the shoulders of giants to see further ahead HMS Beagle voyage gave him exposure to the following ideas from books/readings and physical measurements/observations Gradual change over long periods can produce very large effects (Charles Lyell\u2019s Principles of Geology ) Population growth combined with limited resources creates a struggle for existence (Thomas Malthus\u2019s Essay on the Principle of Population ) Collections of individuals acting in self-interested ways produce global benefit (Adam Smith's Wealth of Nations and the invisible hand) Life seems to allow almost infinite variation, and a species\u2019 particular traits seem designed for the very environment in which the species lives. Species branch out from common ancestors. Eventually arrived at a coherent theory of evolution by natural selection: Individual organisms have more offspring than can survive, given limited food resources. The offspring are not exact copies of the parents but have some small amount of random variation in their traits. The traits that allow some offspring to survive and reproduce will be passed on to further offspring, thus spreading in the population. Very gradually, through reproduction with random variation and individual struggles for existence, new species will be formed with traits ideally adapted to their environments Alfred Russell Wallace had also come up with the idea of evolution by natural selection at the same time and independetly. this led to them publishing their work together A year later darwin published his book On the Origin of Species Major ideas of Darwin's theory: Evolution has occurred; that is, all species descend from a common ancestor. The history of life is a branching tree of species. Natural selection occurs when the number of births is greater than existing resources can support so that individuals undergo competition for resources. Traits of organisms are inherited with variation. The variation is in some sense random \u2014that is, there is no force or bias leading to variations that increase fitness (though, as I mentioned previously, Darwin himself accepted Lamarck\u2019s view that there are such forces). Variations that turn out to be adaptive in the current environment are likely to be selected , meaning that organisms with those variations are more likely to survive and thus pass on the new traits to their offspring, causing the number of organisms with those traits to increase over subsequent generations. Evolutionary change is constant and gradual via the accumulation of small, favorable variations. Entropy decreases (living systems become more organized as opposed to less as 2nd law of thermodynamics says would happen for an isolated system) because natural selection performs work (the energy for this work comes from individual organisms metabolizing energy from their environments) Darwin's theory predated the discovery of DNA (the mechanism explaining how traits get passed from parent to offspring and how variation in those traits occur- mutations/errors during dna repair or replication) Mendel\u2019s experiments contradicted the widely believed notion of \u201cblending inheritance\u201d\u2014 that the offspring\u2019s traits typically will be an average of the parents\u2019 traits. Darwinism and Mendelism were thought to be opposing schools of view until reconciled in the 1920s The Modern Synthesis- wasn't until statistics was developed (by Ronald Fisher & Francis Galton) and applied, that a mathematical framework (population genetics) was concieved that demonstrated the two evidence based theories complemented each other Modern Synthesis principles: Natural selection is the major mechanism of evolutionary change and adaptation. Evolution is a gradual process, occurring via natural selection on very small random variations in individuals. Variation of this sort is highly abundant in populations and is not biased in any direction (e.g., it does not intrinsically lead to \u201cimprovement,\u201d as believed by Lamarck). The source of individual variation is random genetic mutations and recombinations. Macroscale phenomena, such as the origin of new species, can be explained by the microscopic process of gene variation and natural selection. molecular basis of genes- DNA -was not discovered until afterwards (post 1930s and published in 1950s) furthermore the mechnism by which variation arises-- mutation during DNA replication/repair was discovered after that paleontologists disputed the idea of gradual change from darwins theory of evolution due to what appeared to be big leaps in the fossil record. also new tech is making this idea of gradual change due to natural selection come under increasing scrutiny also attacked the idea that all traits were the result of adaptations strictly required for survival and reproduction Ch. 6 Genetics Transcription: RNA polymerase splits a strand of DNA and creates an anticopy of mRNA (gene is transcribed as mRNA) Translation: mRNA leaves the nucleus and goes to a ribosome in the cytoplasm where tRNA is fed in and used to make the protein coded for by the piece of mRNA when the ribosome gets the stop codon, the protein is released into the cytoplasm where it then goes to perform its function The transcription and translation of a gene is called the gene\u2019s expression and a gene is being expressed at a given time if it is being transcribed and translated. All this happens continually and simultaneously in thousands of sites in each cell, and in all of the trillions of cells in your body All this complex cellular machinery\u2014the mRNA, tRNA, ribosomes, polymerases, and so forth\u2014that effect the transcription, translation, and replication of DNA are themselves encoded in that very DNA The DNA contains coded versions of its own decoders The processes sketched above were understood in their basic form by the mid-1960s Ch. 7 Defining and Measuring Complexity there is not yet a single science of complexity but rather several different sciences of complexity with different notions of what complexity means Science often makes progress by inventing new terms to describe incompletely understood phenomena; these terms are gradually refined as the science matures and the phenomena become more completely understood. The diversity of measures that have been proposed indicates that the notions of complexity that we\u2019re trying to get at have many different interacting dimensions and probably can\u2019t be captured by a single measurement scale. Size Doesn't capture complexity in genomes For instance, Humans have 250 times as many base pairs as yeast but an amoeba has 225 times as many base pairs as humans Entropy Doesn't capture our intuituve concept of complexity A completely random genome would have more complexity than the human genome if using shannon entropy as the measure of complexity though using just the string of base bairs as messages doesn't really capture the idea that the string encodes complexity. the string itself can be arbitrarily \"complex\" by whatever measure you use, its the resulting behaviors that emerge when the string of dna is used in an organism that we actually want to measure the complexity of Logical Depth Proposed in early 80s by mathematician Charles Benett More complex objects are harder to construct. Measure the number of steps of the Turing machine needed to construct the description of an object, Theoretical properties match our intuitions of complexity No practical way of measuring this for any natural object of interest Thermodynamic Depth Proposed in late 80s by Seth Llyod and Heiz Pagels Determine \u201cthe most plausible scientifically determined sequence of events that lead to the thing itself,\u201d and measure \u201cthe total amount of thermodynamic and informational resources required by the physical construction process.\u201d Great theoretical properties, not very useful in practice Computational Capacity The sophistication of what they can compute Stephen Wolfram proposed systems are complex if their computational abilities are equivalent to a turing machine Statistical Complexity Proposed by physicists Jim Crutchfield and Karl Young The minimum amount of information about the past behavior of a system that is needed to optimally predict the statistical behavior of the system in the future predicting the statis- tical behavior consists of constructing a model of the system, based on observations of the messages the system produces, such that the model\u2019s behavior is statistically indistinguishable from the behavior of the system itself. ML could play a role here in constructing a model of the system from training information (how much training information and how many params to predict the system's behavior could be a good measure of complexity) would still be limited by compute and available training data so more complex systems like humans would not be able to be fully modeled and their complexity measured I do think this gives one of the best and most practical definitions so far of complexity (actually I think my interpretation is slightly wrong/diff than what the def actually is-- need to read the paper) The quantitative value of statistical complexity is the information content of the simplest such model that predicts the system\u2019s behavior. Thus, like effective complexity, statistical complexity is low for both highly ordered and random systems, and is high for systems in between\u2014those that we would intuitively consider to be complex. Has been measured in real-world pheomena (e.g. firing patterns of neurons) Fractal Dimension The fractal dimension quantifies the number of copies of a self- similar object at each level of magnification of that object Equivalently, fractal dimension quantifies how the total size (or area, or volume) of an object will change as the magnification level changes Only perfect fractals\u2014those whose levels of magnification extend to infinity\u2014have precise fractal dimension. For real-world finite fractal-like objects such as coastlines, we can measure only an approximate fractal dimension fractal dimension \u201cquantifies the cascade of detail\u201d in an object. That is, it quantifies how much detail you see at all scales as you dive deeper and deeper into the infinite cascade of self-similarity. has been applied to measure real-world phenomena but only captures one kind of complexity we want to measure Degree of Hierarchy Proposed by Herbert Simon (genius polymath) in 1962 paper \u201cThe Architecture of Complexity\u201d the complex system being composed of subsystems that, in turn, have their own subsystems, and so on Simon proposed that the most important common attributes of complex systems are hierarchy and near-decomposibility Hierarchy- subsystem that have subsystems themselves. similar otion as fractals with self-similar patterns at all scales Near-decomposibility- many more strong interactions within a subsystem than between subsystems Simon contends that evolution can design complex systems in nature only if they can be put together like building blocks\u2014that is, only if they are hierachical and nearly decomposible; Simon suggests that what the study of complex systems needs is \u201ca theory of hierarchy.\u201d Ch. 8 Self-Reproducing Computer Programs Von Neumann\u2019s original self-reproducing automaton (described mathemat- ically but not actually built by von Neumann) similarly contained not only a self-copying program but also the machinery needed for its own interpretation. The complete work was eventually published in 1966 as a book, Theory of Self-Reproducing Automata Ch. 9 Genetic Algorithms Two inputs: Population of candidate algorithms Fitness function that assigns a fitness value to each candidate algorithm measuring how well it performed the desired task Repeat the following steps for some number of generations : Generate an initial population of candidate solutions. The simplest way to create the initial population is just to generate a bunch of random programs (strings), called \u201cindividuals.\u201d Calculate the fitness of each individual in the current population. Select some number of the individuals with highest fitness to be the parents of the next generation. Pair up the selected parents. Each pair produces offspring by recombining parts of the parents, with some chance of random mutations, and the offspring enter the new population. The selected parents continue creating offspring until the new population is full (i.e., has the same number of individuals as the initial population). The new population now becomes the current population. Go to step 2. the GA will often evolve a solution that works, but it\u2019s hard to see why it works. That is often because GAs find good solutions that are quite different from the ones humans would come up with Evolutionary algorithms are a great tool for exploring the dark corners of design space GAs for neural network architecture and hyperparameter tuning? Ch. 10 Cellular Automata, Life, and the Universe Brain computes in a fundamentally different way than digital computers. Maybe digital computers cannot replicate brain computations at a global scale many people have studied computation in nature via an idealized model of a complex system called a cellular automaton john von neumann showed a cellular automaton with 29 states was equivalent of a universal turing machine conway showed game of life is also universal turing machine not very good at replicating von-neumann style computations since they are inherently non-von-neumann architecture of parallel computation. therefore the computation is slow and resource inefficient if at all possible for humans to figure out the initial start states Wolfram's book New Kinds of Science posits that all natural processes are computations (process information according to set of rules) Ch. 11 Computing with Particles difficult to design cellular automata to perform tasks that require collective decision making among all the cells the genetic algorithm managed to evolve a rule whose behavior can be explained in terms of information-processing particles. expirement worked for 1-d cellular automata but could possibly be scaled up to 3-d to explain the computations in the brain as processing information waves Ch. 12 Information Processing in Living Systems The meaning of the input and output information in a Turing machine comes from its interpretation by humans. The meaning of the information created in intermediate steps in the computation also comes from its interpretation (or design) by humans, who understand the steps in terms of commands in a high-level programming language. This higher level of description allows us to understand computations in a human-friendly way that is abstracted from particular details of machine code and hardware. Ch. 13 Analogy Making in Computers humans are good at perceiving abstract similarity between two entities or situations by letting concepts \u201cslip\u201d from situation to situation in a fluid way takeaways from computer making analogies program: you can\u2019t explore everything, but you don\u2019t know which possibilities are worth exploring without first exploring them. You have to be open-minded, but the territory is too vast to explore everything; you need to use probabilities in order for exploration to be fair uses ant-colony like optimization algorithm to balance exploration of breadth and depth uses temperature to also control how much exploration is done The ultimate goal of AI is to take humans out of the meaning loop and have the computer itself perceive meaning. This is AI\u2019s hardest problem. analogy making will likely be part of the solution Ch. 14 Prospects of Computer Modeling Models are ways for our minds to make sense of observed phenomena in terms of concepts that are familiar to us, concepts that we can get our heads around Prediction Models vs. Idea Models Preditiction models are usually mathematical and can be used to predict the future state of a system Idea models are relatively simple and meant to gain insights into a general concept without the necessity of making detailed predictions about any specific system (e.g. turing machine, cellular automaton, koch curve, prisoner's dilemma) Tit for tat was the optimal strategy in the prisoner's dilemma retaliated a defection by defecting the next turn forgave a defection if the oppononent began cooperating by also cooperating again never was the first to defect (common trait amongst all the best strategies) strategy was clear and predictable for the opponent, making cooperation much easier a genetic algorithm evolved a same/similar strategy to the tit for tat strategy proposed by a mathematician \u201cnice, retaliatory, forgiving, and clear\u201d are the characteristics Axelrod cited as requirements for success in the repeated Prisoner\u2019s Dilemma. \u201cHow to Save the Planet: Be Nice, Retaliatory, Forgiving, and Clear.\u201d \u201cFive Rules for the Evolution of Cooperation.\u201d all models are wrong in some way, but some are very useful for beginning to address highly complex systems. Independent replication can uncover the hidden unrealistic assumptions and sensitivity to parameters that are part of any idealized model. Ch. 15 Network Science A major discovery to date of network science is that high-clustering, skewed degree distributions, and hub structure seem to be characteristic of the vast majority of all the natural, social, and technological networks that network scientists have studied. the small-world property : a network has this property if it has relatively few long-distance connections but has a small average path-length relative to the total number of nodes. Small-world networks also typically exhibit a high degree of clustering It has been hypothesized that at least two conflicting evolutionary selective pressures are responsible: the need for information to travel quickly within the system the high cost of creating and maintaining reliable long-distance connections Small-world networks solve both these problems by having short average path lengths between nodes in spite of having only a relatively small number of long-distance connections. scale free networks = power law degree distribution (e.g. 1/k^2 for webpages) small # hubs nodes with degrees over large range of possible values self similarity (invariant under rescaling) small-world structure Ch. 16 Applying Network Science to Real-world Problems Network science includes techniques that can be applied to a huge domain of fields preferential attachment - networks grow in such a way that nodes with higher degree receive more new links than nodes with lower degree. explains the existence of many scale-free networks in the real world other mechanishms also exist that are similar and quite different studying dynamics of information spread, not just the structure of the network, is important open problem in network science Cascading failures- one nodes failure shifts lode to other nodes, that overload and subsequeuntly fail causing a domino chain of failures The Brain Brain has small-world properties which has several benefits from an evolution perspective: more resilient to losing neurons or functional areas (though losing hubs causes more drastic harm) more energy efficient structure since signals are not sent to all neurons/functional areas greatly facilitates synchronization (groups of neurons firing repeatedly) which is a major mechanism by which the brain transmits information efficiently The brain can be viewed as a network at several different levels of description; for example, with neurons as nodes and synapses as links, or with entire func- tional areas as nodes and larger-scale connections between them (i.e., groups of neural connections) as links. Genetic Regulatory Networks Humans and mustard seeds have roughly same number of genes (25k) Our complexity is thought to come from the network of genes regulating each other regulatory networks are scale free which makes them resilient (important given the transcription process is prone to errors) Ch. 17 The Mystery of Scaling metabolism does not scale linearly with an organism's mass becuase the corresponding surface area to distribute the by-product heat over would not scale at the same rate, making larger animals overheat If you plot a power law on a double logarithmic plot (both axes are log scale), it will look like a straight line, and the slope of that line will be equal to the power law\u2019s exponent Power law distributions are fractals\u2014they are self-similar at all scales of magnification, and a power-law\u2019s exponent gives the dimension of the corresponding fractal, where the dimension quantifies precisely how the distribution\u2019s self-similarity scales with level of magnification fractal structure is one way to generate a power-law distribution; and if you happen to see that some quantity (such as metabolic rate) follows a power-law distribution, then you can hypothesize that there is something about the underlying system that is self-similar or \u201cfractal-like.\u201d metabolic scaling theory came out of network science and fractals and explains the scaling mystery in organisms Understanding power-law distributions, their origins, their significance, and their commonalities across disciplines is currently a very important open problem in many areas of complex systems research. Ch. 18 Evolution Complexified evolutionary developmental biology is answering a lot of questions related to diversity of species and its relationship with genetics and evolution genetic regulatory networks allow for much larger space of possibilities than simply the number of genes would indicate (explains large differences in species despite similar number of genes) Two types of genes: functional- encode proteins for cell building/maintenance regulatory- encode proteins for turning off/on other genes by binding to their corresponding DNA sequences and disallowing or allowing RNA to bind to the gene and complete the transcription and translation process regulatory genes can encode for proteins that regulate other regulatory genes, demonstrating how complex the regulation network can get and how large the combinatorial space of possible genetic expressions is which leads to large diversity in organisms Stuart Kauffman demonstrated natural selection is in principle not necessary to create a complex creature with Random Boolean Networks (RBNs) a network structure with enough nodes (e.g. gene regulatory network) controlling other nodes will result in the emergence of complex and self-organized behavior turned the idea of evolution over time being the key to organisms' complexity on its head Kauffman\u2019s book, The Origins of Order talks more about these ideas Developing accurate models of genetic regulatory networks is currently a very active research area in biology RBNs have severe limatations with noise and make lots of simplifying assumptions that make it less accurate model of genetic regulatory networks Evolutionary biologist Dan McShea classifies evolutionists into three categories: adaptationists, who believe that natural selection is primary historicists, who give credit to historical accident for many evolutionary changes structuralists, such as Kauffman, who focus on how organized structure comes about even in the absence of natural selection Evolutionary biology is still working on answering its most important question: How does complexity in living systems come about through evolution? Ch. 19 Past & Future of Complex Systems Research mathematician Norbert Wiener proposed the science underlying complex systems in both biology and engineering should focus not on the mass , energy , and force concepts of physics, but rather on the concepts of feedback, control, information, communication, and purpose (or \u201cteleology\u201d) created field of cybernetics-- control and communication theory, in machines and animals H. Ross Ashby\u2019s \u201cDesign for a Brain,\u201d an influential proposal for how the ideas of dynamics, information, and feedback should inform neuroscience and psychology Norbert Wiener\u2019s books Cybernetics and The Human Use of Human Beings , which attempted to provide a unified overview of the field and its relevance in many disciplines A similar effort toward finding common principles, under the name of General System Theory, was launched in the 1950s by the biologist Ludwig von Bertalanffy, who characterized the effort as \u201cthe formulation and deduc- tion of those principles which are valid for \u2018systems\u2019 in general.\u201d A system is defined in a very general sense: a collection of interacting elements that together produce, by virtue of their interactions, some form of system-wide behavior. Artificial intelligence, artificial life, systems ecology, systems biology, neural networks, systems analysis, control theory, and the sciences of complexity have all emerged from seeds sown by the cyberneticists and general system theorists. Cybernetics and general system theory have been largely overshadowed by these offspring disciplines Tough to advance field when we can't even come up with a vocab to describe it adequately (also need the mathematics to describe complex systems in general) The mathematician Steven Strogatz puts it this way: \u201cI think we may be missing the conceptual equivalent of calculus, a way of seeing the consequences of myriad interactions that define a complex system. It could be that this ultracalculus, if it were handed to us, would be forever beyond human comprehension. We just don\u2019t know.\u201d pursuing these goals will require, as great science always does, an adventurous intellectual spirit and a willingness to risk failure and reproach by going beyond mainstream science into ill-defined and uncharted territory. \u201cOne doesn\u2019t discover new lands without consenting to lose sight of the shore.\u201d - Andre\u0301 Gide","title":"Complex Systems"},{"location":"ai/complexity/#complexity","text":"Reductionism- belief that a whole can be understood completely by understanding its parts and the nature of their sum Rene Descartes Opposed by phenomena like intelligencewhere complex behavior arrives from large collections of simple components Santa Fe Institute created for study of complex systems that require inherently interdisciplinary environment Founded on idea of antireductionism when solving important problems Melanie Mitchell Her adviser, cognitive scientist Douglas Hofstadter @ UMich Complex Systems ~ Emergent Computation How do we move beyond the traditional paradigm of reductionism toward a new understanding of seemingly irreducibly complex systems? four subject areas that are fundamental to the study of complex systems: information computation dynamics and chaos evolution \"Science has explored the microcosmos and the macrocosmos; we have a good sense of the lay of the land. The great unexplored frontier is complexity.\" - Heinz Pagels, The Dreams of Reason What we now call \u201ccomplex systems\u201d can trace its ancestry to cybernetics and the related field of systems science","title":"Complexity"},{"location":"ai/complexity/#ch-1-what-is-complexity","text":"What if we are viewing intelligence from the wrong persepctive Its possible we see intelligence as too singular an end objective that we can engineer models to produce Maybe we need lots of smaller models with simple functionality that interact to create a collective intelligence we can view neural nets from this persepctive since they are made of lots of simple neurons interacting however the limitation of neural nets is that the neuron interactions are very rigid with predifined connections due to the model's architecture. this isn't quite the way the neurons in the brain are connected and could explain some of the shortcomings of neural nets when it comes to true intelligence Maybe a better persepective is that what we consider intelligence is an emergent property of complex systems and that it is not relegated to only a single animal/human brain but can rather include networks of simpler orgnisms such as ants or humans that form a collective \"intelligence\" Understading the mechanisms that allow ant colonys to express a collective intelligence is still an active area of research Ants have social organizations that allow a colony to collectively do things that increase the survival probability of the community as a whole. Humans are similar with the entire emergence of farming and cities and medicine. Without our social structures, human survival on our own, like ants on their own, is much harder and a lower probability Key aspect of complex systems is the lack of a central controller to organize the simple entities The word complex comes from the Latin root plectere : to weave, entwine complex system : a system in which large networks of components with no central control and simple rules of operation give rise to complex collective behavior, sophisticated information processing, and adaptation via learning or evolution Self-organizing Systems- organized behavior arises without an internal or exter- nal controller or leader Since simple rules produce complex behavior in hard-to-predict ways, the macroscopic behavior of such systems is sometimes called emergent . alternative definition of a complex system : a system that exhibits nontrivial emergent and self-organizing behaviors . The central question of the sciences of complexity is how this emergent self-organized behavior comes about The proper domain of computer science is information processing writ large across all of nature. \u2014Chris Langton (Quoted in Roger Lewin, Complexity: Life at the Edge of Chaos )","title":"Ch. 1 What is Complexity?"},{"location":"ai/complexity/#insect-colonies","text":"An ant colony, for instance, can consist of hundreds to millions of individual ants, each one a rather simple creature that obeys its genetic imperatives to seek out food, respond in simple ways to the chemical signals of other ants in its colony, fight intruders, and so forth build sophisticated colonies, can even build bridges with their bodies for others in the colony to cross how did biological evolution produce creatures with such an enormous contrast between their individual simplicity and their collective sophistication?","title":"Insect Colonies"},{"location":"ai/complexity/#the-brain","text":"global behavior of the brain of perception and conciousness are due to the interactions of billions of simple neurons A neuron fires when it receives enough signals from other neurons through its dendrites. Firing consists of sending an electric pulse through the axon, which is then converted into a chemical signal via chemicals called neurotransmitters . This chemical signal in turn activates other neurons through their dendrites. The firing frequency and the resulting chemical output signals of a neuron can vary over time according to both its input and how much it has been firing recently. individuals (neurons or ants) perceive signals from other individuals, and a sufficient summed strength of these signals causes the individuals to act in certain ways that produce additional signals. The overall effects can be very complex. unsolved questions: what do neuronal signals mean? How do neurons interact to produce global cognitive behavior? How do the interactions cause the brain to think thoughts and learn new thigs? How did this all emerge from evolution?","title":"The Brain"},{"location":"ai/complexity/#the-immune-system","text":"Complex response to inaders caused by a cascade of signals once a independent cell detects an invader We do not yet know precisely how the system avoids attacking the body; or what gives rise to flaws in the system, such as autoimmune diseases, in which the system does attack the body; or the detailed strategies of the human immunodeficiency virus (HIV), which is able to get by the defenses by attacking the immune system itself Figuring out how complex systems like these work is the key to solving many health related issues AI could be critical to the future of healthcare with respect to understanding the body, how its cells work, and the interactions between the systems in the cells","title":"The Immune System"},{"location":"ai/complexity/#economies","text":"Adam Smith's invisible hand that sef-corrects the markets is an example of a complex system at work self-interested individuals make buy/sell decisions that interact to form very hard to predict market behavior","title":"Economies"},{"location":"ai/complexity/#the-internet","text":"complex systems scientists have discovered that the network as a whole has many unexpected large-scale properties involving its overall structure, the way in which it grows, how information propagates over its links, and the coevolutionary relationships between the behavior of search engines and the Web\u2019s link structure, all of which lead to what could be called \u201cadaptive\u201d behavior for the system as a whole","title":"The Internet"},{"location":"ai/complexity/#ch-2-dynamics-chaos-and-prediction","text":"\"It makes me so happy. To be at the beginning again, knowing almost nothing. . . . The ordinary-sized stuff which is our lives, the things people write poetry about\u2014clouds\u2014daffodils\u2014waterfalls...these things are full of mystery, as mysterious to us as the heavens were to the Greeks...It\u2019s the best possible time to be alive, when almost everything you thought you knew is wrong.\" \u2014Tom Stoppard, Arcadia Dynamical Systems Theory (dynamics)- describing and predicting behavior of systems with complex changing behavior at the macroscopic level, emerging from the collective actions of many interacting components describe the general ways systems can change, what types of macroscopic behavior are possible, and what kinds of predictions about that behavior can be made Chaos theory is a fasciating subfield of it Started with Artistotle Aristotle proposed a law of motion which stated that rest is the natural state of objects This seems to make intuitive sense based on our experience in the day to day world so it is no suprise that this dominated western thinking for hundreds of years until Galileo did experiments and proposed that rest is not the natural state of objects, rather it takes force to stop a moving object. this would be an unintuitive result without the knowledge of air resistance and other hard to see forces that affect all our observations on earth. galileo launched the scientific revolution with experimental observations at its core newton came right after galileo and invented the science of dynamics (also inventing calculus to describe motion and change along the way) Classical Mechanics: Newton's work Kinematics- describes how things move Dynamics- describes why things follow the laws of kinematics Newton's laws are foundation of dynamics: Constant motion: Any object not subject to a force moves with unchanging speed. Inertial mass: When an object is subject to a force, the resulting change in its motion is inversely proportional to its mass. Equal and opposite forces: If object A exerts a force on object B, then object B must exert an equal and opposite force on object A. Newtonian mechanics produced a picture of a \u201cclockwork universe,\u201d one that is wound up with the three laws and then runs its mechanical course. The mathematician Pierre Simon Laplace saw the implication of this clockwork view for prediction: in 1814 he asserted that, given Newton\u2019s laws and the current position and velocity of every particle in the universe, it was possible, in principle, to predict everything for all time. Discovery of quantum mechanics demonstrated this idea was not possible Understanding of chaotic systems (small changes in initial conditions = large changes in resulting behavior; aka sensitive dependence on initial conditions) further demonstrated the idea was not possible small errors in measurement of initial conditons would lead to large errors in long term predictions of behavior observed before quantum mechanics discovered: Poincare (founder of dynamical systems theory) in 19th century tried to solve 3 body problem of gravitation but was unsuccesful (invented algebraic topology in the process lol) predict the motion of 3 objects exerting gravitational force on one anothe Poincare prediccted sensitive depen- dence on initial conditions would make weather prediction impossible Meteorologist Edward Lorenz demonstrated in 60s that even simple computer models of weather were subject to sensitigve depedence on initial conditions even now, weather predicitions dont go beyond a week into the future very succesfully It is not yet known whether this limit is due to fundamental chaos in the weather, or how much this limit can be extended by collecting more data and building even better models. TODO: look into deepmind's paper on predicting the weather to see if more data and better models is able to overcome the perceived sensitve dependence on initial conditions","title":"Ch. 2 Dynamics, Chaos, and Prediction"},{"location":"ai/complexity/#linearity-vs-nonlinearity","text":"a linear system can be understood by understanding its parts individually and then putting them together a reductionist's dream a nonlinear system's whole is different from the sum of its parts","title":"Linearity vs. Nonlinearity"},{"location":"ai/complexity/#logistic-map","text":"x_{t+1} = R x_t (1 - x_t) Type of attractor is one way of characterizing the behavior of a system The logistic map is an extremely simple equation and is completely deterministic: every x_t maps onto one and only one value of x_{t+1} . And yet the chaotic trajectories obtained from this map, at certain values of R , look very random\u2014enough so that the logistic map has been used as a basis for generating pseudo-random numbers on a computer. Thus apparent randomness can arise from very simple deterministic systems. In short, the presence of chaos in a system implies that perfect prediction a\u0300 la Laplace is impossible not only in practice but also in principle , since we can never know x 0 to infinitely many decimal places. This is a profound negative result that, along with quantum mechanics, helped wipe out the optimistic nineteenth-century view of a clockwork Newtonian universe that ticked along its predictable path. deeper studies of the logistic map and related maps have resulted in an equally surprising and profound positive result\u2014the discovery of universal characteristics of chaotic systems. even though \u201cprediction becomes impossible\u201d at the detailed level, there are some higher-level aspects of chaotic systems that are indeed predictable. The logistic map is a simplified model of population growth, but the detailed study of it and similar model systems resulted in a major revamp- ing of the scientific understanding of order, randomness, and predictability. This illustrates the power of idea models \u2014models that are simple enough to study via mathematics or computers but that nonetheless capture fundamental properties of natural complex systems","title":"Logistic Map"},{"location":"ai/complexity/#ch-3-information","text":"Why the second law should distinguish between past and future while all the other laws of nature do not is perhaps the greatest mystery in physics making a measurement to gain information entails an increase of entropy since acquiring info requires expending work In his 1948 paper \u201cA Mathematical Theory of Communication,\u201d Claude Shannon (working @ Bell labs) gave a narrow definition of information and proved a very important theorem, which gave the maximum possible transmission rate (channel capacity) of information over a given channel (wire or other medium), even if there are errors in transmission caused by noise on the channel Shannon Entropy- entropy of the message source that information content is defined in terms of a message can be any unit of communi- cation, be it a letter, a word, a sentence, or even a single bit the entropy (and thus information content) of a source is defined in terms of message probabilities Shannon's results led to the development of coding theory for data compression and was also applied to many other fields like crytography, bioinformatics, and ai Information , as narrowly defined by Shannon, concerns the predictability of a message source information theoretic notions such as entropy, information content, mutual information, information dynamics, and others have played central though controversial roles in attempts to define the notion of complexity and in characterizing different types of complex systems.","title":"Ch. 3 Information"},{"location":"ai/complexity/#ch-4-computation","text":"3 big questions on mathematics proposed by David Hilbertin 1900: Is mathematics complete? given a finite set of axioms, can every mathematical statement be proved/disproved Is mathematics consistent? can only true statements be proved (proving 1 + 1 = 3 would mean its inconsistent) Is every statement in mathematics decidable? there is an algorithm that can be applied to every statement that will tell us in finite time whether the statement is true/false decision problem connected to Gottfried Leibniz In 1930, Godel presented his incompleteness theorem stating if mathematics is consistent, then it is incomplete and if it is complete, then it is inconsistent Go\u0308del gave an example of a mathematical statement that can be translated into English as: \u201cThis statement is not provable.\u201d Let\u2019s call this statement \u201cStatement A .\u201d Now, suppose Statement A could indeed be proved. But then it would be false (since it states that it cannot be proved). That would mean a false statement could be proved\u2014arithmetic would be inconsistent. Okay, let\u2019s assume the opposite, that Statement A cannot be proved. That would mean that Statement A is true (because it asserts that it cannot be proved), but then there is a true statement that cannot be proved\u2014 arithmetic would be incomplete. Ergo, arithmetic is either inconsistent or incomplete. Godel essentially translated this statement into a mathematical proof This answered the first two questions proposed by Hilbert (shocking many mathematicians in the process) Turing demonstrated the answer is no to Hilbert's 3rd question by defining the Turing machine","title":"Ch. 4 Computation"},{"location":"ai/complexity/#turing-machines","text":"Consist of 3 parts: Tape divided into squares/cells on which symbols can be written on and read from (infinitely long in both directions) Movable read/write tape head that can read symbols from the tape and write symbols to the tape A set of rules that tell the head what to do next Head starts in a special start state and at a particular tape cell At each time step, the head reads the symbol at its current tape cell. The head then follows the rule that corresponds to that symbol and the head\u2019s current state. The rule tells the head what symbol to write on the current tape cell (replacing the previous symbol); whether the head should move to the right, move to the left, or stay put; and what the head\u2019s new state is. When the head goes into a special halt state, the machine is done and stops. The input to the machine is the set of symbols written on the tape before the machine starts. The output from the machine is the set of symbols written on the tape after the machine halts.","title":"Turing Machines"},{"location":"ai/complexity/#universal-turing-machines","text":"A universal turing machine U can emulate a Turing machine M running on an input I U starts with a tape that encodes the input I and the machine M At each step U reads the current symbol in I from the input part of the tape, decodes the appropriate rule from the M part of the tape, and carries it out on the input part, all the while keeping track (on some other part of its tape) of what state M would be in if M were actually running on the given input. When M would have reached the halt state, U also halts, with the input (now output) part of its tape now containing the symbols M would have on its tape after it was run on the given input I . Led to the development a decade later of programmable computers that developed into the modern computers we have today","title":"Universal Turing Machines"},{"location":"ai/complexity/#turings-solution-to-the-decision-problem","text":"Relies on fact that a turing machie M_1 (encoded on a tape) can be fed as input to another Turing machine M_2 By the assumption that the answer is yes to the decision problem, there is some definite procedure that, given M and I as input, will decide whether or not this particular statement is true. Turing\u2019s proof shows that this assumption leads to a contradiction. assuming answer is yes is equivalent to saying we can design a turing machine H to detect infinite loop (detect if a program halts, aka the halting problem) Turing proved by contradiction that there is no algorithm that can solve the halting problem wich demonstrates the answer to the decision problem (does every mathematical statement have an algorithm that can decide its truth value) is no Turing used similar techniques as Godel in his proof-- encoding mathematical statemenets. He encoded them as Turing machines so that they can run each other Summary of turing's accomplishments: he rigorously defined the notion of \u201cdefinite procedure.\u201d his definition, in the form of Turing machines, laid the groundwork for the invention of electronic programmable computers. he showed what few people ever expected: there are limits to what can be computed.","title":"Turing's Solution to the Decision Problem"},{"location":"ai/complexity/#ch-5-evolution","text":"\"In a single stroke, the idea of evolution by natural selection unifies the realm of life, meaning, and purpose with the realm of space and time, cause and effect, mechanism and physical law.\" --Daniel Dennett Darwin did not come up with the idea of evolution all on his own George Louis Leclerc de Buffon proposed idea of evolution 100 years before Darwin Jean-Baptiste Lamarck was a prominent pre-darwin evolutionist, though his ideas were rejected by his contemporaries (including fellow evolutionists). they did turn out to be wrong but they influenced Darwin SImilarly, Darwin's grandfather also belived in evolution of species from a single ancestor Science is not an act of lone genius, rather we stand on the shoulders of giants to see further ahead HMS Beagle voyage gave him exposure to the following ideas from books/readings and physical measurements/observations Gradual change over long periods can produce very large effects (Charles Lyell\u2019s Principles of Geology ) Population growth combined with limited resources creates a struggle for existence (Thomas Malthus\u2019s Essay on the Principle of Population ) Collections of individuals acting in self-interested ways produce global benefit (Adam Smith's Wealth of Nations and the invisible hand) Life seems to allow almost infinite variation, and a species\u2019 particular traits seem designed for the very environment in which the species lives. Species branch out from common ancestors. Eventually arrived at a coherent theory of evolution by natural selection: Individual organisms have more offspring than can survive, given limited food resources. The offspring are not exact copies of the parents but have some small amount of random variation in their traits. The traits that allow some offspring to survive and reproduce will be passed on to further offspring, thus spreading in the population. Very gradually, through reproduction with random variation and individual struggles for existence, new species will be formed with traits ideally adapted to their environments Alfred Russell Wallace had also come up with the idea of evolution by natural selection at the same time and independetly. this led to them publishing their work together A year later darwin published his book On the Origin of Species Major ideas of Darwin's theory: Evolution has occurred; that is, all species descend from a common ancestor. The history of life is a branching tree of species. Natural selection occurs when the number of births is greater than existing resources can support so that individuals undergo competition for resources. Traits of organisms are inherited with variation. The variation is in some sense random \u2014that is, there is no force or bias leading to variations that increase fitness (though, as I mentioned previously, Darwin himself accepted Lamarck\u2019s view that there are such forces). Variations that turn out to be adaptive in the current environment are likely to be selected , meaning that organisms with those variations are more likely to survive and thus pass on the new traits to their offspring, causing the number of organisms with those traits to increase over subsequent generations. Evolutionary change is constant and gradual via the accumulation of small, favorable variations. Entropy decreases (living systems become more organized as opposed to less as 2nd law of thermodynamics says would happen for an isolated system) because natural selection performs work (the energy for this work comes from individual organisms metabolizing energy from their environments) Darwin's theory predated the discovery of DNA (the mechanism explaining how traits get passed from parent to offspring and how variation in those traits occur- mutations/errors during dna repair or replication) Mendel\u2019s experiments contradicted the widely believed notion of \u201cblending inheritance\u201d\u2014 that the offspring\u2019s traits typically will be an average of the parents\u2019 traits. Darwinism and Mendelism were thought to be opposing schools of view until reconciled in the 1920s The Modern Synthesis- wasn't until statistics was developed (by Ronald Fisher & Francis Galton) and applied, that a mathematical framework (population genetics) was concieved that demonstrated the two evidence based theories complemented each other Modern Synthesis principles: Natural selection is the major mechanism of evolutionary change and adaptation. Evolution is a gradual process, occurring via natural selection on very small random variations in individuals. Variation of this sort is highly abundant in populations and is not biased in any direction (e.g., it does not intrinsically lead to \u201cimprovement,\u201d as believed by Lamarck). The source of individual variation is random genetic mutations and recombinations. Macroscale phenomena, such as the origin of new species, can be explained by the microscopic process of gene variation and natural selection. molecular basis of genes- DNA -was not discovered until afterwards (post 1930s and published in 1950s) furthermore the mechnism by which variation arises-- mutation during DNA replication/repair was discovered after that paleontologists disputed the idea of gradual change from darwins theory of evolution due to what appeared to be big leaps in the fossil record. also new tech is making this idea of gradual change due to natural selection come under increasing scrutiny also attacked the idea that all traits were the result of adaptations strictly required for survival and reproduction","title":"Ch. 5 Evolution"},{"location":"ai/complexity/#ch-6-genetics","text":"Transcription: RNA polymerase splits a strand of DNA and creates an anticopy of mRNA (gene is transcribed as mRNA) Translation: mRNA leaves the nucleus and goes to a ribosome in the cytoplasm where tRNA is fed in and used to make the protein coded for by the piece of mRNA when the ribosome gets the stop codon, the protein is released into the cytoplasm where it then goes to perform its function The transcription and translation of a gene is called the gene\u2019s expression and a gene is being expressed at a given time if it is being transcribed and translated. All this happens continually and simultaneously in thousands of sites in each cell, and in all of the trillions of cells in your body All this complex cellular machinery\u2014the mRNA, tRNA, ribosomes, polymerases, and so forth\u2014that effect the transcription, translation, and replication of DNA are themselves encoded in that very DNA The DNA contains coded versions of its own decoders The processes sketched above were understood in their basic form by the mid-1960s","title":"Ch. 6 Genetics"},{"location":"ai/complexity/#ch-7-defining-and-measuring-complexity","text":"there is not yet a single science of complexity but rather several different sciences of complexity with different notions of what complexity means Science often makes progress by inventing new terms to describe incompletely understood phenomena; these terms are gradually refined as the science matures and the phenomena become more completely understood. The diversity of measures that have been proposed indicates that the notions of complexity that we\u2019re trying to get at have many different interacting dimensions and probably can\u2019t be captured by a single measurement scale.","title":"Ch. 7 Defining and Measuring Complexity"},{"location":"ai/complexity/#size","text":"Doesn't capture complexity in genomes For instance, Humans have 250 times as many base pairs as yeast but an amoeba has 225 times as many base pairs as humans","title":"Size"},{"location":"ai/complexity/#entropy","text":"Doesn't capture our intuituve concept of complexity A completely random genome would have more complexity than the human genome if using shannon entropy as the measure of complexity though using just the string of base bairs as messages doesn't really capture the idea that the string encodes complexity. the string itself can be arbitrarily \"complex\" by whatever measure you use, its the resulting behaviors that emerge when the string of dna is used in an organism that we actually want to measure the complexity of","title":"Entropy"},{"location":"ai/complexity/#logical-depth","text":"Proposed in early 80s by mathematician Charles Benett More complex objects are harder to construct. Measure the number of steps of the Turing machine needed to construct the description of an object, Theoretical properties match our intuitions of complexity No practical way of measuring this for any natural object of interest","title":"Logical Depth"},{"location":"ai/complexity/#thermodynamic-depth","text":"Proposed in late 80s by Seth Llyod and Heiz Pagels Determine \u201cthe most plausible scientifically determined sequence of events that lead to the thing itself,\u201d and measure \u201cthe total amount of thermodynamic and informational resources required by the physical construction process.\u201d Great theoretical properties, not very useful in practice","title":"Thermodynamic Depth"},{"location":"ai/complexity/#computational-capacity","text":"The sophistication of what they can compute Stephen Wolfram proposed systems are complex if their computational abilities are equivalent to a turing machine","title":"Computational Capacity"},{"location":"ai/complexity/#statistical-complexity","text":"Proposed by physicists Jim Crutchfield and Karl Young The minimum amount of information about the past behavior of a system that is needed to optimally predict the statistical behavior of the system in the future predicting the statis- tical behavior consists of constructing a model of the system, based on observations of the messages the system produces, such that the model\u2019s behavior is statistically indistinguishable from the behavior of the system itself. ML could play a role here in constructing a model of the system from training information (how much training information and how many params to predict the system's behavior could be a good measure of complexity) would still be limited by compute and available training data so more complex systems like humans would not be able to be fully modeled and their complexity measured I do think this gives one of the best and most practical definitions so far of complexity (actually I think my interpretation is slightly wrong/diff than what the def actually is-- need to read the paper) The quantitative value of statistical complexity is the information content of the simplest such model that predicts the system\u2019s behavior. Thus, like effective complexity, statistical complexity is low for both highly ordered and random systems, and is high for systems in between\u2014those that we would intuitively consider to be complex. Has been measured in real-world pheomena (e.g. firing patterns of neurons)","title":"Statistical Complexity"},{"location":"ai/complexity/#fractal-dimension","text":"The fractal dimension quantifies the number of copies of a self- similar object at each level of magnification of that object Equivalently, fractal dimension quantifies how the total size (or area, or volume) of an object will change as the magnification level changes Only perfect fractals\u2014those whose levels of magnification extend to infinity\u2014have precise fractal dimension. For real-world finite fractal-like objects such as coastlines, we can measure only an approximate fractal dimension fractal dimension \u201cquantifies the cascade of detail\u201d in an object. That is, it quantifies how much detail you see at all scales as you dive deeper and deeper into the infinite cascade of self-similarity. has been applied to measure real-world phenomena but only captures one kind of complexity we want to measure","title":"Fractal Dimension"},{"location":"ai/complexity/#degree-of-hierarchy","text":"Proposed by Herbert Simon (genius polymath) in 1962 paper \u201cThe Architecture of Complexity\u201d the complex system being composed of subsystems that, in turn, have their own subsystems, and so on Simon proposed that the most important common attributes of complex systems are hierarchy and near-decomposibility Hierarchy- subsystem that have subsystems themselves. similar otion as fractals with self-similar patterns at all scales Near-decomposibility- many more strong interactions within a subsystem than between subsystems Simon contends that evolution can design complex systems in nature only if they can be put together like building blocks\u2014that is, only if they are hierachical and nearly decomposible; Simon suggests that what the study of complex systems needs is \u201ca theory of hierarchy.\u201d","title":"Degree of Hierarchy"},{"location":"ai/complexity/#ch-8-self-reproducing-computer-programs","text":"Von Neumann\u2019s original self-reproducing automaton (described mathemat- ically but not actually built by von Neumann) similarly contained not only a self-copying program but also the machinery needed for its own interpretation. The complete work was eventually published in 1966 as a book, Theory of Self-Reproducing Automata","title":"Ch. 8 Self-Reproducing Computer Programs"},{"location":"ai/complexity/#ch-9-genetic-algorithms","text":"Two inputs: Population of candidate algorithms Fitness function that assigns a fitness value to each candidate algorithm measuring how well it performed the desired task Repeat the following steps for some number of generations : Generate an initial population of candidate solutions. The simplest way to create the initial population is just to generate a bunch of random programs (strings), called \u201cindividuals.\u201d Calculate the fitness of each individual in the current population. Select some number of the individuals with highest fitness to be the parents of the next generation. Pair up the selected parents. Each pair produces offspring by recombining parts of the parents, with some chance of random mutations, and the offspring enter the new population. The selected parents continue creating offspring until the new population is full (i.e., has the same number of individuals as the initial population). The new population now becomes the current population. Go to step 2. the GA will often evolve a solution that works, but it\u2019s hard to see why it works. That is often because GAs find good solutions that are quite different from the ones humans would come up with Evolutionary algorithms are a great tool for exploring the dark corners of design space GAs for neural network architecture and hyperparameter tuning?","title":"Ch. 9 Genetic Algorithms"},{"location":"ai/complexity/#ch-10-cellular-automata-life-and-the-universe","text":"Brain computes in a fundamentally different way than digital computers. Maybe digital computers cannot replicate brain computations at a global scale many people have studied computation in nature via an idealized model of a complex system called a cellular automaton john von neumann showed a cellular automaton with 29 states was equivalent of a universal turing machine conway showed game of life is also universal turing machine not very good at replicating von-neumann style computations since they are inherently non-von-neumann architecture of parallel computation. therefore the computation is slow and resource inefficient if at all possible for humans to figure out the initial start states Wolfram's book New Kinds of Science posits that all natural processes are computations (process information according to set of rules)","title":"Ch. 10 Cellular Automata, Life, and the Universe"},{"location":"ai/complexity/#ch-11-computing-with-particles","text":"difficult to design cellular automata to perform tasks that require collective decision making among all the cells the genetic algorithm managed to evolve a rule whose behavior can be explained in terms of information-processing particles. expirement worked for 1-d cellular automata but could possibly be scaled up to 3-d to explain the computations in the brain as processing information waves","title":"Ch. 11 Computing with Particles"},{"location":"ai/complexity/#ch-12-information-processing-in-living-systems","text":"The meaning of the input and output information in a Turing machine comes from its interpretation by humans. The meaning of the information created in intermediate steps in the computation also comes from its interpretation (or design) by humans, who understand the steps in terms of commands in a high-level programming language. This higher level of description allows us to understand computations in a human-friendly way that is abstracted from particular details of machine code and hardware.","title":"Ch. 12 Information Processing in Living Systems"},{"location":"ai/complexity/#ch-13-analogy-making-in-computers","text":"humans are good at perceiving abstract similarity between two entities or situations by letting concepts \u201cslip\u201d from situation to situation in a fluid way takeaways from computer making analogies program: you can\u2019t explore everything, but you don\u2019t know which possibilities are worth exploring without first exploring them. You have to be open-minded, but the territory is too vast to explore everything; you need to use probabilities in order for exploration to be fair uses ant-colony like optimization algorithm to balance exploration of breadth and depth uses temperature to also control how much exploration is done The ultimate goal of AI is to take humans out of the meaning loop and have the computer itself perceive meaning. This is AI\u2019s hardest problem. analogy making will likely be part of the solution","title":"Ch. 13 Analogy Making in Computers"},{"location":"ai/complexity/#ch-14-prospects-of-computer-modeling","text":"Models are ways for our minds to make sense of observed phenomena in terms of concepts that are familiar to us, concepts that we can get our heads around Prediction Models vs. Idea Models Preditiction models are usually mathematical and can be used to predict the future state of a system Idea models are relatively simple and meant to gain insights into a general concept without the necessity of making detailed predictions about any specific system (e.g. turing machine, cellular automaton, koch curve, prisoner's dilemma) Tit for tat was the optimal strategy in the prisoner's dilemma retaliated a defection by defecting the next turn forgave a defection if the oppononent began cooperating by also cooperating again never was the first to defect (common trait amongst all the best strategies) strategy was clear and predictable for the opponent, making cooperation much easier a genetic algorithm evolved a same/similar strategy to the tit for tat strategy proposed by a mathematician \u201cnice, retaliatory, forgiving, and clear\u201d are the characteristics Axelrod cited as requirements for success in the repeated Prisoner\u2019s Dilemma. \u201cHow to Save the Planet: Be Nice, Retaliatory, Forgiving, and Clear.\u201d \u201cFive Rules for the Evolution of Cooperation.\u201d all models are wrong in some way, but some are very useful for beginning to address highly complex systems. Independent replication can uncover the hidden unrealistic assumptions and sensitivity to parameters that are part of any idealized model.","title":"Ch. 14 Prospects of Computer Modeling"},{"location":"ai/complexity/#ch-15-network-science","text":"A major discovery to date of network science is that high-clustering, skewed degree distributions, and hub structure seem to be characteristic of the vast majority of all the natural, social, and technological networks that network scientists have studied. the small-world property : a network has this property if it has relatively few long-distance connections but has a small average path-length relative to the total number of nodes. Small-world networks also typically exhibit a high degree of clustering It has been hypothesized that at least two conflicting evolutionary selective pressures are responsible: the need for information to travel quickly within the system the high cost of creating and maintaining reliable long-distance connections Small-world networks solve both these problems by having short average path lengths between nodes in spite of having only a relatively small number of long-distance connections. scale free networks = power law degree distribution (e.g. 1/k^2 for webpages) small # hubs nodes with degrees over large range of possible values self similarity (invariant under rescaling) small-world structure","title":"Ch. 15 Network Science"},{"location":"ai/complexity/#ch-16-applying-network-science-to-real-world-problems","text":"Network science includes techniques that can be applied to a huge domain of fields preferential attachment - networks grow in such a way that nodes with higher degree receive more new links than nodes with lower degree. explains the existence of many scale-free networks in the real world other mechanishms also exist that are similar and quite different studying dynamics of information spread, not just the structure of the network, is important open problem in network science Cascading failures- one nodes failure shifts lode to other nodes, that overload and subsequeuntly fail causing a domino chain of failures","title":"Ch. 16 Applying Network Science to Real-world Problems"},{"location":"ai/complexity/#the-brain_1","text":"Brain has small-world properties which has several benefits from an evolution perspective: more resilient to losing neurons or functional areas (though losing hubs causes more drastic harm) more energy efficient structure since signals are not sent to all neurons/functional areas greatly facilitates synchronization (groups of neurons firing repeatedly) which is a major mechanism by which the brain transmits information efficiently The brain can be viewed as a network at several different levels of description; for example, with neurons as nodes and synapses as links, or with entire func- tional areas as nodes and larger-scale connections between them (i.e., groups of neural connections) as links.","title":"The Brain"},{"location":"ai/complexity/#genetic-regulatory-networks","text":"Humans and mustard seeds have roughly same number of genes (25k) Our complexity is thought to come from the network of genes regulating each other regulatory networks are scale free which makes them resilient (important given the transcription process is prone to errors)","title":"Genetic Regulatory Networks"},{"location":"ai/complexity/#ch-17-the-mystery-of-scaling","text":"metabolism does not scale linearly with an organism's mass becuase the corresponding surface area to distribute the by-product heat over would not scale at the same rate, making larger animals overheat If you plot a power law on a double logarithmic plot (both axes are log scale), it will look like a straight line, and the slope of that line will be equal to the power law\u2019s exponent Power law distributions are fractals\u2014they are self-similar at all scales of magnification, and a power-law\u2019s exponent gives the dimension of the corresponding fractal, where the dimension quantifies precisely how the distribution\u2019s self-similarity scales with level of magnification fractal structure is one way to generate a power-law distribution; and if you happen to see that some quantity (such as metabolic rate) follows a power-law distribution, then you can hypothesize that there is something about the underlying system that is self-similar or \u201cfractal-like.\u201d metabolic scaling theory came out of network science and fractals and explains the scaling mystery in organisms Understanding power-law distributions, their origins, their significance, and their commonalities across disciplines is currently a very important open problem in many areas of complex systems research.","title":"Ch. 17 The Mystery of Scaling"},{"location":"ai/complexity/#ch-18-evolution-complexified","text":"evolutionary developmental biology is answering a lot of questions related to diversity of species and its relationship with genetics and evolution genetic regulatory networks allow for much larger space of possibilities than simply the number of genes would indicate (explains large differences in species despite similar number of genes) Two types of genes: functional- encode proteins for cell building/maintenance regulatory- encode proteins for turning off/on other genes by binding to their corresponding DNA sequences and disallowing or allowing RNA to bind to the gene and complete the transcription and translation process regulatory genes can encode for proteins that regulate other regulatory genes, demonstrating how complex the regulation network can get and how large the combinatorial space of possible genetic expressions is which leads to large diversity in organisms Stuart Kauffman demonstrated natural selection is in principle not necessary to create a complex creature with Random Boolean Networks (RBNs) a network structure with enough nodes (e.g. gene regulatory network) controlling other nodes will result in the emergence of complex and self-organized behavior turned the idea of evolution over time being the key to organisms' complexity on its head Kauffman\u2019s book, The Origins of Order talks more about these ideas Developing accurate models of genetic regulatory networks is currently a very active research area in biology RBNs have severe limatations with noise and make lots of simplifying assumptions that make it less accurate model of genetic regulatory networks Evolutionary biologist Dan McShea classifies evolutionists into three categories: adaptationists, who believe that natural selection is primary historicists, who give credit to historical accident for many evolutionary changes structuralists, such as Kauffman, who focus on how organized structure comes about even in the absence of natural selection Evolutionary biology is still working on answering its most important question: How does complexity in living systems come about through evolution?","title":"Ch. 18 Evolution Complexified"},{"location":"ai/complexity/#ch-19-past-future-of-complex-systems-research","text":"mathematician Norbert Wiener proposed the science underlying complex systems in both biology and engineering should focus not on the mass , energy , and force concepts of physics, but rather on the concepts of feedback, control, information, communication, and purpose (or \u201cteleology\u201d) created field of cybernetics-- control and communication theory, in machines and animals H. Ross Ashby\u2019s \u201cDesign for a Brain,\u201d an influential proposal for how the ideas of dynamics, information, and feedback should inform neuroscience and psychology Norbert Wiener\u2019s books Cybernetics and The Human Use of Human Beings , which attempted to provide a unified overview of the field and its relevance in many disciplines A similar effort toward finding common principles, under the name of General System Theory, was launched in the 1950s by the biologist Ludwig von Bertalanffy, who characterized the effort as \u201cthe formulation and deduc- tion of those principles which are valid for \u2018systems\u2019 in general.\u201d A system is defined in a very general sense: a collection of interacting elements that together produce, by virtue of their interactions, some form of system-wide behavior. Artificial intelligence, artificial life, systems ecology, systems biology, neural networks, systems analysis, control theory, and the sciences of complexity have all emerged from seeds sown by the cyberneticists and general system theorists. Cybernetics and general system theory have been largely overshadowed by these offspring disciplines Tough to advance field when we can't even come up with a vocab to describe it adequately (also need the mathematics to describe complex systems in general) The mathematician Steven Strogatz puts it this way: \u201cI think we may be missing the conceptual equivalent of calculus, a way of seeing the consequences of myriad interactions that define a complex system. It could be that this ultracalculus, if it were handed to us, would be forever beyond human comprehension. We just don\u2019t know.\u201d pursuing these goals will require, as great science always does, an adventurous intellectual spirit and a willingness to risk failure and reproach by going beyond mainstream science into ill-defined and uncharted territory. \u201cOne doesn\u2019t discover new lands without consenting to lose sight of the shore.\u201d - Andre\u0301 Gide","title":"Ch. 19 Past &amp; Future of Complex Systems Research"},{"location":"ai/guide/","text":"AI: A Guide for Thinking Humans Neural Networks back-propagation is a way to take an error observed at the output units and to \u201cpropagate\u201d the blame for that error backward so as to assign proper blame to each of the weights in the network. Allows back-propagation to determine how much to change each weight in order to reduce the error. Learning in neural networks simply consists in gradually modifying the weights on connections so that each output\u2019s error gets as close to 0 as possible on all training examples Backprop overcame the learning limitations of perceptron these subsymbolic systems are less brittle on difficult tasks like object recognition compared to symbolic systems however at the cost of explainability/understandability Introduction of ImageNet competition in 2012 which was then effectively solved by CNNs in 2017 with a top-5 accuracy of 98% (82% top-1 accuracy) unlike CNNs, human perception is highly regulated by the context of the situation human perception system has more feedback connections than simply feedforward connections adversarial attacks are a huge flaw in DNNs and beg the question are DNNs even learning the things we want? a prerequisite to trustworthy moral reasoning is general common sense an understanding of causality is important for common sense as is the ability to make analogies understanding limitations of neural networks through studying adversarial attacks machine learning is more accurately: machine inductive inference that is, machines make predictions based on a series of observations (the training data) there have been attempts at more deductive reasoning machines Making predictions based on a set of rules all predictions must follow (inductive systems learn approximations of these rules through observing lots of training data) Reinforcement Learning The Q-learning algorithm is a way to assign values to actions in a given state, including those actions that don\u2019t lead directly to rewards but that set the stage for the relatively rare states in which the agent does receive rewards. In an episode of Q-learning, at each iteration the learning agent: figures out its current state, looks up that state in the Q-table, uses the values in the table to choose an action, performs that action, possibly receives a reward, and\u2014the learning step\u2014updates the values in its Q-table. The neural network\u2019s job is to learn what values should be assigned to actions in a given state (acts as the Q-table). Deep Q-Network aka DQN DQN's input is the state and output is the estimated values for each possible action Learning step: adjusting the network weights (via back-propagation) so as to minimize the difference between the current and the previous iteration\u2019s outputs learning a guess from a better guess temporal difference learning- the network learns to make its outputs consistent from one iteration to the next, assuming that later iterations give better estimates of value than earlier iterations succcesfull transfer of learned skills in simulation to real world is open problem episode- 1 play of the game iteration- 1 action and state pair The system doesn\u2019t always choose the action with the highest estimated value in order to balance between exploration and exploitation Standard Search for Checkers and Chess: at a given turn, create a partial game tree using the current board position as the root; apply an evaluation function to the furthest layer in the tree and then use the minimax algorithm to propagate the values up the tree in order to determine which move to make Checkers: 6 possible moves; Chess: 35 possible moves; Go: 250 possible moves Go's increased number of possible moves combined with the difficulty in making a good evalution function makes it infeasible to apply this same search strategy to the game AlphaGo that beat Lee Sedol used both used an intricate mix of deep Q-learning, \u201cMonte Carlo tree search,\u201d supervised learning, and specialized Go knowledge book has pretty good explanation of how the 3 work together to produce SOA results CNN is used as the evaluation function to kickstart the monte carlo tree search (non exhaustive but rather based on acculumated statistics from random moves chosen probabilistically) AlphaZero, unlike its predecessor, it started off with \u201czero\u201d knowledge of Go besides the rules and was able to beat its predeccesor in all games Charades could be considered a more challenging domain for AI than even Go since it requires sophisticated visual, linguistic, and social understanding deep q-learning is terrible at generalizing and seems to be learn very superficial solutions without any actual understanding: shifting the paddle a few pixels up and using a previously trained superhuman agent gives poor results hints that the system didn't even learn the concept of paddle or really anything in the game (overattribution to say it did) also vulnerable to adversarial changes to the state inputs to damage the ability to play well For humans, a crucial part of intelligence is, rather than being able to learn any particular skill, being able to learn to think and to then apply our thinking flexibly to whatever situations or challenges we encounter Barrier of Meaning Neural networks don't have any understanding of what they are processing (barrier of meaning) intuitive physics\u2014 the basic knowledge and beliefs humans share about objects and how they behave intuitve psychology-- ability to sense and predict the feelings, beliefs, and goals of others intuituve biology-- knowledge that biological organisms differ from inanimate objects These core bodies of intuitive knowledge constitute the foundation for human cognitive development, underpinning all aspects of learning and thinking, such as our ability to learn new concepts from only a few examples, to generalize these concepts, and to quickly make sense of situations and decide what actions we should take in response humans have mental models of important aspects of the world, based on your knowledge of physical and biological facts, cause and effect, and human behavior. These models\u2014representations of how the world works\u2014allow you to mentally \u201csimulate\u201d situations Lawrence Barsalou's \"Perceptual Symbol Systems\" (1999) in Behavioral and Brain Sciences & \"Grounded Cognition\" in the Annual Review of Psychology integral part of understanding a situation is being able to use your mental models to imagine different possible futures. simulations appear central to the representation of meaning we understand abstract concepts in terms of core physical knowledge Ex: warm physical feeling and thinking of social warmth activate same brain regions we understand lots of abstract concepts in terms of metaphors relating them to physical knowlege this could be why more abstract concepts like math can be harder for people to grasp, especially in the absence of using metaphors to teach the concepts analogy making in a very general sense as \u201cthe perception of a common essence between two things without concepts there can be no thought, and without analogies there can be no concepts Marvin Minksy's \"Decentralized Minds\" essentially everyone in AI research agrees that core \u201ccommonsense\u201d knowledge (core intuitive knowledge) and the capacity for sophisticated abstraction and analogy are among the missing links required for future progress in AI Knowledge, Abstraction, and Analogy Works on intuituve physics N. Watters et al. \"Visual Interaction Networks\" T.D. Ullman et al. \"Mind Game: Game Engines as an Architecture for Intuitive Physics\" KK. Kansky eet al. \"Schema Networks: Zero-Shot Transfer with a Generative Causal Model of Intuitive Physics\" For discussion on what is missing in deep learning: G. Marcus \"Deep Learning: A Critical Appraisal\" Bongard problems are good tests of abstraction ability H. E. Foundais \"Phaeaco: A Cognitive Architecture Inspired by Bongard's Problems\" metacognition- the ability to perceive and reflect on one\u2019s own thinking \u201cWe should be afraid. Not of intelligent machines. But of machines making decisions that they do not have the intelligence to make. I am far more afraid of machine stupidity than of machine intelligence. Machine stupidity creates a tail risk. Machines can make many many good decisions and then one day fail spectacularly on a tail event that did not appear in their training data. This is the difference between specific and general intelligence\u201d -Sendhil Mullainathan \u201cPeople worry that computers will get too smart and take over the world, but the real problem is that they\u2019re too stupid and they\u2019ve already taken over the world\u201d -pedro domingos","title":"Guide"},{"location":"ai/guide/#ai-a-guide-for-thinking-humans","text":"","title":"AI: A Guide for Thinking Humans"},{"location":"ai/guide/#neural-networks","text":"back-propagation is a way to take an error observed at the output units and to \u201cpropagate\u201d the blame for that error backward so as to assign proper blame to each of the weights in the network. Allows back-propagation to determine how much to change each weight in order to reduce the error. Learning in neural networks simply consists in gradually modifying the weights on connections so that each output\u2019s error gets as close to 0 as possible on all training examples Backprop overcame the learning limitations of perceptron these subsymbolic systems are less brittle on difficult tasks like object recognition compared to symbolic systems however at the cost of explainability/understandability Introduction of ImageNet competition in 2012 which was then effectively solved by CNNs in 2017 with a top-5 accuracy of 98% (82% top-1 accuracy) unlike CNNs, human perception is highly regulated by the context of the situation human perception system has more feedback connections than simply feedforward connections adversarial attacks are a huge flaw in DNNs and beg the question are DNNs even learning the things we want? a prerequisite to trustworthy moral reasoning is general common sense an understanding of causality is important for common sense as is the ability to make analogies understanding limitations of neural networks through studying adversarial attacks machine learning is more accurately: machine inductive inference that is, machines make predictions based on a series of observations (the training data) there have been attempts at more deductive reasoning machines Making predictions based on a set of rules all predictions must follow (inductive systems learn approximations of these rules through observing lots of training data)","title":"Neural Networks"},{"location":"ai/guide/#reinforcement-learning","text":"The Q-learning algorithm is a way to assign values to actions in a given state, including those actions that don\u2019t lead directly to rewards but that set the stage for the relatively rare states in which the agent does receive rewards. In an episode of Q-learning, at each iteration the learning agent: figures out its current state, looks up that state in the Q-table, uses the values in the table to choose an action, performs that action, possibly receives a reward, and\u2014the learning step\u2014updates the values in its Q-table. The neural network\u2019s job is to learn what values should be assigned to actions in a given state (acts as the Q-table). Deep Q-Network aka DQN DQN's input is the state and output is the estimated values for each possible action Learning step: adjusting the network weights (via back-propagation) so as to minimize the difference between the current and the previous iteration\u2019s outputs learning a guess from a better guess temporal difference learning- the network learns to make its outputs consistent from one iteration to the next, assuming that later iterations give better estimates of value than earlier iterations succcesfull transfer of learned skills in simulation to real world is open problem episode- 1 play of the game iteration- 1 action and state pair The system doesn\u2019t always choose the action with the highest estimated value in order to balance between exploration and exploitation Standard Search for Checkers and Chess: at a given turn, create a partial game tree using the current board position as the root; apply an evaluation function to the furthest layer in the tree and then use the minimax algorithm to propagate the values up the tree in order to determine which move to make Checkers: 6 possible moves; Chess: 35 possible moves; Go: 250 possible moves Go's increased number of possible moves combined with the difficulty in making a good evalution function makes it infeasible to apply this same search strategy to the game AlphaGo that beat Lee Sedol used both used an intricate mix of deep Q-learning, \u201cMonte Carlo tree search,\u201d supervised learning, and specialized Go knowledge book has pretty good explanation of how the 3 work together to produce SOA results CNN is used as the evaluation function to kickstart the monte carlo tree search (non exhaustive but rather based on acculumated statistics from random moves chosen probabilistically) AlphaZero, unlike its predecessor, it started off with \u201czero\u201d knowledge of Go besides the rules and was able to beat its predeccesor in all games Charades could be considered a more challenging domain for AI than even Go since it requires sophisticated visual, linguistic, and social understanding deep q-learning is terrible at generalizing and seems to be learn very superficial solutions without any actual understanding: shifting the paddle a few pixels up and using a previously trained superhuman agent gives poor results hints that the system didn't even learn the concept of paddle or really anything in the game (overattribution to say it did) also vulnerable to adversarial changes to the state inputs to damage the ability to play well For humans, a crucial part of intelligence is, rather than being able to learn any particular skill, being able to learn to think and to then apply our thinking flexibly to whatever situations or challenges we encounter","title":"Reinforcement Learning"},{"location":"ai/guide/#barrier-of-meaning","text":"Neural networks don't have any understanding of what they are processing (barrier of meaning) intuitive physics\u2014 the basic knowledge and beliefs humans share about objects and how they behave intuitve psychology-- ability to sense and predict the feelings, beliefs, and goals of others intuituve biology-- knowledge that biological organisms differ from inanimate objects These core bodies of intuitive knowledge constitute the foundation for human cognitive development, underpinning all aspects of learning and thinking, such as our ability to learn new concepts from only a few examples, to generalize these concepts, and to quickly make sense of situations and decide what actions we should take in response humans have mental models of important aspects of the world, based on your knowledge of physical and biological facts, cause and effect, and human behavior. These models\u2014representations of how the world works\u2014allow you to mentally \u201csimulate\u201d situations Lawrence Barsalou's \"Perceptual Symbol Systems\" (1999) in Behavioral and Brain Sciences & \"Grounded Cognition\" in the Annual Review of Psychology integral part of understanding a situation is being able to use your mental models to imagine different possible futures. simulations appear central to the representation of meaning we understand abstract concepts in terms of core physical knowledge Ex: warm physical feeling and thinking of social warmth activate same brain regions we understand lots of abstract concepts in terms of metaphors relating them to physical knowlege this could be why more abstract concepts like math can be harder for people to grasp, especially in the absence of using metaphors to teach the concepts analogy making in a very general sense as \u201cthe perception of a common essence between two things without concepts there can be no thought, and without analogies there can be no concepts Marvin Minksy's \"Decentralized Minds\" essentially everyone in AI research agrees that core \u201ccommonsense\u201d knowledge (core intuitive knowledge) and the capacity for sophisticated abstraction and analogy are among the missing links required for future progress in AI","title":"Barrier of Meaning"},{"location":"ai/guide/#knowledge-abstraction-and-analogy","text":"Works on intuituve physics N. Watters et al. \"Visual Interaction Networks\" T.D. Ullman et al. \"Mind Game: Game Engines as an Architecture for Intuitive Physics\" KK. Kansky eet al. \"Schema Networks: Zero-Shot Transfer with a Generative Causal Model of Intuitive Physics\" For discussion on what is missing in deep learning: G. Marcus \"Deep Learning: A Critical Appraisal\" Bongard problems are good tests of abstraction ability H. E. Foundais \"Phaeaco: A Cognitive Architecture Inspired by Bongard's Problems\" metacognition- the ability to perceive and reflect on one\u2019s own thinking \u201cWe should be afraid. Not of intelligent machines. But of machines making decisions that they do not have the intelligence to make. I am far more afraid of machine stupidity than of machine intelligence. Machine stupidity creates a tail risk. Machines can make many many good decisions and then one day fail spectacularly on a tail event that did not appear in their training data. This is the difference between specific and general intelligence\u201d -Sendhil Mullainathan \u201cPeople worry that computers will get too smart and take over the world, but the real problem is that they\u2019re too stupid and they\u2019ve already taken over the world\u201d -pedro domingos","title":"Knowledge, Abstraction, and Analogy"},{"location":"algorithms/analysis/","text":"Algorithm Analysis Asymptotic notation captures the growth of a function as its arugments approach infinity. That is, we are concerned with how the algorithms runtime grows as the size of its input n grows. Lets us drop low-order terms and constants to focus on the order of growth as n grows. Big O- Worst Case Gives an upper bound on an algorithm's runtimes f is of order at most g f(x) is O(g(x)) iff there exists a B > 0 and b \\geq 0 such that |f(x)| \\leq B|g(x)| for all real numbers x > b Big Omega- Best Case Gives a lower bound on an algorithm's runtime f is of order at least g f(x) is \\Omega(g(x)) iff there exists an A > 0 and a \\geq 0 such that |f(x)| \\geq A|g(x)| for all real numbers x > a Big Theta Not the average case To find the average case, we need to know details about the inputs given to the function and their frequency/probabilities Not gauranteed to exist (i.e. algorithm's best and worst case are not the same order e.g. O(n^3) and \\Omega(n) ) Tightest gaurantee on runtime of algorithm so use whenever possible f is of order g f(x) is \\Theta(g(x)) iff there exists A, B > 0 and k \\geq 0 such that A|g(x)| \\leq f(x) \\leq B|g(x)| for all real numbers x > k Useful Theorems Polynomial Orders: let f(x) = a_nx^n + a_{n-1}x^{n-1} + .... a_0 where a_n \\neq 0 f(x) \\in O(x^s) where s \\geq n f(x) \\in \\Omega(x^r) where r \\leq n \\forall b > 1 and \\forall x > 0 , we have log_bn \\in O(n^x) \\forall r > 1 and \\forall d > 0 , we have n^d \\in O(r^n) Misc Can talk about the best and worst case of an algorithm from an example but can't say anything like \"the algorithm runs in ...\" since this means with respect to all inputs Best case can't be worse than ____ Worst case can't be better than ___ \\sum_{k=1}^{n} = \\frac{n(n+1)}{2} so \\sum_{k=1}^{n-1} = \\frac{n(n-1)}{2} When analyzing graph algorithms, ask: How many times do I traverse an edge? How many times do I visit a vertex?","title":"Analysis"},{"location":"algorithms/analysis/#algorithm-analysis","text":"Asymptotic notation captures the growth of a function as its arugments approach infinity. That is, we are concerned with how the algorithms runtime grows as the size of its input n grows. Lets us drop low-order terms and constants to focus on the order of growth as n grows.","title":"Algorithm Analysis"},{"location":"algorithms/analysis/#big-o-worst-case","text":"Gives an upper bound on an algorithm's runtimes f is of order at most g f(x) is O(g(x)) iff there exists a B > 0 and b \\geq 0 such that |f(x)| \\leq B|g(x)| for all real numbers x > b","title":"Big O- Worst Case"},{"location":"algorithms/analysis/#big-omega-best-case","text":"Gives a lower bound on an algorithm's runtime f is of order at least g f(x) is \\Omega(g(x)) iff there exists an A > 0 and a \\geq 0 such that |f(x)| \\geq A|g(x)| for all real numbers x > a","title":"Big Omega- Best Case"},{"location":"algorithms/analysis/#big-theta","text":"Not the average case To find the average case, we need to know details about the inputs given to the function and their frequency/probabilities Not gauranteed to exist (i.e. algorithm's best and worst case are not the same order e.g. O(n^3) and \\Omega(n) ) Tightest gaurantee on runtime of algorithm so use whenever possible f is of order g f(x) is \\Theta(g(x)) iff there exists A, B > 0 and k \\geq 0 such that A|g(x)| \\leq f(x) \\leq B|g(x)| for all real numbers x > k","title":"Big Theta"},{"location":"algorithms/analysis/#useful-theorems","text":"Polynomial Orders: let f(x) = a_nx^n + a_{n-1}x^{n-1} + .... a_0 where a_n \\neq 0 f(x) \\in O(x^s) where s \\geq n f(x) \\in \\Omega(x^r) where r \\leq n \\forall b > 1 and \\forall x > 0 , we have log_bn \\in O(n^x) \\forall r > 1 and \\forall d > 0 , we have n^d \\in O(r^n)","title":"Useful Theorems"},{"location":"algorithms/analysis/#misc","text":"Can talk about the best and worst case of an algorithm from an example but can't say anything like \"the algorithm runs in ...\" since this means with respect to all inputs Best case can't be worse than ____ Worst case can't be better than ___ \\sum_{k=1}^{n} = \\frac{n(n+1)}{2} so \\sum_{k=1}^{n-1} = \\frac{n(n-1)}{2} When analyzing graph algorithms, ask: How many times do I traverse an edge? How many times do I visit a vertex?","title":"Misc"},{"location":"algorithms/complexity/","text":"Complexity Theory Polynomial Time Algorithms - have a running time of O(n^k) for some constant k The class P contains problems solvable in polynomial time P stands for polynomial time The class NP contains decision problems with correct answers (\"yes\" answers) verifiable in polynomial time (given a certificate) NP stands for non-deterministic polynomial time Means the problems can be solved in polynomial time on a non-deterministic machine that can check all possible solutions at once to find the actual solution since they are verifiable in polynomial time Our current deterministic computers can only check 1 solution at once (make one decision) Co-NP is the class of problems with incorrect answers (\"no\" answers) verifiable in polynomial time P \\subseteq NP Open question in theoretical CS (proposed in 1971) is whether P \\neq NP (i.e. P \\subset NP )? Question: Do all problems verifiable in polynomial time, also have an algorithm that solves them in polynomial time? Most theorize P \\neq NP or else lots of hard, important problems would already be solved Tractable/Easy - problems that are solvable by polynomial time algorithms Intractable/Hard - problems that require superpolynomial time to solve The class NPC contains problems the hardest problems in NP Exp- classes of problems outside of NP that take exponential time to even verify a solution for (e.g. checking if a move in chess made was even the right move) Cook-Levin Theorem (1971) Every problem in NP can be reduced to the SAT problem in polynomial time If SAT can be solved in polynomial time, so can every other problem in NP If anyone ever proves a problem in NP to be intractable, then SAT must also be intractable The Computational Complexity Zoo P vs. NP Note the above relationships are conjectures and have not been formally proven yet PSPACE- set of all problems solvable by an algorithm w/ polynomial space complexity P \\subseteq \\text{PSPACE} (in polynomial time, an algorithm can use only a polynomial amount of space) \\text{NP} \\subseteq \\text{PSPACE} since the 3-SAT problem is solvable w/ an algorithm using a polynomial amount of space Many problems in AI and game theory are in the domain of PSPACE Decision Problems Oftentimes its easier to work with a decision problem equivalent of an optimization problem Optimization Problem: Find the smallest number of colors needed to color G and produce that coloring Decision Problem: Given G and k , is there a coloring of G using at most k colors? Original optimization problem can be solved using the decision problem Ex: Loop through k = 1,\\dots, V , for the decision problem. If the decision problem is solvable in polynomial time then there exists a polynomial time to solve the optimization problem Certificate - a canidate answer for a decision problem When the optimization is to find the largest, the corresponding decision problem for existance asks \"... k or more\" When the optimization is to find the smallest, the corresponding decision problem for existance asks \"... at most k \" NP-Complete Describes a class of problems who status is unknown no polynomial-time algorithm has been discovered yet no one has been able to prove no polynomial time algorithm can exist for any one of them Prove your problem is just as hard as a large number of other problems for which no efficienct algorithm has been found If a solution could be found for these other problems, then it could be found for yours also Solving NP-Complete Problems Won't be able to find an algorithm that produces an exact solution Can find an algorithm that works for a subset of inputs Can find an algorithm with a good average case time complexity Can find an algorithm that produces an approximate answer that is close to best Prove a problem is NP-Complete Let problem A be the problem we want to show is NP-complete Let B be a well-known NP-complete problem To show A is np-complete: Show A \\in \\text{NP} prove a yes answer from a certificate can be verified in polynomial time Show that B can be reduced to A in polynomial time Technically we need to reduce all NP-complete problems to A , however, Cook-Levin's Theorem on SAT already did this so we just need to do it for one known NPC problem Remember that A and B are decision problems Video Reduction We want to reduce a problem C into problem D in polynomial time Create a function R that transforms inputs for A to inputs for B s.t. A(x) is yes iff B(R(x)) is yes Tree of reducability for combinatorial problems Vertex Cover Given a graph G(V,E) , a vertex cover is a set of vertices V' such that for each edge uv \\in E , u or v is in V' Optimization Problem: What is the size of the smallest vertex cover? Decision Problem: Is there a vertex cover of size k or fewer vertices? Hamiltonian Path Given a graph G(V,E) , a hamiltonian path is a set of edges (a path) that visits each vertex exactly once A hamilton cicuit is a hamilton path that begins and ends at the same vertex Decision Problem: Is there a hamiltonian path in G ?","title":"Complexity Theory"},{"location":"algorithms/complexity/#complexity-theory","text":"Polynomial Time Algorithms - have a running time of O(n^k) for some constant k The class P contains problems solvable in polynomial time P stands for polynomial time The class NP contains decision problems with correct answers (\"yes\" answers) verifiable in polynomial time (given a certificate) NP stands for non-deterministic polynomial time Means the problems can be solved in polynomial time on a non-deterministic machine that can check all possible solutions at once to find the actual solution since they are verifiable in polynomial time Our current deterministic computers can only check 1 solution at once (make one decision) Co-NP is the class of problems with incorrect answers (\"no\" answers) verifiable in polynomial time P \\subseteq NP Open question in theoretical CS (proposed in 1971) is whether P \\neq NP (i.e. P \\subset NP )? Question: Do all problems verifiable in polynomial time, also have an algorithm that solves them in polynomial time? Most theorize P \\neq NP or else lots of hard, important problems would already be solved Tractable/Easy - problems that are solvable by polynomial time algorithms Intractable/Hard - problems that require superpolynomial time to solve The class NPC contains problems the hardest problems in NP Exp- classes of problems outside of NP that take exponential time to even verify a solution for (e.g. checking if a move in chess made was even the right move) Cook-Levin Theorem (1971) Every problem in NP can be reduced to the SAT problem in polynomial time If SAT can be solved in polynomial time, so can every other problem in NP If anyone ever proves a problem in NP to be intractable, then SAT must also be intractable The Computational Complexity Zoo P vs. NP Note the above relationships are conjectures and have not been formally proven yet PSPACE- set of all problems solvable by an algorithm w/ polynomial space complexity P \\subseteq \\text{PSPACE} (in polynomial time, an algorithm can use only a polynomial amount of space) \\text{NP} \\subseteq \\text{PSPACE} since the 3-SAT problem is solvable w/ an algorithm using a polynomial amount of space Many problems in AI and game theory are in the domain of PSPACE","title":"Complexity Theory"},{"location":"algorithms/complexity/#decision-problems","text":"Oftentimes its easier to work with a decision problem equivalent of an optimization problem Optimization Problem: Find the smallest number of colors needed to color G and produce that coloring Decision Problem: Given G and k , is there a coloring of G using at most k colors? Original optimization problem can be solved using the decision problem Ex: Loop through k = 1,\\dots, V , for the decision problem. If the decision problem is solvable in polynomial time then there exists a polynomial time to solve the optimization problem Certificate - a canidate answer for a decision problem When the optimization is to find the largest, the corresponding decision problem for existance asks \"... k or more\" When the optimization is to find the smallest, the corresponding decision problem for existance asks \"... at most k \"","title":"Decision Problems"},{"location":"algorithms/complexity/#np-complete","text":"Describes a class of problems who status is unknown no polynomial-time algorithm has been discovered yet no one has been able to prove no polynomial time algorithm can exist for any one of them Prove your problem is just as hard as a large number of other problems for which no efficienct algorithm has been found If a solution could be found for these other problems, then it could be found for yours also","title":"NP-Complete"},{"location":"algorithms/complexity/#solving-np-complete-problems","text":"Won't be able to find an algorithm that produces an exact solution Can find an algorithm that works for a subset of inputs Can find an algorithm with a good average case time complexity Can find an algorithm that produces an approximate answer that is close to best","title":"Solving NP-Complete Problems"},{"location":"algorithms/complexity/#prove-a-problem-is-np-complete","text":"Let problem A be the problem we want to show is NP-complete Let B be a well-known NP-complete problem To show A is np-complete: Show A \\in \\text{NP} prove a yes answer from a certificate can be verified in polynomial time Show that B can be reduced to A in polynomial time Technically we need to reduce all NP-complete problems to A , however, Cook-Levin's Theorem on SAT already did this so we just need to do it for one known NPC problem Remember that A and B are decision problems Video","title":"Prove a problem is NP-Complete"},{"location":"algorithms/complexity/#reduction","text":"We want to reduce a problem C into problem D in polynomial time Create a function R that transforms inputs for A to inputs for B s.t. A(x) is yes iff B(R(x)) is yes Tree of reducability for combinatorial problems","title":"Reduction"},{"location":"algorithms/complexity/#vertex-cover","text":"Given a graph G(V,E) , a vertex cover is a set of vertices V' such that for each edge uv \\in E , u or v is in V' Optimization Problem: What is the size of the smallest vertex cover? Decision Problem: Is there a vertex cover of size k or fewer vertices?","title":"Vertex Cover"},{"location":"algorithms/complexity/#hamiltonian-path","text":"Given a graph G(V,E) , a hamiltonian path is a set of edges (a path) that visits each vertex exactly once A hamilton cicuit is a hamilton path that begins and ends at the same vertex Decision Problem: Is there a hamiltonian path in G ?","title":"Hamiltonian Path"},{"location":"algorithms/divideconquer/","text":"Divide and Conquer Class of algorithms in which one breaks the input into several smaller parts, solves the problem in each part recursively, and then combines the solutions to these subproblems into an overall solution Analyzing runtime of these algorithms requires solving a recurrence relation Recurrence Relation - bounds running time recursively in terms of running time on smaller instances Used to reduce the running time of a brute force polynomial algorithm to a lower polynomial (instead of exponential to polynomial) General model for divide and conquer algorithm Divide input into two pieces using only constant time Solve the two subproblems on each piece using recursion Combine the results into one solution using only linear time Recurrence Relations We will use mergesort for an example: T(n) \\leq 2 T(n/2) + cn where base case T(2) < c Solving the above recurrence relation involves getting T to the LHS of the inequality Can unroll the recursion to identify a pattern amongst the levels that can be summed until the base case (subproblem of constant size) At level j of the recursion, the number of subproblems has doubled j times so there are now a total of 2^j subproblems on that level However, each subproblem's size has been cut in half j times so each problem has a size n/2^j Since the work to split a problem and combine its results is linear, the work done for each suproblem is at most cn/2^j Therefore, level j contributes 2^j (cn/2^j) = cn work to the total runtime We want to sum over all levels. How many levels are there? Since we are dividing the input in half each time until it reaches a size of 2, the number of levels to reduce an input of size n to 2 by halving each time is \\log_2 n Summing cn work over \\log n Levels gives total runtime of O(n \\log n) This runtime holds for any algorithm satisfying the recurrence relation above by halving the input each time and spending only linear time for the division and recombining of subproblems General form of recurrence relation for divide and conquer: T(n) = aT(n/b) + f(n) a - number of recursive calls at a level b - how much the input size is shrunk f - the work done at a level Master Theorem: \\log_b n = h is the height of the recursive tree ( b^h = n ) MaxMin Goal: Find maximum and minimum of a set S MaxMin(S): if |S| = 2: return (max(s[0], s[1]), min(s[0], s[1])) # O(1) else divide S into S1 and S2 # O(1) max1, min1 = MaxMin(S1) # T(n/2) max2, min2 = MaxMin(S2) # T(n/2) return (MAX(max1, max2), MIN(min1, min2)) # 2 comparisons Recurrence relation: T(n) = 2T(n/2) + 2 where T(2) = 1 O(n) because \\log_2 n levels of recursion Each problem at each level performs 2 operations of work Therefore each level i performs 2^i Summing over all the levels to get the total amount of work yields \\sum_{i=1}^{\\log_2n} = 2^{\\log_2n + 1} - 2 = 2 * 2^{\\log_2n } - 2 = 2n - 2 Sum of Power Property Therefore O(n) total work Helpful to draw out the recursion tree and the corresponding tree of work done kth Smallest Element Goal: Find k th smallest element in an unsorted set of n elements elements only need to support comparison operator Randomly divide n into groups of size 5 Find the median in each group using 6 comparisons Recursively find m^* , the median among the medians Compare each element in the unknown sections to m^* and place them in the appropriate set A > m^* or B < m^* If k = |B| + 1 then m^* is the k th element k \\leq |B| then the k th element is in B and can be found recursively k > |B| then k th element is in A and can be found recursively T(n) \\leq T(\\lceil \\frac{n}{5} \\rceil) + T(\\frac{7n}{10}) + O(n) can be solved to yield O(n) runtime recursively find median of medians. one median in each group of 5 so therefore \\lceil \\frac{n}{5} \\rceil recursive calls recursively solve problem on the remaining elements which in the worst case could be a set of size \\frac{7n}{10} dividing n into groups of 5 , finding the median in all the groups of 5 and partitioning the unknown values around m^* takes O(n) time","title":"Divide and Conquer"},{"location":"algorithms/divideconquer/#divide-and-conquer","text":"Class of algorithms in which one breaks the input into several smaller parts, solves the problem in each part recursively, and then combines the solutions to these subproblems into an overall solution Analyzing runtime of these algorithms requires solving a recurrence relation Recurrence Relation - bounds running time recursively in terms of running time on smaller instances Used to reduce the running time of a brute force polynomial algorithm to a lower polynomial (instead of exponential to polynomial) General model for divide and conquer algorithm Divide input into two pieces using only constant time Solve the two subproblems on each piece using recursion Combine the results into one solution using only linear time","title":"Divide and Conquer"},{"location":"algorithms/divideconquer/#recurrence-relations","text":"We will use mergesort for an example: T(n) \\leq 2 T(n/2) + cn where base case T(2) < c Solving the above recurrence relation involves getting T to the LHS of the inequality Can unroll the recursion to identify a pattern amongst the levels that can be summed until the base case (subproblem of constant size) At level j of the recursion, the number of subproblems has doubled j times so there are now a total of 2^j subproblems on that level However, each subproblem's size has been cut in half j times so each problem has a size n/2^j Since the work to split a problem and combine its results is linear, the work done for each suproblem is at most cn/2^j Therefore, level j contributes 2^j (cn/2^j) = cn work to the total runtime We want to sum over all levels. How many levels are there? Since we are dividing the input in half each time until it reaches a size of 2, the number of levels to reduce an input of size n to 2 by halving each time is \\log_2 n Summing cn work over \\log n Levels gives total runtime of O(n \\log n) This runtime holds for any algorithm satisfying the recurrence relation above by halving the input each time and spending only linear time for the division and recombining of subproblems General form of recurrence relation for divide and conquer: T(n) = aT(n/b) + f(n) a - number of recursive calls at a level b - how much the input size is shrunk f - the work done at a level Master Theorem: \\log_b n = h is the height of the recursive tree ( b^h = n )","title":"Recurrence Relations"},{"location":"algorithms/divideconquer/#maxmin","text":"Goal: Find maximum and minimum of a set S MaxMin(S): if |S| = 2: return (max(s[0], s[1]), min(s[0], s[1])) # O(1) else divide S into S1 and S2 # O(1) max1, min1 = MaxMin(S1) # T(n/2) max2, min2 = MaxMin(S2) # T(n/2) return (MAX(max1, max2), MIN(min1, min2)) # 2 comparisons Recurrence relation: T(n) = 2T(n/2) + 2 where T(2) = 1 O(n) because \\log_2 n levels of recursion Each problem at each level performs 2 operations of work Therefore each level i performs 2^i Summing over all the levels to get the total amount of work yields \\sum_{i=1}^{\\log_2n} = 2^{\\log_2n + 1} - 2 = 2 * 2^{\\log_2n } - 2 = 2n - 2 Sum of Power Property Therefore O(n) total work Helpful to draw out the recursion tree and the corresponding tree of work done","title":"MaxMin"},{"location":"algorithms/divideconquer/#kth-smallest-element","text":"Goal: Find k th smallest element in an unsorted set of n elements elements only need to support comparison operator Randomly divide n into groups of size 5 Find the median in each group using 6 comparisons Recursively find m^* , the median among the medians Compare each element in the unknown sections to m^* and place them in the appropriate set A > m^* or B < m^* If k = |B| + 1 then m^* is the k th element k \\leq |B| then the k th element is in B and can be found recursively k > |B| then k th element is in A and can be found recursively T(n) \\leq T(\\lceil \\frac{n}{5} \\rceil) + T(\\frac{7n}{10}) + O(n) can be solved to yield O(n) runtime recursively find median of medians. one median in each group of 5 so therefore \\lceil \\frac{n}{5} \\rceil recursive calls recursively solve problem on the remaining elements which in the worst case could be a set of size \\frac{7n}{10} dividing n into groups of 5 , finding the median in all the groups of 5 and partitioning the unknown values around m^* takes O(n) time","title":"kth Smallest Element"},{"location":"algorithms/dp/","text":"Dynamic Programming A methodical way to try all possible answers (An exhaustive search) Focus is on ordering computations in a way that avoids duplicate work to get a polynomial time answer Can be used to solve problems that have optimal substrucutre and overlapping subproblems but lack the greedy choice property so greedy algorithm will not work overlapping subproblems- many problems are calculated repeatedly Good for optimization problems (shortest, maximal, minimum, etc.) Top-Down Implemented using recursion Starts from the end and works backwards Memoization- store results of subproblems to be reused since DP problems often have overlapping subproblems Runtime = subproblems * time per subproblem Bottom-Up Avoids recursion to save the memory cost of the call stack Call stack is vulnerable to a stack overflow error Exactly same computation as recursive/memoized version Starts from the beginning Can often be cleaner and more efficient than top-down Downside is you have to determinethe ordering of your calculation of subproblems such that previous subproblem results can be used to compute future subproblem results Essentially a topological sort of subproblem dependency DAG to reveal the order to compute the subproblems Saves storage space Clearer runtime than the recursive version Fibonnaci Numbers F_1 = F_2 = 1 F_n = F_{n-1} + F_{n-2} Naive Algorithm fib(n): if n <= 2: return 1 else: return fib(n-1) + fib(n-2) Exponential runtime: \\Theta(2^n) Memoized DP Algorithm Memoized for efficiency memo = {} fib(n): if n in memo: return memo[n] if n <= 2: return 1 else: f = fib(n-1) + fib(n-2) memo[n] = f return f Overall runtime is \\Theta(n) Memoizied calls of the subproblems cost \\Theta(1) n non-memoized calls ( fib(1) , fib(2) , ... fib(n) ) nonrecursive work per call is \\Theta(1) Bottom-Up DP Algorithm fib = {} for k in range(1, n+1): if k <= 2: f = 1 else: f = fib[k-1] + fib[k-2] fib[k] = f return fib[n] Iteratively builds up to the solution instead of recursively working backwards Oftentimes more efficient due to less function calls Choosing the order to compute the subproblems was easy in this case (just increasing integers up to n ) However, this can be the tricky part for other problems since you want subsequent calls to utilize already computed subproblems to avoid repeat work Shortest Path \\delta(s,v) = \\min\\{w(u,v) + \\delta(s,u) | (u,v) \\in E\\} with base case \\delta(s,s) = 0 Exponential runtime for naive implementation Can memoize to get better runtime Takes infinite time if there are cycles subproblem dependencies should be acyclic For DAG, runtime is O(V +E) time for subproblem \\delta(s,v) = indegree(v) total time = \\sum_{v \\in V} indeg(v) = O(E + V) Bellman Ford algorithm comes from extending this idea to limit k edges in the path form s to v : \\delta(s,v)_k results in increased subproblems but can deal with cycles Runtime O(VE) 0/1 Knapsack Does not have the greedy choice property so cannot use greedy solution Has overlapping subproblems so dp approach should work DP Algorithm Let N be the set of objects where n indicates an object. Let C be the capacity of the knapsack and let s_n indicate the size of object n . Let v_n indicate the value of object n . If item n does fit in the knapsack (i.e. s_n \\leq C ) choose the maximum result of the two subproblems: Do not include object n : value(N \\setminus \\{n \\}, C) Include object n : v_n + value(N \\setminus \\{n\\}, C - s_n) If item n doesn't fit in the knapsack (i.e. s_n > C ) just find value(N \\setminus \\{n\\}, C) Runtime Pseudo-polynomial since they are computable but depend on the capacity and size picked O(2^n) Maximum Sum of List Subset Given a list L of n numbers, select a subset S of L such that their sum is maximized and no two numbers in S are adjacent in L maxsum(<x1, ... ,xn>) = max{x_1 + maxsum(<x3, ... xn>), maxsum(<x2, ..., xn>)} Memoized version: cache = {} function max_sum(<x1, x2, ..., xn>) { if length(<list>) = 1: return x1 if hash(<x3, x4, ..., xn>) in cache: with_x1 = cache[hash(<x3, x4, ..., xn>)] else: with_x1 = max_sum(<x3, ..., xn>) cache[hash(<x3, x4, ..., xn>)] = with_x1 if hash(<x2, x3, ..., xn>) in cache: without_x1 = cache[hash(<x2, x3, ..., xn>)] else: without_x1 = max_sum(<x2, x3, ..., xn>) cache[hash(<x2, x3, ..., xn>)] = without_x1 return max(x1 + with_x1,without_x1) } NP-Complete While certain problems are NP-complete, for certain input sizes, the solution can be calculated using dynamic programming in a reasonable time Resources MIT 6.006 DP I","title":"Dynamic Programming"},{"location":"algorithms/dp/#dynamic-programming","text":"A methodical way to try all possible answers (An exhaustive search) Focus is on ordering computations in a way that avoids duplicate work to get a polynomial time answer Can be used to solve problems that have optimal substrucutre and overlapping subproblems but lack the greedy choice property so greedy algorithm will not work overlapping subproblems- many problems are calculated repeatedly Good for optimization problems (shortest, maximal, minimum, etc.)","title":"Dynamic Programming"},{"location":"algorithms/dp/#top-down","text":"Implemented using recursion Starts from the end and works backwards Memoization- store results of subproblems to be reused since DP problems often have overlapping subproblems Runtime = subproblems * time per subproblem","title":"Top-Down"},{"location":"algorithms/dp/#bottom-up","text":"Avoids recursion to save the memory cost of the call stack Call stack is vulnerable to a stack overflow error Exactly same computation as recursive/memoized version Starts from the beginning Can often be cleaner and more efficient than top-down Downside is you have to determinethe ordering of your calculation of subproblems such that previous subproblem results can be used to compute future subproblem results Essentially a topological sort of subproblem dependency DAG to reveal the order to compute the subproblems Saves storage space Clearer runtime than the recursive version","title":"Bottom-Up"},{"location":"algorithms/dp/#fibonnaci-numbers","text":"F_1 = F_2 = 1 F_n = F_{n-1} + F_{n-2}","title":"Fibonnaci Numbers"},{"location":"algorithms/dp/#naive-algorithm","text":"fib(n): if n <= 2: return 1 else: return fib(n-1) + fib(n-2) Exponential runtime: \\Theta(2^n)","title":"Naive Algorithm"},{"location":"algorithms/dp/#memoized-dp-algorithm","text":"Memoized for efficiency memo = {} fib(n): if n in memo: return memo[n] if n <= 2: return 1 else: f = fib(n-1) + fib(n-2) memo[n] = f return f Overall runtime is \\Theta(n) Memoizied calls of the subproblems cost \\Theta(1) n non-memoized calls ( fib(1) , fib(2) , ... fib(n) ) nonrecursive work per call is \\Theta(1)","title":"Memoized DP Algorithm"},{"location":"algorithms/dp/#bottom-up-dp-algorithm","text":"fib = {} for k in range(1, n+1): if k <= 2: f = 1 else: f = fib[k-1] + fib[k-2] fib[k] = f return fib[n] Iteratively builds up to the solution instead of recursively working backwards Oftentimes more efficient due to less function calls Choosing the order to compute the subproblems was easy in this case (just increasing integers up to n ) However, this can be the tricky part for other problems since you want subsequent calls to utilize already computed subproblems to avoid repeat work","title":"Bottom-Up DP Algorithm"},{"location":"algorithms/dp/#shortest-path","text":"\\delta(s,v) = \\min\\{w(u,v) + \\delta(s,u) | (u,v) \\in E\\} with base case \\delta(s,s) = 0 Exponential runtime for naive implementation Can memoize to get better runtime Takes infinite time if there are cycles subproblem dependencies should be acyclic For DAG, runtime is O(V +E) time for subproblem \\delta(s,v) = indegree(v) total time = \\sum_{v \\in V} indeg(v) = O(E + V) Bellman Ford algorithm comes from extending this idea to limit k edges in the path form s to v : \\delta(s,v)_k results in increased subproblems but can deal with cycles Runtime O(VE)","title":"Shortest Path"},{"location":"algorithms/dp/#01-knapsack","text":"Does not have the greedy choice property so cannot use greedy solution Has overlapping subproblems so dp approach should work","title":"0/1 Knapsack"},{"location":"algorithms/dp/#dp-algorithm","text":"Let N be the set of objects where n indicates an object. Let C be the capacity of the knapsack and let s_n indicate the size of object n . Let v_n indicate the value of object n . If item n does fit in the knapsack (i.e. s_n \\leq C ) choose the maximum result of the two subproblems: Do not include object n : value(N \\setminus \\{n \\}, C) Include object n : v_n + value(N \\setminus \\{n\\}, C - s_n) If item n doesn't fit in the knapsack (i.e. s_n > C ) just find value(N \\setminus \\{n\\}, C)","title":"DP Algorithm"},{"location":"algorithms/dp/#runtime","text":"Pseudo-polynomial since they are computable but depend on the capacity and size picked O(2^n)","title":"Runtime"},{"location":"algorithms/dp/#maximum-sum-of-list-subset","text":"Given a list L of n numbers, select a subset S of L such that their sum is maximized and no two numbers in S are adjacent in L maxsum(<x1, ... ,xn>) = max{x_1 + maxsum(<x3, ... xn>), maxsum(<x2, ..., xn>)} Memoized version: cache = {} function max_sum(<x1, x2, ..., xn>) { if length(<list>) = 1: return x1 if hash(<x3, x4, ..., xn>) in cache: with_x1 = cache[hash(<x3, x4, ..., xn>)] else: with_x1 = max_sum(<x3, ..., xn>) cache[hash(<x3, x4, ..., xn>)] = with_x1 if hash(<x2, x3, ..., xn>) in cache: without_x1 = cache[hash(<x2, x3, ..., xn>)] else: without_x1 = max_sum(<x2, x3, ..., xn>) cache[hash(<x2, x3, ..., xn>)] = without_x1 return max(x1 + with_x1,without_x1) }","title":"Maximum Sum of List Subset"},{"location":"algorithms/dp/#np-complete","text":"While certain problems are NP-complete, for certain input sizes, the solution can be calculated using dynamic programming in a reasonable time","title":"NP-Complete"},{"location":"algorithms/dp/#resources","text":"MIT 6.006 DP I","title":"Resources"},{"location":"algorithms/greedy/","text":"Greedy Algorithms When they work in solving a problem optimally it implies something about the strucutre of the problem itself i.e. There is a local decision rule that one can use to construct optimal solutions Finding cases where greedy algorithms work well and proving their performance is challenging Any algorithm that follows the problem-solving heurisitc of making the locally optimal choice at each stage with the intent of finding a global optimum Follow a form of: select a candidate greedily according to some heuristic if adding the candidate does not corrupt feasability of the solution, add it to your current solution repeat until finished Two methods for proving a greedy algo produces optimal solution to a problem Greedy Algorithm Stays Ahead Exchange Argument Applications: Shortest paths in a graph Interval Scheduling Minimum Spanning trees in an undirected graph Minimum cost aboresence problem in directed graph Huffman code construction in data compression When to use the greedy approach? Does the problem display optimal substructure ? Does your algorithm have the greedy choice property ? If both questions above can be answered yes, then the greedy approach is good, but might also be able to use dynamic programming DP useful in the case of overlapping subproblems Optimal Substructure Property of problems that can be solved with a greedy algorithm or dynamic programming Describes a problem if an optimal solution can be constructed from optimal solutions of its subproblems Has optimal substructure: shortest path, fractional knapsack Does not have optimal substructure: 0/1 knapsack, longest path on non-DAG Structure of a Proof Assume O is an optimal answer Remove an element x from O (often last element) to create O' Redefine the constraints of the problem for which O' is a solution Prove that O' is an optimal answer for this redefined problem Often a proof by contradiction: assume O is optimal but O' is not Find O^* ,the optimal answer to the redefined problem Add x to O^* to make a new answer to the original problem Contradiction reached in that x + O^* is better than O which was optimal Therefore, O' must be optimal and so the problem has optimal substructure Ex: Shortest Path Assume the shortest path from u to v is P and w \\in P . Remove the end of the path from w to v to create P' which is a path from u to w . Is P' the shortest path from u to w ? By way of contradiction assume P is optimal but P' is not. Let P^* be the optimal path from u to w . If we add the previously removed edge from w to v to P^* then we have created a new path from u to v which is more optimal than P . This is a contradiction, so therefore P' must be optimal and so the shortest path problem has optimal substructure. Proving Correctness of Greedy Algorithms Showing the problem has optimal substructure and the algorithm has the greedy choice property does not prove the algorithms correctness Can prove correctness of the algorithm by: Induction Contradiction (suppose your algorithm makes a mistake) useful techniques: stay ahead argument exchange argument given greedy answer and optimal answer, bring the greedy over into the optimal at the place where they first differ, where the results should be a contradiction Example: Greedy Camping problem can be proven correct using stay ahead argument and induction Exchange Argument Incrementally modify the greedy algorithm's solution into the optimal solution Steps: Label your algorithm's solution G and a general optimal solution O Compare G with O by contradiction assume G \\neq O typically you isolate a simple example of a difference element of O not in G and element of G not in O or 2 consecutive elements in O in a different order than they are in G Exchange Swap the elements in question in O (either swap element out and another in for first case or swap order of elements in second case) Argue O is no worse than before Argue if you continue swapping, you can eliminate all the differences between G and O in a polynomial number of steps without worsening the quality of the solution Thus G is optimal The goal in exchange argument is to show how to modify O to create a new solution O' with the following properties: O' is at least as good of solution as O (or equivalently O' is also optimal), and O' is \u201cmore like\u201d G than O . The creative part that differs for each algo/problem is determining how to modify O to create O' Good place to start is think about how G is constructed and look to make the modification at the first point where the algorithm makes a choice for G that is different than what is in O Notes: remember to argue why the elements you are swapping even exist out of order or not in one solution but in the other Cornell Notes Stay Ahead Argument Inductively prove that under some measure, the partial solutions produced by the greedy algorithm \"stay ahead\" of the partial solutions produced by an optimal algorithm Cornell Notes Shortest Paths in a Graph Given a strongly connected directed graph G = (V, E) and a start node s Each edge e has a length \\ell_e \\geq 0 Goal: determine shortest path from s to every other node in the graph Greedy algorithms take advantage of the optimal substructure of the shortest path longest path does not have same optimal substructure (unless working with a DAG) so cannot use a greedy algorithm Dijkstra's Algorithm let S be set of explored nodes initialized to S = {s} dist[s] = 0 let Q be a priority queue initialized with nodes in V \\ {s} with a key of the dist[u] from start vertex for each u in Q for i=1 to |V|: dist[i] = infty for each edge(s,v): dist[v] = weight(s,v) while Q not empty: u = extract_min(Q) //removes u from Q S = S + {u} for each vertex v that is a neighbor of u: dist[v] = min(d[v], d[u] + weight(u,v)) Cannot handle negative edge weightS BFS is faster for shortet path of unweighted graph (could give all edges equal weight and run dijkstra's') \\Theta(V) inserts into priority queue \\Theta(V) extract min operations \\Theta(E) decrease key operations If priority queue is implemented as array: \\Theta(V) extract min \\Theta(1) decrease key \\Theta(V * V + E * 1) = \\Theta(V^2) runtime If prioty queue is implemented as a binary min-heap \\Theta(\\log V) for extract min \\Theta(\\log V) for decrease key \\Theta(V \\log V + E \\log V) runtime IF priority queue is implemented as a fibonnaci heap \\Theta(\\log V) for extract min \\Theta(1) amortized for decrease key \\Theta(V \\log V + E) runtime Interval Scheduling We have n requests each i th request corresponding to an interval of time starting at s(i) and finishing at f(i) A subset of the requests is compatible if no two of them overlap in time Goal: Determine largest compatible subset as possible Greedy rule/heuristic for choosing request: choose request a finishes first let R be set of all intervals Sort R by finish time let G be empty solution set for interval in R: if G is empty: add first interval to G else: if interval does not overlap with last interval in G: add interval to G This algorithm runs in O(n \\log n) Sort is O(n \\log n) Iterate through intervals is O(n) Proof of Correctness We will use the stay ahead argument We will prove for each r \\geq 1 , the r th interval in the algorithm's solution G finishes no later than the r th interval in the optimal schedule Note that |G| = k and |O| = m and we want to show |G| = |O| in order to prove the greedy algorithm creates an optimal solution Proof: We will prove via induction: for all r \\leq k we have f(i_r) \\leq f(j_r) . Base Case (r = 1): The algorithm selects the request i_1 with the minimum finish time so it is clearly an optimal first choice f(i_1) \\leq f(j_1) . For r>1 we will assume the inductive hypothesis is true ( f(i_{r-1}) \\leq f(j_{r-1}) ) for r - 1 and will try to prove it for r . Since O consists of nonoverlapping intervals, f(j_{r-1}) \\leq s(j_r) . Therefore, combining this with the inductive hypothesis implies f(i_{r-1}) \\leq s(j_r) . This means interval j_r is in the set of available intervals at the time when the greedy algorithm selects i_r . The greedy algorithm selects the available interval with the smallest finish time, therefore f(i_r) \\leq f(j_r) . This completes the induction steps so we have proven the optimality of the greedy algorthim's set A . So far we have only proven that the greedy algorithm's solution is as good as the optimal solution. To finish we need to prove |G| = |O| . Proof: By way of contradiction, assume G is not optimal so |O| > |G| . This means there is a requests in O that starts after f(j_k) and therefore after f(i_k) . This means there was a compatible interval left to choose from that the greedy algorithm did not choose and opted to stop instead. This is a contradiction from how the greedy algorithm was designed so therefoer |G| = |O| . Fractional Knapsack Thief robbing a store finds n types of metallic dust The i th dust is worth v per ounce with w_i total ounces available Knapsack can hold total of W Ounces. What is the max value of dust that can fit in the knapsack? Solution: Calc value/oz and then add as much of the most valuable as possible then move to the next valuable, and repeat until the sack is full this approach is greedy and takes advatnage of the optimal substructure of the problem Prove Optimal Substructure Suppose O is the optimal packing of the knapsack of size W and value val(O) give a list L of possible values. Remove one item i from the knapsack with weight w_i and value v_i to get a new packing O' of a knapsack of size W - w_i and choosing from the set of items L - i . By way of contradiction, assume O' is not optimal. This means we have a higher value packing. If we add the discarded stuff w_i to this higher value packing, then we have a solution to the overall packing that is worth more than O . A contradiction has been reached, therefore the problem has optimal substructure. Optimal Substructure Prove Greedy Choice Property Suppose O is an optimal solution and does not include the first choice C_1 made by the greedy algorithm. Let w be the weight of the most valuable item. Remove w oz of any other item and replace that with w oz of the most valuable algorithm. We have now increased the value of O which is a contradiction. Therefore, this w oz of the most valuable item was already in the packing of the optimal solution O . Our first greedy choice could be a part of any optimal solution. Data Compression A prefix code means no code for a single letter is the prefex of another letter this makes decoding significantly easier Full binary tree- tree where each non-leaf node has two children Code Trees- binary trees describing how to encode a letter letters/symbols are leaves of the tree traversing a left edge has a value of 0 traversing a right edge has value of 1 therefore, we want the most frequently occuring characters to be closest to the root of the code tree since this means it will have the smallest code optimal code tree will be a shortest full binary tree Shannon-Faro Algorithm Build tree with top down approach Need one leaf for every symbol in the alphabet Divide symbols into 2 sets where total frequency of each set is near equal A set of size 2 is finished, Represent each symbol w/ 1 bit Recursively divide sets of size > 2 into two balanced sets Turns out the resulting encoding is not optimal (counterexamples exist) Pretty good results still so it was used in practice for a while since no better alternatives existed Huffman Coding Algorithm Bottom-up approach focuses on leaves representing the two lowest frequency letters and continues by recursion Lossless compression algorithm that is better than shannon-faro Goal: Reduce total number of bits used to encode a piece of text without losing any information (optimal coding scheme) Recursively builds up the tree from the lowest frequency characters at the deepest part of the tree to the most frequently occuring characters closest to the root of the tree Greedy algorithm since it can be stopped at any point and the codes built for the included symbols at that point are optimal huffman(S): if |S| = 2: return a tree with root and 2 leaves from S else: S = S \\ {u, v} where u, v are two chars w/ lowest frequency S = S + new char w w/ frequency f_w = f_u + f_v T' = Huffman(S) T = T' w/ leaf w removed and replaced with interior node + 2 children u, v return T Runtime is \\Theta(n \\log n) when using a priority queue that can find the least frequently occuring character in O(\\log n) T(n) = T(n-1) + 2* \\text{find min} The best method for finding a min is a priority queue which is O(\\log n) T(n) = T(n - 1) + 2(\\log n) Recurrence relation can be solved via unrolling to find T(n) \\in \\Theta(n \\log n) Proof of optimal substructure: in an optimal encoding tree the sibling pair at the lowest level of the tree will have the smallest frequency Video Explanation","title":"Greedy"},{"location":"algorithms/greedy/#greedy-algorithms","text":"When they work in solving a problem optimally it implies something about the strucutre of the problem itself i.e. There is a local decision rule that one can use to construct optimal solutions Finding cases where greedy algorithms work well and proving their performance is challenging Any algorithm that follows the problem-solving heurisitc of making the locally optimal choice at each stage with the intent of finding a global optimum Follow a form of: select a candidate greedily according to some heuristic if adding the candidate does not corrupt feasability of the solution, add it to your current solution repeat until finished Two methods for proving a greedy algo produces optimal solution to a problem Greedy Algorithm Stays Ahead Exchange Argument Applications: Shortest paths in a graph Interval Scheduling Minimum Spanning trees in an undirected graph Minimum cost aboresence problem in directed graph Huffman code construction in data compression When to use the greedy approach? Does the problem display optimal substructure ? Does your algorithm have the greedy choice property ? If both questions above can be answered yes, then the greedy approach is good, but might also be able to use dynamic programming DP useful in the case of overlapping subproblems","title":"Greedy Algorithms"},{"location":"algorithms/greedy/#optimal-substructure","text":"Property of problems that can be solved with a greedy algorithm or dynamic programming Describes a problem if an optimal solution can be constructed from optimal solutions of its subproblems Has optimal substructure: shortest path, fractional knapsack Does not have optimal substructure: 0/1 knapsack, longest path on non-DAG","title":"Optimal Substructure"},{"location":"algorithms/greedy/#structure-of-a-proof","text":"Assume O is an optimal answer Remove an element x from O (often last element) to create O' Redefine the constraints of the problem for which O' is a solution Prove that O' is an optimal answer for this redefined problem Often a proof by contradiction: assume O is optimal but O' is not Find O^* ,the optimal answer to the redefined problem Add x to O^* to make a new answer to the original problem Contradiction reached in that x + O^* is better than O which was optimal Therefore, O' must be optimal and so the problem has optimal substructure","title":"Structure of a Proof"},{"location":"algorithms/greedy/#ex-shortest-path","text":"Assume the shortest path from u to v is P and w \\in P . Remove the end of the path from w to v to create P' which is a path from u to w . Is P' the shortest path from u to w ? By way of contradiction assume P is optimal but P' is not. Let P^* be the optimal path from u to w . If we add the previously removed edge from w to v to P^* then we have created a new path from u to v which is more optimal than P . This is a contradiction, so therefore P' must be optimal and so the shortest path problem has optimal substructure.","title":"Ex: Shortest Path"},{"location":"algorithms/greedy/#proving-correctness-of-greedy-algorithms","text":"Showing the problem has optimal substructure and the algorithm has the greedy choice property does not prove the algorithms correctness Can prove correctness of the algorithm by: Induction Contradiction (suppose your algorithm makes a mistake) useful techniques: stay ahead argument exchange argument given greedy answer and optimal answer, bring the greedy over into the optimal at the place where they first differ, where the results should be a contradiction Example: Greedy Camping problem can be proven correct using stay ahead argument and induction","title":"Proving Correctness of Greedy Algorithms"},{"location":"algorithms/greedy/#exchange-argument","text":"Incrementally modify the greedy algorithm's solution into the optimal solution Steps: Label your algorithm's solution G and a general optimal solution O Compare G with O by contradiction assume G \\neq O typically you isolate a simple example of a difference element of O not in G and element of G not in O or 2 consecutive elements in O in a different order than they are in G Exchange Swap the elements in question in O (either swap element out and another in for first case or swap order of elements in second case) Argue O is no worse than before Argue if you continue swapping, you can eliminate all the differences between G and O in a polynomial number of steps without worsening the quality of the solution Thus G is optimal The goal in exchange argument is to show how to modify O to create a new solution O' with the following properties: O' is at least as good of solution as O (or equivalently O' is also optimal), and O' is \u201cmore like\u201d G than O . The creative part that differs for each algo/problem is determining how to modify O to create O' Good place to start is think about how G is constructed and look to make the modification at the first point where the algorithm makes a choice for G that is different than what is in O Notes: remember to argue why the elements you are swapping even exist out of order or not in one solution but in the other Cornell Notes","title":"Exchange Argument"},{"location":"algorithms/greedy/#stay-ahead-argument","text":"Inductively prove that under some measure, the partial solutions produced by the greedy algorithm \"stay ahead\" of the partial solutions produced by an optimal algorithm Cornell Notes","title":"Stay Ahead Argument"},{"location":"algorithms/greedy/#shortest-paths-in-a-graph","text":"Given a strongly connected directed graph G = (V, E) and a start node s Each edge e has a length \\ell_e \\geq 0 Goal: determine shortest path from s to every other node in the graph Greedy algorithms take advantage of the optimal substructure of the shortest path longest path does not have same optimal substructure (unless working with a DAG) so cannot use a greedy algorithm","title":"Shortest Paths in a Graph"},{"location":"algorithms/greedy/#dijkstras-algorithm","text":"let S be set of explored nodes initialized to S = {s} dist[s] = 0 let Q be a priority queue initialized with nodes in V \\ {s} with a key of the dist[u] from start vertex for each u in Q for i=1 to |V|: dist[i] = infty for each edge(s,v): dist[v] = weight(s,v) while Q not empty: u = extract_min(Q) //removes u from Q S = S + {u} for each vertex v that is a neighbor of u: dist[v] = min(d[v], d[u] + weight(u,v)) Cannot handle negative edge weightS BFS is faster for shortet path of unweighted graph (could give all edges equal weight and run dijkstra's') \\Theta(V) inserts into priority queue \\Theta(V) extract min operations \\Theta(E) decrease key operations If priority queue is implemented as array: \\Theta(V) extract min \\Theta(1) decrease key \\Theta(V * V + E * 1) = \\Theta(V^2) runtime If prioty queue is implemented as a binary min-heap \\Theta(\\log V) for extract min \\Theta(\\log V) for decrease key \\Theta(V \\log V + E \\log V) runtime IF priority queue is implemented as a fibonnaci heap \\Theta(\\log V) for extract min \\Theta(1) amortized for decrease key \\Theta(V \\log V + E) runtime","title":"Dijkstra's Algorithm"},{"location":"algorithms/greedy/#interval-scheduling","text":"We have n requests each i th request corresponding to an interval of time starting at s(i) and finishing at f(i) A subset of the requests is compatible if no two of them overlap in time Goal: Determine largest compatible subset as possible Greedy rule/heuristic for choosing request: choose request a finishes first let R be set of all intervals Sort R by finish time let G be empty solution set for interval in R: if G is empty: add first interval to G else: if interval does not overlap with last interval in G: add interval to G This algorithm runs in O(n \\log n) Sort is O(n \\log n) Iterate through intervals is O(n)","title":"Interval Scheduling"},{"location":"algorithms/greedy/#proof-of-correctness","text":"We will use the stay ahead argument We will prove for each r \\geq 1 , the r th interval in the algorithm's solution G finishes no later than the r th interval in the optimal schedule Note that |G| = k and |O| = m and we want to show |G| = |O| in order to prove the greedy algorithm creates an optimal solution","title":"Proof of Correctness"},{"location":"algorithms/greedy/#proof","text":"We will prove via induction: for all r \\leq k we have f(i_r) \\leq f(j_r) . Base Case (r = 1): The algorithm selects the request i_1 with the minimum finish time so it is clearly an optimal first choice f(i_1) \\leq f(j_1) . For r>1 we will assume the inductive hypothesis is true ( f(i_{r-1}) \\leq f(j_{r-1}) ) for r - 1 and will try to prove it for r . Since O consists of nonoverlapping intervals, f(j_{r-1}) \\leq s(j_r) . Therefore, combining this with the inductive hypothesis implies f(i_{r-1}) \\leq s(j_r) . This means interval j_r is in the set of available intervals at the time when the greedy algorithm selects i_r . The greedy algorithm selects the available interval with the smallest finish time, therefore f(i_r) \\leq f(j_r) . This completes the induction steps so we have proven the optimality of the greedy algorthim's set A . So far we have only proven that the greedy algorithm's solution is as good as the optimal solution. To finish we need to prove |G| = |O| .","title":"Proof:"},{"location":"algorithms/greedy/#proof_1","text":"By way of contradiction, assume G is not optimal so |O| > |G| . This means there is a requests in O that starts after f(j_k) and therefore after f(i_k) . This means there was a compatible interval left to choose from that the greedy algorithm did not choose and opted to stop instead. This is a contradiction from how the greedy algorithm was designed so therefoer |G| = |O| .","title":"Proof:"},{"location":"algorithms/greedy/#fractional-knapsack","text":"Thief robbing a store finds n types of metallic dust The i th dust is worth v per ounce with w_i total ounces available Knapsack can hold total of W Ounces. What is the max value of dust that can fit in the knapsack? Solution: Calc value/oz and then add as much of the most valuable as possible then move to the next valuable, and repeat until the sack is full this approach is greedy and takes advatnage of the optimal substructure of the problem","title":"Fractional Knapsack"},{"location":"algorithms/greedy/#prove-optimal-substructure","text":"Suppose O is the optimal packing of the knapsack of size W and value val(O) give a list L of possible values. Remove one item i from the knapsack with weight w_i and value v_i to get a new packing O' of a knapsack of size W - w_i and choosing from the set of items L - i . By way of contradiction, assume O' is not optimal. This means we have a higher value packing. If we add the discarded stuff w_i to this higher value packing, then we have a solution to the overall packing that is worth more than O . A contradiction has been reached, therefore the problem has optimal substructure. Optimal Substructure","title":"Prove Optimal Substructure"},{"location":"algorithms/greedy/#prove-greedy-choice-property","text":"Suppose O is an optimal solution and does not include the first choice C_1 made by the greedy algorithm. Let w be the weight of the most valuable item. Remove w oz of any other item and replace that with w oz of the most valuable algorithm. We have now increased the value of O which is a contradiction. Therefore, this w oz of the most valuable item was already in the packing of the optimal solution O . Our first greedy choice could be a part of any optimal solution.","title":"Prove Greedy Choice Property"},{"location":"algorithms/greedy/#data-compression","text":"A prefix code means no code for a single letter is the prefex of another letter this makes decoding significantly easier Full binary tree- tree where each non-leaf node has two children Code Trees- binary trees describing how to encode a letter letters/symbols are leaves of the tree traversing a left edge has a value of 0 traversing a right edge has value of 1 therefore, we want the most frequently occuring characters to be closest to the root of the code tree since this means it will have the smallest code optimal code tree will be a shortest full binary tree","title":"Data Compression"},{"location":"algorithms/greedy/#shannon-faro-algorithm","text":"Build tree with top down approach Need one leaf for every symbol in the alphabet Divide symbols into 2 sets where total frequency of each set is near equal A set of size 2 is finished, Represent each symbol w/ 1 bit Recursively divide sets of size > 2 into two balanced sets Turns out the resulting encoding is not optimal (counterexamples exist) Pretty good results still so it was used in practice for a while since no better alternatives existed","title":"Shannon-Faro Algorithm"},{"location":"algorithms/greedy/#huffman-coding-algorithm","text":"Bottom-up approach focuses on leaves representing the two lowest frequency letters and continues by recursion Lossless compression algorithm that is better than shannon-faro Goal: Reduce total number of bits used to encode a piece of text without losing any information (optimal coding scheme) Recursively builds up the tree from the lowest frequency characters at the deepest part of the tree to the most frequently occuring characters closest to the root of the tree Greedy algorithm since it can be stopped at any point and the codes built for the included symbols at that point are optimal huffman(S): if |S| = 2: return a tree with root and 2 leaves from S else: S = S \\ {u, v} where u, v are two chars w/ lowest frequency S = S + new char w w/ frequency f_w = f_u + f_v T' = Huffman(S) T = T' w/ leaf w removed and replaced with interior node + 2 children u, v return T Runtime is \\Theta(n \\log n) when using a priority queue that can find the least frequently occuring character in O(\\log n) T(n) = T(n-1) + 2* \\text{find min} The best method for finding a min is a priority queue which is O(\\log n) T(n) = T(n - 1) + 2(\\log n) Recurrence relation can be solved via unrolling to find T(n) \\in \\Theta(n \\log n) Proof of optimal substructure: in an optimal encoding tree the sibling pair at the lowest level of the tree will have the smallest frequency Video Explanation","title":"Huffman Coding Algorithm"},{"location":"algorithms/heaps/","text":"Priority Queue ADT that implements a set S of elements, each element associated with a key Operations insert(S,x) : insert element x into set S max(S) : return element of S with largest key extract_max(S) : return element of S with largest key and remove it from S increase_key(S,x,k) : increase value of x 's key by k Binary Heap Implementation of a priority queue An array visualized as a nearly complete binary tree all leaves are at max depth or max depth -1 every leaf has 0 or 1 sibling Array has benefit of O(1) random access for getting children Calculating node indices (1-indexed): root i =1 parent( i ) = i / 2 left( i ) = 2i right( i ) = 2i + 1 Max-Heap Property- The key of a node is \\geq the keys of its children max(S) is trivial extract_max(S) is not trivial Operations build_max_heap(A) : produces a max heap from an unordered array python def build_max_heap(A): for i in range(n/2, 0, -1): #n/2 to 1 max_heapify(A, i) Why start at n/2? Elements n/2 + 1 to the end of the array are leaves So we build up max-heap from leaves Runtime of O(n) only 1 node with O(\\log n) runtime (the root), the lowest level with the most nodes, has the smallest number of operations detailed analysis: max_heapify takes O(1) for nodes that are one level above the leaves max_heapify takes O(\\ell) time for nodes that are \\ell levels above the leaves n/4 nodes w/ level 1, n / 8 nodes with level 2, .... , 1 node \\log n level Total amount of work in the for loop: n/4 (1c) + n/8 (2 c) + n / 16 (3 c) + \\cdots + 1 (\\log n c) let n/4 = 2^k c 2^k( 1/2^0 + 2/2^1 + 3/2^2 + \\cdots (k+1)/2^k) the series \\sum_{i=0}^k \\frac{i + 1}{2^i} is bounded by a constant Therefore, we have \\Theta (n) time complexity max_heapify(A,i) : correct a single violation of the heap property in a subtree's root assume that the trees rooted at left( i ) and right( i ) are max heaps If element A[i] violates the max-heap property, correct the violation by trickling it down the tree, in order to make the subtree rooted at i a max-heap Exchange bigger child with A[i] Recursively call max heapify on the subtree where the original parent is now the root This operation runs in O(\\log n) algorithm runs level by level on a height constrained tree -> produces logarithmic time complexity def max_heapify(A,i): l = left(i) r = right(i) if (l <= heap-size(A) and A[l] > A[i]): largest = l else: largest = i if (r <= heap-size(A) and A[r] > A[largest]): largest = r if (largest != i): swap(A[i],A[largest]) max_heapify(A, largest) Types of Heaps Binary Heap Min-Heap Max-Heap d -ary heap- every node has 0 up to d children Fibonnaci Heap- collection of trees Binomial Heap: priority queues that can be easily merged together Resources MIT 6.006 Lecture , MIT 6.006 Notes","title":"Heaps"},{"location":"algorithms/heaps/#priority-queue","text":"ADT that implements a set S of elements, each element associated with a key","title":"Priority Queue"},{"location":"algorithms/heaps/#operations","text":"insert(S,x) : insert element x into set S max(S) : return element of S with largest key extract_max(S) : return element of S with largest key and remove it from S increase_key(S,x,k) : increase value of x 's key by k","title":"Operations"},{"location":"algorithms/heaps/#binary-heap","text":"Implementation of a priority queue An array visualized as a nearly complete binary tree all leaves are at max depth or max depth -1 every leaf has 0 or 1 sibling Array has benefit of O(1) random access for getting children Calculating node indices (1-indexed): root i =1 parent( i ) = i / 2 left( i ) = 2i right( i ) = 2i + 1 Max-Heap Property- The key of a node is \\geq the keys of its children max(S) is trivial extract_max(S) is not trivial","title":"Binary Heap"},{"location":"algorithms/heaps/#operations_1","text":"build_max_heap(A) : produces a max heap from an unordered array python def build_max_heap(A): for i in range(n/2, 0, -1): #n/2 to 1 max_heapify(A, i) Why start at n/2? Elements n/2 + 1 to the end of the array are leaves So we build up max-heap from leaves Runtime of O(n) only 1 node with O(\\log n) runtime (the root), the lowest level with the most nodes, has the smallest number of operations detailed analysis: max_heapify takes O(1) for nodes that are one level above the leaves max_heapify takes O(\\ell) time for nodes that are \\ell levels above the leaves n/4 nodes w/ level 1, n / 8 nodes with level 2, .... , 1 node \\log n level Total amount of work in the for loop: n/4 (1c) + n/8 (2 c) + n / 16 (3 c) + \\cdots + 1 (\\log n c) let n/4 = 2^k c 2^k( 1/2^0 + 2/2^1 + 3/2^2 + \\cdots (k+1)/2^k) the series \\sum_{i=0}^k \\frac{i + 1}{2^i} is bounded by a constant Therefore, we have \\Theta (n) time complexity max_heapify(A,i) : correct a single violation of the heap property in a subtree's root assume that the trees rooted at left( i ) and right( i ) are max heaps If element A[i] violates the max-heap property, correct the violation by trickling it down the tree, in order to make the subtree rooted at i a max-heap Exchange bigger child with A[i] Recursively call max heapify on the subtree where the original parent is now the root This operation runs in O(\\log n) algorithm runs level by level on a height constrained tree -> produces logarithmic time complexity def max_heapify(A,i): l = left(i) r = right(i) if (l <= heap-size(A) and A[l] > A[i]): largest = l else: largest = i if (r <= heap-size(A) and A[r] > A[largest]): largest = r if (largest != i): swap(A[i],A[largest]) max_heapify(A, largest)","title":"Operations"},{"location":"algorithms/heaps/#types-of-heaps","text":"Binary Heap Min-Heap Max-Heap d -ary heap- every node has 0 up to d children Fibonnaci Heap- collection of trees Binomial Heap: priority queues that can be easily merged together","title":"Types of Heaps"},{"location":"algorithms/heaps/#resources","text":"MIT 6.006 Lecture , MIT 6.006 Notes","title":"Resources"},{"location":"algorithms/sorting/","text":"Sorting Algorithms General Sorting algorithms on abstract data types where the only operation you can perform is a comparison provably have a lower bound of O(n \\log n) this means there are no faster sorting algorithms than O(n \\log n) except for in the unique case of sorting integers in which case we can do more than comparisons in order to get the sort down to linear time the proof follows from the gauranteed height of a decision tree for sorting the elements (see the MIT 6.006 lecture 7 video for an intuition) Heap Sort Time: O(n \\log n) Space: O(1) Algorithm w/ Max-Heap Build max heap from unordered array Find maximum element A[1] Swap elements A[n] and A[1] now max element is at the end of the array Discard node n from the heap by decrementing the heap-size variable New root may violate max heap property, but its children are max heaps. Run max heapify to fix this Goto step 2 unless the heap is empty Algorithm w/ Min-Heap Build min-heap from unordered array O(n) Select and remove root O(1) Fix heap O(\\log n) Can't make assumptions about rest of tree like in build heap Repeat 2,3 n times to give runtime O(n \\log n) Quick Sort Avg Time: O(n \\log n) Worst Case is O(n^2) Space: O(1) Divide and Conquer (in place) HackerRank Video Select a pivot value from the array Using left and right indices starting from the edges, swap elements out of order (every element < pivot should be before every element > pivot) return the partition point (the point where the elements < pivot and > pivot meet) call quicksort recursively on the two halves of defined by the partition point Can choose pivot in many ways (e.g. median/middle of array) how you choose your pivot is main thing that affects runtime def quicksort(A, left, right): if (left < right): pivot = A[left + (right-left) / 2] index = partition(A, left, right, pivot) quicksort(A, left, index - 1) quicksort(A, index, right) def partition(A, left, right, pivot): while (left <= right): while (A[left] < pivot): left += 1 while (A[right] > pivot): right -= 1 if (left <= right): swap(A, left, right) left += 1 right -= 1 return left Merge Sort Time: O(n \\log n) Space: O(n) Divide & Conquer HackerRank Video Split the array into halves until you reach a base case of 2, sort the base case, then combine the sorted subproblems in sorted order to create the final sorted array Bubble Sort Time: O(n^2) Space: O(1) HackerRank Video \"bubbles\" the largest elements to the end of the array inefficient since each iteration of n comparisons only finishes sorting 1 element only time this might be useful is if the array is mostly sorted def bubblesort(A): is_sorted = False last_unsorted = len(A) - 1 while not is_sorted: is_sorted = True for i in range(last_unsorted): if (A[i] > A[i+1]): swap(A, i, i+1) is_sorted = False last_unsorted -= 1 Linear-Time Sorting More accurately Integer Sorting major area of reserach Assume n keys being sorted are integers in a range (0, ..., k-1) and each fits in a word of memory Since we are working with only integers, we can do more than just comparisons in order to speed up the sort MIT 6.006 Lecture Video Counting/Bucket Sort Performs no comparisons Uses knowledge of the range with upper bound of k Counts number of occurences of each element in the range (0 to k) Then in the output array, it will merely make sure there are the correct number of occurences for each element in the range and the frequency array is traversed in order to produce the sort Can generalize this procedure using the idea of buckets Create buckets (e.g. array/linked list) for each element in the range of your data Buckets must be accesible in O(1) time Create a function that is a bijection betwen different element types and the bucket indices function that maps everything to its own bucket with no crashes (e.g. temperature data mapped to a bucket) A more generalized version is seen below where the items can be any data structure, as long as they have an integer key This version will make sure all of the item's data is moved during the sort def bucket_sort(A, k) L = [[] for _ in range(k)] # array of k empty lists # O(n) for j in range(n): L[key(A[j])].append(A[j]) # O(1) output = [] # O(n + k) for i in range(k): output.extend(L[i]) #O (|L| + 1) return output Overall runtime: O(n + k) If k is order n , then the runtime is linear When not to use: Ex: sorting integers in range 1 to 10,000,000 but only sorting 100 numbers Bucket sort takes 10^7 to collect all the buckets Mergesort would take ~665 comparisons Radix Sort Radix means base Uses counting sort as a subroutine Performs in linear time even for k polynomial in n (e.g. k \\in O(n^{100}) ) Imagine each integer as base b (e.g. in the form of its digits) # digits: d = \\log_b k Sort the integers by least significant digit repeat d times (up to sorting by the most significant digit) Sort by digit using counting/bucket sort O(n + b) all digits are between 0 and b - 1 we can compute the digits in constant time (no need to actually convert them to base b ) using modulo and other operators So the total time is O(d(n+b)) We substitute value of d from above to get O(\\log_b k (n + b)) We want to choose a b to minimize the runtime minimized when b = \\Theta(n) O(n \\log_n k ) If k \\leq n^c then O(nc) If integers are reasonably small in value (polynomial in n ), then we get a linear time sorting algorithm","title":"Sorting"},{"location":"algorithms/sorting/#sorting-algorithms","text":"General Sorting algorithms on abstract data types where the only operation you can perform is a comparison provably have a lower bound of O(n \\log n) this means there are no faster sorting algorithms than O(n \\log n) except for in the unique case of sorting integers in which case we can do more than comparisons in order to get the sort down to linear time the proof follows from the gauranteed height of a decision tree for sorting the elements (see the MIT 6.006 lecture 7 video for an intuition)","title":"Sorting Algorithms"},{"location":"algorithms/sorting/#heap-sort","text":"Time: O(n \\log n) Space: O(1)","title":"Heap Sort"},{"location":"algorithms/sorting/#algorithm-w-max-heap","text":"Build max heap from unordered array Find maximum element A[1] Swap elements A[n] and A[1] now max element is at the end of the array Discard node n from the heap by decrementing the heap-size variable New root may violate max heap property, but its children are max heaps. Run max heapify to fix this Goto step 2 unless the heap is empty","title":"Algorithm w/ Max-Heap"},{"location":"algorithms/sorting/#algorithm-w-min-heap","text":"Build min-heap from unordered array O(n) Select and remove root O(1) Fix heap O(\\log n) Can't make assumptions about rest of tree like in build heap Repeat 2,3 n times to give runtime O(n \\log n)","title":"Algorithm w/ Min-Heap"},{"location":"algorithms/sorting/#quick-sort","text":"Avg Time: O(n \\log n) Worst Case is O(n^2) Space: O(1) Divide and Conquer (in place) HackerRank Video Select a pivot value from the array Using left and right indices starting from the edges, swap elements out of order (every element < pivot should be before every element > pivot) return the partition point (the point where the elements < pivot and > pivot meet) call quicksort recursively on the two halves of defined by the partition point Can choose pivot in many ways (e.g. median/middle of array) how you choose your pivot is main thing that affects runtime def quicksort(A, left, right): if (left < right): pivot = A[left + (right-left) / 2] index = partition(A, left, right, pivot) quicksort(A, left, index - 1) quicksort(A, index, right) def partition(A, left, right, pivot): while (left <= right): while (A[left] < pivot): left += 1 while (A[right] > pivot): right -= 1 if (left <= right): swap(A, left, right) left += 1 right -= 1 return left","title":"Quick Sort"},{"location":"algorithms/sorting/#merge-sort","text":"Time: O(n \\log n) Space: O(n) Divide & Conquer HackerRank Video Split the array into halves until you reach a base case of 2, sort the base case, then combine the sorted subproblems in sorted order to create the final sorted array","title":"Merge Sort"},{"location":"algorithms/sorting/#bubble-sort","text":"Time: O(n^2) Space: O(1) HackerRank Video \"bubbles\" the largest elements to the end of the array inefficient since each iteration of n comparisons only finishes sorting 1 element only time this might be useful is if the array is mostly sorted def bubblesort(A): is_sorted = False last_unsorted = len(A) - 1 while not is_sorted: is_sorted = True for i in range(last_unsorted): if (A[i] > A[i+1]): swap(A, i, i+1) is_sorted = False last_unsorted -= 1","title":"Bubble Sort"},{"location":"algorithms/sorting/#linear-time-sorting","text":"More accurately Integer Sorting major area of reserach Assume n keys being sorted are integers in a range (0, ..., k-1) and each fits in a word of memory Since we are working with only integers, we can do more than just comparisons in order to speed up the sort MIT 6.006 Lecture Video","title":"Linear-Time Sorting"},{"location":"algorithms/sorting/#countingbucket-sort","text":"Performs no comparisons Uses knowledge of the range with upper bound of k Counts number of occurences of each element in the range (0 to k) Then in the output array, it will merely make sure there are the correct number of occurences for each element in the range and the frequency array is traversed in order to produce the sort Can generalize this procedure using the idea of buckets Create buckets (e.g. array/linked list) for each element in the range of your data Buckets must be accesible in O(1) time Create a function that is a bijection betwen different element types and the bucket indices function that maps everything to its own bucket with no crashes (e.g. temperature data mapped to a bucket) A more generalized version is seen below where the items can be any data structure, as long as they have an integer key This version will make sure all of the item's data is moved during the sort def bucket_sort(A, k) L = [[] for _ in range(k)] # array of k empty lists # O(n) for j in range(n): L[key(A[j])].append(A[j]) # O(1) output = [] # O(n + k) for i in range(k): output.extend(L[i]) #O (|L| + 1) return output Overall runtime: O(n + k) If k is order n , then the runtime is linear When not to use: Ex: sorting integers in range 1 to 10,000,000 but only sorting 100 numbers Bucket sort takes 10^7 to collect all the buckets Mergesort would take ~665 comparisons","title":"Counting/Bucket Sort"},{"location":"algorithms/sorting/#radix-sort","text":"Radix means base Uses counting sort as a subroutine Performs in linear time even for k polynomial in n (e.g. k \\in O(n^{100}) ) Imagine each integer as base b (e.g. in the form of its digits) # digits: d = \\log_b k Sort the integers by least significant digit repeat d times (up to sorting by the most significant digit) Sort by digit using counting/bucket sort O(n + b) all digits are between 0 and b - 1 we can compute the digits in constant time (no need to actually convert them to base b ) using modulo and other operators So the total time is O(d(n+b)) We substitute value of d from above to get O(\\log_b k (n + b)) We want to choose a b to minimize the runtime minimized when b = \\Theta(n) O(n \\log_n k ) If k \\leq n^c then O(nc) If integers are reasonably small in value (polynomial in n ), then we get a linear time sorting algorithm","title":"Radix Sort"},{"location":"algorithms/tips/","text":"Writers Workshop Work out examples to get a rough idea for an algorithm (might not be most efficient but can improve from there) since solving the examples, your brain is using an algorithm Always can start with brute force might gain insight into problem will realize where unecessary work can be removed might be only choice in some cases Have to explore and refine find, go, delete keywords and explain how long they will take Try to break your algorithm with different examples","title":"Tips"},{"location":"algorithms/tips/#writers-workshop","text":"Work out examples to get a rough idea for an algorithm (might not be most efficient but can improve from there) since solving the examples, your brain is using an algorithm Always can start with brute force might gain insight into problem will realize where unecessary work can be removed might be only choice in some cases Have to explore and refine find, go, delete keywords and explain how long they will take Try to break your algorithm with different examples","title":"Writers Workshop"},{"location":"algorithms/graphs/bfs_dfs/","text":"Basic Graph Algorithms Breadth First Search Given graph G = (V,E) and source vertex s Explores edges of G to visit every vertex reachable from s Computes the distance (smallest # of edges) to from s to each vertex Explores all edges at depth k before exploring any edges at depth k + 1 Marks explored vertices as visited so they are not reexplored Creates a breadth-first forest comprising several breadth-first trees each level in a breadth-first tree represents all the nodes at that depth from the source node Analysis Enqueing and dequeing take O(1) time All nodes are added to the queue when exploring the entire graph so this takes O(V) time (overhead for initialization) Once a vertex is dequeued, its entire adjacency linked list is scanned (adding vertices to the queue that have not been visited) Since all the adjacency lists must be scanned in their entirety, it takes \\Theta(E) time We explore all edges \\Theta(E)) each edge explored once in undirected graph each edge explored twice in directed graph Total runtime is O(V + E) linear to the size of the adjacency list of G Depth First Search Searches deeper in the graph when possible and when it gsets stuck, the search backtracks Creates a depth-first forest comprising several depth-first trees time stamps when each vertex is disocvered and when the search finishes examining the vertex's neighbors (adjacency list) \\Theta(V + E) since all edges are traversed and all edges are visited Edge Classification Can classify edges in a graph based on how they are discovered when running DFS tree edge backward edge goes from v to an ancestor of u in the DFT happens when v disocvers u while u has been discovered but not finished yet and u is an ancestor of v forward edge goes from u to a descendant of u in the DFT happens when v discovers u while u is finished and u was discovered after v cross edge between u and v , neither is ancestor of the other in DFT happens when v discovers u while u is finished and u was discovered before v edge classification will change depending on where you start building the DFT from","title":"BFS & DFS"},{"location":"algorithms/graphs/bfs_dfs/#basic-graph-algorithms","text":"","title":"Basic Graph Algorithms"},{"location":"algorithms/graphs/bfs_dfs/#breadth-first-search","text":"Given graph G = (V,E) and source vertex s Explores edges of G to visit every vertex reachable from s Computes the distance (smallest # of edges) to from s to each vertex Explores all edges at depth k before exploring any edges at depth k + 1 Marks explored vertices as visited so they are not reexplored Creates a breadth-first forest comprising several breadth-first trees each level in a breadth-first tree represents all the nodes at that depth from the source node","title":"Breadth First Search"},{"location":"algorithms/graphs/bfs_dfs/#analysis","text":"Enqueing and dequeing take O(1) time All nodes are added to the queue when exploring the entire graph so this takes O(V) time (overhead for initialization) Once a vertex is dequeued, its entire adjacency linked list is scanned (adding vertices to the queue that have not been visited) Since all the adjacency lists must be scanned in their entirety, it takes \\Theta(E) time We explore all edges \\Theta(E)) each edge explored once in undirected graph each edge explored twice in directed graph Total runtime is O(V + E) linear to the size of the adjacency list of G","title":"Analysis"},{"location":"algorithms/graphs/bfs_dfs/#depth-first-search","text":"Searches deeper in the graph when possible and when it gsets stuck, the search backtracks Creates a depth-first forest comprising several depth-first trees time stamps when each vertex is disocvered and when the search finishes examining the vertex's neighbors (adjacency list) \\Theta(V + E) since all edges are traversed and all edges are visited","title":"Depth First Search"},{"location":"algorithms/graphs/bfs_dfs/#edge-classification","text":"Can classify edges in a graph based on how they are discovered when running DFS tree edge backward edge goes from v to an ancestor of u in the DFT happens when v disocvers u while u has been discovered but not finished yet and u is an ancestor of v forward edge goes from u to a descendant of u in the DFT happens when v discovers u while u is finished and u was discovered after v cross edge between u and v , neither is ancestor of the other in DFT happens when v discovers u while u is finished and u was discovered before v edge classification will change depending on where you start building the DFT from","title":"Edge Classification"},{"location":"algorithms/graphs/directed/","text":"Directed Graph Strongly Connected - path from every node to every other node Since not all nodes on a graph may be able to reach each other, a graph may be composed of strongly connected components (scc) or strong components SCC- a set of vertices such that there is a path from every vertex to every other vertex in the set Finding Strongly Connected Components Perform DFS (from random start vertex), when a vertex is finished (colored black) push onto a stack Compute the transpose of the graph (flip direction of edges) Run DFS on G^T , with the starting vertex being the top of the stack When you get stuck, pop from the stack to restart DFS with a new start ppint Each tree in the DFS forest of G^T is a strongly connected component Analysis: 2 DFS: \\Theta(V + E) Transpose of G is \\Theta(V + E) Overall Runtime: \\Theta (V+ E) Topological Sorts Only occur on DAGs- directed, acyclic graphs (directed graphs with no cycles) Can be perfomed on disconnected graphs Useful for task scheduling or building a project with dependencies in the correct order (topological sort is just a valid ordering of tasks or dependencies to complete/build in sequential order) Can be more than one topological sort How to find topological ordering? Start with vertex with no incoming edges CLAIM: every DAG has a vertex with no incoming edges PROOF: by way of contradiction, suppose there is a DAG and every vertex has an incoming edge. Choose uv and walk backwards from v to u . From u find one of its outgoing edges wu and walk backwards to w . Continue indefinitely. After n steps, at least one vertex was visited twice, thus a cycle. A contradiction has been reached since the graph is a DAG If graph is disconnected, choose any connected component and repeat the process above If no connected components, there are no edges and evey vertex has no incoming edges For every directed edge uv from vertex u to vertex v , u comes before v in the ordering Prove via induction every DAG has a topological ordering: Base case, n = 2 Assume true for k nodes, that a DAG on k nodes has a topological ordering Prove true for k+1 nodes that a DAG G on k+1 nodes has a topological ordering Given an arbitrary graph G on k+1 nodes that is a DAG, find v in G where v is a node with no incoming edges. Remove v to create G' , a graph on k Nodes. G' must be a DAG also because if you have a DAG and remove a node, you cannot create a cycle. G' is a DAG on k nodes so it has a topological ordering by the inductive hypothesis Since we removed from G the node v with no incoming edges, we can place v at the front of the topological sort of G' to produce a topological sort for G The inductive proof leads to an algorithm: Find a node with no incoming edges, v Remove v and its edges from G, v is head of topological sort deleting v with no edges means only need to delete outoing edges so v isn't on anyone's neighbor list need to decrement the count of incoming edges on each of v 's neighbors Recursively find a node v of G with no incoming edges O(V^2) but can be faster \\Theta(V+E) if there is a more efficient way to find vertex with no incoming edges instead of a simple O(V) search (there is and it uses dfs) CLAIM: If you run a DFS on a DAG, you will not find any back edges (no cycles) Better algorithm using DFS: Execute DFS and as each vertex is finished (all edges explored), add it as the head of the topological sort (build the topological sort from back to front) Nodes that get finished first have no further descendants/dependencies so they can be added to the topological sort in order of completion since that means they either have no more dependencies or their dependencies are already in the sort \\Theta(V + E) Shortest-Path Bellman Ford Algorithm Can handle negative edge weights and negative cycles in the graph detects negative cycles since they can lead to indeterminate path of length - \\infty Based on idea that repeatedly relaxing the edge weights will eventually converge to the shortest path Bellman-Ford(G, w, s){ Initialize() for i = 1 to |V| - 1 { for each edge (u,v) in E { Relax(u, v, w) } } # check for negative edge cycles for each edge (u,v ) in E { if d[v] > d[u] + w(u, v) { report negative edge cycle exists } } } Relax(u, v, w) { if (d[v] > d[u] + w(u, v)) { d[v] = d[u] + w(u, v) predecessor[v] = u } } Runtime is O(VE) Much slower than dijkstra's Should only be used when potential for negative edge cycles","title":"Directed"},{"location":"algorithms/graphs/directed/#directed-graph","text":"Strongly Connected - path from every node to every other node Since not all nodes on a graph may be able to reach each other, a graph may be composed of strongly connected components (scc) or strong components SCC- a set of vertices such that there is a path from every vertex to every other vertex in the set","title":"Directed Graph"},{"location":"algorithms/graphs/directed/#finding-strongly-connected-components","text":"Perform DFS (from random start vertex), when a vertex is finished (colored black) push onto a stack Compute the transpose of the graph (flip direction of edges) Run DFS on G^T , with the starting vertex being the top of the stack When you get stuck, pop from the stack to restart DFS with a new start ppint Each tree in the DFS forest of G^T is a strongly connected component Analysis: 2 DFS: \\Theta(V + E) Transpose of G is \\Theta(V + E) Overall Runtime: \\Theta (V+ E)","title":"Finding Strongly Connected Components"},{"location":"algorithms/graphs/directed/#topological-sorts","text":"Only occur on DAGs- directed, acyclic graphs (directed graphs with no cycles) Can be perfomed on disconnected graphs Useful for task scheduling or building a project with dependencies in the correct order (topological sort is just a valid ordering of tasks or dependencies to complete/build in sequential order) Can be more than one topological sort How to find topological ordering? Start with vertex with no incoming edges CLAIM: every DAG has a vertex with no incoming edges PROOF: by way of contradiction, suppose there is a DAG and every vertex has an incoming edge. Choose uv and walk backwards from v to u . From u find one of its outgoing edges wu and walk backwards to w . Continue indefinitely. After n steps, at least one vertex was visited twice, thus a cycle. A contradiction has been reached since the graph is a DAG If graph is disconnected, choose any connected component and repeat the process above If no connected components, there are no edges and evey vertex has no incoming edges For every directed edge uv from vertex u to vertex v , u comes before v in the ordering Prove via induction every DAG has a topological ordering: Base case, n = 2 Assume true for k nodes, that a DAG on k nodes has a topological ordering Prove true for k+1 nodes that a DAG G on k+1 nodes has a topological ordering Given an arbitrary graph G on k+1 nodes that is a DAG, find v in G where v is a node with no incoming edges. Remove v to create G' , a graph on k Nodes. G' must be a DAG also because if you have a DAG and remove a node, you cannot create a cycle. G' is a DAG on k nodes so it has a topological ordering by the inductive hypothesis Since we removed from G the node v with no incoming edges, we can place v at the front of the topological sort of G' to produce a topological sort for G The inductive proof leads to an algorithm: Find a node with no incoming edges, v Remove v and its edges from G, v is head of topological sort deleting v with no edges means only need to delete outoing edges so v isn't on anyone's neighbor list need to decrement the count of incoming edges on each of v 's neighbors Recursively find a node v of G with no incoming edges O(V^2) but can be faster \\Theta(V+E) if there is a more efficient way to find vertex with no incoming edges instead of a simple O(V) search (there is and it uses dfs) CLAIM: If you run a DFS on a DAG, you will not find any back edges (no cycles) Better algorithm using DFS: Execute DFS and as each vertex is finished (all edges explored), add it as the head of the topological sort (build the topological sort from back to front) Nodes that get finished first have no further descendants/dependencies so they can be added to the topological sort in order of completion since that means they either have no more dependencies or their dependencies are already in the sort \\Theta(V + E)","title":"Topological Sorts"},{"location":"algorithms/graphs/directed/#shortest-path-bellman-ford-algorithm","text":"Can handle negative edge weights and negative cycles in the graph detects negative cycles since they can lead to indeterminate path of length - \\infty Based on idea that repeatedly relaxing the edge weights will eventually converge to the shortest path Bellman-Ford(G, w, s){ Initialize() for i = 1 to |V| - 1 { for each edge (u,v) in E { Relax(u, v, w) } } # check for negative edge cycles for each edge (u,v ) in E { if d[v] > d[u] + w(u, v) { report negative edge cycle exists } } } Relax(u, v, w) { if (d[v] > d[u] + w(u, v)) { d[v] = d[u] + w(u, v) predecessor[v] = u } } Runtime is O(VE) Much slower than dijkstra's Should only be used when potential for negative edge cycles","title":"Shortest-Path Bellman Ford Algorithm"},{"location":"algorithms/graphs/graphs/","text":"Graph Representation A graph is a set of vertices and edges G = (V, E) Adjacency List Array of length |V| with each array value being a linked list of neighboring nodes Common choice b/c its a compact way to represent sparse graphs ( |E| < |V|^2 ) Can represent a weighted graph by using a weight function to compute the weight and store it in the linked list node for neighboring vertices (also can use another array and linked list, it really depends on language and implementation details) Cons: no quicker way to determine whether an edge is present in the graph than to search for the 2nd vertex in the first vertex's linked list of neighbors Takes O(V + E) to build Adjacency Matrix 2D array/matrix of size |V| * |V| Good choice when graph is dense ( |E| \\approx |V|^2 ) Good choice when we need to quickly know if an edge connects to vertices ( O(1) ) due to random-access property of arrays/matrices) Comes at the cost of higher space complexity than adjacency list ( \\Theta(V^2) memory) Can represent a weighted graph by using weights instead of just 0 and 1 In an undirected graph, the adjacency matrix A = A^T so in very large graphs it can be more space efficient to only store entries above or below the diagonal (saves half the memory) Simpler so they are sometimes preferred in cases where V is known to be small Runtimes Building a graph: adjacency list: O(V + E) adjacency matrix: O(V^2) Finding vertex x in an array or matrix using its id: O(1) Determine number of vertices or edges in graph: O(1) assume information is recorded when graph was input Explore all neighbors of vertex x : O(V) Explore all neighbors of all vertices in the graph: adjacency list: O(V+E) adjacency matrix: O(V^2) O(V + E) \\neq O(V^2) let algo A run in O(V+E) let algo B run in O(V^2) for dense graph where E \\approx V^2 , algo A and algo B both run in O(V^2) for a sparse graph where E \\leq V , algo A runs in O(V) while algo B runs in O(V^2) still therefore, these two runtime notations are not the same since one is dependent on edges and the other is not","title":"Representations"},{"location":"algorithms/graphs/graphs/#graph-representation","text":"A graph is a set of vertices and edges G = (V, E)","title":"Graph Representation"},{"location":"algorithms/graphs/graphs/#adjacency-list","text":"Array of length |V| with each array value being a linked list of neighboring nodes Common choice b/c its a compact way to represent sparse graphs ( |E| < |V|^2 ) Can represent a weighted graph by using a weight function to compute the weight and store it in the linked list node for neighboring vertices (also can use another array and linked list, it really depends on language and implementation details) Cons: no quicker way to determine whether an edge is present in the graph than to search for the 2nd vertex in the first vertex's linked list of neighbors Takes O(V + E) to build","title":"Adjacency List"},{"location":"algorithms/graphs/graphs/#adjacency-matrix","text":"2D array/matrix of size |V| * |V| Good choice when graph is dense ( |E| \\approx |V|^2 ) Good choice when we need to quickly know if an edge connects to vertices ( O(1) ) due to random-access property of arrays/matrices) Comes at the cost of higher space complexity than adjacency list ( \\Theta(V^2) memory) Can represent a weighted graph by using weights instead of just 0 and 1 In an undirected graph, the adjacency matrix A = A^T so in very large graphs it can be more space efficient to only store entries above or below the diagonal (saves half the memory) Simpler so they are sometimes preferred in cases where V is known to be small","title":"Adjacency Matrix"},{"location":"algorithms/graphs/graphs/#runtimes","text":"Building a graph: adjacency list: O(V + E) adjacency matrix: O(V^2) Finding vertex x in an array or matrix using its id: O(1) Determine number of vertices or edges in graph: O(1) assume information is recorded when graph was input Explore all neighbors of vertex x : O(V) Explore all neighbors of all vertices in the graph: adjacency list: O(V+E) adjacency matrix: O(V^2) O(V + E) \\neq O(V^2) let algo A run in O(V+E) let algo B run in O(V^2) for dense graph where E \\approx V^2 , algo A and algo B both run in O(V^2) for a sparse graph where E \\leq V , algo A runs in O(V) while algo B runs in O(V^2) still therefore, these two runtime notations are not the same since one is dependent on edges and the other is not","title":"Runtimes"},{"location":"algorithms/graphs/max_flow/","text":"Network Flow A general class of problems that share a common structure Bipartite Matching problem is one type of network flow problem that has many applications (e.g. matching jobs to available machines) Ford-Fulkerson Method Continue finding augmenting paths and augmenting the flow until no more augmenting paths from s to v exist Max Flow = sum of bottlenecks in each augmenting path Time complexity depends on algorithm used to find augmenting paths Can use DFS but this gives a runtime dependent on the max flow in the graph f , O(fE) Can use BFS to get runtime independent of max flow in graph: O(E^2 V) In practice, the average runtimes are better than the worst cases Video Edmonds Karp Algorithm Method for finding augmenting paths using BFS Uses BFS to find the shortest (in terms of # edges) augmenting path from s to t at each iteration Beneficial compared to DFS arbitrarly long augmenting path since the longer the path, the higher chance of getting a small bottleneck value which will result in more iterations to get the max flow Rule: Only explore an edge if its remaining capacity > 0 remaining capacity = capacity - flow Repeat until termination criteria: Run BFS from s to t to get the shortest path (whichever reaches T first) Can take residual edges as long as they satisfy the exploration rule Find bottleneck value by taking min of remaining capaciites of the edges on the path Augment (update) the flow of the forward edges (+ bottleneck value) and the residual edges (- bottleneck value) Termination Criteria: all outgoing edges from s have remaining capacity = 0 (i.e. no more augmenting paths from s to t ) Video","title":"Network Flow"},{"location":"algorithms/graphs/max_flow/#network-flow","text":"A general class of problems that share a common structure Bipartite Matching problem is one type of network flow problem that has many applications (e.g. matching jobs to available machines)","title":"Network Flow"},{"location":"algorithms/graphs/max_flow/#ford-fulkerson-method","text":"Continue finding augmenting paths and augmenting the flow until no more augmenting paths from s to v exist Max Flow = sum of bottlenecks in each augmenting path Time complexity depends on algorithm used to find augmenting paths Can use DFS but this gives a runtime dependent on the max flow in the graph f , O(fE) Can use BFS to get runtime independent of max flow in graph: O(E^2 V) In practice, the average runtimes are better than the worst cases Video","title":"Ford-Fulkerson Method"},{"location":"algorithms/graphs/max_flow/#edmonds-karp-algorithm","text":"Method for finding augmenting paths using BFS Uses BFS to find the shortest (in terms of # edges) augmenting path from s to t at each iteration Beneficial compared to DFS arbitrarly long augmenting path since the longer the path, the higher chance of getting a small bottleneck value which will result in more iterations to get the max flow Rule: Only explore an edge if its remaining capacity > 0 remaining capacity = capacity - flow Repeat until termination criteria: Run BFS from s to t to get the shortest path (whichever reaches T first) Can take residual edges as long as they satisfy the exploration rule Find bottleneck value by taking min of remaining capaciites of the edges on the path Augment (update) the flow of the forward edges (+ bottleneck value) and the residual edges (- bottleneck value) Termination Criteria: all outgoing edges from s have remaining capacity = 0 (i.e. no more augmenting paths from s to t ) Video","title":"Edmonds Karp Algorithm"},{"location":"algorithms/graphs/undirected/","text":"Undirected Graph Connected - run DFS or BFS and see you visit all the nodes (keep a count and compare to size of graph) BFS tree from a node is a connected component Articulation Point - a node that if removed, will split G into 2+ parts a is an articulation point if every path btw v and w contains a Biconnected Components - components with no articulation points Articulation Points Execute DFS while keeping track of additional info Overall runtime of \\Theta (V + E) A node u is an articulation point if: u is the root of the DFS tree and has at least 2 children in the tree (not in the graph!) This means the children cannot reach each other in any other way except through u u is not a root of the DFS tree and u has a child with a subtree that has no backedge to one of u 's ancestors This means all the descendants of u must travel through u to reach any ancestors of u in the DFS tree Minimum Spanning Trees Can be found for undirected, weighted graphs Both algorithms fail on directed graphs A tree T of G such that the sum of the edge weights is minimized Can be optimally found using greedy algorithms due to the structure of the problem Both algorithms only include an edge in the MST when it is justified by the Cut Property Both can run in O(E \\log V) time given the correct data structure Cut property is a common technique used in proving correctness of gredey MST algorithms A cut is a partition of the vertices of a graph G into two disjoint sets The cut property states that for any cut C of the graph, if the weight of an edge e \\in C is strictly smaller than the weights of all other edges of C , then this edge belongs to all MSTs of the graph lightest edge in a cut-set must be in the MST Prim's Start with a root node and greedily grow the tree otuward, always adding the node that can be reached cheapest from the current node Greedy algorithm Can stop at any point and have a valid mst that doesn't reach all the nodes optimal substructure O(E \\log V) when implemented using a priority queue ADT priority queue allows us to pick the cheapest vertex in O(\\log V) instead of O(V) using just a basic array/list which results in O(V^2) runtime Kruskal's Sort the edges from least to greatest ( O(E \\log V) ) this is the bottleneck in terms of speed (faster union-find implementations won't help) Insert the next edge in the sorted edge list into the tree if it does not cause any cycles (othewise discard it) stopping at any point will not leave you with a valid msg implemented using the union-find structure as each edge (v,w) is considered we need to efficiently find the connected components containing v and w . if the components are different, there is no path btw v and w and thus no cycle so the edge can be included if the edge is included, the components of v and w should be merged into a single new component Union-Find Data Structure Stores graph components (disjoint sets) in a way that supports rapid searching and updating can only be used to maintain graph components as we add edges (not remove them) Find(u) will return the name of the set containing u Find(u) == Find(v) checks if u and v are in the same set O(\\log V) compress the path (e.g. set pointer directly to set root) after every find operation to make subsequent finds faster Union(A,B) merges two sets A and B into a single set O(1) keep the name of the larger set as the name of the union MakeUnionFind(G) for a set G will return a UFDS with all elements in separate sets O(V)","title":"Undirected"},{"location":"algorithms/graphs/undirected/#undirected-graph","text":"Connected - run DFS or BFS and see you visit all the nodes (keep a count and compare to size of graph) BFS tree from a node is a connected component Articulation Point - a node that if removed, will split G into 2+ parts a is an articulation point if every path btw v and w contains a Biconnected Components - components with no articulation points","title":"Undirected Graph"},{"location":"algorithms/graphs/undirected/#articulation-points","text":"Execute DFS while keeping track of additional info Overall runtime of \\Theta (V + E) A node u is an articulation point if: u is the root of the DFS tree and has at least 2 children in the tree (not in the graph!) This means the children cannot reach each other in any other way except through u u is not a root of the DFS tree and u has a child with a subtree that has no backedge to one of u 's ancestors This means all the descendants of u must travel through u to reach any ancestors of u in the DFS tree","title":"Articulation Points"},{"location":"algorithms/graphs/undirected/#minimum-spanning-trees","text":"Can be found for undirected, weighted graphs Both algorithms fail on directed graphs A tree T of G such that the sum of the edge weights is minimized Can be optimally found using greedy algorithms due to the structure of the problem Both algorithms only include an edge in the MST when it is justified by the Cut Property Both can run in O(E \\log V) time given the correct data structure Cut property is a common technique used in proving correctness of gredey MST algorithms A cut is a partition of the vertices of a graph G into two disjoint sets The cut property states that for any cut C of the graph, if the weight of an edge e \\in C is strictly smaller than the weights of all other edges of C , then this edge belongs to all MSTs of the graph lightest edge in a cut-set must be in the MST","title":"Minimum Spanning Trees"},{"location":"algorithms/graphs/undirected/#prims","text":"Start with a root node and greedily grow the tree otuward, always adding the node that can be reached cheapest from the current node Greedy algorithm Can stop at any point and have a valid mst that doesn't reach all the nodes optimal substructure O(E \\log V) when implemented using a priority queue ADT priority queue allows us to pick the cheapest vertex in O(\\log V) instead of O(V) using just a basic array/list which results in O(V^2) runtime","title":"Prim's"},{"location":"algorithms/graphs/undirected/#kruskals","text":"Sort the edges from least to greatest ( O(E \\log V) ) this is the bottleneck in terms of speed (faster union-find implementations won't help) Insert the next edge in the sorted edge list into the tree if it does not cause any cycles (othewise discard it) stopping at any point will not leave you with a valid msg implemented using the union-find structure as each edge (v,w) is considered we need to efficiently find the connected components containing v and w . if the components are different, there is no path btw v and w and thus no cycle so the edge can be included if the edge is included, the components of v and w should be merged into a single new component","title":"Kruskal's"},{"location":"algorithms/graphs/undirected/#union-find-data-structure","text":"Stores graph components (disjoint sets) in a way that supports rapid searching and updating can only be used to maintain graph components as we add edges (not remove them) Find(u) will return the name of the set containing u Find(u) == Find(v) checks if u and v are in the same set O(\\log V) compress the path (e.g. set pointer directly to set root) after every find operation to make subsequent finds faster Union(A,B) merges two sets A and B into a single set O(1) keep the name of the larger set as the name of the union MakeUnionFind(G) for a set G will return a UFDS with all elements in separate sets O(V)","title":"Union-Find Data Structure"},{"location":"azure/networking/vnets/","text":"Virtual Networks Virtual Network- customer's private network within Azure public cloud Have an address space (all resources in the vnet must have addresses in this range) Specify an address space using CIDR notation Specify starting address and number of pits of prefix (called the mask) 10.0.0.0/16 means starting address of 10.0.0.0 and first 16 bits identify the network --> 65k addresses range from 10.0.0.0 to 10.0.255.255 Subnets- vnet is often divided into multiple subnets Additional security in filtering network trafffic between subnets Address space is a subset of the parent vnet's address space CIDR Notation Convert the IP address to binary: e.g., 172.31.0.0 in binary is 10101100.00011111.00000000.00000000 The mask tells you how many bits of the binary IP address identify the network (and stay constant for everything in that network) and how many bits identify unique hosts (and therefore, can vary). For a /16 mask, the left-most 16 bits stay constant, while the right-most 16 bits are allowed to vary. Putting that together, 172.31.0.0/16 represents all IP addresses from 10101100.00011111.00000000.00000000 ( 172.31.0.0 ) to 10101100.00011111.11111111.11111111 ( 172.31.255.255 ) Read More","title":"Virtual Networks"},{"location":"azure/networking/vnets/#virtual-networks","text":"Virtual Network- customer's private network within Azure public cloud Have an address space (all resources in the vnet must have addresses in this range) Specify an address space using CIDR notation Specify starting address and number of pits of prefix (called the mask) 10.0.0.0/16 means starting address of 10.0.0.0 and first 16 bits identify the network --> 65k addresses range from 10.0.0.0 to 10.0.255.255 Subnets- vnet is often divided into multiple subnets Additional security in filtering network trafffic between subnets Address space is a subset of the parent vnet's address space","title":"Virtual Networks"},{"location":"azure/networking/vnets/#cidr-notation","text":"Convert the IP address to binary: e.g., 172.31.0.0 in binary is 10101100.00011111.00000000.00000000 The mask tells you how many bits of the binary IP address identify the network (and stay constant for everything in that network) and how many bits identify unique hosts (and therefore, can vary). For a /16 mask, the left-most 16 bits stay constant, while the right-most 16 bits are allowed to vary. Putting that together, 172.31.0.0/16 represents all IP addresses from 10101100.00011111.00000000.00000000 ( 172.31.0.0 ) to 10101100.00011111.11111111.11111111 ( 172.31.255.255 ) Read More","title":"CIDR Notation"},{"location":"azure/storage/blob_storage/","text":"Blob Storage Blob Types Understanding block blobs, append blobs, and page blobs - Azure Storage | Microsoft Docs Block Blob- optimized foruploading large amounts of data efficiently Composed of blocks each of which have a block id 50k blocks max in a blob Write set of blocks via Put Block op Commit blocks to a blob with Put Block List op When you upload a block to a blob in your storage account, it is associated with the specified block blob, but it does not become part of the blob until you commit a list of blocks that includes the new block's ID 4000 MiB max block size Better suited for SJ blocks since stream duration may make them very large depending on length Can upload multiple blocks to same blob in parallel Can include MD5 hash to verify transfer of a block Track upload progress and resend a block if needed Can upload blocks in any order and then finalize the order in the blob in the commit step Append Blob- composed ofblocks and optimized for append operations Blocks added to end of blob Cannot update/delete existing blocks 4 MiB ~ 4MB max size for an append block Could easily go past this since with a longer stream duration and higher bitrate for the video streams so likely not a good choice Max 50k blocks Page Blob- collection of512-byte pages optimized for random read/write ops Useful for VM disks Access Tiers: Hot Tier- online; optimized for storing data that is accessed/modified frequently (higheststorage cost, lowest access cost) Cool Tier- online; optimized for storing data that is infrequently accessed or modified (lower storage costs, higher access cost) Data stored for min 30 days (pay early deletion fee otherwise) No min retention for blob storage accounts specifically ArchiveTier- offline; optimized for storing data that is rarely accessed and has flexible latency requirements (order of hours) Data stored for min 180 days (pay early deletion fee otherwise) Data can't be read or modified here, must first move it to online tier (can take up to 15 hours to \"rehydrate\") Blob metadata available for access Online- users can access the data immediately Offline- must move data to online to access data (this process can take up to 15 hrs) Per GB capacity cost decreases as tier gets cooler Data access charges increaseas tier gets cooler Authorization Methods Azure Active Directfory (AAD) Connection String Access Token/Key AAD for Blobs: Security Principal- user, group, application service principal, or managed identity Resource access has 2 steps w/ AAD Security Principal's identity is authenticated and an Oauth 2.0 token is returned Token is passed as part of a request to the Blob service and used by the service to authorize access to the specified resource Requires 1+ Azure RBAC roles be assigned to security principal making the request","title":"Blobs"},{"location":"azure/storage/blob_storage/#blob-storage","text":"","title":"Blob Storage"},{"location":"azure/storage/blob_storage/#blob-types","text":"Understanding block blobs, append blobs, and page blobs - Azure Storage | Microsoft Docs Block Blob- optimized foruploading large amounts of data efficiently Composed of blocks each of which have a block id 50k blocks max in a blob Write set of blocks via Put Block op Commit blocks to a blob with Put Block List op When you upload a block to a blob in your storage account, it is associated with the specified block blob, but it does not become part of the blob until you commit a list of blocks that includes the new block's ID 4000 MiB max block size Better suited for SJ blocks since stream duration may make them very large depending on length Can upload multiple blocks to same blob in parallel Can include MD5 hash to verify transfer of a block Track upload progress and resend a block if needed Can upload blocks in any order and then finalize the order in the blob in the commit step Append Blob- composed ofblocks and optimized for append operations Blocks added to end of blob Cannot update/delete existing blocks 4 MiB ~ 4MB max size for an append block Could easily go past this since with a longer stream duration and higher bitrate for the video streams so likely not a good choice Max 50k blocks Page Blob- collection of512-byte pages optimized for random read/write ops Useful for VM disks","title":"Blob Types"},{"location":"azure/storage/blob_storage/#access-tiers","text":"Hot Tier- online; optimized for storing data that is accessed/modified frequently (higheststorage cost, lowest access cost) Cool Tier- online; optimized for storing data that is infrequently accessed or modified (lower storage costs, higher access cost) Data stored for min 30 days (pay early deletion fee otherwise) No min retention for blob storage accounts specifically ArchiveTier- offline; optimized for storing data that is rarely accessed and has flexible latency requirements (order of hours) Data stored for min 180 days (pay early deletion fee otherwise) Data can't be read or modified here, must first move it to online tier (can take up to 15 hours to \"rehydrate\") Blob metadata available for access Online- users can access the data immediately Offline- must move data to online to access data (this process can take up to 15 hrs) Per GB capacity cost decreases as tier gets cooler Data access charges increaseas tier gets cooler","title":"Access Tiers:"},{"location":"azure/storage/blob_storage/#authorization-methods","text":"Azure Active Directfory (AAD) Connection String Access Token/Key","title":"Authorization Methods"},{"location":"azure/storage/blob_storage/#aad-for-blobs","text":"Security Principal- user, group, application service principal, or managed identity Resource access has 2 steps w/ AAD Security Principal's identity is authenticated and an Oauth 2.0 token is returned Token is passed as part of a request to the Blob service and used by the service to authorize access to the specified resource Requires 1+ Azure RBAC roles be assigned to security principal making the request","title":"AAD for Blobs:"},{"location":"azure/storage/overview/","text":"Storage Overview Can access data objects over HTTP/HTTPS via Rest API Client libraries exist in Java, Python, etc. for building apps/services Data Services Blobs- object store for text/binary data Files- file shares Queues- messaging store Tables- NoSQL store for schema-less storage of structured data Shares same table data model & CRUD operations as Cosmos DB Table API Not same as Cosmos DB Microsoft Azure Cosmos DB vs. Microsoft Azure Table Storage Comparison Disks- block level storage volumes for VMs Types of Storage Accounts Standard- recommended for most scenarios Blob storage, Queue, Table Storage, Files Premium Block Blobs- recommended for high transaction rates, smaller objects, or low storage latency requirements Blob storage Premium File Shares Files Premium Page Blobs Page blobs only in blob storage Endpoints Every object in Azure storage has a URL that includes the unique storage account name Authorization Shared Key- header in each request signed w/ storage account access key Recommendation to disallow for security Share Access Signatures (SAS)- signed url specifying permissions granted to the resource and the interval the signature is valid over Service/Account SAS- signed w/ account key User delegation SAS- signed w/ Azure AD credentials; applies to blobs only Azure Active Directory (AAD)- Recommended method of auth for optimal security and ease of use Azure role-based access control (Azure RBAC) can be used for managing permissions to a resource in a storage account Authorize operations for data access - Azure Storage | Microsoft Docs","title":"Overview"},{"location":"azure/storage/overview/#storage-overview","text":"Can access data objects over HTTP/HTTPS via Rest API Client libraries exist in Java, Python, etc. for building apps/services","title":"Storage Overview"},{"location":"azure/storage/overview/#data-services","text":"Blobs- object store for text/binary data Files- file shares Queues- messaging store Tables- NoSQL store for schema-less storage of structured data Shares same table data model & CRUD operations as Cosmos DB Table API Not same as Cosmos DB Microsoft Azure Cosmos DB vs. Microsoft Azure Table Storage Comparison Disks- block level storage volumes for VMs","title":"Data Services"},{"location":"azure/storage/overview/#types-of-storage-accounts","text":"Standard- recommended for most scenarios Blob storage, Queue, Table Storage, Files Premium Block Blobs- recommended for high transaction rates, smaller objects, or low storage latency requirements Blob storage Premium File Shares Files Premium Page Blobs Page blobs only in blob storage","title":"Types of Storage Accounts"},{"location":"azure/storage/overview/#endpoints","text":"Every object in Azure storage has a URL that includes the unique storage account name","title":"Endpoints"},{"location":"azure/storage/overview/#authorization","text":"Shared Key- header in each request signed w/ storage account access key Recommendation to disallow for security Share Access Signatures (SAS)- signed url specifying permissions granted to the resource and the interval the signature is valid over Service/Account SAS- signed w/ account key User delegation SAS- signed w/ Azure AD credentials; applies to blobs only Azure Active Directory (AAD)- Recommended method of auth for optimal security and ease of use Azure role-based access control (Azure RBAC) can be used for managing permissions to a resource in a storage account Authorize operations for data access - Azure Storage | Microsoft Docs","title":"Authorization"},{"location":"data_structures/binary-tree/","text":"Binary Tree explain like im five picture or visualization Purpose why does it exist? why would you ever choose this over other data structures? what is the data structure optimized for? insertions/deletion? resizing? etc? Advantages Disadvantages Implementations Array : - Can be efficiently stored as an array due to each node having a max of two children - left child: (index * 2) + 1 - right child: (index * 2) + 2 - parent: (index - 1) / 2 (not used on the root!) Nodes : - Can be stored as nodes with left and right child pointers Big O Analysis Array Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Node Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Code Binary Trees Each parent has maximum of two children (left and right child) Predetermined max number of children lets us store binary trees as arrays of size at least 2^{depth - 1} Tree with 3 full levels has 2^3 -1 nodes Array representation allows use of formulas to access specific nodes: - Binary Search Trees: special case of a binary tree where the left child values are less than the parent and the right child values are greater than the parent traversal - in-order: left, cur, right - -, 5, , 3, +, 4 - pre-order: cur, left, right - , -, 5, +, 3, 4 - post-order: left, right, cur - 5,-,3,4,+, - easier for computers to compute in - level-order: across each level from left to right - , -, +, 5, 3, 4 - discards lots of info encoded in the tree so not as useful as the others","title":"Binary Tree"},{"location":"data_structures/binary-tree/#binary-tree","text":"explain like im five picture or visualization","title":"Binary Tree"},{"location":"data_structures/binary-tree/#purpose","text":"why does it exist? why would you ever choose this over other data structures? what is the data structure optimized for? insertions/deletion? resizing? etc?","title":"Purpose"},{"location":"data_structures/binary-tree/#advantages","text":"","title":"Advantages"},{"location":"data_structures/binary-tree/#disadvantages","text":"","title":"Disadvantages"},{"location":"data_structures/binary-tree/#implementations","text":"Array : - Can be efficiently stored as an array due to each node having a max of two children - left child: (index * 2) + 1 - right child: (index * 2) + 2 - parent: (index - 1) / 2 (not used on the root!) Nodes : - Can be stored as nodes with left and right child pointers","title":"Implementations"},{"location":"data_structures/binary-tree/#big-o-analysis","text":"Array Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion | Node Implementation | Operation | Big O | Explanation | |-----------|-------|-------------| | insertion | O(log N) | traverse logN levels to perform insertion |","title":"Big O Analysis"},{"location":"data_structures/binary-tree/#code","text":"","title":"Code"},{"location":"data_structures/binary-tree/#binary-trees","text":"Each parent has maximum of two children (left and right child) Predetermined max number of children lets us store binary trees as arrays of size at least 2^{depth - 1} Tree with 3 full levels has 2^3 -1 nodes Array representation allows use of formulas to access specific nodes:","title":"Binary Trees"},{"location":"data_structures/binary-tree/#-binary-search-trees-special-case-of-a-binary-tree-where-the-left-child-values-are-less-than-the-parent-and-the-right-child-values-are-greater-than-the-parent","text":"","title":"- Binary Search Trees: special case of a binary tree where the left child values are less than the parent and the right child values are greater than the parent"},{"location":"data_structures/binary-tree/#traversal","text":"- in-order: left, cur, right - -, 5, , 3, +, 4 - pre-order: cur, left, right - , -, 5, +, 3, 4 - post-order: left, right, cur - 5,-,3,4,+, - easier for computers to compute in - level-order: across each level from left to right - , -, +, 5, 3, 4 - discards lots of info encoded in the tree so not as useful as the others","title":"traversal"},{"location":"data_structures/graph/","text":"Graph Theory The mathematical theory of the properties and applications of graphs/networks Types of Graphs Undirected Graph - edges have no orientation (i.e. edge (u,v) == edge (v,u) ) Directed Graph - edges have orientations (i.e. edge (u,v) is the edge from node u to node v) Weighted Graphs - edges contain a certain weight that represent an arbitrary value such as cost, distance, quantity, etc. (Can be directed or undirected). Ex: (u, v, w) is the edge from node u to node v with a weight of w Special Graphs Tree an undirected graph with no cycles (equivalent definition- a connected graph with N nodes and N - 1 edges) Rooted Tree is a tree with a designated root node where every edge either points away from or towards the root node Arborescence (out-tree) - edges point away from the root Anti-arborescence (in-tree) - edges point towards the root Directed Acyclic Graphs (DAGs) - directed graphs with no cycles. Imporant in representing strctures with dependencies and prerequisites. (All out-trees are DAGs but not all DAGs are out-trees) Bipartite Graph - the vertices can be split into two independent groups U, V such that every edge connects between U and V. Other definitions are- the graph is two colourable or there is no odd length cycle Complete Graph - there is a unique edge between every pair of nodes (complete graph with n vertices is denoted as Kn)","title":"Graph"},{"location":"data_structures/graph/#graph-theory","text":"The mathematical theory of the properties and applications of graphs/networks","title":"Graph Theory"},{"location":"data_structures/graph/#types-of-graphs","text":"Undirected Graph - edges have no orientation (i.e. edge (u,v) == edge (v,u) ) Directed Graph - edges have orientations (i.e. edge (u,v) is the edge from node u to node v) Weighted Graphs - edges contain a certain weight that represent an arbitrary value such as cost, distance, quantity, etc. (Can be directed or undirected). Ex: (u, v, w) is the edge from node u to node v with a weight of w","title":"Types of Graphs"},{"location":"data_structures/graph/#special-graphs","text":"Tree an undirected graph with no cycles (equivalent definition- a connected graph with N nodes and N - 1 edges) Rooted Tree is a tree with a designated root node where every edge either points away from or towards the root node Arborescence (out-tree) - edges point away from the root Anti-arborescence (in-tree) - edges point towards the root Directed Acyclic Graphs (DAGs) - directed graphs with no cycles. Imporant in representing strctures with dependencies and prerequisites. (All out-trees are DAGs but not all DAGs are out-trees) Bipartite Graph - the vertices can be split into two independent groups U, V such that every edge connects between U and V. Other definitions are- the graph is two colourable or there is no odd length cycle Complete Graph - there is a unique edge between every pair of nodes (complete graph with n vertices is denoted as Kn)","title":"Special Graphs"},{"location":"data_structures/hash-table/","text":"Hashmaps: Built on top of an array using a special indexing system. A key-value storage with fast assignments and lookup. A table that represents a map from a set of keys to a set of values. Uses a hash function which turns a key into an index into the underlying array. A hash collision is when a hash function returns the same index for two different keys. Hash collision strategies: Separate Chaining - each array index points to a different data structure (e.g. array of linked lists) Open addressing -a collision triggers a probing sequence to find where to store the value for a given key. Hash table: A key-value store that uses an array and a hashing function to save and retrieve values. Key: The identifier given to a value for later retrieval. Hash function: A function that takes some input and returns a number Compression function: A function that transforms its inputs into some smaller range of possible outputs (e.g. Hash Function) Key property is that it is not reversible Recipe for saving to a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index is empty, if so, save the value (and the key) there. - If the array is full at that index continue to the next possible position depending on your collision strategy. Recipe for retrieving from a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index has contents, if so, check the key saved there. - If the key matches the one you're looking for, return the value. - If the keys don't match, continue to the next position depending on your collision strategy.","title":"Hash table"},{"location":"data_structures/hash-table/#hashmaps","text":"Built on top of an array using a special indexing system. A key-value storage with fast assignments and lookup. A table that represents a map from a set of keys to a set of values. Uses a hash function which turns a key into an index into the underlying array. A hash collision is when a hash function returns the same index for two different keys. Hash collision strategies: Separate Chaining - each array index points to a different data structure (e.g. array of linked lists) Open addressing -a collision triggers a probing sequence to find where to store the value for a given key. Hash table: A key-value store that uses an array and a hashing function to save and retrieve values. Key: The identifier given to a value for later retrieval. Hash function: A function that takes some input and returns a number Compression function: A function that transforms its inputs into some smaller range of possible outputs (e.g. Hash Function) Key property is that it is not reversible Recipe for saving to a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index is empty, if so, save the value (and the key) there. - If the array is full at that index continue to the next possible position depending on your collision strategy. Recipe for retrieving from a hash table: - Take the key and plug it into the hash function, getting the hash code. - Modulo that hash code by the length of the underlying array, getting an array index. - Check if the array at that index has contents, if so, check the key saved there. - If the key matches the one you're looking for, return the value. - If the keys don't match, continue to the next position depending on your collision strategy.","title":"Hashmaps:"},{"location":"data_structures/heap/","text":"Heap Used to keep track of max or min values in a dataset Max-Heap: Value of root node is the greatest of all the values in the tree Must be true for all sub-trees Min-Heap Value of the root node is the smallest of all the values in the tree Must be true for all sub-trees Implementation Binary tree representation is stored as an array Random access to nodes is very efficient compared to pointer traversals through a tree Elements are added left to right until an entire level is filled up Leaves no gaps in the array Purpose Useful for: Heap Sort- sort an array in O(nlogn) time Priority Queues- insert() , delete() , extractMax() and decreaseKey() operations in O(logn) time Finding the k th largest element in an array","title":"Heap"},{"location":"data_structures/heap/#heap","text":"Used to keep track of max or min values in a dataset Max-Heap: Value of root node is the greatest of all the values in the tree Must be true for all sub-trees Min-Heap Value of the root node is the smallest of all the values in the tree Must be true for all sub-trees","title":"Heap"},{"location":"data_structures/heap/#implementation","text":"Binary tree representation is stored as an array Random access to nodes is very efficient compared to pointer traversals through a tree Elements are added left to right until an entire level is filled up Leaves no gaps in the array","title":"Implementation"},{"location":"data_structures/heap/#purpose","text":"Useful for: Heap Sort- sort an array in O(nlogn) time Priority Queues- insert() , delete() , extractMax() and decreaseKey() operations in O(logn) time Finding the k th largest element in an array","title":"Purpose"},{"location":"data_structures/linked-list/","text":"Linked List A linked list is basically a data structure that consists of chunks of data that are connected to each other by references to where the next (and possibly previous) chunk is stored in the computer's memory. Purpose It is optimized for fast insertions/deletions as well as combining and making segments of lists since all of these things are quickly done with simple pointer assignments. Since linked lists point to different places in memory and require minimal copying of the actual data being stored, linked lists are ideal for storing large pieces of data in a program. For instance, a linked list would be ideal for storing a list of files/images/videos since it does not require actually copying them around when doing operations, it simply just changes the pointers to where they are located in memory. Linked lists are also useful for implementing other data structures such as stacks, queues, adjacency lists, and sparse matrices. Advantages Constant time insertions/deletions to/from front and back of list No sihifting elements up or down when insertions/deletions occur Constant time splicing of multiple lists since its just pointer assignments Dynamic use of memory Dynamically resizes without any additional copying costs No memory pre-allocated that might go unused Efficient way to implement stacks and queues Circular linked lists do not have to deal with null pointers Disadvantages Not stored in contiguous chunk of memory so no random access Direct access to elements via indices is not possible without traversal Take up more memory to store than an array due to the pointers Traversal is more time consuming compared to an array Singly linked list only allow forward traversal Doubly linked lists allow bidirectoional traversal at the cost of an extra back pointer for each node (costly in terms of memory for large lists of millions of nodes) Big O Analysis Singly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(n) traverse to 2nd to last node and change pointers delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Doubly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(1) just change the end nodes' pointers (makes use of prev pointer) delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Code Singly Linked List: class Node: def __init__(self, data = None): self.data = data self.next = None class SinglyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: self.tail.next = Node(data) self.tail = self.tail.next self.length += 1 def prepend(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: temp = Node(data) temp.next = self.head self.head = temp self.length += 1 def delete_front(self): self.head = self.head.next self.length -= 1 Doubly Linked List class Node: def __init__(self, data = None): self.data = data self.next = None self.prev = None class DblyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self, data): old_tail = self.tail old_tail.next = Node(data) self.tail = old_tail.next self.tail.prev = old_tail self.length += 1 def prepend(self, data): new_node = Node(data) self.head.prev = new_node new_node.next = self.head self.head = new_node self.length += 1 def delete_front(self): self.head = self.head.next self.head.prev = None self.length -= 1 def delete_back(self): new_end = self.tail.prev new_end.next = None self.tail = new_end self.length -= 1 Circular Linked List Implemented as a doubly linked list but could also be implemented as singly linked list that only uses a tail pointer where tail.next is the head. class Node: def __init__(self,data=None, next_ = self, prev_ = self): self.data = data self.next = next_ self.prev = prev_ class CircularLinkedList: def __init__(self): self.dummy = Node() self.length = 0 def append(self,data): temp = self.dummy.prev self.dummy.prev = Node(data,self.dummy,temp) temp.next = self.dummy.prev self.length += 1 def prepend(self,data): temp = self.dummy.next self.dummy.next = Node(data,temp,self.dummy) temp.prev = self.dummy.next self.length += 1 def delete_front(self): del_head = self.dummy.next self.dummy.next = del_head.next self.dummy.next.prev = self.dummy self.length -= 1 def delete_back(self): del_tail = self.dummy.prev self.dummy.prev = del_tail.prev self.dummy.prev.next = self.dummy self.length -= 1","title":"Linked List"},{"location":"data_structures/linked-list/#linked-list","text":"A linked list is basically a data structure that consists of chunks of data that are connected to each other by references to where the next (and possibly previous) chunk is stored in the computer's memory.","title":"Linked List"},{"location":"data_structures/linked-list/#purpose","text":"It is optimized for fast insertions/deletions as well as combining and making segments of lists since all of these things are quickly done with simple pointer assignments. Since linked lists point to different places in memory and require minimal copying of the actual data being stored, linked lists are ideal for storing large pieces of data in a program. For instance, a linked list would be ideal for storing a list of files/images/videos since it does not require actually copying them around when doing operations, it simply just changes the pointers to where they are located in memory. Linked lists are also useful for implementing other data structures such as stacks, queues, adjacency lists, and sparse matrices.","title":"Purpose"},{"location":"data_structures/linked-list/#advantages","text":"Constant time insertions/deletions to/from front and back of list No sihifting elements up or down when insertions/deletions occur Constant time splicing of multiple lists since its just pointer assignments Dynamic use of memory Dynamically resizes without any additional copying costs No memory pre-allocated that might go unused Efficient way to implement stacks and queues Circular linked lists do not have to deal with null pointers","title":"Advantages"},{"location":"data_structures/linked-list/#disadvantages","text":"Not stored in contiguous chunk of memory so no random access Direct access to elements via indices is not possible without traversal Take up more memory to store than an array due to the pointers Traversal is more time consuming compared to an array Singly linked list only allow forward traversal Doubly linked lists allow bidirectoional traversal at the cost of an extra back pointer for each node (costly in terms of memory for large lists of millions of nodes)","title":"Disadvantages"},{"location":"data_structures/linked-list/#big-o-analysis","text":"Singly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(n) traverse to 2nd to last node and change pointers delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers Doubly Linked List: with head and tail references Operation Big O Explanation append O(1) just change the tail node pointers prepend O(1) just change the head node pointers insert (index) O(n) traverse to index and then do pointer assignments delete front O(1) just change head pointer delete back O(1) just change the end nodes' pointers (makes use of prev pointer) delete (index) O(n) traverse to index and then change pointers traversal (index) O(n) follow chain of pointers","title":"Big O Analysis"},{"location":"data_structures/linked-list/#code","text":"Singly Linked List: class Node: def __init__(self, data = None): self.data = data self.next = None class SinglyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: self.tail.next = Node(data) self.tail = self.tail.next self.length += 1 def prepend(self,data): if (self.head == None): self.head = Node(data) self.tail = self.head else: temp = Node(data) temp.next = self.head self.head = temp self.length += 1 def delete_front(self): self.head = self.head.next self.length -= 1 Doubly Linked List class Node: def __init__(self, data = None): self.data = data self.next = None self.prev = None class DblyLinkedList: def __init__(self): self.head = None self.tail = None self.length = 0 def append(self, data): old_tail = self.tail old_tail.next = Node(data) self.tail = old_tail.next self.tail.prev = old_tail self.length += 1 def prepend(self, data): new_node = Node(data) self.head.prev = new_node new_node.next = self.head self.head = new_node self.length += 1 def delete_front(self): self.head = self.head.next self.head.prev = None self.length -= 1 def delete_back(self): new_end = self.tail.prev new_end.next = None self.tail = new_end self.length -= 1 Circular Linked List Implemented as a doubly linked list but could also be implemented as singly linked list that only uses a tail pointer where tail.next is the head. class Node: def __init__(self,data=None, next_ = self, prev_ = self): self.data = data self.next = next_ self.prev = prev_ class CircularLinkedList: def __init__(self): self.dummy = Node() self.length = 0 def append(self,data): temp = self.dummy.prev self.dummy.prev = Node(data,self.dummy,temp) temp.next = self.dummy.prev self.length += 1 def prepend(self,data): temp = self.dummy.next self.dummy.next = Node(data,temp,self.dummy) temp.prev = self.dummy.next self.length += 1 def delete_front(self): del_head = self.dummy.next self.dummy.next = del_head.next self.dummy.next.prev = self.dummy self.length -= 1 def delete_back(self): del_tail = self.dummy.prev self.dummy.prev = del_tail.prev self.dummy.prev.next = self.dummy self.length -= 1","title":"Code"},{"location":"data_structures/overview/","text":"Overview of Data Structures Its important to note that many of these data structures are implemented using other data structures. For instance, a stack may be implemented with a linked list. Oftentimes more complex data structures are built off of arrays, using more specialized behaviors and rules to increase performance in some aspect (e.g. binary trees can be implented with arrays and using math to calculate node indices). Linear/Sequential Array Linked List Singly/Doubly Linked Circular Stack (LIFO) Queue (FIFO) Tree Binary Tree Binary Heap Binary Search Tree Self Balancing: AVL, Red-Black B Trees 2-3 Trees Trie Associative Hash-table/Map Set","title":"Overview"},{"location":"data_structures/overview/#overview-of-data-structures","text":"Its important to note that many of these data structures are implemented using other data structures. For instance, a stack may be implemented with a linked list. Oftentimes more complex data structures are built off of arrays, using more specialized behaviors and rules to increase performance in some aspect (e.g. binary trees can be implented with arrays and using math to calculate node indices).","title":"Overview of Data Structures"},{"location":"data_structures/overview/#linearsequential","text":"Array Linked List Singly/Doubly Linked Circular Stack (LIFO) Queue (FIFO)","title":"Linear/Sequential"},{"location":"data_structures/overview/#tree","text":"Binary Tree Binary Heap Binary Search Tree Self Balancing: AVL, Red-Black B Trees 2-3 Trees Trie","title":"Tree"},{"location":"data_structures/overview/#associative","text":"Hash-table/Map Set","title":"Associative"},{"location":"data_structures/queue/","text":"Queue Stores data in a first in, first out (FIFO) manner. Basically can be thought of like a line at a store or anywhere. Purpose Queues are great for use where the order of events occur is important Useful for - Breadth first search - Message or print queues - Simulations with ordered events Big O Analysis The follow operations are due to the linked list implementation Operation Big O push (front/back) O(1) pop (front/back) O(1) peek (front/back) O(1) Code from linked-list import DblyLinkedList class Queue: def __init__(self): self.list = DblyLinkedList() def push_front(self,data): self.list.prepend(data) def push_back(self,data): self.list.append(data) def pop_front(self): self.list.delete_front() def pop_back(self): self.list.delete_back() def peek_front(self): return self.list.head def peek_back(self): return self.list.tail","title":"Queue"},{"location":"data_structures/queue/#queue","text":"Stores data in a first in, first out (FIFO) manner. Basically can be thought of like a line at a store or anywhere.","title":"Queue"},{"location":"data_structures/queue/#purpose","text":"Queues are great for use where the order of events occur is important Useful for - Breadth first search - Message or print queues - Simulations with ordered events","title":"Purpose"},{"location":"data_structures/queue/#big-o-analysis","text":"The follow operations are due to the linked list implementation Operation Big O push (front/back) O(1) pop (front/back) O(1) peek (front/back) O(1)","title":"Big O Analysis"},{"location":"data_structures/queue/#code","text":"from linked-list import DblyLinkedList class Queue: def __init__(self): self.list = DblyLinkedList() def push_front(self,data): self.list.prepend(data) def push_back(self,data): self.list.append(data) def pop_front(self): self.list.delete_front() def pop_back(self): self.list.delete_back() def peek_front(self): return self.list.head def peek_back(self): return self.list.tail","title":"Code"},{"location":"data_structures/stack/","text":"Stack Stores data in in a last in, first out (LIFO) manner or first in, last out (FILO) Can be implemented using either an array for when the max size of elements in the stack is known (e.g. deck of cards) or can be implemented using a linked list. Purpose Stacks are optimized for adding and removing things from often, where the order of addition and removal plays an important role in solving a certain problem (e.g. matching parentheses) Useful for: - Depth First Search - Backtracking algorithms (e.g. N queens) - Checking proper brackets/parentheses - Expression Conversions - String reversals - Solving towers of hanoi - Memory management Disadvantages Fixed size when implemented as static array Slow to grow when implemented as dynamic array New/delete operations are slower than array operations for linked list implementation Big O Analysis The follow operations are due to the linked list implementation Operation Big O push O(1) pop O(1) peek O(1) Code from linked-list import DblyLinkedList class Stack: def __init__(self): self.top = DblyLinkedList() self.size = 0 def push(self,data): self.top.prepend(data) def peek(self, data): return self.top.head def pop(self,data): self.top.delete_front()","title":"Stack"},{"location":"data_structures/stack/#stack","text":"Stores data in in a last in, first out (LIFO) manner or first in, last out (FILO) Can be implemented using either an array for when the max size of elements in the stack is known (e.g. deck of cards) or can be implemented using a linked list.","title":"Stack"},{"location":"data_structures/stack/#purpose","text":"Stacks are optimized for adding and removing things from often, where the order of addition and removal plays an important role in solving a certain problem (e.g. matching parentheses) Useful for: - Depth First Search - Backtracking algorithms (e.g. N queens) - Checking proper brackets/parentheses - Expression Conversions - String reversals - Solving towers of hanoi - Memory management","title":"Purpose"},{"location":"data_structures/stack/#disadvantages","text":"Fixed size when implemented as static array Slow to grow when implemented as dynamic array New/delete operations are slower than array operations for linked list implementation","title":"Disadvantages"},{"location":"data_structures/stack/#big-o-analysis","text":"The follow operations are due to the linked list implementation Operation Big O push O(1) pop O(1) peek O(1)","title":"Big O Analysis"},{"location":"data_structures/stack/#code","text":"from linked-list import DblyLinkedList class Stack: def __init__(self): self.top = DblyLinkedList() self.size = 0 def push(self,data): self.top.prepend(data) def peek(self, data): return self.top.head def pop(self,data): self.top.delete_front()","title":"Code"},{"location":"data_structures/template/","text":"Data Structure explain like im five picture or visualization Purpose why does it exist? why would you ever choose this over other data structures? common what is the data structure optimized for? insertions/deletion? resizing? etc? Advantages Disadvantages Big O Analysis Operation Big O Explanation insertion O(1) just change the pointers of each node to insert Code Next Steps: Anki flashcards from the notes Apply to problems that are designed for that data structure Apply to random problems that may or may not use the data structure (so you can begin to find patterns of when to apply the data structure)","title":"Data Structure"},{"location":"data_structures/template/#data-structure","text":"explain like im five picture or visualization","title":"Data Structure"},{"location":"data_structures/template/#purpose","text":"why does it exist? why would you ever choose this over other data structures? common what is the data structure optimized for? insertions/deletion? resizing? etc?","title":"Purpose"},{"location":"data_structures/template/#advantages","text":"","title":"Advantages"},{"location":"data_structures/template/#disadvantages","text":"","title":"Disadvantages"},{"location":"data_structures/template/#big-o-analysis","text":"Operation Big O Explanation insertion O(1) just change the pointers of each node to insert","title":"Big O Analysis"},{"location":"data_structures/template/#code","text":"","title":"Code"},{"location":"data_structures/template/#next-steps","text":"Anki flashcards from the notes Apply to problems that are designed for that data structure Apply to random problems that may or may not use the data structure (so you can begin to find patterns of when to apply the data structure)","title":"Next Steps:"},{"location":"databases/dbms/","text":"Database Mangament Systems (DBMS) Special software program to help create and maintain a database Easy to handle lots of info Handles security, Backups, import/exporting data, & concurrency interacts w/ software apps and programming languages Ex: Amazon.com will interact w/ the DBMS in order to create, read, update, & delete product info Relational Database (SQL) organize data into 1 or more tables Each table has columns and rows A unique key identifies each row Relation Database Management Systems (RDBMS) mySQL,Oracle,postgreSQL,mariaDB,etc Non-Relational Database (noSQL) Not organized in traditional table Key-value stores, Documents, Graphs, Flexible Tablees, etc Non-Relational Database Management Systems (NRDBMS) mongoDB,dynamoDB,apache cassandra, firebase, etc no standard language b/c each implementation is language specific","title":"DBMS"},{"location":"databases/dbms/#database-mangament-systems-dbms","text":"Special software program to help create and maintain a database Easy to handle lots of info Handles security, Backups, import/exporting data, & concurrency interacts w/ software apps and programming languages Ex: Amazon.com will interact w/ the DBMS in order to create, read, update, & delete product info","title":"Database Mangament Systems (DBMS)"},{"location":"databases/dbms/#relational-database-sql","text":"organize data into 1 or more tables Each table has columns and rows A unique key identifies each row Relation Database Management Systems (RDBMS) mySQL,Oracle,postgreSQL,mariaDB,etc","title":"Relational Database (SQL)"},{"location":"databases/dbms/#non-relational-database-nosql","text":"Not organized in traditional table Key-value stores, Documents, Graphs, Flexible Tablees, etc Non-Relational Database Management Systems (NRDBMS) mongoDB,dynamoDB,apache cassandra, firebase, etc no standard language b/c each implementation is language specific","title":"Non-Relational Database (noSQL)"},{"location":"databases/mysql/","text":"MySQL Python Access Connect to the MySQL Database, you get a MySQLConnection object. a. To connect to the database, read the database configuration parameters from config.ini using configparser and pass the resulting dictionary to the constructor of the MySQLConnection Object Instantiate a MySQLCursor object from the the MySQLConnection object. Use the cursor to execute a query by calling its execute() method. Use fetchone() , fetchmany() or fetchall() method to fetch data from the result set. Close the cursor as well as the database connection by calling the close() method of the corresponding object from mysql.connector import MySQLConnection, Error dbconfig = { 'host' = 'localhost', 'database' = 'Books', 'user' = 'root', 'password' = 'password' } conn = None try: conn = MySQLConnection(**dbconfig) cursor = conn.cursor() cursor.execute('SELECT * FROM books LIMIT 5') for row in iter_row(cursor): print(row) except Error as e: print(e) finally: cursor.close() conn.close() Generator that chunks the database calls into a series of fetchmany() calls def iter_row(cursor,size=10): while True: rows = cursor.fetchmany(size) if not rows: break for row in rows: yield row","title":"MySQL"},{"location":"databases/mysql/#mysql","text":"","title":"MySQL"},{"location":"databases/mysql/#python-access","text":"Connect to the MySQL Database, you get a MySQLConnection object. a. To connect to the database, read the database configuration parameters from config.ini using configparser and pass the resulting dictionary to the constructor of the MySQLConnection Object Instantiate a MySQLCursor object from the the MySQLConnection object. Use the cursor to execute a query by calling its execute() method. Use fetchone() , fetchmany() or fetchall() method to fetch data from the result set. Close the cursor as well as the database connection by calling the close() method of the corresponding object from mysql.connector import MySQLConnection, Error dbconfig = { 'host' = 'localhost', 'database' = 'Books', 'user' = 'root', 'password' = 'password' } conn = None try: conn = MySQLConnection(**dbconfig) cursor = conn.cursor() cursor.execute('SELECT * FROM books LIMIT 5') for row in iter_row(cursor): print(row) except Error as e: print(e) finally: cursor.close() conn.close() Generator that chunks the database calls into a series of fetchmany() calls def iter_row(cursor,size=10): while True: rows = cursor.fetchmany(size) if not rows: break for row in rows: yield row","title":"Python Access"},{"location":"databases/sql/","text":"Structured Query Language (SQL) Standardized language for interacting w/ RDBMS used to perform CRUD operations and other admin tasks(e.g user managment, security, backup, etc) SQL code on one RDBMS might not be portable to a different RDBMS b/c SQL implementations vary btw systems 4 Types of Languages in SQL: Data Query Language (DQL) - queries the DB for stored info Data Definition Language (DDL) - defines database schemas Data Control Language (DCL) - controls access to data in DB & manages users and permissions Data Manipulation Laguage (DML) - inserts, updates, and deletes data from DB Keys Primary Key - attribute that is unique for each row in the table Surrogate Key - type of primary key that has no mapping to anything in the real world Natural Key - type of primary key that has a mapping to the real world (e.g. SSN) Foreign Key - stores the primary key of a row in another database table (Link to another table) Can define relationships between tables or within a table Composite Key - type of primary key that is made up of two attributes Used when either of the attributes on their own do not uniquely identify a row Datatypes INT DECIMAL(M,N) -- m: total # digits, n: # digits after decimal place VARCHAR(L) -- String of text of max length L BLOB -- Binary large objects, stores large data like images DATE -- 'YYYY-MM-DD' TIMESTAMP -- 'YYYY-MM-DD HH:MM:SS' Functions --Find Num of Students SELECT COUNT(student_id) FROM students; --Find Num of female student born after 1980 SELECT COUNT(student_id) FROM students WHERE sex = 'F' AND birth_date > '1981-01-01'; --Find avg male salary SELECT AVG(salary) FROM employees WHERE sex = 'M'; --Find sum of all salaries SELECT SUM(salary) FROM employees; --Find num of males & females SELECT COUNT(sex), sex FROM employe GROUP BY sex; --Group By command used for aggregation Queries SELECT student.name AS forename, student.major FROM student ORDER BY name DESC --Descending alphabetical order LIMIT 20; --limits # of entries returned -- Comparison Operators: <, >, <=, >=, =, AND, OR, <> (not equal to) Tables CREATE TABLE student ( student_id INT AUTO_INCREMENT, -- you don't have to insert a primary key b/c its auto incremented name VARCHAR(20) UNIQUE, major VARCHAR(20) DEFAULT 'undecided', PRIMARY KEY(student_id) ); -- Delete a Table DROP TABLE student; --Show the table schema DESCRIBE student; -- Add & Drop Attributes ALTER TABLE student ADD gpa DECIMAL(3,2); ALTER TABLE student DROP COLUMN gpa; Insert, Update, Delete INSERT INTO student VALUES(1,'Jack','Biology'); INSERT INTO student(name) VALUES('Kate'); UPDATE student SET major = 'Computer Science and Engineering' WHERE major = 'Computer Science' OR major = 'Computer Engineering'; DELETE FROM student WHERE student_id > 100;","title":"SQL"},{"location":"databases/sql/#structured-query-language-sql","text":"Standardized language for interacting w/ RDBMS used to perform CRUD operations and other admin tasks(e.g user managment, security, backup, etc) SQL code on one RDBMS might not be portable to a different RDBMS b/c SQL implementations vary btw systems","title":"Structured Query Language (SQL)"},{"location":"databases/sql/#4-types-of-languages-in-sql","text":"Data Query Language (DQL) - queries the DB for stored info Data Definition Language (DDL) - defines database schemas Data Control Language (DCL) - controls access to data in DB & manages users and permissions Data Manipulation Laguage (DML) - inserts, updates, and deletes data from DB","title":"4 Types of Languages in SQL:"},{"location":"databases/sql/#keys","text":"Primary Key - attribute that is unique for each row in the table Surrogate Key - type of primary key that has no mapping to anything in the real world Natural Key - type of primary key that has a mapping to the real world (e.g. SSN) Foreign Key - stores the primary key of a row in another database table (Link to another table) Can define relationships between tables or within a table Composite Key - type of primary key that is made up of two attributes Used when either of the attributes on their own do not uniquely identify a row","title":"Keys"},{"location":"databases/sql/#datatypes","text":"INT DECIMAL(M,N) -- m: total # digits, n: # digits after decimal place VARCHAR(L) -- String of text of max length L BLOB -- Binary large objects, stores large data like images DATE -- 'YYYY-MM-DD' TIMESTAMP -- 'YYYY-MM-DD HH:MM:SS'","title":"Datatypes"},{"location":"databases/sql/#functions","text":"--Find Num of Students SELECT COUNT(student_id) FROM students; --Find Num of female student born after 1980 SELECT COUNT(student_id) FROM students WHERE sex = 'F' AND birth_date > '1981-01-01'; --Find avg male salary SELECT AVG(salary) FROM employees WHERE sex = 'M'; --Find sum of all salaries SELECT SUM(salary) FROM employees; --Find num of males & females SELECT COUNT(sex), sex FROM employe GROUP BY sex; --Group By command used for aggregation","title":"Functions"},{"location":"databases/sql/#queries","text":"SELECT student.name AS forename, student.major FROM student ORDER BY name DESC --Descending alphabetical order LIMIT 20; --limits # of entries returned -- Comparison Operators: <, >, <=, >=, =, AND, OR, <> (not equal to)","title":"Queries"},{"location":"databases/sql/#tables","text":"CREATE TABLE student ( student_id INT AUTO_INCREMENT, -- you don't have to insert a primary key b/c its auto incremented name VARCHAR(20) UNIQUE, major VARCHAR(20) DEFAULT 'undecided', PRIMARY KEY(student_id) ); -- Delete a Table DROP TABLE student; --Show the table schema DESCRIBE student; -- Add & Drop Attributes ALTER TABLE student ADD gpa DECIMAL(3,2); ALTER TABLE student DROP COLUMN gpa;","title":"Tables"},{"location":"databases/sql/#insert-update-delete","text":"INSERT INTO student VALUES(1,'Jack','Biology'); INSERT INTO student(name) VALUES('Kate'); UPDATE student SET major = 'Computer Science and Engineering' WHERE major = 'Computer Science' OR major = 'Computer Engineering'; DELETE FROM student WHERE student_id > 100;","title":"Insert, Update, Delete"},{"location":"dig_sys/ch6-assembly/","text":"Architecture Assembly Language MOV R1, R7 copies the contents of register 7 into register 1 Memory ARM uses byte-addressable memory meaning each byte in memory has a unique address 32-bit word has 4 bytes, so each word address is a multiple of 4 Big Endian- bytes are numbered starting with 0 at the most significant end Little Endian- bytes are numbered starting with 0 at the least significant end LDR destination register, [base register, offset] loads the data from the base register + offset into the destination register STR destination, [base register, offset] writes a data word from the base register + offset address to the destination register Machine Language ARM uses 32-bit instructions that can be either data-processing, memory, or branch. Data-Processing Has 2 source operands 1st source operand which is a register 2nd source operand which is register or (optionally shifted)register cond - conditional execution op - operate code funct - rn - first source register rd - destination register src2 - second source (3 variations) 1) Immediate 2) Register (rm) optionally shifted by a constant (shamt5) 3) Register (rm) shifted by another register (rs) For 2) and 3), sh encodes the type of shift to perform Branch The immediate\u2019s value is relative to 2 instructions in front of the branch instruction (PC + 8) Encoded in two\u2019s complement so there can be negative values for branches in loops","title":"Assembly"},{"location":"dig_sys/ch6-assembly/#architecture","text":"","title":"Architecture"},{"location":"dig_sys/ch6-assembly/#assembly-language","text":"MOV R1, R7 copies the contents of register 7 into register 1","title":"Assembly Language"},{"location":"dig_sys/ch6-assembly/#memory","text":"ARM uses byte-addressable memory meaning each byte in memory has a unique address 32-bit word has 4 bytes, so each word address is a multiple of 4 Big Endian- bytes are numbered starting with 0 at the most significant end Little Endian- bytes are numbered starting with 0 at the least significant end LDR destination register, [base register, offset] loads the data from the base register + offset into the destination register STR destination, [base register, offset] writes a data word from the base register + offset address to the destination register","title":"Memory"},{"location":"dig_sys/ch6-assembly/#machine-language","text":"ARM uses 32-bit instructions that can be either data-processing, memory, or branch.","title":"Machine Language"},{"location":"dig_sys/ch6-assembly/#data-processing","text":"Has 2 source operands 1st source operand which is a register 2nd source operand which is register or (optionally shifted)register cond - conditional execution op - operate code funct - rn - first source register rd - destination register src2 - second source (3 variations) 1) Immediate 2) Register (rm) optionally shifted by a constant (shamt5) 3) Register (rm) shifted by another register (rs) For 2) and 3), sh encodes the type of shift to perform","title":"Data-Processing"},{"location":"dig_sys/ch6-assembly/#branch","text":"The immediate\u2019s value is relative to 2 instructions in front of the branch instruction (PC + 8) Encoded in two\u2019s complement so there can be negative values for branches in loops","title":"Branch"},{"location":"dig_sys/ch7-processor/","text":"Microarchitecture Microarchitecture - the connection between logic and architecture specific arrangement of registers, ALUs, FSMs, memories, etc. A particular architecture like ARM can have many different microarchitectures, each with their own trade-offs on performance, cost, and complexity Architectural State and Instruction Set A computer architecture is defined by its instruction set and architectural state (e.g. 16, 32-bit registers and status register for ARM processor) Based on current architectural state ,the processor executes an instruction with a set of data to produce a new state We will consider only the following instructions for simplicity: Data Processing: ADD , SUB , AND , ORR (no shifts) Memory: LDR and STR Branching: B Design Process Split microarchitectuers into two interacting parts: 1) Datapath- operates on words of data and contains structures like memories, registers, ALUs, and muxes 32-bit arch --> 32-bit datapath 2) Control Unit- receives current instruction from the datapath and tells the datapath how to execute the instruction Signals Produced by control unit: mux select register enable memory write start with hardware containing state elements and add in combinational logic btw the state elements to compute new state based on current state memory is usually split into 2 for instructionsa and data State Elements Status Register: contains the 4 flags from the ALU Program Counter: PC' input is the address of the next instruction PC output is address of the current instructon Instruction Memory: A input is the address of the 32-bit instruction RD output is the 32-bit data (instruction) at the input address Register File: holds registers R0-R14 Read Ports: A1 and A2 inputs are the 4-bit addresses of one of the 16 registers (each specifies a source operand) RD1 and RD2 outputs are the 32-bit register values for the input registers Write Port: A3 input is a 4-bit register address WD3 input is 32-bit data to be written WE3 input specifies whether to write (write enable) If write is asserted, the data is written to the register specified by A3 on the rising edge of the clock R15 is for managing the relationship with the PC read from here should always be PC + 8 Data Memory: WD input is the 32-bit data to write to memory WE input is whether write is enabled (writes on rising edge of the clock) A input is the 32-bit address to read from (if WE = 0 ) or write to (if WE = 1 ) RD output is the 32-bit data read from the specified memory address only has a value if WE = 0 Instruction memory, register file, and data memory are read combinationally (i.e. no clock is involved) The clock is used in the register file and data memory for controlling writes to only occur on the rising edge (i.e. state only changes on rising edge of clock) This makes the microprocessor a synchronous sequential circuit (i.e. microprocessor is a giant FSM or collection of many smaller FSMs) Microarchitectures Single-cycled, multicycleed, and pipelined differ in how the state elements are connected together and in the amount of nonarchitectural state Single-Cycled - executes an entire instruction in one cycle cycle time limited by slowest instruction no nonarchitectural state required Multicycle - executes instructions in a series of shorter cycles Simpler instructions execute in fewer cycles than more complex one Several nonarchitectural state registers to hold intermediate results Cheaper b/c it reuses expensive harware like adders and memories Executes on instruction at a time, but it takes multiple clock cycles Pipelined - executes several instructions simulataneously Requires extra logic for handling dependencies between simultaneously executing instructions Requires nonarchitecutral state registers Use seperate instruction and data caches since they must access instructions and data in the same cycle Used by all commercial high-performance processors Performance Analysis Clock frequency and number of cores are unreliable methods of analyzing a processor since certain processors can do more work in a cycle than others Execution time on benchmark programs is a more reliable way of measuring performance The number of instructions in a program can vary depending on the microarchitecture and the cleverness of the programmer Cycles per instruction (CPI)- # clock cycles required to execute an average instruction Affected by memory system when its not ideal and there are misses Single-Cycle Processor Next instruction is 32 bits or 4 bytes so we need to add 4 to the current instruction PC to get the next instruction PC' The extend block extends the 12 bits from the src2 component to get a properly extended 32 bit result which is send to the ALU with the output from the register file's read output port Result of ALU is the memory address we want to read from (the data at outputby the data memory is then passed to the write port in the register file ) Example: LDR R1, [R2, #5] requires: read value from R2 (should be an address) add offset to it read whats at the resulting address write the data into R1 Controller Combinational logic responsible for calculating the control signals based on the current instruction and current state of the system Inputs: Different parts of the instruction The ALU status flags Outputs: 8 control signals that control the flow of data in the datapath Control Signals PCSrc decides where to get next instruction from 1 : ReadData (result of a write to R15 or a branch instruction) 0 : PC + 4 (next instruction) RegSrc : two bits which controls two muxes that select where the register addresss of the register file should come from MSB decides whether the 1st register address should come from instruction bits or from the value 15 to support operations with R15 LSB decides which part of the instruction bits the 2nd register address should come from RegWrite specifies whether we are writing into a register ImmSrc is two bits that control what kind of immediate extension needed unsigned 8 bit, unsigned 12 bit or signed 24 bit immediate to 32-bit immediate ALUSrc selects where the 2nd ALU argumnet should come from either a register or the result of an immediate extension ALUControl selects which operation the ALU should perform MemWrite specifies whether or not we are writing our data into memory MemToReg selects what results should be passed along either something read from memory or the ALU's result","title":"Microarchitecture"},{"location":"dig_sys/ch7-processor/#microarchitecture","text":"Microarchitecture - the connection between logic and architecture specific arrangement of registers, ALUs, FSMs, memories, etc. A particular architecture like ARM can have many different microarchitectures, each with their own trade-offs on performance, cost, and complexity","title":"Microarchitecture"},{"location":"dig_sys/ch7-processor/#architectural-state-and-instruction-set","text":"A computer architecture is defined by its instruction set and architectural state (e.g. 16, 32-bit registers and status register for ARM processor) Based on current architectural state ,the processor executes an instruction with a set of data to produce a new state We will consider only the following instructions for simplicity: Data Processing: ADD , SUB , AND , ORR (no shifts) Memory: LDR and STR Branching: B","title":"Architectural State and Instruction Set"},{"location":"dig_sys/ch7-processor/#design-process","text":"Split microarchitectuers into two interacting parts: 1) Datapath- operates on words of data and contains structures like memories, registers, ALUs, and muxes 32-bit arch --> 32-bit datapath 2) Control Unit- receives current instruction from the datapath and tells the datapath how to execute the instruction Signals Produced by control unit: mux select register enable memory write start with hardware containing state elements and add in combinational logic btw the state elements to compute new state based on current state memory is usually split into 2 for instructionsa and data","title":"Design Process"},{"location":"dig_sys/ch7-processor/#state-elements","text":"Status Register: contains the 4 flags from the ALU Program Counter: PC' input is the address of the next instruction PC output is address of the current instructon Instruction Memory: A input is the address of the 32-bit instruction RD output is the 32-bit data (instruction) at the input address Register File: holds registers R0-R14 Read Ports: A1 and A2 inputs are the 4-bit addresses of one of the 16 registers (each specifies a source operand) RD1 and RD2 outputs are the 32-bit register values for the input registers Write Port: A3 input is a 4-bit register address WD3 input is 32-bit data to be written WE3 input specifies whether to write (write enable) If write is asserted, the data is written to the register specified by A3 on the rising edge of the clock R15 is for managing the relationship with the PC read from here should always be PC + 8 Data Memory: WD input is the 32-bit data to write to memory WE input is whether write is enabled (writes on rising edge of the clock) A input is the 32-bit address to read from (if WE = 0 ) or write to (if WE = 1 ) RD output is the 32-bit data read from the specified memory address only has a value if WE = 0 Instruction memory, register file, and data memory are read combinationally (i.e. no clock is involved) The clock is used in the register file and data memory for controlling writes to only occur on the rising edge (i.e. state only changes on rising edge of clock) This makes the microprocessor a synchronous sequential circuit (i.e. microprocessor is a giant FSM or collection of many smaller FSMs)","title":"State Elements"},{"location":"dig_sys/ch7-processor/#microarchitectures","text":"Single-cycled, multicycleed, and pipelined differ in how the state elements are connected together and in the amount of nonarchitectural state Single-Cycled - executes an entire instruction in one cycle cycle time limited by slowest instruction no nonarchitectural state required Multicycle - executes instructions in a series of shorter cycles Simpler instructions execute in fewer cycles than more complex one Several nonarchitectural state registers to hold intermediate results Cheaper b/c it reuses expensive harware like adders and memories Executes on instruction at a time, but it takes multiple clock cycles Pipelined - executes several instructions simulataneously Requires extra logic for handling dependencies between simultaneously executing instructions Requires nonarchitecutral state registers Use seperate instruction and data caches since they must access instructions and data in the same cycle Used by all commercial high-performance processors","title":"Microarchitectures"},{"location":"dig_sys/ch7-processor/#performance-analysis","text":"Clock frequency and number of cores are unreliable methods of analyzing a processor since certain processors can do more work in a cycle than others Execution time on benchmark programs is a more reliable way of measuring performance The number of instructions in a program can vary depending on the microarchitecture and the cleverness of the programmer Cycles per instruction (CPI)- # clock cycles required to execute an average instruction Affected by memory system when its not ideal and there are misses","title":"Performance Analysis"},{"location":"dig_sys/ch7-processor/#single-cycle-processor","text":"Next instruction is 32 bits or 4 bytes so we need to add 4 to the current instruction PC to get the next instruction PC' The extend block extends the 12 bits from the src2 component to get a properly extended 32 bit result which is send to the ALU with the output from the register file's read output port Result of ALU is the memory address we want to read from (the data at outputby the data memory is then passed to the write port in the register file ) Example: LDR R1, [R2, #5] requires: read value from R2 (should be an address) add offset to it read whats at the resulting address write the data into R1","title":"Single-Cycle Processor"},{"location":"dig_sys/ch7-processor/#controller","text":"Combinational logic responsible for calculating the control signals based on the current instruction and current state of the system Inputs: Different parts of the instruction The ALU status flags Outputs: 8 control signals that control the flow of data in the datapath","title":"Controller"},{"location":"dig_sys/ch7-processor/#control-signals","text":"PCSrc decides where to get next instruction from 1 : ReadData (result of a write to R15 or a branch instruction) 0 : PC + 4 (next instruction) RegSrc : two bits which controls two muxes that select where the register addresss of the register file should come from MSB decides whether the 1st register address should come from instruction bits or from the value 15 to support operations with R15 LSB decides which part of the instruction bits the 2nd register address should come from RegWrite specifies whether we are writing into a register ImmSrc is two bits that control what kind of immediate extension needed unsigned 8 bit, unsigned 12 bit or signed 24 bit immediate to 32-bit immediate ALUSrc selects where the 2nd ALU argumnet should come from either a register or the result of an immediate extension ALUControl selects which operation the ALU should perform MemWrite specifies whether or not we are writing our data into memory MemToReg selects what results should be passed along either something read from memory or the ALU's result","title":"Control Signals"},{"location":"dig_sys/ch8-mem-sys/","text":"Memory Systems Computer performance depends on both the processor and the memory system Memory is slower than processors so designs try to approximate a memory as fast as a processor Simple memory interface used in previous chapters: Send memory address over the Address bus To read from memory: send MemWrite = 0 and then ReadData will contain the data at the specified address To write to memory: send MemWrite = 1 and send data to be written over the WriteData bus Tradeoffs In practice, a memory system has only 2 of the 3: Fast Large Cheap Can approximate an ideal fast, large, and cheap memory system by combining a fast small cheap memory and a slow large cheap memory. The fast memory stores most commmonly used data and instructions The large memory stores the remainder of the data and instructions Principles of Locality: Used to determine what data to store in the fast memory Temporal Locality: a referenced memory location will tend to be referenced again soon Spatial Locality: a referenced memory location will tend have its nearby addresses also referenced soon Memory Hierarchy Registers Fastest memory access Cache L1 is smaller and faster than secondary cache L2 L2 is larger Main Memory (DRAM) Order of GB Disk memory External hardrives on order of TB, PB, etc. (essentially infinite) Very slow access (e.g 1s) Want to put most useful memory as close to processor as possible to reduce access time Performance Analysis Miss Rate - how often the processor requests data from a memory system and it does not find it Hit Rate - how often the processor requests data from a memory system and it returns Average Memory Access Time (AMAT) - average time a processor must wait for memory per load or store instruction cache --> main memory --> virutal memory on hard disk AMAT = cache access time + cache miss rate(main memory access time + main memory miss rate * virtual memory access time) Amdahl's Law- effort spent increasing the performance of a subsystem is only worth it if the subsystem affects a large percentage of the overall performance Caches Goal is to anticipate all the data needed by processor and fetch it ahead of time so the cache has a 0% miss rate. Caches are located on the same chip as the processor or very close to it. Cache uses temporal and spatial locality to achieve a low miss rate. Cache block/cache line is the group of adjacent words fetched by the cache when it fetches on word from memory. block size- # words in the cache block ( b ) capacity ( C ) contains B = C / b blocks Caches are organized into S sets each of which hold 1+ block of data","title":"Memory Systems"},{"location":"dig_sys/ch8-mem-sys/#memory-systems","text":"Computer performance depends on both the processor and the memory system Memory is slower than processors so designs try to approximate a memory as fast as a processor Simple memory interface used in previous chapters: Send memory address over the Address bus To read from memory: send MemWrite = 0 and then ReadData will contain the data at the specified address To write to memory: send MemWrite = 1 and send data to be written over the WriteData bus","title":"Memory Systems"},{"location":"dig_sys/ch8-mem-sys/#tradeoffs","text":"In practice, a memory system has only 2 of the 3: Fast Large Cheap Can approximate an ideal fast, large, and cheap memory system by combining a fast small cheap memory and a slow large cheap memory. The fast memory stores most commmonly used data and instructions The large memory stores the remainder of the data and instructions Principles of Locality: Used to determine what data to store in the fast memory Temporal Locality: a referenced memory location will tend to be referenced again soon Spatial Locality: a referenced memory location will tend have its nearby addresses also referenced soon","title":"Tradeoffs"},{"location":"dig_sys/ch8-mem-sys/#memory-hierarchy","text":"Registers Fastest memory access Cache L1 is smaller and faster than secondary cache L2 L2 is larger Main Memory (DRAM) Order of GB Disk memory External hardrives on order of TB, PB, etc. (essentially infinite) Very slow access (e.g 1s) Want to put most useful memory as close to processor as possible to reduce access time","title":"Memory Hierarchy"},{"location":"dig_sys/ch8-mem-sys/#performance-analysis","text":"Miss Rate - how often the processor requests data from a memory system and it does not find it Hit Rate - how often the processor requests data from a memory system and it returns Average Memory Access Time (AMAT) - average time a processor must wait for memory per load or store instruction cache --> main memory --> virutal memory on hard disk AMAT = cache access time + cache miss rate(main memory access time + main memory miss rate * virtual memory access time) Amdahl's Law- effort spent increasing the performance of a subsystem is only worth it if the subsystem affects a large percentage of the overall performance","title":"Performance Analysis"},{"location":"dig_sys/ch8-mem-sys/#caches","text":"Goal is to anticipate all the data needed by processor and fetch it ahead of time so the cache has a 0% miss rate. Caches are located on the same chip as the processor or very close to it. Cache uses temporal and spatial locality to achieve a low miss rate. Cache block/cache line is the group of adjacent words fetched by the cache when it fetches on word from memory. block size- # words in the cache block ( b ) capacity ( C ) contains B = C / b blocks Caches are organized into S sets each of which hold 1+ block of data","title":"Caches"},{"location":"dig_sys/ch9-io-sys/","text":"I/O Systems Input/Output (I/O) systems are used to connect a computer with external devices caled peripherals. Example devices for a personal computer include keyboards, monitors, printers, and wireless networks. Example devices for an embedded system include toaster's heating element, a toy's speech synthesizer, an engine's fuel injector, and a satellite's panel motors. Memory-mapped I/O A method of communicating with input-output devices such as printers. Memory-mapped I/O involves dedicating a portion of the address space to I/O devices instead of memory. This allows a store to the specified address to send data to the device while a load from the address will receive data from the device. The blow program writes the value 7 to a an I/O device at a specified memory address. MOV R1, #7 LDR R2, =ioadr STR R1, [R2] ioadr DCD 0x20001000 To read from the the same device: LDR R1, [R2] A device driver is software that communicates with an I/O device. They are often downloaded or installed for things such as printers since writing a device driver requires detailed knowledge about the I/O device hardware including the addresses and behavior of the memory mapped I/O registers. Other programs can access the device by making calls to functions in the device driver, therefore avoiding the need to understand the low-level device hardware. Programmed I/O Certain architectures, such as x86, use specialzied instructions instead of memory-mapped I/O to communicate with I/O devices. LDRIO R1, device1 STRIO R2, device2 Serial I/O When a microcontroller needs to send more bits than free pins so it breaks the message into bits that it sends at each step. There are different standards for serial I/O: Serial Peripheral Interface (SPI) Clocks synchronized btw sender and receiver Universal Asynchronous Receiver/Transmitter (UART) Clocks unsychronizd btw sender and receiver Uses the TX (transmit) and RX (receive) line on the pies Signaling in units of baud instead of bits/sec since 8 data bits are sent using 10 symbols (a start and stop bit) 9600 baud rate = 9600 symbols /sec = 960 bytes(chars)/sec Slow compared to modern standards Universal Serial Bus (USB) Ethernet Many embedded systems use analog I/O. Therefore they use analog-to-digital converters (ADCs) to turn analog signals (voltages) to digital values (bits) and they use digital-to-analog converters (DACs) to turn bits to voltages. ADCs are built into many microcontrollers but few have built-in DACs. Motors Motors draw a very high current that can cause glitches on the power supply that disturb the digital logic Problem is mitigated by using different power supply for motor DC and stepper motors require a high drive current so a powerful driver such as an H-bridge must be connected between the microcontroller and the motor Stepper Motors accept a sequence of pulses that each rotate the motor by a fixed angle called a step More precise position control DC Motors tend to spin at thousands of RPM at very low torque so gear trains are added at cost of decreased RPM but benefit of higher torque Reversing the current makes the motor spin in the opposite direction Changing the current abruptly will result in a large potentially damagaging voltage spike from the inductance of the motor's electromagnet H-bridges handle all the these current related details Requires a seperate logic and motor power supply Supports coast, brake, reverse, and forward for DC motors Servo Motor A DC motor integrated with a gear train and shaft encoder Limited rotation (unless you get a continuous rotation servo)","title":"IO Systems"},{"location":"dig_sys/ch9-io-sys/#io-systems","text":"Input/Output (I/O) systems are used to connect a computer with external devices caled peripherals. Example devices for a personal computer include keyboards, monitors, printers, and wireless networks. Example devices for an embedded system include toaster's heating element, a toy's speech synthesizer, an engine's fuel injector, and a satellite's panel motors.","title":"I/O Systems"},{"location":"dig_sys/ch9-io-sys/#memory-mapped-io","text":"A method of communicating with input-output devices such as printers. Memory-mapped I/O involves dedicating a portion of the address space to I/O devices instead of memory. This allows a store to the specified address to send data to the device while a load from the address will receive data from the device. The blow program writes the value 7 to a an I/O device at a specified memory address. MOV R1, #7 LDR R2, =ioadr STR R1, [R2] ioadr DCD 0x20001000 To read from the the same device: LDR R1, [R2] A device driver is software that communicates with an I/O device. They are often downloaded or installed for things such as printers since writing a device driver requires detailed knowledge about the I/O device hardware including the addresses and behavior of the memory mapped I/O registers. Other programs can access the device by making calls to functions in the device driver, therefore avoiding the need to understand the low-level device hardware.","title":"Memory-mapped I/O"},{"location":"dig_sys/ch9-io-sys/#programmed-io","text":"Certain architectures, such as x86, use specialzied instructions instead of memory-mapped I/O to communicate with I/O devices. LDRIO R1, device1 STRIO R2, device2","title":"Programmed I/O"},{"location":"dig_sys/ch9-io-sys/#serial-io","text":"When a microcontroller needs to send more bits than free pins so it breaks the message into bits that it sends at each step. There are different standards for serial I/O: Serial Peripheral Interface (SPI) Clocks synchronized btw sender and receiver Universal Asynchronous Receiver/Transmitter (UART) Clocks unsychronizd btw sender and receiver Uses the TX (transmit) and RX (receive) line on the pies Signaling in units of baud instead of bits/sec since 8 data bits are sent using 10 symbols (a start and stop bit) 9600 baud rate = 9600 symbols /sec = 960 bytes(chars)/sec Slow compared to modern standards Universal Serial Bus (USB) Ethernet Many embedded systems use analog I/O. Therefore they use analog-to-digital converters (ADCs) to turn analog signals (voltages) to digital values (bits) and they use digital-to-analog converters (DACs) to turn bits to voltages. ADCs are built into many microcontrollers but few have built-in DACs.","title":"Serial I/O"},{"location":"dig_sys/ch9-io-sys/#motors","text":"Motors draw a very high current that can cause glitches on the power supply that disturb the digital logic Problem is mitigated by using different power supply for motor DC and stepper motors require a high drive current so a powerful driver such as an H-bridge must be connected between the microcontroller and the motor Stepper Motors accept a sequence of pulses that each rotate the motor by a fixed angle called a step More precise position control DC Motors tend to spin at thousands of RPM at very low torque so gear trains are added at cost of decreased RPM but benefit of higher torque Reversing the current makes the motor spin in the opposite direction Changing the current abruptly will result in a large potentially damagaging voltage spike from the inductance of the motor's electromagnet H-bridges handle all the these current related details Requires a seperate logic and motor power supply Supports coast, brake, reverse, and forward for DC motors Servo Motor A DC motor integrated with a gear train and shaft encoder Limited rotation (unless you get a continuous rotation servo)","title":"Motors"},{"location":"dl/activation_functions/","text":"Activation Functions Mathematical equations that determine the output of a node/neuron in a neural network Determines whether each neuron should be activated based on the neuron's input and the specific activation function Normalize the output of a neuron to a range: [0,1] or [-1,1] Must be computationally efficient b/c they are calculated across thousands or millions of neurons for each pass Having a computationally efficient derivative is good too for backpropagation Can be as simple as a step function that turns the neuron output on or off (e.g. 0 or 1) Binary Step Function (Doesn't allow multi-value outputs so it can't do multi-class classification) Can be a trasnformation that maps input signals to output signals Linear activations functions collapse a neural network into one layer b/c a linear combination of linear functions is still a linear function (not very useful) Can't use backpropagation with linear activation functions b/c the derivative is a constant so its impossible to see the effect of changing weights Non-linear activation functions allow the neural network to learn more complex data like images, videos, and audio Allow backpropagation b/c the derivative function is related to the inputs Allow sacking of multiple hidden layers unlike linear activation functions Most all processes can be modeled by a neural network w/ nonlinear activation functions Why do we need nonlinear activation functions? Matrix multiplication and vector addition are simply linear transformations so in order to learn any nonlinear representations of data, we need to introduce a non-linear function or else the most complex classification boundary it can learn will be linear (e.g. line, plane, etc. ) which isn't that useful for interesting problems. If the activation function was linear (e.g. identity function), then the network would essentially just be a linear regression. In order to introduce non-linearity (otherwise matrix ops will result in only linear transformations), we apply non-linear activation functions pointwise to the results of the linear transformations at each layer. Sigmoid/Logistic \\sigma(x) = \\dfrac{1}{1 + e^{-x}} \\dfrac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x)) Pros: Smooth Gradient prevents jumps in the output values Output vaues bound btw 0 and 1, normalizing the each neuron's output can be interpreted as a probability Clear predictions - any values above 2 or below -2 are very close to the edge of the curve Cons: Vanishing Gradient- almost no change in the prediction for very high and very low input values Very large input values to sigmoid function result in a tiny gradient since we are at a nearly flat point of the function This makes it hard to update the parameters earlier in the network Can result in the network refusing to learn further or being too slow to reach an accurate prediction Works well in linear regime but work poorly in the saturating regimes Outputs not zero centered Computationally expensive Detailed Derivation: \\begin{align}\\dfrac{d}{dx} \\sigma(x) &= \\dfrac{d}{dx} \\left[ \\dfrac{1}{1 + e^{-x}} \\right] \\\\ &= \\dfrac{d}{dx} \\left( 1 + \\mathrm{e}^{-x} \\right)^{-1} \\\\ &= -(1 + e^{-x})^{-2}(-e^{-x}) \\\\ &= \\dfrac{e^{-x}}{\\left(1 + e^{-x}\\right)^2} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{e^{-x}}{1 + e^{-x}} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{(1 + e^{-x}) - 1}{1 + e^{-x}} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( \\dfrac{1 + e^{-x}}{1 + e^{-x}} - \\dfrac{1}{1 + e^{-x}} \\right) \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( 1 - \\dfrac{1}{1 + e^{-x}} \\right) \\\\ &= \\sigma(x) \\cdot (1 - \\sigma(x)) \\end{align} TanH (Hyperbolic Tangent) \\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} \\text{tanh}'(z) = 1 - \\text{tanh}(z)^2 Similar in advantages and disadvantages to sigmoid except it has the advantage of being zero centered (i.e. output range is [-1, 1] ), making it easier to models input that have strongly negative, neutral, and strongly positive values (e.g. reward for deep RL model) ReLU (Rectified Linear Unit) \\text{ReLU}(z) = \\begin{cases}z & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0\\end{cases} \\text{ReLU}'(z) = \\begin{cases}1 & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0\\end{cases} Pros: Computationally efficient - allows the network to converge quickly Non-linear - although it seems like a lienar function, its derivative allows for backpropagation Cons: The Dying ReLU problem - as inputs approach zero or are negative, the gradient becomes zero, so the network can't perform backpropagation and therefore cannot learn Leaky ReLU Pros: Prevents dying ReLU problem - the smallpositive slope in the negative area enables backpropagation for negative inputs Otherwise like ReLU Cons: Inconsistent Results - does't provide consistent predicitions for negative input values https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/","title":"Activation Functions"},{"location":"dl/activation_functions/#activation-functions","text":"Mathematical equations that determine the output of a node/neuron in a neural network Determines whether each neuron should be activated based on the neuron's input and the specific activation function Normalize the output of a neuron to a range: [0,1] or [-1,1] Must be computationally efficient b/c they are calculated across thousands or millions of neurons for each pass Having a computationally efficient derivative is good too for backpropagation Can be as simple as a step function that turns the neuron output on or off (e.g. 0 or 1) Binary Step Function (Doesn't allow multi-value outputs so it can't do multi-class classification) Can be a trasnformation that maps input signals to output signals Linear activations functions collapse a neural network into one layer b/c a linear combination of linear functions is still a linear function (not very useful) Can't use backpropagation with linear activation functions b/c the derivative is a constant so its impossible to see the effect of changing weights Non-linear activation functions allow the neural network to learn more complex data like images, videos, and audio Allow backpropagation b/c the derivative function is related to the inputs Allow sacking of multiple hidden layers unlike linear activation functions Most all processes can be modeled by a neural network w/ nonlinear activation functions","title":"Activation Functions"},{"location":"dl/activation_functions/#why-do-we-need-nonlinear-activation-functions","text":"Matrix multiplication and vector addition are simply linear transformations so in order to learn any nonlinear representations of data, we need to introduce a non-linear function or else the most complex classification boundary it can learn will be linear (e.g. line, plane, etc. ) which isn't that useful for interesting problems. If the activation function was linear (e.g. identity function), then the network would essentially just be a linear regression. In order to introduce non-linearity (otherwise matrix ops will result in only linear transformations), we apply non-linear activation functions pointwise to the results of the linear transformations at each layer.","title":"Why do we need nonlinear activation functions?"},{"location":"dl/activation_functions/#sigmoidlogistic","text":"\\sigma(x) = \\dfrac{1}{1 + e^{-x}} \\dfrac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x)) Pros: Smooth Gradient prevents jumps in the output values Output vaues bound btw 0 and 1, normalizing the each neuron's output can be interpreted as a probability Clear predictions - any values above 2 or below -2 are very close to the edge of the curve Cons: Vanishing Gradient- almost no change in the prediction for very high and very low input values Very large input values to sigmoid function result in a tiny gradient since we are at a nearly flat point of the function This makes it hard to update the parameters earlier in the network Can result in the network refusing to learn further or being too slow to reach an accurate prediction Works well in linear regime but work poorly in the saturating regimes Outputs not zero centered Computationally expensive Detailed Derivation: \\begin{align}\\dfrac{d}{dx} \\sigma(x) &= \\dfrac{d}{dx} \\left[ \\dfrac{1}{1 + e^{-x}} \\right] \\\\ &= \\dfrac{d}{dx} \\left( 1 + \\mathrm{e}^{-x} \\right)^{-1} \\\\ &= -(1 + e^{-x})^{-2}(-e^{-x}) \\\\ &= \\dfrac{e^{-x}}{\\left(1 + e^{-x}\\right)^2} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{e^{-x}}{1 + e^{-x}} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{(1 + e^{-x}) - 1}{1 + e^{-x}} \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( \\dfrac{1 + e^{-x}}{1 + e^{-x}} - \\dfrac{1}{1 + e^{-x}} \\right) \\\\ &= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( 1 - \\dfrac{1}{1 + e^{-x}} \\right) \\\\ &= \\sigma(x) \\cdot (1 - \\sigma(x)) \\end{align}","title":"Sigmoid/Logistic"},{"location":"dl/activation_functions/#tanh-hyperbolic-tangent","text":"\\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} \\text{tanh}'(z) = 1 - \\text{tanh}(z)^2 Similar in advantages and disadvantages to sigmoid except it has the advantage of being zero centered (i.e. output range is [-1, 1] ), making it easier to models input that have strongly negative, neutral, and strongly positive values (e.g. reward for deep RL model)","title":"TanH (Hyperbolic Tangent)"},{"location":"dl/activation_functions/#relu-rectified-linear-unit","text":"\\text{ReLU}(z) = \\begin{cases}z & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0\\end{cases} \\text{ReLU}'(z) = \\begin{cases}1 & \\text{if } z \\geq 0 \\\\ 0 & \\text{if } z < 0\\end{cases} Pros: Computationally efficient - allows the network to converge quickly Non-linear - although it seems like a lienar function, its derivative allows for backpropagation Cons: The Dying ReLU problem - as inputs approach zero or are negative, the gradient becomes zero, so the network can't perform backpropagation and therefore cannot learn","title":"ReLU (Rectified Linear Unit)"},{"location":"dl/activation_functions/#leaky-relu","text":"Pros: Prevents dying ReLU problem - the smallpositive slope in the negative area enables backpropagation for negative inputs Otherwise like ReLU Cons: Inconsistent Results - does't provide consistent predicitions for negative input values https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/","title":"Leaky ReLU"},{"location":"dl/auto_encoders/","text":"Auto Encoders Takes high dim input and tries to compress it to a smaller representation Two Principle Components: Encoder- series of layers that compress input to smaller layer callde the bottleneck Decoder-","title":"AutoEncoders"},{"location":"dl/auto_encoders/#auto-encoders","text":"Takes high dim input and tries to compress it to a smaller representation Two Principle Components: Encoder- series of layers that compress input to smaller layer callde the bottleneck Decoder-","title":"Auto Encoders"},{"location":"dl/embeddings/","text":"Embeddings Map items (e.g. movies, text, imgs, etc.) to low-dimensional real vectors such that similar items are close to each other Can be applied to dense data like audio to create a meaningful similarity metric Can jointly embedd multiple data types (e.g. text and images) to define a similarity between them embedding layer in a neural network is just a single hidden layer with one neuron for each dimension (usually d dimensions) d \\approx \\text{possible vals}^ {1/4} rule of thumb, should be cross validated for particular datasets Continuous Retrieval Classical retrieval uses inverted index oftentimes on word Continuous retrieval represents objects as vectors in a vector space where similar objects are placed closer together 3 Requirements: learn to represent objects as contiuous vectors (place everything in a learned space) learn to place similar objects close together learn to retrieve neighboring objects really fast (given a new query, encode it in the learned space and find its nearest neighbors) Resources PyTorch Embedding Module Video Google Devs Embeddings Lecture Word Embeddings","title":"Embeddings"},{"location":"dl/embeddings/#embeddings","text":"Map items (e.g. movies, text, imgs, etc.) to low-dimensional real vectors such that similar items are close to each other Can be applied to dense data like audio to create a meaningful similarity metric Can jointly embedd multiple data types (e.g. text and images) to define a similarity between them embedding layer in a neural network is just a single hidden layer with one neuron for each dimension (usually d dimensions) d \\approx \\text{possible vals}^ {1/4} rule of thumb, should be cross validated for particular datasets","title":"Embeddings"},{"location":"dl/embeddings/#continuous-retrieval","text":"Classical retrieval uses inverted index oftentimes on word Continuous retrieval represents objects as vectors in a vector space where similar objects are placed closer together 3 Requirements: learn to represent objects as contiuous vectors (place everything in a learned space) learn to place similar objects close together learn to retrieve neighboring objects really fast (given a new query, encode it in the learned space and find its nearest neighbors)","title":"Continuous Retrieval"},{"location":"dl/embeddings/#resources","text":"PyTorch Embedding Module Video Google Devs Embeddings Lecture Word Embeddings","title":"Resources"},{"location":"dl/overview/","text":"Neural Networks network can be viewed as a function we want to learn that perfectly maps from inputs to outputs given a dataset, how we define our loss function determines how well we learn the mapping (how well we approximate the function) logistic regression can be seen as a special instance of a neural network A neuron is an operation that is a composite of a linear operation with an activation/thresholding operation Classification Tasks: Neurons in early layers of a network become feature detectors for things such as edges 1st layer can only detect edges or similar basic features since it is given only pixel information in a simple fully connected network later layers can detect more complex features by combining information from earlier feature detectors indicating the presence/orientation of certain edges or other simple features Neurons in the later layers build up more complex feature detectors using the feature detector neurons in the previous layer and the weights connecting the layers Regression Tasks: Layers learn more complex features from the input features (e.g. relationships between features, the weighting of importance of certain features) The learned features are often better than hand engineered features Often difficult to understand what features are being learned and that's why NN's are often considered black boxes A model is an architecture with parameters end-to-end learning- we train based on inputs and outputs and don't care about whats happening on the inside (blackbox model) Loss Function \\mathcal{L} - for 1 example Cost Function J - for multiple examples J = \\frac{1}{m}\\sum_{i=1}^m \\mathcal{L}^{(i)} Can find the derivative by just computing derivative of \\mathcal{L} since summation is a linear operation so we can just compute the derivative inside the summation Normalizing input to neural networks can help it learn better since certain features will not have outsized influence due to their scaling/units normalize = center (subtract by mean) and standardize (divide by std deviation) this results in circular contours to the cost function which result in a smoother descent for gradient descent compared to the unnormalized input which will have ellipsoidal contours mean and standard deviation from the train set must also be applied to test set Smaller the batch, the more noisy the convergence Full batch is the best approximation of the true cost function Smaller batches serve as good enough approximations of the true cost function that are faster to compute, allowing more updates to the parameters in a given amount of time More (less accurate) updates are typically preferred over fewer (very accurate) updates the most accurate updates computed over the whole batch will have the smoothest convergence Some research suggests the stochastity of smaller batches/single samples in gradient descent can help it escape local minima in the cost function that full batch gradient might get caught in Weight Initialization One way to avoid vanishing and exploding gradients is by initializing the weights to be near the ideal values The larger the number of input features to a layer, the smaller we want each individual weight to be so that the dot product of w^Tx does not explode/become too lare For sigmoid activation an initialization that works well: w^{[\\ell] } = \\text{random}(shape) \\times \\frac{1}{\\sqrt{n^{[\\ell - 1]}}} For ReLU activation an initialization that works well: w^{[\\ell] } = \\text{random}(shape) \\times \\frac{2}{\\sqrt{n^{[\\ell - 1]}}} Xavier Initialization used for sigmoid and tanh activation Read More He Initialization: used for relu activation takes into account number of inputs and outputs b/c of the back propagation step Weights need to be randomly initialized or else network will suffer from the symmetry problem where all neurons start learning the same thing (need to be able to evolve independently)","title":"Overview"},{"location":"dl/overview/#neural-networks","text":"network can be viewed as a function we want to learn that perfectly maps from inputs to outputs given a dataset, how we define our loss function determines how well we learn the mapping (how well we approximate the function) logistic regression can be seen as a special instance of a neural network A neuron is an operation that is a composite of a linear operation with an activation/thresholding operation Classification Tasks: Neurons in early layers of a network become feature detectors for things such as edges 1st layer can only detect edges or similar basic features since it is given only pixel information in a simple fully connected network later layers can detect more complex features by combining information from earlier feature detectors indicating the presence/orientation of certain edges or other simple features Neurons in the later layers build up more complex feature detectors using the feature detector neurons in the previous layer and the weights connecting the layers Regression Tasks: Layers learn more complex features from the input features (e.g. relationships between features, the weighting of importance of certain features) The learned features are often better than hand engineered features Often difficult to understand what features are being learned and that's why NN's are often considered black boxes A model is an architecture with parameters end-to-end learning- we train based on inputs and outputs and don't care about whats happening on the inside (blackbox model) Loss Function \\mathcal{L} - for 1 example Cost Function J - for multiple examples J = \\frac{1}{m}\\sum_{i=1}^m \\mathcal{L}^{(i)} Can find the derivative by just computing derivative of \\mathcal{L} since summation is a linear operation so we can just compute the derivative inside the summation Normalizing input to neural networks can help it learn better since certain features will not have outsized influence due to their scaling/units normalize = center (subtract by mean) and standardize (divide by std deviation) this results in circular contours to the cost function which result in a smoother descent for gradient descent compared to the unnormalized input which will have ellipsoidal contours mean and standard deviation from the train set must also be applied to test set Smaller the batch, the more noisy the convergence Full batch is the best approximation of the true cost function Smaller batches serve as good enough approximations of the true cost function that are faster to compute, allowing more updates to the parameters in a given amount of time More (less accurate) updates are typically preferred over fewer (very accurate) updates the most accurate updates computed over the whole batch will have the smoothest convergence Some research suggests the stochastity of smaller batches/single samples in gradient descent can help it escape local minima in the cost function that full batch gradient might get caught in","title":"Neural Networks"},{"location":"dl/overview/#weight-initialization","text":"One way to avoid vanishing and exploding gradients is by initializing the weights to be near the ideal values The larger the number of input features to a layer, the smaller we want each individual weight to be so that the dot product of w^Tx does not explode/become too lare For sigmoid activation an initialization that works well: w^{[\\ell] } = \\text{random}(shape) \\times \\frac{1}{\\sqrt{n^{[\\ell - 1]}}} For ReLU activation an initialization that works well: w^{[\\ell] } = \\text{random}(shape) \\times \\frac{2}{\\sqrt{n^{[\\ell - 1]}}} Xavier Initialization used for sigmoid and tanh activation Read More He Initialization: used for relu activation takes into account number of inputs and outputs b/c of the back propagation step Weights need to be randomly initialized or else network will suffer from the symmetry problem where all neurons start learning the same thing (need to be able to evolve independently)","title":"Weight Initialization"},{"location":"dl/pytorch/","text":"PyTorch Blitz autograd- calculates and stores the gradients for each model param in each parameter's .grad attribute simple training loop: import torch model = torchvision.models.resnet18(pretrained=True) data = torch.rand(1,3,64,64) # 64 x 64 img with 3 channels labels = torch.rand(1,1000) prediction = model(data) # Forward pass loss = (prediction - labels).sum() loss.backward() # backward pass (backprop) # register all the model params in the optimizer optimizer = torch.optim.SGD(model.parameters(),lr=1e-2,momentum=0.9) optimizer.step() # initiate gradient descent if a parameter in a NN does not requires_grad then these params are known as frozen meaning the gradients won't be recomputed. NOTE: torch.no_grad also does same thing ( read more ). also useful for finetuning pretrained networks where you only want to modify the params in the classifer layers to make predictions on the new labels: model = torchvision.models.resnet18(pretrained=True) # Freeze all the parameters in the network for param in model.parameters(): param.requires_grad = False # replace last linear layer (the classifier) with new unfrozen classification layer model.fc = nn.Linear(512, 10) torch.nn pkg nn.Module contains layers and a forward(input) method that returns the output. Can build modules of networks that can be used in other networks. Only have to define the forward function and the backward function will be automatically defined using autograd (relies on autograd parsing the operations in the forward function and creating the appropriate computational graph of all the derivatives) net.parameters() returns the learnable parameters of a nn module only supports mini-batch inputs, no single input samples import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target. Many are provided by the nn pkg such as nn.MSELoss but you can also define your own In order to backpropagate the error/loss, we need to clear the existing gradients ( net.zero_grad() ) and then call loss.backwards() https://pytorch.org/docs/stable/nn.html updating the weights can be done using the below code since weights = weights - learning rate * gradient for SGD: learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) using the torch.optim module lets you easily use other update rules like SGD, Adam, RMSProp, etc. import torch.optim as optim # create your optimizer optimizer = optim.SGD(net.parameters(), lr=0.01) # in your training loop: optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # Does the update recap torch.Tensor - A multi-dimensional array with support for autograd operations like backward() . Also holds the gradient w.r.t. the tensor. nn.Module - Neural network module. Convenient way of encapsulating parameters , with helpers for moving them to GPU, exporting, loading, etc. nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module . autograd.Function - Implements forward and backward definitions of an autograd operation . Every Tensor operation creates at least a single Function node that connects to functions that created a Tensor and encodes its history . gradient clipping optimizer.zero_grad() loss.backward() # by value torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1) # by norm # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm=1) optimizer.step() Note that it stacks all the paremeters into a single vector then performs the clipping we want to just clip the gradients from th hooks tensor.backward() starts the backward pass on the computational graph with a default starting gradient value of 1.0 allow us to inspect (and possibly change) gradients as they flow backwards through the graph hooks get called on tensors in the order they were added .retain_grad() stores the grad on non-leaf/intermediate nodes in the computational graph when adding hooks to a intermediate node in the forward graph (stored in the backward_hooks dict), the function will also be added as a pre-hook to the corresponding node in the backwards graph to be run on the gradient before the node does its thing def fn(grad): print(grad) return grad + 2 # if you return nothing, the same gradient as before will be used c.register_hook(fn) loss functions Cross Entropy Loss- multiclass classification when used for binary classification it expects 2 output features (e.g. [-2.34, 3.61]) Can get probability of each class by using softmax does not give meaningful probabilities in case of binary classification (will always be something like [0.3%, 99.7%]) Binary Cross Entropy Loss- binary classification expects 1 output feature (e.g. [-2.34]) Can easily get probability of class 1 using sigmoid on the network's output logits PyTorch Training Step Dissection","title":"PyTorch"},{"location":"dl/pytorch/#pytorch-blitz","text":"autograd- calculates and stores the gradients for each model param in each parameter's .grad attribute simple training loop: import torch model = torchvision.models.resnet18(pretrained=True) data = torch.rand(1,3,64,64) # 64 x 64 img with 3 channels labels = torch.rand(1,1000) prediction = model(data) # Forward pass loss = (prediction - labels).sum() loss.backward() # backward pass (backprop) # register all the model params in the optimizer optimizer = torch.optim.SGD(model.parameters(),lr=1e-2,momentum=0.9) optimizer.step() # initiate gradient descent if a parameter in a NN does not requires_grad then these params are known as frozen meaning the gradients won't be recomputed. NOTE: torch.no_grad also does same thing ( read more ). also useful for finetuning pretrained networks where you only want to modify the params in the classifer layers to make predictions on the new labels: model = torchvision.models.resnet18(pretrained=True) # Freeze all the parameters in the network for param in model.parameters(): param.requires_grad = False # replace last linear layer (the classifier) with new unfrozen classification layer model.fc = nn.Linear(512, 10)","title":"PyTorch Blitz"},{"location":"dl/pytorch/#torchnn-pkg","text":"nn.Module contains layers and a forward(input) method that returns the output. Can build modules of networks that can be used in other networks. Only have to define the forward function and the backward function will be automatically defined using autograd (relies on autograd parsing the operations in the forward function and creating the appropriate computational graph of all the derivatives) net.parameters() returns the learnable parameters of a nn module only supports mini-batch inputs, no single input samples import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = torch.flatten(x, 1) # flatten all dimensions except batch x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target. Many are provided by the nn pkg such as nn.MSELoss but you can also define your own In order to backpropagate the error/loss, we need to clear the existing gradients ( net.zero_grad() ) and then call loss.backwards() https://pytorch.org/docs/stable/nn.html updating the weights can be done using the below code since weights = weights - learning rate * gradient for SGD: learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) using the torch.optim module lets you easily use other update rules like SGD, Adam, RMSProp, etc. import torch.optim as optim # create your optimizer optimizer = optim.SGD(net.parameters(), lr=0.01) # in your training loop: optimizer.zero_grad() # zero the gradient buffers output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # Does the update","title":"torch.nn pkg"},{"location":"dl/pytorch/#recap","text":"torch.Tensor - A multi-dimensional array with support for autograd operations like backward() . Also holds the gradient w.r.t. the tensor. nn.Module - Neural network module. Convenient way of encapsulating parameters , with helpers for moving them to GPU, exporting, loading, etc. nn.Parameter - A kind of Tensor, that is automatically registered as a parameter when assigned as an attribute to a Module . autograd.Function - Implements forward and backward definitions of an autograd operation . Every Tensor operation creates at least a single Function node that connects to functions that created a Tensor and encodes its history .","title":"recap"},{"location":"dl/pytorch/#gradient-clipping","text":"optimizer.zero_grad() loss.backward() # by value torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1) # by norm # torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm=1) optimizer.step() Note that it stacks all the paremeters into a single vector then performs the clipping we want to just clip the gradients from th","title":"gradient clipping"},{"location":"dl/pytorch/#hooks","text":"tensor.backward() starts the backward pass on the computational graph with a default starting gradient value of 1.0 allow us to inspect (and possibly change) gradients as they flow backwards through the graph hooks get called on tensors in the order they were added .retain_grad() stores the grad on non-leaf/intermediate nodes in the computational graph when adding hooks to a intermediate node in the forward graph (stored in the backward_hooks dict), the function will also be added as a pre-hook to the corresponding node in the backwards graph to be run on the gradient before the node does its thing def fn(grad): print(grad) return grad + 2 # if you return nothing, the same gradient as before will be used c.register_hook(fn)","title":"hooks"},{"location":"dl/pytorch/#loss-functions","text":"Cross Entropy Loss- multiclass classification when used for binary classification it expects 2 output features (e.g. [-2.34, 3.61]) Can get probability of each class by using softmax does not give meaningful probabilities in case of binary classification (will always be something like [0.3%, 99.7%]) Binary Cross Entropy Loss- binary classification expects 1 output feature (e.g. [-2.34]) Can easily get probability of class 1 using sigmoid on the network's output logits PyTorch Training Step Dissection","title":"loss functions"},{"location":"dl/ssl/","text":"Self Supervised Learning By forcing the model to learn a task defined in terms of input images, it forces the network to learn features which will be useful for downstream general visual recognition tasks later Weakenss of Supervised Learning Annotations: costly (e.g. medical imaging data) ambiguous (set of labels not always obvious ) biased (bias in selecting data and/or annotator) privacy concerns (e.g. medical imaging data) limits learning to predefined categories e.g. all dogs are one category but later we might want to seperate dog breeds with transfer learning but this isnt great for that SSL Model Capacity Compared to SL, SSL benefits more from deeper models also benefits from abundance of unlabeled data Can benefit from training a very deep model (teacher model) and then compressing it into a smaller model (student model) this is done for categorical outputs from the teacher by training the students to mimic the output of the teacher network using something like KL divergence loss when the teacher outputs non categorical outputs such as embeddings other loss functions need to be used such as MSE (performs not that well) or clustering with cross entropy Pretext Tasks aka pseudo or proxy task Turn input to grayscale and make network colorize the image learns features detectors for things such as grass and sky that are often the same color Contrastive Learning Recent SSL technique Moco- Momentum Contrast Learning (CVPR 20) From a query image it makes two augmented ones (e.g. two different crops) The augmented ones are passed through two copies of the network (shared weights) to create two embeddings The network is trained to pull together these augmented pairs (positive pairs) In order to prevent the network from learning trivial embeddings, random images are passed through the network and the loss function is structured to push negative pairs away from the positive pairs A memory bank that remembers other negatives also helps","title":"Self-Supervised Learning"},{"location":"dl/ssl/#self-supervised-learning","text":"By forcing the model to learn a task defined in terms of input images, it forces the network to learn features which will be useful for downstream general visual recognition tasks later","title":"Self Supervised Learning"},{"location":"dl/ssl/#weakenss-of-supervised-learning","text":"Annotations: costly (e.g. medical imaging data) ambiguous (set of labels not always obvious ) biased (bias in selecting data and/or annotator) privacy concerns (e.g. medical imaging data) limits learning to predefined categories e.g. all dogs are one category but later we might want to seperate dog breeds with transfer learning but this isnt great for that","title":"Weakenss of Supervised Learning"},{"location":"dl/ssl/#ssl-model-capacity","text":"Compared to SL, SSL benefits more from deeper models also benefits from abundance of unlabeled data Can benefit from training a very deep model (teacher model) and then compressing it into a smaller model (student model) this is done for categorical outputs from the teacher by training the students to mimic the output of the teacher network using something like KL divergence loss when the teacher outputs non categorical outputs such as embeddings other loss functions need to be used such as MSE (performs not that well) or clustering with cross entropy","title":"SSL Model Capacity"},{"location":"dl/ssl/#pretext-tasks","text":"aka pseudo or proxy task Turn input to grayscale and make network colorize the image learns features detectors for things such as grass and sky that are often the same color","title":"Pretext Tasks"},{"location":"dl/ssl/#contrastive-learning","text":"Recent SSL technique Moco- Momentum Contrast Learning (CVPR 20) From a query image it makes two augmented ones (e.g. two different crops) The augmented ones are passed through two copies of the network (shared weights) to create two embeddings The network is trained to pull together these augmented pairs (positive pairs) In order to prevent the network from learning trivial embeddings, random images are passed through the network and the loss function is structured to push negative pairs away from the positive pairs A memory bank that remembers other negatives also helps","title":"Contrastive Learning"},{"location":"dl/transformers/","text":"Transformers Attention token -> query vector q \\in \\mathbb{R}^{d_{attn}} context tokens -> key vectors k_t \\in \\mathbb{R}^{d_{attn}} and value vectors v_t \\in \\mathbb{R}^{d_{val}} q^Tk_t represents how important token t is for predicting the current token q Types Bidirectional (aka unmasked)- applies attention to each token with all the tokens as the context Unidirectional (aka masked)- applies attention to each token with the preceding tokens + itself as the context can think of the following tokens as being masked Cross- given two token sequence representations X,Z (can be diff lengths), applies attention to each token of the primary sequence X with the second sequence Z as the context Dense- uses all of the context Sparse- uses a subset of the context","title":"Transformers"},{"location":"dl/transformers/#transformers","text":"","title":"Transformers"},{"location":"dl/transformers/#attention","text":"token -> query vector q \\in \\mathbb{R}^{d_{attn}} context tokens -> key vectors k_t \\in \\mathbb{R}^{d_{attn}} and value vectors v_t \\in \\mathbb{R}^{d_{val}} q^Tk_t represents how important token t is for predicting the current token q","title":"Attention"},{"location":"dl/transformers/#types","text":"Bidirectional (aka unmasked)- applies attention to each token with all the tokens as the context Unidirectional (aka masked)- applies attention to each token with the preceding tokens + itself as the context can think of the following tokens as being masked Cross- given two token sequence representations X,Z (can be diff lengths), applies attention to each token of the primary sequence X with the second sequence Z as the context Dense- uses all of the context Sparse- uses a subset of the context","title":"Types"},{"location":"math_science/brain/","text":"The average adult brain weighs about 3 lbs which is roughly 2% of total body weight. However it requires 20% of the total amount of energy our bodies spend in a day of no activity. This means it takes roughly 13 watts to power the brain. To put things in perspective, this is 1/5 of the power required by a standard 60 watt lightbulb. When compared to even the most impressive computers-- IBM's Watson which runs on a supercomputer that requires around 1,000 watts-- the brains ability computational ability compared to power consumption is remarkable. The Neuron Our brain is comprised of an estimated 100 billion neurons that operate together in order to produce behavior by transmitting and integrating information at the individual level. Each neuron is connected to roughly 50,000 others. A neuron is comprised of 3 main parts: 1. Dendrites- \"input\" side that receives signals from many other neurons 2. Cell Body- contains the nucleus and all elements needed for normal metabolic activities of these cells 3. Axon- \"output\" side that transmitts neural impulses to other neurons There are many varities of neurons that range in size from 5 microns in diameter to 100 microns-- the size of a human hair in diameter. The 3 main types of neurons are the following: Efferent Neurons- carry information outward from the central nervous system Afferent Neurons- carry information from the external world and body's internal environment inward to the central nervous system Interneurons- carry information from one neuron to another and comprise 99% of neurons in the brain How are signals transferrred? The science behind how electrical signals are transferred in the brain involves some physics and biology. Cells have a higher concentration of positive ions on the outside than the inside which creates a higher potential on the outside. The V_{out} = 0 mV while V_{in} = -70 mV . At the peak of the potential inside the nerve cell, the positive charges begin moving down the axon in order to maximize the distance between positive ions. This is the start of an electrical signal being transmitted. The myelin sheath which has a high resisitvity and covers the axon keeps the positive ions trapped, preventing the signal from disappating. Gaps in the myelin sheath called nodes of ranvier contain voltage gated sodium pumps that repeat the same process as above with the action potential when the electrical charge signal, helping to push the electrical signal further down the axon. The myelin sheath combined with nodes of ranvier allow for the electrical signal to be transmitted at very high speeds. These transmissions of electrical signals form the basis for all activity and computation done by the brain. While there are always things to further understand such as why sodium pumps work or the quantum mechanics behind the movement of electrons, we use layers of abstraction to allow us to build up understanding of certain aspects without having to understand every single thing that makes something occur. Abstraction is the key to making things understandable to humans and is critical in many fields outside of CS/EE in areas such as bio where complex phenomena can be studied at varying levels of abstraction in order to gain different insights. Its pretty meta when you think about how a brain is creating these layers of abstraction just so it can think about how itself works and begin to have an understanding of what it means to think. Brain Diseases Multiple Sclerosis (MS) is a disease where damage is done to the myelin sheaths in the brain, making it difficult for signals to travel, thus causing a breakdown in many critical functions such as muscle control. Sources PSY-PC 1205 PHYS 1602 Brain Power","title":"The Brain"},{"location":"math_science/brain/#the-neuron","text":"Our brain is comprised of an estimated 100 billion neurons that operate together in order to produce behavior by transmitting and integrating information at the individual level. Each neuron is connected to roughly 50,000 others. A neuron is comprised of 3 main parts: 1. Dendrites- \"input\" side that receives signals from many other neurons 2. Cell Body- contains the nucleus and all elements needed for normal metabolic activities of these cells 3. Axon- \"output\" side that transmitts neural impulses to other neurons There are many varities of neurons that range in size from 5 microns in diameter to 100 microns-- the size of a human hair in diameter. The 3 main types of neurons are the following: Efferent Neurons- carry information outward from the central nervous system Afferent Neurons- carry information from the external world and body's internal environment inward to the central nervous system Interneurons- carry information from one neuron to another and comprise 99% of neurons in the brain","title":"The Neuron"},{"location":"math_science/brain/#how-are-signals-transferrred","text":"The science behind how electrical signals are transferred in the brain involves some physics and biology. Cells have a higher concentration of positive ions on the outside than the inside which creates a higher potential on the outside. The V_{out} = 0 mV while V_{in} = -70 mV . At the peak of the potential inside the nerve cell, the positive charges begin moving down the axon in order to maximize the distance between positive ions. This is the start of an electrical signal being transmitted. The myelin sheath which has a high resisitvity and covers the axon keeps the positive ions trapped, preventing the signal from disappating. Gaps in the myelin sheath called nodes of ranvier contain voltage gated sodium pumps that repeat the same process as above with the action potential when the electrical charge signal, helping to push the electrical signal further down the axon. The myelin sheath combined with nodes of ranvier allow for the electrical signal to be transmitted at very high speeds. These transmissions of electrical signals form the basis for all activity and computation done by the brain. While there are always things to further understand such as why sodium pumps work or the quantum mechanics behind the movement of electrons, we use layers of abstraction to allow us to build up understanding of certain aspects without having to understand every single thing that makes something occur. Abstraction is the key to making things understandable to humans and is critical in many fields outside of CS/EE in areas such as bio where complex phenomena can be studied at varying levels of abstraction in order to gain different insights. Its pretty meta when you think about how a brain is creating these layers of abstraction just so it can think about how itself works and begin to have an understanding of what it means to think.","title":"How are signals transferrred?"},{"location":"math_science/brain/#brain-diseases","text":"Multiple Sclerosis (MS) is a disease where damage is done to the myelin sheaths in the brain, making it difficult for signals to travel, thus causing a breakdown in many critical functions such as muscle control.","title":"Brain Diseases"},{"location":"math_science/brain/#sources","text":"PSY-PC 1205 PHYS 1602 Brain Power","title":"Sources"},{"location":"math_science/dev_psy/","text":"Developmental Psychology Essential Messages & Policy: Essential messages came from neuroscientists, developmental psychologists, pediatricians, economists, & educators Each essential message represents a mountain of research Economists were involved b/c research shows money spent early in child\u2019s life pays off (informs policies targeted at children) Psychology & neuroscience research can be used to inform policy Policies aim to: 1) Prep young children for school 2) Provide best forms of child care 3) Improve well-being of children growing up in poverty 4) Protect those who have been abused/neglected The Brain: Not enough genetic material to specify all the synaptic connections in the brain Most neurons are place at birth with few connections/synapses Brains builds connections with experience Brains initially overproduces synapses and then prunes/discards half of them by adolescence (if the connections are not used, they are lost) Takeaway from neurobiology research: Early experiences shape the architecture of the baby\u2019s brain (Firm foundations) Toxic Stress: Healthy development depends on stress response systems being able to quickly ramp up and then return to baseline Children raised in chronic stress (e.g. poverty) keep these systems activated and that can damage brain architecture and regulatory systems Lead to policy outcome of low-income kids being prescribed medicine at a much higher rate to combat psychological related behavioral problems","title":"Dev Psychology"},{"location":"math_science/dev_psy/#developmental-psychology","text":"","title":"Developmental Psychology"},{"location":"math_science/dev_psy/#essential-messages-policy","text":"Essential messages came from neuroscientists, developmental psychologists, pediatricians, economists, & educators Each essential message represents a mountain of research Economists were involved b/c research shows money spent early in child\u2019s life pays off (informs policies targeted at children) Psychology & neuroscience research can be used to inform policy Policies aim to: 1) Prep young children for school 2) Provide best forms of child care 3) Improve well-being of children growing up in poverty 4) Protect those who have been abused/neglected","title":"Essential Messages &amp; Policy:"},{"location":"math_science/dev_psy/#the-brain","text":"Not enough genetic material to specify all the synaptic connections in the brain Most neurons are place at birth with few connections/synapses Brains builds connections with experience Brains initially overproduces synapses and then prunes/discards half of them by adolescence (if the connections are not used, they are lost) Takeaway from neurobiology research: Early experiences shape the architecture of the baby\u2019s brain (Firm foundations)","title":"The Brain:"},{"location":"math_science/dev_psy/#toxic-stress","text":"Healthy development depends on stress response systems being able to quickly ramp up and then return to baseline Children raised in chronic stress (e.g. poverty) keep these systems activated and that can damage brain architecture and regulatory systems Lead to policy outcome of low-income kids being prescribed medicine at a much higher rate to combat psychological related behavioral problems","title":"Toxic Stress:"},{"location":"math_science/molecular_genetics/","text":"Molecular Genetics Molecular Basis of Life: DNA --> RNA --> Proteins --> All biological functions Originally thought that DNA was the basis for all life until viruses that are made up of purely RNA were discovered Knowing the function of a protein is largely dependent on knowing the shape of the protein which is determined by a complex series of interactions. By being able to accurately predict the shape of a string of amino acids, such as with AlphaFold, the function of any DNA sequence can be inferred through a much easier process than doing imaging and experiments to painstakingly indetify the shape of a protein. 20 amino acids have different degrees of attraction to and repulsion to water. this determines the shape of a string of amino acids An important type of protein is an enzyme which catalyzes a reaction that otherwise would not occur or would take a very long time to occur. This results in enzymes having a very important function of being able to put two things together and breaking one thing apart Codon- sequence of 3 base pairs 1 codon codes for 1 amino acid the 3 base pairs have 4^3 = 64 possibilities. since there are only 20 amino acids, there are some combinations that can encode for other signals such as start/stop each amino acid is coded for a by number of similar triplets (roughly 3) the reason that a micromutation will sometimes have no effect Micromutations changes the efficacy of a protein a mutated protein with a drastically different shape won't be able to fit into another protein to do its job properly can have 1) no effect 2) a minor effect (by changing to diff amino acid w/ similar properties) 3) a major effect (by changing to a diff amino w/ diff properties like attraction to water) point mutation- one letter in DNA sequence is changed deletion/insertion mutation- big deal because it entirelly changes the coding downstream from it since all the codons are shifted by one PKU Disease Phenylanine is produced in the brain but cannot be there in too high of concentrations, luckily an enzyme breaks it down into something safer in this disease a small micromutation changes the enzyme, making it not function properly letting the phenylanine build up in the brain and destroys the nervous system quickly if left untreated genetic diseases like these hold great prompise for genetic engineering with biotech like CRISPR FoxP2 Gene FoxP2 gene is related to communication and is found in humans and animals. One base pair difference between lots of animal species and then when compared to humans, there are lots of base pair differences in just a short amount of time which can be correlated to humans superior communication ability that has allowed them to take over the earth. When they replaced the mouse version of FoxP2 gene with the human FoxP2 gene, the mice had more complex ultrasonic communication The Code Breaker Discovery of genes (mendleys pea experiment) -> discovery of DNA (watson, crick, wilkins, & franklin) -> human genome project (ability to read human genes) -> CRISPR (ability to write/edit human genes) This entire progression happened in the span of less than a century! Human body cell has 46 chromosomes that contain the entire human genome btw them all (sex cells have 23 chromosomes) On genetic engineering: just because a slope is slippery doesn\u2019t mean it shouldn\u2019t be crossed. it just means proceed a little slower and a little more carefully in order to reach the tremendous benefits on the other side Epigenetics environment affects regulation of genes all about chromatin regulating transciption access to the DNA chromatin changes in regulation can permanently disallow access to a transcription factor in a DNA, thus silencing that gene often happens early in life (e.g. rat mother parental style affects chromatin's regulation of the stress hormone in the baby rat) Can override anything happening on the transcription factor end 95% of DNA is non-coding meaning it does not code for a gene This means the remaining 95% deal with regulation of when a gene downstream is supposed to be turned off or on. By having certain transcription receptors upstream of a gene's encoding, certain enzymes that are present in different areas of the body can bind to it and then release the proper enzymes to go read the correlated section of DNA and start the rna to protein process. The interesting part of behavior and evolution comes not as much from mutations in the specific genes but the numerous levels of regulation that determine when specific genes are activated. Resources Molecular Genetics I Lecture The Code Breaker by Walter Isaacson","title":"Molecular Genetics"},{"location":"math_science/molecular_genetics/#molecular-genetics","text":"Molecular Basis of Life: DNA --> RNA --> Proteins --> All biological functions Originally thought that DNA was the basis for all life until viruses that are made up of purely RNA were discovered Knowing the function of a protein is largely dependent on knowing the shape of the protein which is determined by a complex series of interactions. By being able to accurately predict the shape of a string of amino acids, such as with AlphaFold, the function of any DNA sequence can be inferred through a much easier process than doing imaging and experiments to painstakingly indetify the shape of a protein. 20 amino acids have different degrees of attraction to and repulsion to water. this determines the shape of a string of amino acids An important type of protein is an enzyme which catalyzes a reaction that otherwise would not occur or would take a very long time to occur. This results in enzymes having a very important function of being able to put two things together and breaking one thing apart Codon- sequence of 3 base pairs 1 codon codes for 1 amino acid the 3 base pairs have 4^3 = 64 possibilities. since there are only 20 amino acids, there are some combinations that can encode for other signals such as start/stop each amino acid is coded for a by number of similar triplets (roughly 3) the reason that a micromutation will sometimes have no effect","title":"Molecular Genetics"},{"location":"math_science/molecular_genetics/#micromutations","text":"changes the efficacy of a protein a mutated protein with a drastically different shape won't be able to fit into another protein to do its job properly can have 1) no effect 2) a minor effect (by changing to diff amino acid w/ similar properties) 3) a major effect (by changing to a diff amino w/ diff properties like attraction to water) point mutation- one letter in DNA sequence is changed deletion/insertion mutation- big deal because it entirelly changes the coding downstream from it since all the codons are shifted by one","title":"Micromutations"},{"location":"math_science/molecular_genetics/#pku-disease","text":"Phenylanine is produced in the brain but cannot be there in too high of concentrations, luckily an enzyme breaks it down into something safer in this disease a small micromutation changes the enzyme, making it not function properly letting the phenylanine build up in the brain and destroys the nervous system quickly if left untreated genetic diseases like these hold great prompise for genetic engineering with biotech like CRISPR","title":"PKU Disease"},{"location":"math_science/molecular_genetics/#foxp2-gene","text":"FoxP2 gene is related to communication and is found in humans and animals. One base pair difference between lots of animal species and then when compared to humans, there are lots of base pair differences in just a short amount of time which can be correlated to humans superior communication ability that has allowed them to take over the earth. When they replaced the mouse version of FoxP2 gene with the human FoxP2 gene, the mice had more complex ultrasonic communication","title":"FoxP2 Gene"},{"location":"math_science/molecular_genetics/#the-code-breaker","text":"Discovery of genes (mendleys pea experiment) -> discovery of DNA (watson, crick, wilkins, & franklin) -> human genome project (ability to read human genes) -> CRISPR (ability to write/edit human genes) This entire progression happened in the span of less than a century! Human body cell has 46 chromosomes that contain the entire human genome btw them all (sex cells have 23 chromosomes) On genetic engineering: just because a slope is slippery doesn\u2019t mean it shouldn\u2019t be crossed. it just means proceed a little slower and a little more carefully in order to reach the tremendous benefits on the other side","title":"The Code Breaker"},{"location":"math_science/molecular_genetics/#epigenetics","text":"environment affects regulation of genes all about chromatin regulating transciption access to the DNA chromatin changes in regulation can permanently disallow access to a transcription factor in a DNA, thus silencing that gene often happens early in life (e.g. rat mother parental style affects chromatin's regulation of the stress hormone in the baby rat) Can override anything happening on the transcription factor end 95% of DNA is non-coding meaning it does not code for a gene This means the remaining 95% deal with regulation of when a gene downstream is supposed to be turned off or on. By having certain transcription receptors upstream of a gene's encoding, certain enzymes that are present in different areas of the body can bind to it and then release the proper enzymes to go read the correlated section of DNA and start the rna to protein process. The interesting part of behavior and evolution comes not as much from mutations in the specific genes but the numerous levels of regulation that determine when specific genes are activated.","title":"Epigenetics"},{"location":"math_science/molecular_genetics/#resources","text":"Molecular Genetics I Lecture The Code Breaker by Walter Isaacson","title":"Resources"},{"location":"math_science/physics/ch25/","text":"Current Current is the movement of net charges. More formally it is defined as the rate at which net charge flows past any section of a conductor. The unit of current is the ampere (1 A = 1 C/sec) Current density is the amount of net charge flowing through a unit area. J = nev_d The relation between current density and current is intuitively going to be the sum of the current density at each point times the area of each point. This can be expressed in general using a surface integral: I = \\int \\int J \\cdot dA If the current density J is uniform and the area A is flat, we get a simplified I = J \\cdot A which for simple wires where the angle between the flow and the area is 0, yields the equation I = JA . Resistance Voltage and current are observed to be proportional in most materials. The constant that relates the voltage and current for a given material is called the resistance R : V = RI . The resistance can be thought of as a measure of how difficult it is for current to flow. When free electrons are flowing through a material, they will inevitably collide with the nuclei of the materials' atoms. Certain materials will have nuclei arrangmenets that will result in more collisions, corresponding to lower current flow and a higher resistance value. This relationship of V = RI is known as Ohm's law after being discovered by George Ohm in 1827. Materials that are observed to follow Ohm's law are known as ohmic materials while ones that do not are known as nonohmic materials. Resistance has numerous applications such as being used to design circuit boards as well as its use in the myelin sheaths of our nerves to transmit electrical signals. Factors affecting Resistance Resistance depends on the material and details/geometry of the sample . Resistivity is the resistance of a unit cube of a given material and depends on the material only. \\rho = \\frac{E}{J} Note that conductivtiy is simply the inverse of resistivity. Resistivity and thus resistance, depends on temperature. Higher temperatures will increase the resistivity and thus increase the resistance and vice versa.","title":"Current & Resistance"},{"location":"math_science/physics/ch25/#current","text":"Current is the movement of net charges. More formally it is defined as the rate at which net charge flows past any section of a conductor. The unit of current is the ampere (1 A = 1 C/sec) Current density is the amount of net charge flowing through a unit area. J = nev_d The relation between current density and current is intuitively going to be the sum of the current density at each point times the area of each point. This can be expressed in general using a surface integral: I = \\int \\int J \\cdot dA If the current density J is uniform and the area A is flat, we get a simplified I = J \\cdot A which for simple wires where the angle between the flow and the area is 0, yields the equation I = JA .","title":"Current"},{"location":"math_science/physics/ch25/#resistance","text":"Voltage and current are observed to be proportional in most materials. The constant that relates the voltage and current for a given material is called the resistance R : V = RI . The resistance can be thought of as a measure of how difficult it is for current to flow. When free electrons are flowing through a material, they will inevitably collide with the nuclei of the materials' atoms. Certain materials will have nuclei arrangmenets that will result in more collisions, corresponding to lower current flow and a higher resistance value. This relationship of V = RI is known as Ohm's law after being discovered by George Ohm in 1827. Materials that are observed to follow Ohm's law are known as ohmic materials while ones that do not are known as nonohmic materials. Resistance has numerous applications such as being used to design circuit boards as well as its use in the myelin sheaths of our nerves to transmit electrical signals.","title":"Resistance"},{"location":"math_science/physics/ch25/#factors-affecting-resistance","text":"Resistance depends on the material and details/geometry of the sample . Resistivity is the resistance of a unit cube of a given material and depends on the material only. \\rho = \\frac{E}{J} Note that conductivtiy is simply the inverse of resistivity. Resistivity and thus resistance, depends on temperature. Higher temperatures will increase the resistivity and thus increase the resistance and vice versa.","title":"Factors affecting Resistance"},{"location":"math_science/physics/notes/","text":"Voltage The electric potential energy difference per unit charge. 1 volt = 1 J / 1 C. 1 volt represents 1 Joule of electric potential energy per 1 Coloumb of charge. 5 volts represent 5 joules of potential energy per coloumb meaning each charge carries 5 joules of potential energy higher voltage means the electrons have more energy final - initial current is the flow of charge per unit charge 1 Amp = 1 C / 1 s 5 Amp = 5 C / 1s meaning 5 coloumbs of charge are flowing per second analogous rate of flow of water resistance measure of materials' ability to resist the flow of charges (current) longer wire will have a greater resistance than a shorter wire because the electrons will have to travel through more material, meaning they will run into more obstacles thin wire will have larger resistance than thick wire since more electrons can get through a thicker wire resistance and current are inversely relateed ohm's law Relates voltage, resistance, and current V = IR current flows from high potential to low potential electrons actually travel in the opposite direction of current (direction of current travel can be thought of as the direction of travel of imaginary positive charges) increasing the voltage will increase the current increasing the resistance will decrease the current capacitors capacitors in parallel Equivalent capcitance is the sum of individual capacitances Voltage is same across all capacitors in parallel Follows that the total charge is the equivalent capacitance times the voltage potential energy in a capacitor is U = 1/2 CV^2 capacitors in series inverses for equivalent capacitance series => diff voltage across capacitor if diff capacitance charge stored on each capacitor is the same for capacitors in series dielectrics and capacitors when a circuit is not connected to a battery , inserting a dielectric will increase capacitance by a factor of K and decrease potential by a factor of K meaning charge remains the same due to Q = KV. Since E = V/l, decreasing V by a factor of K also decreases E by a factor of K When a circuit is connected to a battery , inserting a dielectric will increase the capacitane by a factor of K.= Voltage will remain the same as before due to the battery recharging the initial decrease in voltage so that it stays consistent with the potential supplied by the battery. Therefore, electric field will also be the same since voltae remains the same. In this case, charge will increase with the increase in capacitance. The increase in charge by factor of K will result in an increase of potential energy by a factor of K since U = 1/2 Q V .","title":"Voltage"},{"location":"math_science/physics/notes/#voltage","text":"The electric potential energy difference per unit charge. 1 volt = 1 J / 1 C. 1 volt represents 1 Joule of electric potential energy per 1 Coloumb of charge. 5 volts represent 5 joules of potential energy per coloumb meaning each charge carries 5 joules of potential energy higher voltage means the electrons have more energy final - initial","title":"Voltage"},{"location":"math_science/physics/notes/#current","text":"is the flow of charge per unit charge 1 Amp = 1 C / 1 s 5 Amp = 5 C / 1s meaning 5 coloumbs of charge are flowing per second analogous rate of flow of water","title":"current"},{"location":"math_science/physics/notes/#resistance","text":"measure of materials' ability to resist the flow of charges (current) longer wire will have a greater resistance than a shorter wire because the electrons will have to travel through more material, meaning they will run into more obstacles thin wire will have larger resistance than thick wire since more electrons can get through a thicker wire resistance and current are inversely relateed","title":"resistance"},{"location":"math_science/physics/notes/#ohms-law","text":"Relates voltage, resistance, and current V = IR current flows from high potential to low potential electrons actually travel in the opposite direction of current (direction of current travel can be thought of as the direction of travel of imaginary positive charges) increasing the voltage will increase the current increasing the resistance will decrease the current","title":"ohm's law"},{"location":"math_science/physics/notes/#capacitors","text":"","title":"capacitors"},{"location":"math_science/physics/notes/#capacitors-in-parallel","text":"Equivalent capcitance is the sum of individual capacitances Voltage is same across all capacitors in parallel Follows that the total charge is the equivalent capacitance times the voltage potential energy in a capacitor is U = 1/2 CV^2","title":"capacitors in parallel"},{"location":"math_science/physics/notes/#capacitors-in-series","text":"inverses for equivalent capacitance series => diff voltage across capacitor if diff capacitance charge stored on each capacitor is the same for capacitors in series","title":"capacitors in series"},{"location":"math_science/physics/notes/#dielectrics-and-capacitors","text":"when a circuit is not connected to a battery , inserting a dielectric will increase capacitance by a factor of K and decrease potential by a factor of K meaning charge remains the same due to Q = KV. Since E = V/l, decreasing V by a factor of K also decreases E by a factor of K When a circuit is connected to a battery , inserting a dielectric will increase the capacitane by a factor of K.= Voltage will remain the same as before due to the battery recharging the initial decrease in voltage so that it stays consistent with the potential supplied by the battery. Therefore, electric field will also be the same since voltae remains the same. In this case, charge will increase with the increase in capacitance. The increase in charge by factor of K will result in an increase of potential energy by a factor of K since U = 1/2 Q V .","title":"dielectrics and capacitors"},{"location":"math_science/prob_stats/bayesian/","text":"Ch. 2 Probability 2 interpretations: Frequentist- prob represent long run frequencies of events that can happen multiple times Bayesian- prob represents our uncertainty about something (related to information content instead of repeated trials) 2 cases of uncertainty in predictions: Epistemic (aka model)- ignorance of the data generation method/underlying causes can be reduced by collecting more data Aleatoric (aka data)- intrinsic variability cannot be reduced by collecting more data low order summary stats can be insufficient inference- generalizing from sample data (usually also calculating degrees of certainty) bayesian inference- represents degrees of certainty using probability theory bayes rule follows from the product rule of probability Ch. 4 Stats Bayesian Stats inference- modeling uncertainty about parameters using a prob distribution (as opposed to only a point estimate) posterior distribution p(\\theta | D) represents our uncertainty about the params givven the data prior distribution p(\\theta) reflects what we know before seeing the data likelihood function p(D|\\theta ) reflects the data we expect to see for each set of parameters Class Notes probabilistic approaches to ml has benefits ml can be seen asreasoning under uncertainty (e.g. model outputs and params have uncertainty) regression, classification, generation, and discovery problems benefit from probabilistc formulations inference- computing the distribution that governs a model's parameters given data major focus of the course aka Bayesian ML empirical risk minimization is the standard approach to ml","title":"Ch. 2 Probability"},{"location":"math_science/prob_stats/bayesian/#ch-2-probability","text":"2 interpretations: Frequentist- prob represent long run frequencies of events that can happen multiple times Bayesian- prob represents our uncertainty about something (related to information content instead of repeated trials) 2 cases of uncertainty in predictions: Epistemic (aka model)- ignorance of the data generation method/underlying causes can be reduced by collecting more data Aleatoric (aka data)- intrinsic variability cannot be reduced by collecting more data low order summary stats can be insufficient inference- generalizing from sample data (usually also calculating degrees of certainty) bayesian inference- represents degrees of certainty using probability theory bayes rule follows from the product rule of probability","title":"Ch. 2 Probability"},{"location":"math_science/prob_stats/bayesian/#ch-4-stats","text":"","title":"Ch. 4 Stats"},{"location":"math_science/prob_stats/bayesian/#bayesian-stats","text":"inference- modeling uncertainty about parameters using a prob distribution (as opposed to only a point estimate) posterior distribution p(\\theta | D) represents our uncertainty about the params givven the data prior distribution p(\\theta) reflects what we know before seeing the data likelihood function p(D|\\theta ) reflects the data we expect to see for each set of parameters","title":"Bayesian Stats"},{"location":"math_science/prob_stats/bayesian/#class-notes","text":"probabilistic approaches to ml has benefits ml can be seen asreasoning under uncertainty (e.g. model outputs and params have uncertainty) regression, classification, generation, and discovery problems benefit from probabilistc formulations inference- computing the distribution that governs a model's parameters given data major focus of the course aka Bayesian ML empirical risk minimization is the standard approach to ml","title":"Class Notes"},{"location":"math_science/prob_stats/crvs/","text":"Continuous Random Variables A CRV X satisifes: 1) Possible values of X make up an interval or union of disjoint intervals 2) P(X = c) = 0) for any c that is a possible value of X Probability Density Function DEF: Let X be a CRV. Then a probability density function of X is a function f s.t. P(a \\leq X \\leq b) = \\int_a^b f(x) dx This can be interpreted as the probability that X takes on a value in the interval [a,b] is the area above the interval and under the graph of the density function. Properties of pdfs: 1) f(x) \\geq 0 for all x 2) \\int_{-\\infty}^\\infty f(x)dx = 1 (area under the entire graph of f(x) ) Cumulative Distribution Function F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(y) dy This can be interpreted as the area under the density curve to the left of x . Propositions P(x > a) = 1 - F(a) P(a \\leq X \\leq b) = F(b) - F(a) The (100p) th percentile of a CRV X : p = F[n(p)] = \\int_{-\\infty}^{n(p)} f(y) dy where n(p) is the value on the measurement axis s.t. 100p % of the area under the density curve is to left of n(p) Ex: n(.75) stands for the 75% percentile where 75% of the area is to the left of n(.75) PDFs and CDFs PDFs measure how much the mass changes per unit of length (aka contribution to mass per unit length) CDFs measure the total mass up to a pt x (achieves this my taking the integral on the desired interval to get the mass of that interval) F(x) = \\int_{-\\infty}^x f(y) dy In the cdf's formula, the dy is a tiny length so f(y)dy is the contribution of mass by the point y so integrating (summing over an uncountable interval) the interval gives the total mass of probability. To get the cdf from the pdf, we integrate the pdf over the desired interval. To get the pdf from the cdf, we take the derivative of the cdf and evaluate it at the desired point. At every x which F'(x) exists, F'(x) = f(x) Variance \\sigma_X^2 = V(X)= \\int_{-\\infty}^\\infty (x - \\mu)^2 f(x) dx = E[(X - \\mu)^2] V(X) = E(X^2) - [E(X)]^2 V(aX + b) = a^2\\sigma_X^2 Expected Value E(aX + b) = aE(X) + b If X is largely concentrated on an interval of values close to \\mu , the mean value and variance of Y = h(X) can be approximated using the assumption that h(x) is differentiable. Approximating E[h(X)] \\approx h(\\mu) V[h(X)] \\approx [h'(\\mu)]^2 \\sigma^2 These follow from approximating h(X) using a first order taylor series expansion about (\\mu,h(\\mu)) : Y = h(X) \\approx h(\\mu) + h'(\\mu)(X - \\mu) Moment Generating Functions M_X(t) = E(e^{tX}) = \\int_{-\\infty}^{\\infty} e^{tx}f(x)dx Properties: M_X(0) = E(e^0) = \\int_{-\\infty}^{\\infty} e^{0x}(fx)dx = \\int_{-\\infty}^{\\infty} f(x)dx = 1 Let Y = aX +b . Then M_Y(t) = e^{bt}M_X(at) .","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/crvs/#continuous-random-variables","text":"A CRV X satisifes: 1) Possible values of X make up an interval or union of disjoint intervals 2) P(X = c) = 0) for any c that is a possible value of X","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/crvs/#probability-density-function","text":"DEF: Let X be a CRV. Then a probability density function of X is a function f s.t. P(a \\leq X \\leq b) = \\int_a^b f(x) dx This can be interpreted as the probability that X takes on a value in the interval [a,b] is the area above the interval and under the graph of the density function. Properties of pdfs: 1) f(x) \\geq 0 for all x 2) \\int_{-\\infty}^\\infty f(x)dx = 1 (area under the entire graph of f(x) )","title":"Probability Density Function"},{"location":"math_science/prob_stats/crvs/#cumulative-distribution-function","text":"F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(y) dy This can be interpreted as the area under the density curve to the left of x .","title":"Cumulative Distribution Function"},{"location":"math_science/prob_stats/crvs/#propositions","text":"P(x > a) = 1 - F(a) P(a \\leq X \\leq b) = F(b) - F(a) The (100p) th percentile of a CRV X : p = F[n(p)] = \\int_{-\\infty}^{n(p)} f(y) dy where n(p) is the value on the measurement axis s.t. 100p % of the area under the density curve is to left of n(p) Ex: n(.75) stands for the 75% percentile where 75% of the area is to the left of n(.75)","title":"Propositions"},{"location":"math_science/prob_stats/crvs/#pdfs-and-cdfs","text":"PDFs measure how much the mass changes per unit of length (aka contribution to mass per unit length) CDFs measure the total mass up to a pt x (achieves this my taking the integral on the desired interval to get the mass of that interval) F(x) = \\int_{-\\infty}^x f(y) dy In the cdf's formula, the dy is a tiny length so f(y)dy is the contribution of mass by the point y so integrating (summing over an uncountable interval) the interval gives the total mass of probability. To get the cdf from the pdf, we integrate the pdf over the desired interval. To get the pdf from the cdf, we take the derivative of the cdf and evaluate it at the desired point. At every x which F'(x) exists, F'(x) = f(x)","title":"PDFs and CDFs"},{"location":"math_science/prob_stats/crvs/#variance","text":"\\sigma_X^2 = V(X)= \\int_{-\\infty}^\\infty (x - \\mu)^2 f(x) dx = E[(X - \\mu)^2] V(X) = E(X^2) - [E(X)]^2 V(aX + b) = a^2\\sigma_X^2","title":"Variance"},{"location":"math_science/prob_stats/crvs/#expected-value","text":"E(aX + b) = aE(X) + b If X is largely concentrated on an interval of values close to \\mu , the mean value and variance of Y = h(X) can be approximated using the assumption that h(x) is differentiable.","title":"Expected Value"},{"location":"math_science/prob_stats/crvs/#approximating","text":"E[h(X)] \\approx h(\\mu) V[h(X)] \\approx [h'(\\mu)]^2 \\sigma^2 These follow from approximating h(X) using a first order taylor series expansion about (\\mu,h(\\mu)) : Y = h(X) \\approx h(\\mu) + h'(\\mu)(X - \\mu)","title":"Approximating"},{"location":"math_science/prob_stats/crvs/#moment-generating-functions","text":"M_X(t) = E(e^{tX}) = \\int_{-\\infty}^{\\infty} e^{tx}f(x)dx Properties: M_X(0) = E(e^0) = \\int_{-\\infty}^{\\infty} e^{0x}(fx)dx = \\int_{-\\infty}^{\\infty} f(x)dx = 1 Let Y = aX +b . Then M_Y(t) = e^{bt}M_X(at) .","title":"Moment Generating Functions"},{"location":"math_science/prob_stats/joint-distributions/","text":"Joint Probability Distributions Many problems involves several random variables, thus it is useful to have models for the joint behavior of several random variables, especially the case where the variables are independent of each other. Joint PMF for 2 DRVs A single pmf for a DRV X specifies the amount of mass for each possible value of X . The joint pmf of DRVs X and Y describes the amount of mass for each possible pair of values (x,y) . Let X and Y be two DRVs defined on sample space S of an experiment: p(x,y) = P(X = x \\cap Y = y) = \\sum_x \\sum_y p(x,y) The marginal pmfs of X and Y : p_X(x) = \\sum_y p(x,y) p_Y(y) = \\sum_x p(x,y) This makes sense since order to get the probability of a certain value of x, we take its probability as the sum over all possible y values. The marginal pmfs are useful for computing probabilites of events involving only one of the RVs. Joint PDF for 2 CRVs A single pdf for a CRV X specifies the amount of mass per unit length for each possible value of X on an interval/set. A joint pdf of CRVs X and Y specifies the amount of mass per unit area for each possible pair of values (x,y) . Let X and Y be two CRVs and A a two-dimensional set. P[(X,Y) \\in A] = \\int_A \\int f(x,y)dx dy Then f(x,y) is the joint pdf with properties: 1) f(x,y) \\geq 0 2) \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x,y) dx dy = 1 If A is a two-dimensional rectangle: P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f(x,y)dy dx The marginal pdfs for X and Y : f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) dy f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) dx Independence of 2 RV DEF: Two RVs X and Y are independent if \\forall (x,y) p(x,y) = p_X(x)*p_Y(y) for DRVs f(x,y) = f_X(x)*f_Y(y) for CRVs Independence of n RV Def: x_1 ... x_n are independent RV if (for any subset a_1 to a_r ) for DRV P(x_{a_1}, ..., x_{a_r}) = P(x_{a_1}) * ... *P(x_{a_r}) for CRV f(x_{a_1}, ..., x_{a_r}) = f(x_{a_1}) * ... *f(x_{a_r}) Multinomial Distribution Model: n independent trials with replacement with r possible outcomes each. P_i = prob of getting ith outcome i = 1, ..., r . X_i = # times the ith outcome appears The jpmf of X_1 ,... X_r has a multinomial distribution. P(X_1, \\cdots , X_r) = \\frac{n!}{X_1!X_2! \\cdots X_r!}P_1^{X_1}P_2^{X_2} \\cdots P_r^{X_r} Divide by the number of permutations of each element to remove permutations from the total number of ways the elements can be arranged Expected Value for Functions of 2 RV X, Y are RV and Z = h(X,Y) . Remeber that the expected value can be thought of as a weighted average so the same idea extends to functions of 2 RV: DRV: E(Z) = \\sum_X \\sum_Y h(X,Y)P(X,Y) CRV: E(Z) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} h(x,y) dy dx Note: You can change the order of summation/integration when the series is convergent (i dont really understand why) Propositions: 1) E(aX + Y) = aE(X) + E(Y) 2) If X,Y are independent, then E(X,Y) = E(X)E(Y) A counterexample s can be found such that the reverse of 2) does not hold meaning E(X,Y) = E(X)E(Y) does not imply independence of X and Y . Proof of 1) \\begin{aligned} E(aX+Y) &= \\sum_X \\sum_Y (aX+Y)P(X,Y) \\\\ &= a \\sum_X \\sum_Y X P(X,Y) + \\sum_X \\sum_Y YP(X,Y) \\\\ &= a \\sum_X X \\sum_Y P(X,Y) + \\sum_Y Y \\sum_X P(X,Y) \\\\ &= a \\sum_X X \\sum_Y P_X(X) + \\sum_Y Y \\sum_X P_Y(Y) \\\\ &= aE(X) + E(Y) \\end{aligned} Covariance DEF: X,Y are RV. Then Cov(X,Y) = E((x- \\mu_x)(Y-\\mu_y)) = E(X,Y) - E(X)E(Y) Interpretations Covariance measures how much X and Y are spread since Cov(X,X) = \\sigma^2 How much are X and Y related How much X and Y fail to be independent Cov(X,Y) = 0 does not imply independence as demonstrated by the counterexample to proposition 2 above. How linear is the relation between X and Y Examples The leftmost graph reprsents X and Y variables highly related in an inversely proportional way meaning when X increases, Y decreases and when X decresases, Y increases. The rightmost graph represents X and Y variables highly related in a directly proprtional way. Properties Cov(aX,Z) = aCov(X,Z) This implies Cov(aX,aX) = a^2Cov(X,X) . Cov(aX + bY, Z) = aCov(X,Z) + bCov(Y,Z) Correlation DEF: X and Y are random vars. Corr(X,Y) = \\delta_{x,y} = \\frac{Cov(X,Y)}{\\sigma_x \\sigma_y} Properties: 1) a,c > 0 or a, c <0 implies Corr(aX+b, cY+d) = Corr(X,Y) 2) -1 \\leq Corr(X,Y) \\leq 1 3) Corr(X,Y) = \\pm 1 iff Y = aX +b for some a \\neq 0 Correlation is unrelated to the value of the slope. Simply means when it is one, the slope is positive/increasing. WHen it is negative one, the slope is negative/decreasing. Correlation of 0 means no relation between the points (points are distributed roughly as a circle/sphere). As the correlation approaches -1 or 1, the circle of points flattens, with the spread increasing. Independent random variables will have a correlation of 0. However, uncorrelated random variables do not imply independence. Correlation does not imply causation! From a dataset we can compute correlation with the following formula: \\delta_{x,y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(n-1)s_x s_y} Transformations of RVs X is a CRV and Y = h(X) . Goal: Find the pdf of Y from the pdf of X . Assume h has an inverse. F_Y(y) = P(Y \\leq y) = P(h(X) \\leq y) = P(X \\leq h^{-1}(y) = F_X(h^{-1}(y) Therefore, f_Y(y) = f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) If h has a decreasing inverse, f_Y(y) = -f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) P(h(X) \\leq y) = P(X \\leq h^{-1}(y) only holds if h^{-1} is increasing. If h^{-1} is decreasing then P(h(X) \\leq y) = P(X \\geq h^{-1}(y) f_Y(h(x)) = f_X(x) \\lvert \\frac{1}{h'(x)} \\rvert Change of Variables Formula for 2 RVs X and Y are CRV. U, V = h(X, Y) f_{(u,v)}(h(x,y)) = f_{x,y}(x,y)\\lvert \\frac{1}{\\frac{\\partial u,v}{\\partial x,y}} \\rvert In the equation above, the denominator is the determinant of the jacobian. This represents the change in areas from X,Y to U,V (remember 3Blue1Brown determinant visualization intuition of differencec between areas). Conditional Distributions DEF: the condititonal pmf of Y given X = x P_{Y|X}(Y|X) = \\frac{P(X,Y)}{P_X(x)} = \\frac{f_{x,y}(x,y)}{f_x(x)} Warning: notice that for 1 fixed x , P_{Y|X}(Y | X = x) are pdfs and pmfs resp P_{Y|X}(Y | X = x) = \\sum_y P_{Y|X}(Y|X =x) = \\sum_y \\frac{P(X = x,Y)}{P_X(x)} = \\frac{1}{P_X(x)} \\sum_y P(X,Y) = \\frac{P_X(X)}{P_X(X)} = 1 DEF: E(Y|X=x) = \\sum_y y P(Y|X=x) E(g(Y) | X = x) = \\sum_y g(y) P(Y|X=x) V(Y) = \\sum_y [y - E(Y|X=x)]^2 P(Y|X=x) For CRV: similar formula with integrals instead of summation THM: 1) E(Y) = E(E(Y|X)) 2) V(Y) = E(V(Y|X)) + V(E(Y|X)) Intuition for 1: E(Y|X) is a curve/RV since you evaluate it for all X to give each x and expceted value of Y . So to get an expected value for Y , we simply take the weighted average (expected value) of all the possible values for the RV E(Y|X) . Intuition for 2: Varaiance of Y can be thought of as Avg(spreads) + Spread(avgs) Proof for 1: Assume E(Y) is finite so we can flip the order of summation \\begin{aligned} E(E(Y|X))) &= \\sum_x E(Y|X=x) P_X(x) \\\\ &= \\sum_x \\sum_y y P(Y|X=x)P_X(x) \\\\ &= \\sum_y y \\sum_x P(Y | X=x) P_X(x) \\\\ &= \\sum_y y P_Y(y) \\\\ &= E(Y) \\end{aligned}","title":"Joint Probability Distributions"},{"location":"math_science/prob_stats/joint-distributions/#joint-probability-distributions","text":"Many problems involves several random variables, thus it is useful to have models for the joint behavior of several random variables, especially the case where the variables are independent of each other.","title":"Joint Probability Distributions"},{"location":"math_science/prob_stats/joint-distributions/#joint-pmf-for-2-drvs","text":"A single pmf for a DRV X specifies the amount of mass for each possible value of X . The joint pmf of DRVs X and Y describes the amount of mass for each possible pair of values (x,y) . Let X and Y be two DRVs defined on sample space S of an experiment: p(x,y) = P(X = x \\cap Y = y) = \\sum_x \\sum_y p(x,y) The marginal pmfs of X and Y : p_X(x) = \\sum_y p(x,y) p_Y(y) = \\sum_x p(x,y) This makes sense since order to get the probability of a certain value of x, we take its probability as the sum over all possible y values. The marginal pmfs are useful for computing probabilites of events involving only one of the RVs.","title":"Joint PMF for 2 DRVs"},{"location":"math_science/prob_stats/joint-distributions/#joint-pdf-for-2-crvs","text":"A single pdf for a CRV X specifies the amount of mass per unit length for each possible value of X on an interval/set. A joint pdf of CRVs X and Y specifies the amount of mass per unit area for each possible pair of values (x,y) . Let X and Y be two CRVs and A a two-dimensional set. P[(X,Y) \\in A] = \\int_A \\int f(x,y)dx dy Then f(x,y) is the joint pdf with properties: 1) f(x,y) \\geq 0 2) \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x,y) dx dy = 1 If A is a two-dimensional rectangle: P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_a^b \\int_c^d f(x,y)dy dx The marginal pdfs for X and Y : f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) dy f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) dx","title":"Joint PDF for 2 CRVs"},{"location":"math_science/prob_stats/joint-distributions/#independence-of-2-rv","text":"DEF: Two RVs X and Y are independent if \\forall (x,y) p(x,y) = p_X(x)*p_Y(y) for DRVs f(x,y) = f_X(x)*f_Y(y) for CRVs","title":"Independence of 2 RV"},{"location":"math_science/prob_stats/joint-distributions/#independence-of-n-rv","text":"Def: x_1 ... x_n are independent RV if (for any subset a_1 to a_r ) for DRV P(x_{a_1}, ..., x_{a_r}) = P(x_{a_1}) * ... *P(x_{a_r}) for CRV f(x_{a_1}, ..., x_{a_r}) = f(x_{a_1}) * ... *f(x_{a_r})","title":"Independence of n RV"},{"location":"math_science/prob_stats/joint-distributions/#multinomial-distribution","text":"Model: n independent trials with replacement with r possible outcomes each. P_i = prob of getting ith outcome i = 1, ..., r . X_i = # times the ith outcome appears The jpmf of X_1 ,... X_r has a multinomial distribution. P(X_1, \\cdots , X_r) = \\frac{n!}{X_1!X_2! \\cdots X_r!}P_1^{X_1}P_2^{X_2} \\cdots P_r^{X_r} Divide by the number of permutations of each element to remove permutations from the total number of ways the elements can be arranged","title":"Multinomial Distribution"},{"location":"math_science/prob_stats/joint-distributions/#expected-value-for-functions-of-2-rv","text":"X, Y are RV and Z = h(X,Y) . Remeber that the expected value can be thought of as a weighted average so the same idea extends to functions of 2 RV: DRV: E(Z) = \\sum_X \\sum_Y h(X,Y)P(X,Y) CRV: E(Z) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} h(x,y) dy dx Note: You can change the order of summation/integration when the series is convergent (i dont really understand why) Propositions: 1) E(aX + Y) = aE(X) + E(Y) 2) If X,Y are independent, then E(X,Y) = E(X)E(Y) A counterexample s can be found such that the reverse of 2) does not hold meaning E(X,Y) = E(X)E(Y) does not imply independence of X and Y . Proof of 1) \\begin{aligned} E(aX+Y) &= \\sum_X \\sum_Y (aX+Y)P(X,Y) \\\\ &= a \\sum_X \\sum_Y X P(X,Y) + \\sum_X \\sum_Y YP(X,Y) \\\\ &= a \\sum_X X \\sum_Y P(X,Y) + \\sum_Y Y \\sum_X P(X,Y) \\\\ &= a \\sum_X X \\sum_Y P_X(X) + \\sum_Y Y \\sum_X P_Y(Y) \\\\ &= aE(X) + E(Y) \\end{aligned}","title":"Expected Value for Functions of 2 RV"},{"location":"math_science/prob_stats/joint-distributions/#covariance","text":"DEF: X,Y are RV. Then Cov(X,Y) = E((x- \\mu_x)(Y-\\mu_y)) = E(X,Y) - E(X)E(Y)","title":"Covariance"},{"location":"math_science/prob_stats/joint-distributions/#interpretations","text":"Covariance measures how much X and Y are spread since Cov(X,X) = \\sigma^2 How much are X and Y related How much X and Y fail to be independent Cov(X,Y) = 0 does not imply independence as demonstrated by the counterexample to proposition 2 above. How linear is the relation between X and Y","title":"Interpretations"},{"location":"math_science/prob_stats/joint-distributions/#examples","text":"The leftmost graph reprsents X and Y variables highly related in an inversely proportional way meaning when X increases, Y decreases and when X decresases, Y increases. The rightmost graph represents X and Y variables highly related in a directly proprtional way.","title":"Examples"},{"location":"math_science/prob_stats/joint-distributions/#properties","text":"Cov(aX,Z) = aCov(X,Z) This implies Cov(aX,aX) = a^2Cov(X,X) . Cov(aX + bY, Z) = aCov(X,Z) + bCov(Y,Z)","title":"Properties"},{"location":"math_science/prob_stats/joint-distributions/#correlation","text":"DEF: X and Y are random vars. Corr(X,Y) = \\delta_{x,y} = \\frac{Cov(X,Y)}{\\sigma_x \\sigma_y} Properties: 1) a,c > 0 or a, c <0 implies Corr(aX+b, cY+d) = Corr(X,Y) 2) -1 \\leq Corr(X,Y) \\leq 1 3) Corr(X,Y) = \\pm 1 iff Y = aX +b for some a \\neq 0 Correlation is unrelated to the value of the slope. Simply means when it is one, the slope is positive/increasing. WHen it is negative one, the slope is negative/decreasing. Correlation of 0 means no relation between the points (points are distributed roughly as a circle/sphere). As the correlation approaches -1 or 1, the circle of points flattens, with the spread increasing. Independent random variables will have a correlation of 0. However, uncorrelated random variables do not imply independence. Correlation does not imply causation! From a dataset we can compute correlation with the following formula: \\delta_{x,y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(n-1)s_x s_y}","title":"Correlation"},{"location":"math_science/prob_stats/joint-distributions/#transformations-of-rvs","text":"X is a CRV and Y = h(X) . Goal: Find the pdf of Y from the pdf of X . Assume h has an inverse. F_Y(y) = P(Y \\leq y) = P(h(X) \\leq y) = P(X \\leq h^{-1}(y) = F_X(h^{-1}(y) Therefore, f_Y(y) = f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) If h has a decreasing inverse, f_Y(y) = -f_X(h^{-1}(y)) \\frac{dh^{-1}}{dy}(y) P(h(X) \\leq y) = P(X \\leq h^{-1}(y) only holds if h^{-1} is increasing. If h^{-1} is decreasing then P(h(X) \\leq y) = P(X \\geq h^{-1}(y) f_Y(h(x)) = f_X(x) \\lvert \\frac{1}{h'(x)} \\rvert","title":"Transformations of RVs"},{"location":"math_science/prob_stats/joint-distributions/#change-of-variables-formula-for-2-rvs","text":"X and Y are CRV. U, V = h(X, Y) f_{(u,v)}(h(x,y)) = f_{x,y}(x,y)\\lvert \\frac{1}{\\frac{\\partial u,v}{\\partial x,y}} \\rvert In the equation above, the denominator is the determinant of the jacobian. This represents the change in areas from X,Y to U,V (remember 3Blue1Brown determinant visualization intuition of differencec between areas).","title":"Change of Variables Formula for 2 RVs"},{"location":"math_science/prob_stats/joint-distributions/#conditional-distributions","text":"DEF: the condititonal pmf of Y given X = x P_{Y|X}(Y|X) = \\frac{P(X,Y)}{P_X(x)} = \\frac{f_{x,y}(x,y)}{f_x(x)} Warning: notice that for 1 fixed x , P_{Y|X}(Y | X = x) are pdfs and pmfs resp P_{Y|X}(Y | X = x) = \\sum_y P_{Y|X}(Y|X =x) = \\sum_y \\frac{P(X = x,Y)}{P_X(x)} = \\frac{1}{P_X(x)} \\sum_y P(X,Y) = \\frac{P_X(X)}{P_X(X)} = 1 DEF: E(Y|X=x) = \\sum_y y P(Y|X=x) E(g(Y) | X = x) = \\sum_y g(y) P(Y|X=x) V(Y) = \\sum_y [y - E(Y|X=x)]^2 P(Y|X=x) For CRV: similar formula with integrals instead of summation THM: 1) E(Y) = E(E(Y|X)) 2) V(Y) = E(V(Y|X)) + V(E(Y|X)) Intuition for 1: E(Y|X) is a curve/RV since you evaluate it for all X to give each x and expceted value of Y . So to get an expected value for Y , we simply take the weighted average (expected value) of all the possible values for the RV E(Y|X) . Intuition for 2: Varaiance of Y can be thought of as Avg(spreads) + Spread(avgs) Proof for 1: Assume E(Y) is finite so we can flip the order of summation \\begin{aligned} E(E(Y|X))) &= \\sum_x E(Y|X=x) P_X(x) \\\\ &= \\sum_x \\sum_y y P(Y|X=x)P_X(x) \\\\ &= \\sum_y y \\sum_x P(Y | X=x) P_X(x) \\\\ &= \\sum_y y P_Y(y) \\\\ &= E(Y) \\end{aligned}","title":"Conditional Distributions"},{"location":"math_science/prob_stats/rv/","text":"Discrete Random Variables Binomial Negative Binomial Hypergeometric Geometric Poisson Continuous Random Variables Uniform DEF: A CRV X has a uniform distribution on the interval [A,B] if the pdf for A \\leq X \\leq B is: f(x; A,B) = \\frac{1}{B-A} E(X) = \\frac{A + B}{2} V(X) = \\frac{(B-A)^2}{12} M_X(t) = E(e^{tx}) = \\frac{e^{tb} - e^{ta}}{t(b-a)} Normal DEF: A CRV X has a normal/gaussian distribution with parameters \\mu and \\sigma (or \\sigma^2 ) where -\\infty < \\mu < \\infty and 0 < \\sigma if the pdf is: f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} X \\sim N(\\mu,\\sigma^2) A large \\sigma implies a value far from \\mu is well observed whereas such a value is unlikely when \\sigma is small. Standard Normal Distribution Since standard integration techniques cannot be used to evaluate the cdf of a normal distribution, the standard normal distribution ( \\mu = 0 and \\sigma = 1 ) has been tabulated and can be used to compute probabilities for any other values of \\mu and \\sigma . The PDF: f(z;0,1) = \\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}} The CDF: \\Phi(z) = P(Z \\leq z) = \\int_{-\\infty}^z f(y;0,1)dy Non Standard Normal Distributions To compute probabilities for X \\sim N(\\mu,\\sigma^2) we create a standardized random variable: Z = \\frac{X - \\mu}{\\sigma} Thus, P(a\\leq X \\leq b) = P(\\frac{a-\\mu}{\\sigma} \\leq Z \\leq \\frac{b - \\mu}{\\sigma}) = \\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma}) P(X \\leq a) = \\Phi(\\frac{a - \\mu}{\\sigma}) This results in expected values, variances, and mgfs of the following form: E(X) = E(\\sigma Z + \\mu) = \\sigma E(Z) + \\mu = \\sigma(0) + \\mu = \\mu V(X) = V(\\sigma Z + \\mu) = \\sigma^2V(Z) = \\sigma^2(1) = \\sigma^2 M_X(t) = e^{\\frac{\\mu t + \\sigma^2 t^2}{2}} Normal Approximation of Binomial Distribution Normal distributions can approximate binomial distributions quite well as long as they are not too skewed meaning their probabaility of success p is roughly around 0.5 . X \\sim N(np, \\sqrt{np(1-p)}) P(X \\leq x) = \\Phi(\\frac{x + 0.5 - np}{\\sqrt{np(1-p)}}) 0.5 is the continuity correction that basically corrects for the discreteness of the underyling binomial distribution. The approximation is adequate provided that np \\geq 10 and n(1-p) \\geq 10 . Otherwise, the binomial distribution may be too skewed for the symmetric normal curve to give accurate approximations. Z Critical Values In statistical inference, we need values on the measurement axis that capture small tail areas under the standard normal curve. z_\\alpha denotes the value on the measurement axis for which \\alpha of the area under the z curve lies to the right of z_\\alpha . Also is the 100(1-\\alpha) th percentile of the standard normal distribution. Gamma The gamma family of pdfs yield a wide variety of skewed distributional shapes that can be used for situations in which the symmetric normal disitrubtion does not accurately represent the skewed random variable. In order to define the family of gama distributions we first must define an important function in many areas of mathematics. Gamma Function DEF: For \\alpha > 0 , the gamma function \\Gamma(\\alpha) is defined by: \\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha - 1}e^{-x}dx 1) For any \\alpha > 1 , \\Gamma(\\alpha) = (\\alpha - 1) * \\Gamma(\\alpha - 1) 2) For any positive integer n, \\Gamma(n) = (n - 1)! 3) \\Gamma(\\frac{1}{2}) = \\sqrt{\\pi} Distribution With the gamma function, we can then define the gamma distribution for a CRV X : f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\frac{1}{\\beta^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1}e^{-x/\\beta} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} where \\alpha > 0 and \\beta > 0 . The Standard Gamma Distribution has \\beta = 1 . \\beta is known as the scale parameter because values less than one compress the pdf in the x direction, and values greater than one stretch the pdf in the x direction \\alpha determines how far to the right the distribution's center is, with larger values making it centered more to the right. E(X) = \\alpha \\beta V(X) = \\alpha \\beta^2 M_X(t) = \\frac{1}{(1- \\beta t)^\\alpha} Incomplete Gamma Function The cdf when X is a standard gamma rv (for x >0 ), F(x; \\alpha) = \\int_0^x \\frac{y^{\\alpha - 1}e^{-y}}{\\Gamma(\\alpha)}dy The incomplete gamma can be used to compute any non standard gamma distibution's probabilities since it has been tabulated. For X \\sim G(\\alpha,\\beta) , the cdf of X is the incomplete gamma function evaluated at x/\\beta : F_X(x; \\alpha,\\beta) = F(\\frac{x}{\\beta};\\alpha) Exponential Often used to model the time elapsed between events DEF: A CRV X has an exponential distribution with parameter \\lambda where \\lambda > 0 if the pdf of X is: f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\lambda e^{-\\lambda x} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} Exponential pdf is special case of the gamma pdf where \\alpha = 1 and \\beta = \\frac{1}{\\lambda} . So we can use the expected value and variance formula for the gamma distribution to derive the mean and variance of the exponential distribution: E(X) = \\alpha \\beta = \\frac{1}{\\lambda} V(X) = \\alpha \\beta^2 = \\frac{1}{\\lambda^2} The pdf can be easily integrated unlike the general gamma pdf so the cdf is: F_X(x; \\lambda) = \\int_0^x \\lambda e^{-\\lambda x} dx = 1 - e^{-\\lambda x} Memoryless Property P(X \\geq t + t_0 | X \\geq t_0) = P(X \\geq t_0) The above can be thought of through analogy: If we toss a coin several times until we observe heads, not getting heads for several tosses does not affect the probability of the next toss since they are independent. Memorylessness of the exponential distribution is basically this idea. Read More about memorylessness and approximating the geometric distribution here .","title":"Random Variables"},{"location":"math_science/prob_stats/rv/#discrete-random-variables","text":"","title":"Discrete Random Variables"},{"location":"math_science/prob_stats/rv/#binomial","text":"","title":"Binomial"},{"location":"math_science/prob_stats/rv/#negative-binomial","text":"","title":"Negative Binomial"},{"location":"math_science/prob_stats/rv/#hypergeometric","text":"","title":"Hypergeometric"},{"location":"math_science/prob_stats/rv/#geometric","text":"","title":"Geometric"},{"location":"math_science/prob_stats/rv/#poisson","text":"","title":"Poisson"},{"location":"math_science/prob_stats/rv/#continuous-random-variables","text":"","title":"Continuous Random Variables"},{"location":"math_science/prob_stats/rv/#uniform","text":"DEF: A CRV X has a uniform distribution on the interval [A,B] if the pdf for A \\leq X \\leq B is: f(x; A,B) = \\frac{1}{B-A} E(X) = \\frac{A + B}{2} V(X) = \\frac{(B-A)^2}{12} M_X(t) = E(e^{tx}) = \\frac{e^{tb} - e^{ta}}{t(b-a)}","title":"Uniform"},{"location":"math_science/prob_stats/rv/#normal","text":"DEF: A CRV X has a normal/gaussian distribution with parameters \\mu and \\sigma (or \\sigma^2 ) where -\\infty < \\mu < \\infty and 0 < \\sigma if the pdf is: f(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} X \\sim N(\\mu,\\sigma^2) A large \\sigma implies a value far from \\mu is well observed whereas such a value is unlikely when \\sigma is small.","title":"Normal"},{"location":"math_science/prob_stats/rv/#standard-normal-distribution","text":"Since standard integration techniques cannot be used to evaluate the cdf of a normal distribution, the standard normal distribution ( \\mu = 0 and \\sigma = 1 ) has been tabulated and can be used to compute probabilities for any other values of \\mu and \\sigma . The PDF: f(z;0,1) = \\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}} The CDF: \\Phi(z) = P(Z \\leq z) = \\int_{-\\infty}^z f(y;0,1)dy","title":"Standard Normal Distribution"},{"location":"math_science/prob_stats/rv/#non-standard-normal-distributions","text":"To compute probabilities for X \\sim N(\\mu,\\sigma^2) we create a standardized random variable: Z = \\frac{X - \\mu}{\\sigma} Thus, P(a\\leq X \\leq b) = P(\\frac{a-\\mu}{\\sigma} \\leq Z \\leq \\frac{b - \\mu}{\\sigma}) = \\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma}) P(X \\leq a) = \\Phi(\\frac{a - \\mu}{\\sigma}) This results in expected values, variances, and mgfs of the following form: E(X) = E(\\sigma Z + \\mu) = \\sigma E(Z) + \\mu = \\sigma(0) + \\mu = \\mu V(X) = V(\\sigma Z + \\mu) = \\sigma^2V(Z) = \\sigma^2(1) = \\sigma^2 M_X(t) = e^{\\frac{\\mu t + \\sigma^2 t^2}{2}}","title":"Non Standard Normal Distributions"},{"location":"math_science/prob_stats/rv/#normal-approximation-of-binomial-distribution","text":"Normal distributions can approximate binomial distributions quite well as long as they are not too skewed meaning their probabaility of success p is roughly around 0.5 . X \\sim N(np, \\sqrt{np(1-p)}) P(X \\leq x) = \\Phi(\\frac{x + 0.5 - np}{\\sqrt{np(1-p)}}) 0.5 is the continuity correction that basically corrects for the discreteness of the underyling binomial distribution. The approximation is adequate provided that np \\geq 10 and n(1-p) \\geq 10 . Otherwise, the binomial distribution may be too skewed for the symmetric normal curve to give accurate approximations.","title":"Normal Approximation of Binomial Distribution"},{"location":"math_science/prob_stats/rv/#z-critical-values","text":"In statistical inference, we need values on the measurement axis that capture small tail areas under the standard normal curve. z_\\alpha denotes the value on the measurement axis for which \\alpha of the area under the z curve lies to the right of z_\\alpha . Also is the 100(1-\\alpha) th percentile of the standard normal distribution.","title":"Z Critical Values"},{"location":"math_science/prob_stats/rv/#gamma","text":"The gamma family of pdfs yield a wide variety of skewed distributional shapes that can be used for situations in which the symmetric normal disitrubtion does not accurately represent the skewed random variable. In order to define the family of gama distributions we first must define an important function in many areas of mathematics.","title":"Gamma"},{"location":"math_science/prob_stats/rv/#gamma-function","text":"DEF: For \\alpha > 0 , the gamma function \\Gamma(\\alpha) is defined by: \\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha - 1}e^{-x}dx 1) For any \\alpha > 1 , \\Gamma(\\alpha) = (\\alpha - 1) * \\Gamma(\\alpha - 1) 2) For any positive integer n, \\Gamma(n) = (n - 1)! 3) \\Gamma(\\frac{1}{2}) = \\sqrt{\\pi}","title":"Gamma Function"},{"location":"math_science/prob_stats/rv/#distribution","text":"With the gamma function, we can then define the gamma distribution for a CRV X : f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\frac{1}{\\beta^\\alpha \\Gamma(\\alpha)}x^{\\alpha - 1}e^{-x/\\beta} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} where \\alpha > 0 and \\beta > 0 . The Standard Gamma Distribution has \\beta = 1 . \\beta is known as the scale parameter because values less than one compress the pdf in the x direction, and values greater than one stretch the pdf in the x direction \\alpha determines how far to the right the distribution's center is, with larger values making it centered more to the right. E(X) = \\alpha \\beta V(X) = \\alpha \\beta^2 M_X(t) = \\frac{1}{(1- \\beta t)^\\alpha}","title":"Distribution"},{"location":"math_science/prob_stats/rv/#incomplete-gamma-function","text":"The cdf when X is a standard gamma rv (for x >0 ), F(x; \\alpha) = \\int_0^x \\frac{y^{\\alpha - 1}e^{-y}}{\\Gamma(\\alpha)}dy The incomplete gamma can be used to compute any non standard gamma distibution's probabilities since it has been tabulated. For X \\sim G(\\alpha,\\beta) , the cdf of X is the incomplete gamma function evaluated at x/\\beta : F_X(x; \\alpha,\\beta) = F(\\frac{x}{\\beta};\\alpha)","title":"Incomplete Gamma Function"},{"location":"math_science/prob_stats/rv/#exponential","text":"Often used to model the time elapsed between events DEF: A CRV X has an exponential distribution with parameter \\lambda where \\lambda > 0 if the pdf of X is: f(x; \\alpha, \\beta) = \\begin{array}{cc} \\Bigg \\{ & \\begin{array}{cc} \\lambda e^{-\\lambda x} & x > 0 \\\\ 0 & otherwise \\end{array} \\end{array} Exponential pdf is special case of the gamma pdf where \\alpha = 1 and \\beta = \\frac{1}{\\lambda} . So we can use the expected value and variance formula for the gamma distribution to derive the mean and variance of the exponential distribution: E(X) = \\alpha \\beta = \\frac{1}{\\lambda} V(X) = \\alpha \\beta^2 = \\frac{1}{\\lambda^2} The pdf can be easily integrated unlike the general gamma pdf so the cdf is: F_X(x; \\lambda) = \\int_0^x \\lambda e^{-\\lambda x} dx = 1 - e^{-\\lambda x}","title":"Exponential"},{"location":"math_science/prob_stats/rv/#memoryless-property","text":"P(X \\geq t + t_0 | X \\geq t_0) = P(X \\geq t_0) The above can be thought of through analogy: If we toss a coin several times until we observe heads, not getting heads for several tosses does not affect the probability of the next toss since they are independent. Memorylessness of the exponential distribution is basically this idea. Read More about memorylessness and approximating the geometric distribution here .","title":"Memoryless Property"},{"location":"math_science/prob_stats/stats/","text":"Statistics and Sampling Distributions A sample mean will have variance since each new sample from the population will result in slightly different observed values. This uncertainty in the observed values means the resulting sample mean will also have uncertainty. This uncertainty means the sample mean can be represented with a distribution. DEF: a statistic is any quantity that can be calculated from sampled data. Prior to obtaining data, there is uncertainty as to what the value of the statistic will be so the statistic is a special case of a random variable. The probability distribution of a statistic is known as its sampling distribution to emphasize how its value varies across all possible samples. The probability distribution of a statistic depends not only on the population distribution (normal, uniform, etc.) and sample size n , but also on the method of sampling. The random variables X_1, ... X_n are said to form a simple random sample of size n if 1) X_i 's are independent 2) Every X_i has the same probability distribution The above properties are summarized by saying that X_i 's are iid (independent and identically distributed random variables). If we sample without replacement, we can assume X_i 's are iid if the sample size n is much smaller than the population size N (i.e. population size is so big that not replacing the sampled values does not really change the probability too much of what is sampeled next). In practice if \\frac{n}{N} \\leq 0.05 (at most 5% of the population is sampeled), we can proceed as if the X_i 's form a random sample. There are two methods for obtaining information about a statistic's sampling distribution: 1) Calculations based on info about X_i 's 2) Simulation experiment Deriving the Sampling Distribution Example 6.3 : (in book) X_i \\sim Exp(\\lambda) is iid for all i in range 1 to n where X_i represents the service time for customer i . The total service time could then be represented as T_n = \\sum_{i = i}^n X_i . Set up the cdf using double integrals and a region of integration Differentiating the cdf to get the pdf of T_n will then yield an equation in the form of a gamma pdf with \\alpha = n and \\beta = \\frac{1}{\\lambda} . T_n \\sim Gamma(n, \\frac{1}{\\alpha}) With the distribution for T_n , we can easily find the expected value, variance, etc. for the statistic. Simulation Experiment When we cannot derive the distribution of a statistic, we run experiments programmatically: We need the: 1. Statistic of interest ( \\bar{X}, S, , etc.) 2. Population Distribution (i.e. distribution of the X_i 's) - Ex: normal with \\mu = 100 and \\sigma = 15 3. Number of samples n 4. Number of repetitions k A computer then obtains k different random samples, each of size n , from the designated population distribution. For each of the k random samples, the value of the statistic is calculated and added to a histogram. The histogram gives the approximate sampling distribution of the statistic. Kernel density estimators perform a similer function except instead of using bins to approximate the pdf, it outputs a smooth line to approximate the pdf. This helps reduce information loss due to the width of bins. The more repetitions k , the better the approximation since as k \\to \\infty the actual sampling distribution emerges. As you increase the number of samples n , the resulting normal distribution of the statistic will converge to the true value of the statistic. This is the idea behind the central limit theorem- As n increases, the spread decreases since the effect of one outlier is less when there are more data points being sampeled. Sample Mean's Distribution Let X_1, ..., X_n be iid from a distribution with mean \\mu and standard deviation \\sigma . Then, E(\\bar{X}) = \\mu_{\\bar{X}} = \\mu V(\\bar{X}) = \\sigma_{\\bar{X}}^2 = \\sigma^2/n So the standard deviation \\sigma_{\\bar{X}} = \\sigma/\\sqrt{n} In addition where the sample total T_n = X_1 + \\dots + X_n , E(T_n) = n \\mu and V(T_n) = n\\sigma^2 . These results show that the \\bar{X} distribution becomes more concentrated about the population mean as the sample size increases while the sample total's distribution spreads out more as sample size increases. Rough proof for property 1: E(\\bar{x}) = \\sum E(x_i) / n = n \\mu /n = \\mu where \\mu is the average of X_i . Lemma: X_1, ..., X_n independent random variables: E(a_1X_1 + ... + a_nX_n) = a_1E(X_1) + ... + a_nE(X_n) V(a_1X_1 + ... + a_nX_n) = a_1^2V(X_1) + ... + a_n^2V(X_n) M_{a_1X_1 + ... + a_nX_n}(t) = M_{X_1}(a_1t) * ... * M_{X_n}(a_nt) This property is the motivating idea behind moment generating function. Its the change of basis that diaglonizes the linear statistics. This is a probabilistic laplace transform. \\begin{aligned} M_{a_1x_1 + a_2x_2}(t) &= E(e^{t(a_1x_1 + a_2x_2)}) \\\\ &= \\int \\int e^{t(a_1x_1 + a_2x_2)} * f_{X_1,X_2}(X_1,X_2) dX_1 dX_2 \\\\ &= \\int \\int e^{ta_1x_1} * f_{X_1}(X_1) e^{ta_2x_2} * f_{X_2}(X_2) dX_1 dX_2 \\\\ &= E(e^{ta_1x_1}) E(e^{ta_2x_2}) \\end{aligned} Summing Distributions: X_i \\sim N(\\mu_i, \\sigma_i^2) L = a_1X_1 + ... a_nX_n M_{X_i} = e^{t\\mu_i + t^2a_1^2\\sigma^2/2} = e^{t(a_1\\mu_1 + ... a_n\\mu_n) + 0.5 t^2 (a_1^2\\sigma_1^2 + ... ++ a_n^2\\sigma_n^2)} So X \\sim N(\\sum a_i \\mu_i, \\sum a_i^2\\sigma_i^2) Central Limit Theorem If X_i indepednent and identically distributed with mean \\mu and variance \\sigma^2 , then \\lim_{n \\to \\infty} P(\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z) = P(Z \\leq z) = \\Phi(z) and \\lim_{n \\to \\infty}P(\\frac{T_n - n\\mu}{\\sqrt{n}\\sigma} \\leq z) = P( Z \\leq z) = \\Phi(z) where Z is a standard normal random variable. NOTE: If n >> 0 ( n > 30 is enough) then you can approximate the distribution of the mean by a normal distribution meaning the above central limit theorem holds. INTERPRETATION: When n is sufficiently large, \\bar{X} has an approximately normal distribution with mean \\mu and variance \\sigma^2/n . The CLT is useful as a shortcut in computing probabilities involving the sample mean since it allows us to use a standard normal such that we don't have to actually find the sample mean distribution. Appling the CLT: X \\sim Gamma(\\alpha, \\beta) . If \\alpha >> 0 then X is approximately normally distributed. This is true because X = \\sum_{i = 1}^\\alpha X_i where X_i \\sim Exp(\\frac{1}{\\beta}) . So X = T_\\alpha of X_i 's so X is approximately normal according to the central limit theorem. Y \\sim Bi(n,p) where n >> 0 . Then Y is normally distributed since Y = \\sum_{i = 1}^n Y_i where Y_i is 1 if success, 0 if failure. Y \\approx NormaL(np, \\sqrt{n}\\sqrt{p(1-p)}) Law of Large Numbers Two forms with different interpretations/strengths in their proof of convergence. The mean square of the variance of the mean approaches 0 as the number of samples increases. This requires afinite variance to demonstrate convergence of the mean. Chebyshev's inequality is stronger in demonstrating convergance as it does not require a finite variance. Take an interval around \\mu of [\\mu - \\epsilon, \\mu + \\epsilon] . Summary LLN tells us the average tends to the mean with increased number of observations CLT tells us the average tends to the mean in the shape of a normal distribution For linear statistics we can find the expected value, variance, and cdf from the sampled random variables using the mgf property","title":"Statistics"},{"location":"math_science/prob_stats/stats/#statistics-and-sampling-distributions","text":"A sample mean will have variance since each new sample from the population will result in slightly different observed values. This uncertainty in the observed values means the resulting sample mean will also have uncertainty. This uncertainty means the sample mean can be represented with a distribution. DEF: a statistic is any quantity that can be calculated from sampled data. Prior to obtaining data, there is uncertainty as to what the value of the statistic will be so the statistic is a special case of a random variable. The probability distribution of a statistic is known as its sampling distribution to emphasize how its value varies across all possible samples. The probability distribution of a statistic depends not only on the population distribution (normal, uniform, etc.) and sample size n , but also on the method of sampling. The random variables X_1, ... X_n are said to form a simple random sample of size n if 1) X_i 's are independent 2) Every X_i has the same probability distribution The above properties are summarized by saying that X_i 's are iid (independent and identically distributed random variables). If we sample without replacement, we can assume X_i 's are iid if the sample size n is much smaller than the population size N (i.e. population size is so big that not replacing the sampled values does not really change the probability too much of what is sampeled next). In practice if \\frac{n}{N} \\leq 0.05 (at most 5% of the population is sampeled), we can proceed as if the X_i 's form a random sample. There are two methods for obtaining information about a statistic's sampling distribution: 1) Calculations based on info about X_i 's 2) Simulation experiment","title":"Statistics and Sampling Distributions"},{"location":"math_science/prob_stats/stats/#deriving-the-sampling-distribution","text":"Example 6.3 : (in book) X_i \\sim Exp(\\lambda) is iid for all i in range 1 to n where X_i represents the service time for customer i . The total service time could then be represented as T_n = \\sum_{i = i}^n X_i . Set up the cdf using double integrals and a region of integration Differentiating the cdf to get the pdf of T_n will then yield an equation in the form of a gamma pdf with \\alpha = n and \\beta = \\frac{1}{\\lambda} . T_n \\sim Gamma(n, \\frac{1}{\\alpha}) With the distribution for T_n , we can easily find the expected value, variance, etc. for the statistic.","title":"Deriving the Sampling Distribution"},{"location":"math_science/prob_stats/stats/#simulation-experiment","text":"When we cannot derive the distribution of a statistic, we run experiments programmatically: We need the: 1. Statistic of interest ( \\bar{X}, S, , etc.) 2. Population Distribution (i.e. distribution of the X_i 's) - Ex: normal with \\mu = 100 and \\sigma = 15 3. Number of samples n 4. Number of repetitions k A computer then obtains k different random samples, each of size n , from the designated population distribution. For each of the k random samples, the value of the statistic is calculated and added to a histogram. The histogram gives the approximate sampling distribution of the statistic. Kernel density estimators perform a similer function except instead of using bins to approximate the pdf, it outputs a smooth line to approximate the pdf. This helps reduce information loss due to the width of bins. The more repetitions k , the better the approximation since as k \\to \\infty the actual sampling distribution emerges. As you increase the number of samples n , the resulting normal distribution of the statistic will converge to the true value of the statistic. This is the idea behind the central limit theorem- As n increases, the spread decreases since the effect of one outlier is less when there are more data points being sampeled.","title":"Simulation Experiment"},{"location":"math_science/prob_stats/stats/#sample-means-distribution","text":"Let X_1, ..., X_n be iid from a distribution with mean \\mu and standard deviation \\sigma . Then, E(\\bar{X}) = \\mu_{\\bar{X}} = \\mu V(\\bar{X}) = \\sigma_{\\bar{X}}^2 = \\sigma^2/n So the standard deviation \\sigma_{\\bar{X}} = \\sigma/\\sqrt{n} In addition where the sample total T_n = X_1 + \\dots + X_n , E(T_n) = n \\mu and V(T_n) = n\\sigma^2 . These results show that the \\bar{X} distribution becomes more concentrated about the population mean as the sample size increases while the sample total's distribution spreads out more as sample size increases. Rough proof for property 1: E(\\bar{x}) = \\sum E(x_i) / n = n \\mu /n = \\mu where \\mu is the average of X_i . Lemma: X_1, ..., X_n independent random variables: E(a_1X_1 + ... + a_nX_n) = a_1E(X_1) + ... + a_nE(X_n) V(a_1X_1 + ... + a_nX_n) = a_1^2V(X_1) + ... + a_n^2V(X_n) M_{a_1X_1 + ... + a_nX_n}(t) = M_{X_1}(a_1t) * ... * M_{X_n}(a_nt) This property is the motivating idea behind moment generating function. Its the change of basis that diaglonizes the linear statistics. This is a probabilistic laplace transform. \\begin{aligned} M_{a_1x_1 + a_2x_2}(t) &= E(e^{t(a_1x_1 + a_2x_2)}) \\\\ &= \\int \\int e^{t(a_1x_1 + a_2x_2)} * f_{X_1,X_2}(X_1,X_2) dX_1 dX_2 \\\\ &= \\int \\int e^{ta_1x_1} * f_{X_1}(X_1) e^{ta_2x_2} * f_{X_2}(X_2) dX_1 dX_2 \\\\ &= E(e^{ta_1x_1}) E(e^{ta_2x_2}) \\end{aligned} Summing Distributions: X_i \\sim N(\\mu_i, \\sigma_i^2) L = a_1X_1 + ... a_nX_n M_{X_i} = e^{t\\mu_i + t^2a_1^2\\sigma^2/2} = e^{t(a_1\\mu_1 + ... a_n\\mu_n) + 0.5 t^2 (a_1^2\\sigma_1^2 + ... ++ a_n^2\\sigma_n^2)} So X \\sim N(\\sum a_i \\mu_i, \\sum a_i^2\\sigma_i^2)","title":"Sample Mean's Distribution"},{"location":"math_science/prob_stats/stats/#central-limit-theorem","text":"If X_i indepednent and identically distributed with mean \\mu and variance \\sigma^2 , then \\lim_{n \\to \\infty} P(\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\leq z) = P(Z \\leq z) = \\Phi(z) and \\lim_{n \\to \\infty}P(\\frac{T_n - n\\mu}{\\sqrt{n}\\sigma} \\leq z) = P( Z \\leq z) = \\Phi(z) where Z is a standard normal random variable. NOTE: If n >> 0 ( n > 30 is enough) then you can approximate the distribution of the mean by a normal distribution meaning the above central limit theorem holds. INTERPRETATION: When n is sufficiently large, \\bar{X} has an approximately normal distribution with mean \\mu and variance \\sigma^2/n . The CLT is useful as a shortcut in computing probabilities involving the sample mean since it allows us to use a standard normal such that we don't have to actually find the sample mean distribution.","title":"Central Limit Theorem"},{"location":"math_science/prob_stats/stats/#appling-the-clt","text":"X \\sim Gamma(\\alpha, \\beta) . If \\alpha >> 0 then X is approximately normally distributed. This is true because X = \\sum_{i = 1}^\\alpha X_i where X_i \\sim Exp(\\frac{1}{\\beta}) . So X = T_\\alpha of X_i 's so X is approximately normal according to the central limit theorem. Y \\sim Bi(n,p) where n >> 0 . Then Y is normally distributed since Y = \\sum_{i = 1}^n Y_i where Y_i is 1 if success, 0 if failure. Y \\approx NormaL(np, \\sqrt{n}\\sqrt{p(1-p)})","title":"Appling the CLT:"},{"location":"math_science/prob_stats/stats/#law-of-large-numbers","text":"Two forms with different interpretations/strengths in their proof of convergence. The mean square of the variance of the mean approaches 0 as the number of samples increases. This requires afinite variance to demonstrate convergence of the mean. Chebyshev's inequality is stronger in demonstrating convergance as it does not require a finite variance. Take an interval around \\mu of [\\mu - \\epsilon, \\mu + \\epsilon] .","title":"Law of Large Numbers"},{"location":"math_science/prob_stats/stats/#summary","text":"LLN tells us the average tends to the mean with increased number of observations CLT tells us the average tends to the mean in the shape of a normal distribution For linear statistics we can find the expected value, variance, and cdf from the sampled random variables using the mgf property","title":"Summary"},{"location":"misc/how-to-speak/","text":"How to Speak Notes from the legendary lecture by MIT professor Patrick Winston. Article on his advice. Success in life mostly depends on : your ability to speak your ability to write the quality of your ideas Quality of your communication depends mostly on how much you know (your knowledge), some on how much you practice, and a only a tiny bit on talent Can be better than people with inherent talent by having the right amount of knowledge Giving a Talk dont start with a joke for a talk people are still getting settled in and don't really understand your way of speaking yet start with a promise of what people will know at the end of the talk (empowerment promise) cycle around a subject (repeat your point) build a fence around your idea so it can be distinguished from other people's ideas helps to prevent confusion on how your idea is different need verbal punctuation give people a place to get back on the talk if they zoned out or something when asking a question need to wait 7 seconds for responses too easy and people will be embarrased to respond too hard and people can't respond time and place for a talk: best time for a talk: 11am (people are awake and not too hungry or too full) need a talk to be well lit case the place you will be speaking so you can anticipate any challenges get a place where the size of the anticipated audience will not seem too small for the place Inspire people most inspiring thing for people is to see someone talk about something they are passionate about when talking about your research, you need to give context as to why you are doing it don't practice on people that know the material b/c they might fill in the gaps in your presentation on their own in a job talk you need to do both within 5 min: express your vision (the problem and your approach) show you've done something (enumerate the steps to reach the vision and talk about your contribution to these steps) your ideas are like your children so you want to ready them for the world thats why packaging them properly is important for their success in order for your work to get recognized it needs a: symbol slogan surprise (e.g. suprising result) salient (an idea that sticks out) story (need to tell story of how you did it, how it works, why its important) Tools board: graphics fast and easy to make speed you can go is the speed people can absorb (slides can be too fast) you have something to do with your hands good for informing props are great at demonstrating things slides always too many words on the slide too many words on slide forces audience to disengage from listening in order to read using big font sizes helps force less words and improves readability for the audience dont read the slide slides with words and a far away speaker can pull the audience's attention in different directions be near the slides reduce the background junk and keep images simple e.g. get rid of logos and even titles good for exposing ideas using a laser pointer forces you to lose contact with audience better to use labels like arrows in the slideshow/ppt for emphasis final slide: recognize collaborators on 1st slide, not last slide don't do: questions? go to this website for more details slide the end or thank you should be your contributions a joke at the end could work and be better well received than at the beginning saying thank you for listening is a weak last move (implies you were not interesting) can say/mouth thanks during the applause can end by saluting the audience verbally","title":"How to Speak"},{"location":"misc/how-to-speak/#how-to-speak","text":"Notes from the legendary lecture by MIT professor Patrick Winston. Article on his advice. Success in life mostly depends on : your ability to speak your ability to write the quality of your ideas Quality of your communication depends mostly on how much you know (your knowledge), some on how much you practice, and a only a tiny bit on talent Can be better than people with inherent talent by having the right amount of knowledge","title":"How to Speak"},{"location":"misc/how-to-speak/#giving-a-talk","text":"dont start with a joke for a talk people are still getting settled in and don't really understand your way of speaking yet start with a promise of what people will know at the end of the talk (empowerment promise) cycle around a subject (repeat your point) build a fence around your idea so it can be distinguished from other people's ideas helps to prevent confusion on how your idea is different need verbal punctuation give people a place to get back on the talk if they zoned out or something when asking a question need to wait 7 seconds for responses too easy and people will be embarrased to respond too hard and people can't respond time and place for a talk: best time for a talk: 11am (people are awake and not too hungry or too full) need a talk to be well lit case the place you will be speaking so you can anticipate any challenges get a place where the size of the anticipated audience will not seem too small for the place Inspire people most inspiring thing for people is to see someone talk about something they are passionate about when talking about your research, you need to give context as to why you are doing it don't practice on people that know the material b/c they might fill in the gaps in your presentation on their own in a job talk you need to do both within 5 min: express your vision (the problem and your approach) show you've done something (enumerate the steps to reach the vision and talk about your contribution to these steps) your ideas are like your children so you want to ready them for the world thats why packaging them properly is important for their success in order for your work to get recognized it needs a: symbol slogan surprise (e.g. suprising result) salient (an idea that sticks out) story (need to tell story of how you did it, how it works, why its important)","title":"Giving a Talk"},{"location":"misc/how-to-speak/#tools","text":"board: graphics fast and easy to make speed you can go is the speed people can absorb (slides can be too fast) you have something to do with your hands good for informing props are great at demonstrating things slides always too many words on the slide too many words on slide forces audience to disengage from listening in order to read using big font sizes helps force less words and improves readability for the audience dont read the slide slides with words and a far away speaker can pull the audience's attention in different directions be near the slides reduce the background junk and keep images simple e.g. get rid of logos and even titles good for exposing ideas using a laser pointer forces you to lose contact with audience better to use labels like arrows in the slideshow/ppt for emphasis final slide: recognize collaborators on 1st slide, not last slide don't do: questions? go to this website for more details slide the end or thank you should be your contributions a joke at the end could work and be better well received than at the beginning saying thank you for listening is a weak last move (implies you were not interesting) can say/mouth thanks during the applause can end by saluting the audience verbally","title":"Tools"},{"location":"misc/macos/","text":"MacOS Overview Executable PATH PATH is an environment variable that contains a colon-seperated list of directories where your shell will look for executables that are called by name on the command line without an explicit path to them Ex: /usr/bin:/bin:/home/bin Any executable called by name will be searched for in these directories in the order from left to right if an executable exists in 2 directories, the one that is found first is executed If no executable is found in any of the directories on the path, the shell will not execute the command and will throw a command not recognized error /etc/paths sets the PATH system wide for all users (macOS specific) .~/zsh_profile sets per-user preferences ( ~ is the user's home directory) PATH , $PATH , and ${PATH} all reference the same variable just in different contexts PATH is for setting the variable (e.g. PATH=/usr/bin ) $ denotes an environment variable variable names are case sensitive so PATH is different than Path Bash/zsh Profile vs RC: .bash_profile is executed for login shells (e.g. logging into machine via console or via ssh) .bashrc is executed for interactive non-login shells (e.g. already logged in and open a new terminal window) Also run when starting a new bash instance by typing /bin/bash such as the shebang at the top of some python scripts In OSX, terminal runs a login shell every time by default unlike other operating systems Filesystem Does not follow the Filesystem Hierarchy Standard that Linux operating systems do so there are some similarities and differences / is the root of the MacOS filesystem /System/Library/Kernels : Contains the OS kernel (replaces /boot folder in FHS) /Users : replaces the /home folder in FHS /var/root/ : replaces the /root folder in FHS /usr contains user installed utilities and apps user commands: /usr/bin for normal users /usr/sbin for admin users shared libraries: /usr/lib Man pages (manual page- software documentation) /usr/share/man executables that shouldn't directly be run by users /usr/libexec a subdirectory to place programs, libraries, and other files that don't come with the base OS /usr/local /dev contains device files /etc contains system configuration files and scripts /etc/paths contains a list of paths used by path_helper to build and set the PATH to search for commands along /bin contians executables to provide essential user utilities (e.g common command line commands like ls or pwd or cd) man hier : / root directory of the filesystem /bin/ user utilities fundamental to both single-user and multi-user environments /dev/ block and character device files /etc/ system configuration files and scripts /mach_kernel kernel executable (the operating system loaded into memory at boot time). /sbin/ system programs and administration utilities fundamental to both single-user and multi- user environments /tmp/ temporary files /usr/ contains the majority of user utilities and applications bin/ common utilities, programming tools, and apps include/ standard C include files arpa/ C include files for Internet service protocols hfs/ C include files for HFS machine/ machine specific C include files net/ misc network C include files netinet/ C include files for Internet standard protocols; see inet(4) nfs/ C include files for NFS (Network File System) objc/ C include files for Objective-C protocols/ C include files for Berkeley service protocols sys/ system C include files (kernel data structures) ufs/ C include files for UFS lib/ archive libraries libexec/ system daemons & system utilities (executed by other programs) local/ executables, libraries, etc. not included by the basic OS sbin/ system daemons & system utilities (executed by users) share/ architecture-independent data files calendar/ a variety of pre-fab calendar files dict/ word lists man/ manual pages misc/ misc system-wide ascii text files mk/ templates for make skel/ example . (dot) files for new accounts tabset/ tab description files zoneinfo/ timezone configuration information /var/ multi-purpose log, temporary, transient, and spool files at/ timed command scheduling files; see at(1) backups/ misc. backup files db/ misc. automatically generated system-specific database files log/ misc. system log files mail/ user mailbox files run/ system information files describing various info about system since it was booted rwho/ rwho data files spool/ misc. printer and mail system spooling directories tmp/ temporary files that are kept between system reboots folders/ per-user temporary files and caches Useful Commands man cmd will display the manual page for the terminal command (useful for getting the flag descriptions for commands like ls ) | pipe operator is great for doing additional commands to the output of the first command echo \"source /opt/ros/foxy/setup.zsh\" >> .zshrc is useful for adding things to the .zshrc without opening it up in an editor which python3 is usefull for figuring out where commands/executables are installed on the PATH compaudit | xargs chmod g-w basically runs an audit for insecure directories (usually related to read-write permissions) and removes any write permissions that should not be on directories ( Source ) needed to use this to fix a compaudit warning when sourcing ros2-foxy-base Resources MacOS Filesystem PATH Explanation Bash Profile vs RC Homebrew symlinks in /usr/local/opt to /usr/local/Cellar","title":"MacOS"},{"location":"misc/macos/#macos-overview","text":"","title":"MacOS Overview"},{"location":"misc/macos/#executable-path","text":"PATH is an environment variable that contains a colon-seperated list of directories where your shell will look for executables that are called by name on the command line without an explicit path to them Ex: /usr/bin:/bin:/home/bin Any executable called by name will be searched for in these directories in the order from left to right if an executable exists in 2 directories, the one that is found first is executed If no executable is found in any of the directories on the path, the shell will not execute the command and will throw a command not recognized error /etc/paths sets the PATH system wide for all users (macOS specific) .~/zsh_profile sets per-user preferences ( ~ is the user's home directory) PATH , $PATH , and ${PATH} all reference the same variable just in different contexts PATH is for setting the variable (e.g. PATH=/usr/bin ) $ denotes an environment variable variable names are case sensitive so PATH is different than Path","title":"Executable PATH"},{"location":"misc/macos/#bashzsh-profile-vs-rc","text":".bash_profile is executed for login shells (e.g. logging into machine via console or via ssh) .bashrc is executed for interactive non-login shells (e.g. already logged in and open a new terminal window) Also run when starting a new bash instance by typing /bin/bash such as the shebang at the top of some python scripts In OSX, terminal runs a login shell every time by default unlike other operating systems","title":"Bash/zsh Profile vs RC:"},{"location":"misc/macos/#filesystem","text":"Does not follow the Filesystem Hierarchy Standard that Linux operating systems do so there are some similarities and differences / is the root of the MacOS filesystem /System/Library/Kernels : Contains the OS kernel (replaces /boot folder in FHS) /Users : replaces the /home folder in FHS /var/root/ : replaces the /root folder in FHS /usr contains user installed utilities and apps user commands: /usr/bin for normal users /usr/sbin for admin users shared libraries: /usr/lib Man pages (manual page- software documentation) /usr/share/man executables that shouldn't directly be run by users /usr/libexec a subdirectory to place programs, libraries, and other files that don't come with the base OS /usr/local /dev contains device files /etc contains system configuration files and scripts /etc/paths contains a list of paths used by path_helper to build and set the PATH to search for commands along /bin contians executables to provide essential user utilities (e.g common command line commands like ls or pwd or cd) man hier : / root directory of the filesystem /bin/ user utilities fundamental to both single-user and multi-user environments /dev/ block and character device files /etc/ system configuration files and scripts /mach_kernel kernel executable (the operating system loaded into memory at boot time). /sbin/ system programs and administration utilities fundamental to both single-user and multi- user environments /tmp/ temporary files /usr/ contains the majority of user utilities and applications bin/ common utilities, programming tools, and apps include/ standard C include files arpa/ C include files for Internet service protocols hfs/ C include files for HFS machine/ machine specific C include files net/ misc network C include files netinet/ C include files for Internet standard protocols; see inet(4) nfs/ C include files for NFS (Network File System) objc/ C include files for Objective-C protocols/ C include files for Berkeley service protocols sys/ system C include files (kernel data structures) ufs/ C include files for UFS lib/ archive libraries libexec/ system daemons & system utilities (executed by other programs) local/ executables, libraries, etc. not included by the basic OS sbin/ system daemons & system utilities (executed by users) share/ architecture-independent data files calendar/ a variety of pre-fab calendar files dict/ word lists man/ manual pages misc/ misc system-wide ascii text files mk/ templates for make skel/ example . (dot) files for new accounts tabset/ tab description files zoneinfo/ timezone configuration information /var/ multi-purpose log, temporary, transient, and spool files at/ timed command scheduling files; see at(1) backups/ misc. backup files db/ misc. automatically generated system-specific database files log/ misc. system log files mail/ user mailbox files run/ system information files describing various info about system since it was booted rwho/ rwho data files spool/ misc. printer and mail system spooling directories tmp/ temporary files that are kept between system reboots folders/ per-user temporary files and caches","title":"Filesystem"},{"location":"misc/macos/#useful-commands","text":"man cmd will display the manual page for the terminal command (useful for getting the flag descriptions for commands like ls ) | pipe operator is great for doing additional commands to the output of the first command echo \"source /opt/ros/foxy/setup.zsh\" >> .zshrc is useful for adding things to the .zshrc without opening it up in an editor which python3 is usefull for figuring out where commands/executables are installed on the PATH compaudit | xargs chmod g-w basically runs an audit for insecure directories (usually related to read-write permissions) and removes any write permissions that should not be on directories ( Source ) needed to use this to fix a compaudit warning when sourcing ros2-foxy-base","title":"Useful Commands"},{"location":"misc/macos/#resources","text":"MacOS Filesystem PATH Explanation Bash Profile vs RC Homebrew symlinks in /usr/local/opt to /usr/local/Cellar","title":"Resources"},{"location":"ml/classification/","text":"Classification Perceptron Very early learning algorithm that performs simple linear classification between two classes Never converges if training data is not linearly separable z = w^Tx + b g(z) = <script type=\"math/tex; mode=display\">\\begin{cases}1 & z \\geq 0 \\\\ 0 & z < 0\\end{cases} Update rule: \\theta_j := \\theta_j + \\alpha (y^{(i)} - h_\\theta(x^{(i)})x_j^{(i)} Its predictions do not have meaningful probabilistic interpretations Cannot be derived as a maximum likelihood estimation algorithm Forms the basis for multilayer perceptrons (neural networks) Backpropagation is used to train Nonlinear activitaion functions that are part of the network need to be differentiable Perceptron vs Logistic Regression Logistic Regression Fisher Scoring- when the log likelihood function is optimizied using multi-dimensional Newton's method \\theta := \\theta - H^{-1} \\nabla_\\theta \\ell(\\theta) H_{ij} = \\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta_i \\partial \\theta_j} Faster convergence than batch gradient descent but one iteration can be more expensive due to finding and inverting hessian If number of params is small, and therefore hessian is small, then it is usually much faster overall CS 229 Notes Softmax Regression aka Multinomial Logistic Regression Generalization of logistic regression to C classes If C = 2 then softmax reduces to binary logistic regression Creates linear decision boundaries between classes Adding hidden layers with nonlinear activation functions is what allows NNs to learn nonlinear decision boundaries Applies the softmax activation function to a vector of real numbers to produce a vector of probabilities S(x) = \\frac{e^x}{\\sum_{i =1}^C e^{x_i}} S: \\mathbb{R}^n \\to \\mathbb{R}^n The sum of the output probabilites = 1 Applies the exponetial elementwise to a vector Temperature parameter t is a scalar that x is multiplied by before being passed to the softmax activation 0 < t < 1 moves the probabilities closer together t > 1 moves the probabilites further apart Uses cross entropy loss to train \\mathcal{L}(y, \\hat y) = - \\sum_{j=1}^C y_j \\log \\hat y_j assumes target y uses one-hot encoding (e.g. y^{(i)} = (0, 0, 1, 0)^T ) In order to minimize -\\log \\hat y we need to make \\hat y >> 0 J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(y^{(i)}, \\hat y^{(i)}) Stanford UFLDL DeepLearningAI Video on Softmax Regression Gaussian Discriminant Analysis Naive Bayes Features are discrete unlike the continue features in Gaussian Discriminant Analysis Ex: dictionary of words showing up in an email to classify whether it is spam mispelled words in spam messages to try to get past these dictionaries of possible spam values the feature vector of words that show up in the desired dictionary is considered a bernoulli event model a multinomial event model takes into account the structure of the sentence or how the words appear in order to help prevent stuffing an email with a bunch of hidden good words that help the email get past the spam filter using a bernoulli event model naive bayes is no longer valid the feature vector will now depend on email length laplace mothing based on dictionary size instead of the size of the feature vector Support Vector Machines Multiclass Classification To classify an input into one of k classes, there are two techniques that can be applied to any of the classification methods (logistic regression, perceptron, SVM) ML Mastery One-vs-All aka one-vs-rest For each i = 1, \\dots, k train a binary classifier to succesfully classify y = i . This yields a set of parameters \\theta^{(1)}, \\dots, \\theta^{(k)} To make predictions for x , select the class i that produces the highest value for h_\\theta^{(i)}(x) = (\\theta^{(i)})^Tx One-vs-One For each class i = 1, \\dots, k train a separate binary classifier to succesfully classify y = i against each other class Results in \\frac{k(k-1)}{2} Classifiers To make predictions for x : Each model may predict a class label for x and the class label with the most votes (most frequently occuring) amongst all the models is the predicted label Each model may predict a probability of a class membership of x , so then the probabilites for each class membership are summed up and the class with the highest probability is the predicted label. Example w/ 4 classes: \u2018 red ,\u2019 \u2018 blue ,\u2019 and \u2018 green ,\u2019 \u2018 yellow .\u2019 This would be divided into six binary classification problems: 1: red vs. blue 2: red vs. green 3: red vs. yellow 4: blue vs. green 5: blue vs. yellow 6: green vs. yellow","title":"Classification"},{"location":"ml/classification/#classification","text":"","title":"Classification"},{"location":"ml/classification/#perceptron","text":"Very early learning algorithm that performs simple linear classification between two classes Never converges if training data is not linearly separable z = w^Tx + b g(z) = <script type=\"math/tex; mode=display\">\\begin{cases}1 & z \\geq 0 \\\\ 0 & z < 0\\end{cases} Update rule: \\theta_j := \\theta_j + \\alpha (y^{(i)} - h_\\theta(x^{(i)})x_j^{(i)} Its predictions do not have meaningful probabilistic interpretations Cannot be derived as a maximum likelihood estimation algorithm Forms the basis for multilayer perceptrons (neural networks) Backpropagation is used to train Nonlinear activitaion functions that are part of the network need to be differentiable Perceptron vs Logistic Regression","title":"Perceptron"},{"location":"ml/classification/#logistic-regression","text":"Fisher Scoring- when the log likelihood function is optimizied using multi-dimensional Newton's method \\theta := \\theta - H^{-1} \\nabla_\\theta \\ell(\\theta) H_{ij} = \\frac{\\partial^2 \\ell(\\theta)}{\\partial \\theta_i \\partial \\theta_j} Faster convergence than batch gradient descent but one iteration can be more expensive due to finding and inverting hessian If number of params is small, and therefore hessian is small, then it is usually much faster overall CS 229 Notes","title":"Logistic Regression"},{"location":"ml/classification/#softmax-regression","text":"aka Multinomial Logistic Regression Generalization of logistic regression to C classes If C = 2 then softmax reduces to binary logistic regression Creates linear decision boundaries between classes Adding hidden layers with nonlinear activation functions is what allows NNs to learn nonlinear decision boundaries Applies the softmax activation function to a vector of real numbers to produce a vector of probabilities S(x) = \\frac{e^x}{\\sum_{i =1}^C e^{x_i}} S: \\mathbb{R}^n \\to \\mathbb{R}^n The sum of the output probabilites = 1 Applies the exponetial elementwise to a vector Temperature parameter t is a scalar that x is multiplied by before being passed to the softmax activation 0 < t < 1 moves the probabilities closer together t > 1 moves the probabilites further apart Uses cross entropy loss to train \\mathcal{L}(y, \\hat y) = - \\sum_{j=1}^C y_j \\log \\hat y_j assumes target y uses one-hot encoding (e.g. y^{(i)} = (0, 0, 1, 0)^T ) In order to minimize -\\log \\hat y we need to make \\hat y >> 0 J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(y^{(i)}, \\hat y^{(i)}) Stanford UFLDL DeepLearningAI Video on Softmax Regression","title":"Softmax Regression"},{"location":"ml/classification/#gaussian-discriminant-analysis","text":"","title":"Gaussian Discriminant Analysis"},{"location":"ml/classification/#naive-bayes","text":"Features are discrete unlike the continue features in Gaussian Discriminant Analysis Ex: dictionary of words showing up in an email to classify whether it is spam mispelled words in spam messages to try to get past these dictionaries of possible spam values the feature vector of words that show up in the desired dictionary is considered a bernoulli event model a multinomial event model takes into account the structure of the sentence or how the words appear in order to help prevent stuffing an email with a bunch of hidden good words that help the email get past the spam filter using a bernoulli event model naive bayes is no longer valid the feature vector will now depend on email length laplace mothing based on dictionary size instead of the size of the feature vector","title":"Naive Bayes"},{"location":"ml/classification/#support-vector-machines","text":"","title":"Support Vector Machines"},{"location":"ml/classification/#multiclass-classification","text":"To classify an input into one of k classes, there are two techniques that can be applied to any of the classification methods (logistic regression, perceptron, SVM) ML Mastery","title":"Multiclass Classification"},{"location":"ml/classification/#one-vs-all","text":"aka one-vs-rest For each i = 1, \\dots, k train a binary classifier to succesfully classify y = i . This yields a set of parameters \\theta^{(1)}, \\dots, \\theta^{(k)} To make predictions for x , select the class i that produces the highest value for h_\\theta^{(i)}(x) = (\\theta^{(i)})^Tx","title":"One-vs-All"},{"location":"ml/classification/#one-vs-one","text":"For each class i = 1, \\dots, k train a separate binary classifier to succesfully classify y = i against each other class Results in \\frac{k(k-1)}{2} Classifiers To make predictions for x : Each model may predict a class label for x and the class label with the most votes (most frequently occuring) amongst all the models is the predicted label Each model may predict a probability of a class membership of x , so then the probabilites for each class membership are summed up and the class with the highest probability is the predicted label. Example w/ 4 classes: \u2018 red ,\u2019 \u2018 blue ,\u2019 and \u2018 green ,\u2019 \u2018 yellow .\u2019 This would be divided into six binary classification problems: 1: red vs. blue 2: red vs. green 3: red vs. yellow 4: blue vs. green 5: blue vs. yellow 6: green vs. yellow","title":"One-vs-One"},{"location":"ml/clustering/","text":"Clustering k-means Given a dataset \\{ x^{(1)}, \\cdots, x^{(m)}\\} where x^{(i)} \\in \\mathbb{R}^n Want to create k clusters CS 229 Notes algorithm randomly initialize cluster centroids \\mu_1, \\cdots, \\mu_k \\in \\mathbb{R}^n repeat until convergence for every i , set c^{(i)} := argmin_j ||x^{(i)} - \\mu_j||^2 assign each datapoint to closest cluster centroid for every j , \\mu_j = \\frac{\\sum 1(c^{(i)} = j) x^{(i)}}{\\sum 1(c^{(i)} = j)} move each centroid to the avg position of the datapoints assigned to it convergence guaranteed to converge Distortion Function: J(c, \\mu) = \\sum ||x^{(i)} - \\mu_{c^{(i)}}||^2 Sum of the squared distances between the training samples and their assigned cluster centroid k-means performs coordinate descent on J J is nonconvex so might get trapped in local min can run k-means multiple times with different intializations to escape local mins hierarchical","title":"Clustering"},{"location":"ml/clustering/#clustering","text":"","title":"Clustering"},{"location":"ml/clustering/#k-means","text":"Given a dataset \\{ x^{(1)}, \\cdots, x^{(m)}\\} where x^{(i)} \\in \\mathbb{R}^n Want to create k clusters CS 229 Notes","title":"k-means"},{"location":"ml/clustering/#algorithm","text":"randomly initialize cluster centroids \\mu_1, \\cdots, \\mu_k \\in \\mathbb{R}^n repeat until convergence for every i , set c^{(i)} := argmin_j ||x^{(i)} - \\mu_j||^2 assign each datapoint to closest cluster centroid for every j , \\mu_j = \\frac{\\sum 1(c^{(i)} = j) x^{(i)}}{\\sum 1(c^{(i)} = j)} move each centroid to the avg position of the datapoints assigned to it","title":"algorithm"},{"location":"ml/clustering/#convergence","text":"guaranteed to converge Distortion Function: J(c, \\mu) = \\sum ||x^{(i)} - \\mu_{c^{(i)}}||^2 Sum of the squared distances between the training samples and their assigned cluster centroid k-means performs coordinate descent on J J is nonconvex so might get trapped in local min can run k-means multiple times with different intializations to escape local mins","title":"convergence"},{"location":"ml/clustering/#hierarchical","text":"","title":"hierarchical"},{"location":"ml/dim_red/","text":"Dimensionality Reduction Similar to feature selection in that it reduces the complexity of features being learned different from feature selection in that it finds a smaller set of new features, each being a combination of input features, that contain the same information as the input features (compare to only keeping the most relevant features from the input features like in feature selection) Principal Components Analysis Can model data x \\in \\mathbb{R}^n as approximately lying in some k -dimension subspace where k << d Prior to running PCA, we preprocess the data by normalizing each feature to have mean 0 and variance 1 can be ommmitted if we know different features are on the same scale (e.g. pixels in a grayscale img) Want to compute the major axis of variation (i.e. the direction on which the data approximately lies) find the direction of maximum variance For a given unit vector u and a point x , the length of the porjection of x onto. u Is given by their dot product (e.g. x^T u ). \\textit{proj}_u(x) if x is a point in our dataset, then x^Tu is a distance from the origin we want to maximize: \\begin{align}\\frac{1}{n} \\sum_{i=1}^n (x^T u)^2 &= \\frac{1}{n}\\sum_{i=1}^n (x^T u)^T (x^T u) \\\\ &= \\frac{1}{n}\\sum_{i=1}^n u^T x x^T u \\\\ &= u^T (\\frac{ 1}{n} \\sum_{i=1}^n x x^T)u \\\\ &= u^T \\Sigma u \\end{align} subject to u^T u = 1 (e.g. ||u||_2 = 1 ) gaurantees all basis vectors are orthogonal Def of variance: \\frac{ 1}{n} \\sum_{i=1}^n x x^T = \\sigma^2 We can define the lagragian of this optimization problem as \\mathcal{L}(u, \\lambda) = u^T \\Sigma u - \\lambda (u^T u - 1) \\Sigma \\in \\mathbb{R}^{n \\times n} , u \\in \\mathbb{R}^n \\nabla_u \\mathcal{L}( \\cdot) = \\Sigma u - \\lambda u = 0 yields \\Sigma u = \\lambda u n solutions every time eigenvalues are the solutions \\lambda_1, \\cdots, \\lambda_n to \\det (\\lambda - \\Sigma) = 0 principal eigenvector take the largest |\\lambda_i| and find u_1 s.t. \\Sigma u_1 = \\lambda_1 u_1 repeat to find the 2nd, 3rd, etc. principal eigenvectors z is the new data poiint in reduced space: z = (x^T u_1, \\cdots, x^T u_k)^T where $k << n to cast z back to original space x_{approx} = (z_1 u_1) + \\cdots + z_k u_k = u_k z where each u_i \\in \\mathbb{R}^n","title":"Dimensionality Reduction"},{"location":"ml/dim_red/#dimensionality-reduction","text":"Similar to feature selection in that it reduces the complexity of features being learned different from feature selection in that it finds a smaller set of new features, each being a combination of input features, that contain the same information as the input features (compare to only keeping the most relevant features from the input features like in feature selection)","title":"Dimensionality Reduction"},{"location":"ml/dim_red/#principal-components-analysis","text":"Can model data x \\in \\mathbb{R}^n as approximately lying in some k -dimension subspace where k << d Prior to running PCA, we preprocess the data by normalizing each feature to have mean 0 and variance 1 can be ommmitted if we know different features are on the same scale (e.g. pixels in a grayscale img) Want to compute the major axis of variation (i.e. the direction on which the data approximately lies) find the direction of maximum variance For a given unit vector u and a point x , the length of the porjection of x onto. u Is given by their dot product (e.g. x^T u ). \\textit{proj}_u(x) if x is a point in our dataset, then x^Tu is a distance from the origin we want to maximize: \\begin{align}\\frac{1}{n} \\sum_{i=1}^n (x^T u)^2 &= \\frac{1}{n}\\sum_{i=1}^n (x^T u)^T (x^T u) \\\\ &= \\frac{1}{n}\\sum_{i=1}^n u^T x x^T u \\\\ &= u^T (\\frac{ 1}{n} \\sum_{i=1}^n x x^T)u \\\\ &= u^T \\Sigma u \\end{align} subject to u^T u = 1 (e.g. ||u||_2 = 1 ) gaurantees all basis vectors are orthogonal Def of variance: \\frac{ 1}{n} \\sum_{i=1}^n x x^T = \\sigma^2 We can define the lagragian of this optimization problem as \\mathcal{L}(u, \\lambda) = u^T \\Sigma u - \\lambda (u^T u - 1) \\Sigma \\in \\mathbb{R}^{n \\times n} , u \\in \\mathbb{R}^n \\nabla_u \\mathcal{L}( \\cdot) = \\Sigma u - \\lambda u = 0 yields \\Sigma u = \\lambda u n solutions every time eigenvalues are the solutions \\lambda_1, \\cdots, \\lambda_n to \\det (\\lambda - \\Sigma) = 0 principal eigenvector take the largest |\\lambda_i| and find u_1 s.t. \\Sigma u_1 = \\lambda_1 u_1 repeat to find the 2nd, 3rd, etc. principal eigenvectors z is the new data poiint in reduced space: z = (x^T u_1, \\cdots, x^T u_k)^T where $k << n to cast z back to original space x_{approx} = (z_1 u_1) + \\cdots + z_k u_k = u_k z where each u_i \\in \\mathbb{R}^n","title":"Principal Components Analysis"},{"location":"ml/dts/","text":"Decision Trees Pros Easily explainable Highly interpretable cons low accuracy compared to other methods Cannot deal with additive structure (e,g. diagonal line separating classes) Ensemble Methods Used to improve the accuracy of predictions, especially with decision trees Training different types of algorithms and then averaging their results Training on multiple train sets from the population and then averaging their results Bagging (random forrests) Boosting (Adaboost, Xgboost) Bagging and boosting are most popular ensemble methods since the other two either require collecting more data (oftentimes infeasible) or using more algorithms Bagging Boosting Decreasing bias Additive CS 229 Lecture","title":"Decision Trees"},{"location":"ml/dts/#decision-trees","text":"","title":"Decision Trees"},{"location":"ml/dts/#pros","text":"Easily explainable","title":"Pros"},{"location":"ml/dts/#highly-interpretable","text":"","title":"Highly interpretable"},{"location":"ml/dts/#cons","text":"low accuracy compared to other methods Cannot deal with additive structure (e,g. diagonal line separating classes)","title":"cons"},{"location":"ml/dts/#ensemble-methods","text":"Used to improve the accuracy of predictions, especially with decision trees Training different types of algorithms and then averaging their results Training on multiple train sets from the population and then averaging their results Bagging (random forrests) Boosting (Adaboost, Xgboost) Bagging and boosting are most popular ensemble methods since the other two either require collecting more data (oftentimes infeasible) or using more algorithms","title":"Ensemble Methods"},{"location":"ml/dts/#bagging","text":"","title":"Bagging"},{"location":"ml/dts/#boosting","text":"Decreasing bias Additive CS 229 Lecture","title":"Boosting"},{"location":"ml/feature_scaling/","text":"Feature Scaling Datasets can have features with varying magnitudes, ranges, and units Pre-processing the features can improve model performance decision tree based algorithms are invariant to feature scaling due to making decisions at each node based on a single feature Use when optimizing using gradient desecent (e.g. regressions, NNs) feature value in the cost function derivative and gradient step will cause different step sizes for each feature due to the difference in feature ranges scale the data to ensure params are updated at the same rate for all features similarly scaled features can make it converge faster applying distance based algorithms (e.g. KNN, SVMs) using distance btw data points as a measure of similarity will bias the measure towards higher magnitude features scaling data ensures unbiased measure of similarity Normalization Values are shifted and rescaled to the range [0,1] aka min-max scaling X' = \\frac{X - X_{min}}{X_{max} -X_{min}} where X_{min} and X_{max} are the min and max values of the feature more affected by outliers from sklearn.preprocessing import MinMaxScaler scale = MinMaxScaler().fit(x_train) std_x_train = scale.transform(x_train) std_x_test = scale.transform(x_test) #can also compute the fit and then transform in one step std_x_train = MinMaxScaler().fit_transform(x_train) Use when data is not gaussianly distributed useful in algorithms that don't assume any distribution of the data (KNN, neural nets) Standardization Values are centered around the mean with a unit standard deviation new mean of feature is 0 and new standard deviation is 1 X' = \\frac{X - \\mu}{\\sigma} where \\mu is the mean of that feature's values and \\sigma is the standard deviation values are not restricted to a particular range more robust to outliers from sklearn.preprocessing import StandardScaler scale = StandardScaler().fit(x_train) std_x_train = scale.transform(x_train) std_x_test = scale.transform(x_test) Use when data is gaussianly distributed can be useful in some cases where this isn't true Notes Normalization vs. Standardization depends on the problem and the learning algorithm being used Best practice to scale the training data and use the same values to scale the test set Don't need to scale the target values normally Resources Analytics Vidhya Machine Learning Mastery Scikit-Learn Preprocessing Docs","title":"Feature Scaling"},{"location":"ml/feature_scaling/#feature-scaling","text":"Datasets can have features with varying magnitudes, ranges, and units Pre-processing the features can improve model performance decision tree based algorithms are invariant to feature scaling due to making decisions at each node based on a single feature","title":"Feature Scaling"},{"location":"ml/feature_scaling/#use-when","text":"optimizing using gradient desecent (e.g. regressions, NNs) feature value in the cost function derivative and gradient step will cause different step sizes for each feature due to the difference in feature ranges scale the data to ensure params are updated at the same rate for all features similarly scaled features can make it converge faster applying distance based algorithms (e.g. KNN, SVMs) using distance btw data points as a measure of similarity will bias the measure towards higher magnitude features scaling data ensures unbiased measure of similarity","title":"Use when"},{"location":"ml/feature_scaling/#normalization","text":"Values are shifted and rescaled to the range [0,1] aka min-max scaling X' = \\frac{X - X_{min}}{X_{max} -X_{min}} where X_{min} and X_{max} are the min and max values of the feature more affected by outliers from sklearn.preprocessing import MinMaxScaler scale = MinMaxScaler().fit(x_train) std_x_train = scale.transform(x_train) std_x_test = scale.transform(x_test) #can also compute the fit and then transform in one step std_x_train = MinMaxScaler().fit_transform(x_train)","title":"Normalization"},{"location":"ml/feature_scaling/#use-when_1","text":"data is not gaussianly distributed useful in algorithms that don't assume any distribution of the data (KNN, neural nets)","title":"Use when"},{"location":"ml/feature_scaling/#standardization","text":"Values are centered around the mean with a unit standard deviation new mean of feature is 0 and new standard deviation is 1 X' = \\frac{X - \\mu}{\\sigma} where \\mu is the mean of that feature's values and \\sigma is the standard deviation values are not restricted to a particular range more robust to outliers from sklearn.preprocessing import StandardScaler scale = StandardScaler().fit(x_train) std_x_train = scale.transform(x_train) std_x_test = scale.transform(x_test)","title":"Standardization"},{"location":"ml/feature_scaling/#use-when_2","text":"data is gaussianly distributed can be useful in some cases where this isn't true","title":"Use when"},{"location":"ml/feature_scaling/#notes","text":"Normalization vs. Standardization depends on the problem and the learning algorithm being used Best practice to scale the training data and use the same values to scale the test set Don't need to scale the target values normally","title":"Notes"},{"location":"ml/feature_scaling/#resources","text":"Analytics Vidhya Machine Learning Mastery Scikit-Learn Preprocessing Docs","title":"Resources"},{"location":"ml/model_selection/","text":"Model Selection Learning algorithms have many different hyperparameters that can be tuned We want to select the hyperparameters that lead to the best models We utilize algorithms to perform an optimizing search in the space of possible models to determine the bset one Given a set of models M = \\{M_1, \\dots \\} Cross Validation Hold-Out (Simple) Hold-out cross validation (aka simple cross validation): Randomly slit the train set S into a S_{train} and S_{cv} (the hold-out cross validation set) Train each model M_i on S_{train} to get a hypothesis h_i Select h_i with the smallest error on the hold out cross validation set S_{cv} Can optionally retrain the best model h_i on the entire train set S Even then, we are still selecting best model based on 0.8m training examples rather than m Wastes some of the dataset on holding out- bad for situations with scare data (e.g. m =20 ) k-fold Holds out less data compared to simple cv Randomly split train set S into k disjoint subsets S_1, \\dots, S_k of m / k training examples each For each model M_i evaluate: for each of the k folds, hold out S_j and train the model on all the other folds test the hypothesis h_{ij} on S_j to get the error the estimated generalization error of model M_i is the average of the errors over each if the k tests Pick the model M_i with the lowest estimated generalization error and retrain the model on the entire training set S . The resulting hypothesis is our final output Typical choice is k =10 Computationally more expensive than hold-out since we need to train each model k times Leave-one-out Useful for when data is scare Perform k-fold cross validation where k = m in order to leave out as little data as possible each time Holds out one training example each time and then averages together the resulting m = k errors to get an estimate for the generalization error of a model Nested Cross Validation Used to do model hyperparameter optimization and model selection at the same time while avoiding overfitting the training data k-fold CV for model hyperparam optimization is nested inside th k-fold CV for model selection this prevents hyperparam search from overfitting the dataset since it is exposed to only a subset of the data provided by the outer CV procedure Very computationally expensive Feature Selection If n >> m , its best to reduce the number of features to learn from Reducing the number of input variables to produce simpler models simpler models = more explainable since decisions are made based on less features Reduces overfitting Reduces training time/compute time For n features, there are 2^n possible feature subsets Each of the n features can be included or excluded from the subset Feature selection can be viewed as a model selection problem over 2^n possible models For large n , its too expensive to compare all 2^n models explicitly Therefore, a heuristic search procedure is used to find a good feature subset Wrapper Procedure that wraps your learning algorithm Dependent on the algorithm you are selecting features for Different learning algorithms may have different best features from the same wrapper algorithm More computationally expensive O(n^2) calls to learning algorithm Forward Search Makes assumption that best answer is a small set of features, likely those that come first Order the features are specified in matters Unable to remove feature Define feature set F = \\empty to be the indices of the features that matter Repeat until |F| = n or |F| > max features: For each feature i = 1, \\dots, n : train a model using F \\cup \\{i\\} measure the generalization using some version of cross validation Set F to be the best feature subset found in the previous step Backward Search Makes assumption that best answer is a near full set of the features Spends most time checking large subsets Cannot reinstate removed features Define feature set F = \\{1, \\dots, n \\} Repeat until |F| = \\empty : For each feature i = 1, \\dots, n : train a model using F \\setminus \\{i\\} measure the generalization using some version of cross validation Set F to be the best feature subset found in the previous step Filter Computationally cheaper than wrapper method Compute a score on the data that measures the effectiveness Indepedent of the underyling learning algorithm in determining most important features Define some score S(j) which measure how informative feature j is for the output Choose the features with the largest scores This heuristic for selecting intital features can be used to select an initial set of features to use with forward and backward search Example heuristics: mutual infromation absolute value of the correletion Mutual Information Common scoring heuristic (especially for discrete-valued features) Can be expressed as Kullback-Leibler (KL) divergence which measures the difference between two probability distributions Resources Feature Selection (ML Mastery)","title":"Model Selection"},{"location":"ml/model_selection/#model-selection","text":"Learning algorithms have many different hyperparameters that can be tuned We want to select the hyperparameters that lead to the best models We utilize algorithms to perform an optimizing search in the space of possible models to determine the bset one Given a set of models M = \\{M_1, \\dots \\}","title":"Model Selection"},{"location":"ml/model_selection/#cross-validation","text":"","title":"Cross Validation"},{"location":"ml/model_selection/#hold-out-simple","text":"Hold-out cross validation (aka simple cross validation): Randomly slit the train set S into a S_{train} and S_{cv} (the hold-out cross validation set) Train each model M_i on S_{train} to get a hypothesis h_i Select h_i with the smallest error on the hold out cross validation set S_{cv} Can optionally retrain the best model h_i on the entire train set S Even then, we are still selecting best model based on 0.8m training examples rather than m Wastes some of the dataset on holding out- bad for situations with scare data (e.g. m =20 )","title":"Hold-Out (Simple)"},{"location":"ml/model_selection/#k-fold","text":"Holds out less data compared to simple cv Randomly split train set S into k disjoint subsets S_1, \\dots, S_k of m / k training examples each For each model M_i evaluate: for each of the k folds, hold out S_j and train the model on all the other folds test the hypothesis h_{ij} on S_j to get the error the estimated generalization error of model M_i is the average of the errors over each if the k tests Pick the model M_i with the lowest estimated generalization error and retrain the model on the entire training set S . The resulting hypothesis is our final output Typical choice is k =10 Computationally more expensive than hold-out since we need to train each model k times","title":"k-fold"},{"location":"ml/model_selection/#leave-one-out","text":"Useful for when data is scare Perform k-fold cross validation where k = m in order to leave out as little data as possible each time Holds out one training example each time and then averages together the resulting m = k errors to get an estimate for the generalization error of a model","title":"Leave-one-out"},{"location":"ml/model_selection/#nested-cross-validation","text":"Used to do model hyperparameter optimization and model selection at the same time while avoiding overfitting the training data k-fold CV for model hyperparam optimization is nested inside th k-fold CV for model selection this prevents hyperparam search from overfitting the dataset since it is exposed to only a subset of the data provided by the outer CV procedure Very computationally expensive","title":"Nested Cross Validation"},{"location":"ml/model_selection/#feature-selection","text":"If n >> m , its best to reduce the number of features to learn from Reducing the number of input variables to produce simpler models simpler models = more explainable since decisions are made based on less features Reduces overfitting Reduces training time/compute time For n features, there are 2^n possible feature subsets Each of the n features can be included or excluded from the subset Feature selection can be viewed as a model selection problem over 2^n possible models For large n , its too expensive to compare all 2^n models explicitly Therefore, a heuristic search procedure is used to find a good feature subset","title":"Feature Selection"},{"location":"ml/model_selection/#wrapper","text":"Procedure that wraps your learning algorithm Dependent on the algorithm you are selecting features for Different learning algorithms may have different best features from the same wrapper algorithm More computationally expensive O(n^2) calls to learning algorithm","title":"Wrapper"},{"location":"ml/model_selection/#forward-search","text":"Makes assumption that best answer is a small set of features, likely those that come first Order the features are specified in matters Unable to remove feature Define feature set F = \\empty to be the indices of the features that matter Repeat until |F| = n or |F| > max features: For each feature i = 1, \\dots, n : train a model using F \\cup \\{i\\} measure the generalization using some version of cross validation Set F to be the best feature subset found in the previous step","title":"Forward Search"},{"location":"ml/model_selection/#backward-search","text":"Makes assumption that best answer is a near full set of the features Spends most time checking large subsets Cannot reinstate removed features Define feature set F = \\{1, \\dots, n \\} Repeat until |F| = \\empty : For each feature i = 1, \\dots, n : train a model using F \\setminus \\{i\\} measure the generalization using some version of cross validation Set F to be the best feature subset found in the previous step","title":"Backward Search"},{"location":"ml/model_selection/#filter","text":"Computationally cheaper than wrapper method Compute a score on the data that measures the effectiveness Indepedent of the underyling learning algorithm in determining most important features Define some score S(j) which measure how informative feature j is for the output Choose the features with the largest scores This heuristic for selecting intital features can be used to select an initial set of features to use with forward and backward search Example heuristics: mutual infromation absolute value of the correletion","title":"Filter"},{"location":"ml/model_selection/#mutual-information","text":"Common scoring heuristic (especially for discrete-valued features) Can be expressed as Kullback-Leibler (KL) divergence which measures the difference between two probability distributions","title":"Mutual Information"},{"location":"ml/model_selection/#resources","text":"Feature Selection (ML Mastery)","title":"Resources"},{"location":"ml/optimization/","text":"Optimization Techniques Gradient Descent Optimization technique (aka steepest descent) Stochastic : cost function for single datapoint before doing a model parameter update take step for each datapoint in dataset may get closer to minimum faster than batch but might never converge and just keep oscillating around the minmum (usually approximations of the minimum are good enough) adaptive learning rate that decreases over time will ensure params converge and dont oscillate around the min preferred when the training set is large Batch : cost function over the entire dataset before doing a model parameter update scan entire dataset before taking step For convex cost functions, gradient descent always converges to the global minimum assuming learning rate is not too large MSE Cost is Convex Proof Momentum- takes average of previous gradients into account this results in less zigzagged trajectory throught the parameter space over the cost function reduces changes in directions that are not useful in moving towards the min since previous gradients will all share a common direction towards the minimizer while less useful directions will tend to cancel, thus we want to generally follow the most followed direction of previous gradients we don't update parameters directly, instead we update the velocity vector very low memory (store 1 previous gradient which encapsulates the effect of gradients before it) and low computational cost but greatly helps convergence v = Bv + (1 - B) gradient_w w = w - alpha * v Gradient Ascent- maximization of a concave function (e.g. maximizing distance btw separation hyperplan and observations) w_{n+1} = w_n + \\alpha \\nabla_w f(w) can apply gradient ascent on -f to get equivalent solution to gradient descent on f using positive log-likelihood: objective function is concave therefore we use gradient ascent using negative log-likelihood: objective function is convex therefore we use gradient descent GD Ascent Coordinate Descent Wiki Advanced Techniques Conjugate Gradient BFGS- iterative method for solving unconstrained nonlinear optimization problems determines descent direction by preconditioning gradient w/ curvature information curvature from a gradually improved approximation of the hessian of the loss function (obtained from gradient evalations via a secant method L-BFGS (limited memory version of BFGS)","title":"Optimization Techniques"},{"location":"ml/optimization/#optimization-techniques","text":"","title":"Optimization Techniques"},{"location":"ml/optimization/#gradient-descent","text":"Optimization technique (aka steepest descent) Stochastic : cost function for single datapoint before doing a model parameter update take step for each datapoint in dataset may get closer to minimum faster than batch but might never converge and just keep oscillating around the minmum (usually approximations of the minimum are good enough) adaptive learning rate that decreases over time will ensure params converge and dont oscillate around the min preferred when the training set is large Batch : cost function over the entire dataset before doing a model parameter update scan entire dataset before taking step For convex cost functions, gradient descent always converges to the global minimum assuming learning rate is not too large MSE Cost is Convex Proof Momentum- takes average of previous gradients into account this results in less zigzagged trajectory throught the parameter space over the cost function reduces changes in directions that are not useful in moving towards the min since previous gradients will all share a common direction towards the minimizer while less useful directions will tend to cancel, thus we want to generally follow the most followed direction of previous gradients we don't update parameters directly, instead we update the velocity vector very low memory (store 1 previous gradient which encapsulates the effect of gradients before it) and low computational cost but greatly helps convergence v = Bv + (1 - B) gradient_w w = w - alpha * v Gradient Ascent- maximization of a concave function (e.g. maximizing distance btw separation hyperplan and observations) w_{n+1} = w_n + \\alpha \\nabla_w f(w) can apply gradient ascent on -f to get equivalent solution to gradient descent on f using positive log-likelihood: objective function is concave therefore we use gradient ascent using negative log-likelihood: objective function is convex therefore we use gradient descent GD Ascent","title":"Gradient Descent"},{"location":"ml/optimization/#coordinate-descent","text":"Wiki","title":"Coordinate Descent"},{"location":"ml/optimization/#advanced-techniques","text":"Conjugate Gradient BFGS- iterative method for solving unconstrained nonlinear optimization problems determines descent direction by preconditioning gradient w/ curvature information curvature from a gradually improved approximation of the hessian of the loss function (obtained from gradient evalations via a secant method L-BFGS (limited memory version of BFGS)","title":"Advanced Techniques"},{"location":"ml/pca/","text":"Singular Value Decomposition Allows us to decompose a data matrix X \\in \\mathbb{R}^{n \\times m} into matrices U \\Sigma V^T . U and V are orothonormal matrices (unitary so UU^T = U^TU = I_{n \\times n} ) Columns of U are \"eigen\" and give us a basis (that retains the variance of X ) that we can represent the column vectors in X in \\Sigma is a diagonal matrix ( \\sigma_1 \\geq \\cdots \\geq \\sigma_m \\geq 0 ). X - each column is a sample U - left singular vectors V - right singular vectors. V^T columns give the mixture of the basis columns in U needed to get the corresponding columns in the data matrix X \\Sigma - singular values (sigmas are ordered by importance) Guaranted to exist and be unique Matlab: [u, s, v] = svd(x); Resources SVD Overview Video Principal Component Analysis Common dimensionality reduction technique Background Math Refresher Variance & Covariance Variance measures the spread of the data variance = sum of (dist from mean)^2 / n Var(X) = \\sigma_X^2 = \\frac{\\sum_{i=1}^n ( x_i - \\mu_X)^2}{n-1} (this is sample variance, population variance has n ) Std Deviation is the square root of variance \\sigma_X = \\sqrt{\\sigma_X^2} For data x \\in \\mathbb{R}^n , you can measure the variance along each dimension by calculating the variance of the components in that dimenson However, variance does not show the whole structure of how multi-dimensional data is distributed so we also use covariance to describe multidimensional data Cov(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] Subtracting by the expected values of X and Y centers the data at (0,0) Can be interpreted as taking the avg of the product of coordinates We define a covariance matrix \\Sigma = <script type=\"math/tex; mode=display\">\\begin{bmatrix} cov(X,X) & cov(X,Y) \\\\cov(Y,X) & cov(Y,Y) \\\\ \\end{bmatrix} = \\begin{bmatrix} var(X) & cov(X,Y) \\\\cov(Y,X) & var(Y) \\\\ \\end{bmatrix} Symmetric since property of covariance is that cov(X,Y) = cov(Y,X) can be n \\times n where covariance of each dimension with itself for a zero-mean matrix X , we \\Sigma = \\frac{1}{n-1} XX^T Eigenvectors & Eigenvalues Eigenvectors of a matrix/linear transform are vectors who maintain the same direction before and after the transformation Eigenvalue is the scalar amount eigenvectors are stretched by imaginary eigenvalues indicate rotation Av = \\lambda v eigenvectors of A - direction of stretch of LT from A eigenvalues of A - magnitude/amt of stretch of LT from A Symmetric matrices have orthogonal eigenvectors and real eigenvalues covariance matrices are always symmetric Tieing them Together We can view the covariance matrix as a linear transformation The eigenvectors of \\Sigma indicate the directions of the variance of the data The eigenvalues of \\Sigma indicate the magnitude of the variance of the data along the direction of the eigenvectors Larger eigenvalues will indicate more variance is captured along the direction of the corresponding eigenvector Covariance Perspective Calculate the covariance matrix \\Sigma of the data Find the eigenvalues and corresponding eigenvectors of the covariance matrix Select the eigenvectors with the largest eigenvalues to be the basis of a smaller subspace to represent the data Eigenvectors w/ largest eigenvalues represent the directions in which the most variance of the data is capture In order to accurately represent the data in lower dimensional space, we want to preserve as much of the original variance as possible Can select a new basis based on desired dimension of the subspace or based on how much variance you want preserved (e.g. 80%) sum of eigenvalues of current selected eigenvectors / sum of all eigenvalues = variance preserved in current subspace sum of eigenvalues should equal the sum along the diagonal of the covariance matrix (sum of variability in dataset) SVD Perspective Statistical Interpretation of SVD Gives us a heirirachial coordiante system (based on data) want to uncover dominant combinations of features that describe the data as much as possible X - each row is a sample assumption of gaussian distribution for the data compute mean row and make a giant mean matrix X' out of it that is the same size as X subtract the mean from the data matrix to get the mean centered matrix \\Beta = X - X' centers data at the origin Covariance matrix ( \\Sigma in SVD) of rows of \\Beta : C = \\Beta^T \\Beta Takeaway: Can compute principal components and loadings from the SVD of your mean subtracted data principal components: T = U \\Sigma Optimization Perspective We want compute the major axis of variation u of a mean normalized dataset \\max_u \\frac{1}{n} \\sum_{i=1}^n (x^{(i)^T} u)^2 subject to ||u||_2 = 1 x^Tu is the distance/variation from the origin (assumes the data's mean is at the origin) so we want to maximize it for all samples, subject to the constraint of u being a unit vector the problem expands to: \\max_u \\frac{1}{n} u^T \\Sigma u subject to u^Tu = 1 Can be solved using the method of lagrange multiplier to yield \\Sigma u = \\lambda u This means the top k eigenvectors of \\Sigma \\in \\mathbb{R}^{n \\times n} are the principal components that form a new orthogonal basis for the data in \\mathbb{R}^k Given x \\in \\mathbb{R}^n where n >> k , we can represent it in \\mathbb{R}^k using the k principal components u_i \\in \\mathbb{R}^n <script type=\"math/tex; mode=display\">\\begin{bmatrix} u_1^Tx \\\\ \\vdots \\\\ u_k^T x\\end{bmatrix} \\in \\mathbb{R}^k Applications Noise Reduction Image Compression Resources PCA using SVD Video PCA Intuition Video Covariance Matrix Relationship btw SVD & PCA Tutorial on PCA CS 229 Notes","title":"PCA"},{"location":"ml/pca/#singular-value-decomposition","text":"Allows us to decompose a data matrix X \\in \\mathbb{R}^{n \\times m} into matrices U \\Sigma V^T . U and V are orothonormal matrices (unitary so UU^T = U^TU = I_{n \\times n} ) Columns of U are \"eigen\" and give us a basis (that retains the variance of X ) that we can represent the column vectors in X in \\Sigma is a diagonal matrix ( \\sigma_1 \\geq \\cdots \\geq \\sigma_m \\geq 0 ). X - each column is a sample U - left singular vectors V - right singular vectors. V^T columns give the mixture of the basis columns in U needed to get the corresponding columns in the data matrix X \\Sigma - singular values (sigmas are ordered by importance) Guaranted to exist and be unique Matlab: [u, s, v] = svd(x);","title":"Singular Value Decomposition"},{"location":"ml/pca/#resources","text":"SVD Overview Video","title":"Resources"},{"location":"ml/pca/#principal-component-analysis","text":"Common dimensionality reduction technique","title":"Principal Component Analysis"},{"location":"ml/pca/#background-math-refresher","text":"","title":"Background Math Refresher"},{"location":"ml/pca/#variance-covariance","text":"Variance measures the spread of the data variance = sum of (dist from mean)^2 / n Var(X) = \\sigma_X^2 = \\frac{\\sum_{i=1}^n ( x_i - \\mu_X)^2}{n-1} (this is sample variance, population variance has n ) Std Deviation is the square root of variance \\sigma_X = \\sqrt{\\sigma_X^2} For data x \\in \\mathbb{R}^n , you can measure the variance along each dimension by calculating the variance of the components in that dimenson However, variance does not show the whole structure of how multi-dimensional data is distributed so we also use covariance to describe multidimensional data Cov(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] Subtracting by the expected values of X and Y centers the data at (0,0) Can be interpreted as taking the avg of the product of coordinates We define a covariance matrix \\Sigma = <script type=\"math/tex; mode=display\">\\begin{bmatrix} cov(X,X) & cov(X,Y) \\\\cov(Y,X) & cov(Y,Y) \\\\ \\end{bmatrix} = \\begin{bmatrix} var(X) & cov(X,Y) \\\\cov(Y,X) & var(Y) \\\\ \\end{bmatrix} Symmetric since property of covariance is that cov(X,Y) = cov(Y,X) can be n \\times n where covariance of each dimension with itself for a zero-mean matrix X , we \\Sigma = \\frac{1}{n-1} XX^T","title":"Variance &amp; Covariance"},{"location":"ml/pca/#eigenvectors-eigenvalues","text":"Eigenvectors of a matrix/linear transform are vectors who maintain the same direction before and after the transformation Eigenvalue is the scalar amount eigenvectors are stretched by imaginary eigenvalues indicate rotation Av = \\lambda v eigenvectors of A - direction of stretch of LT from A eigenvalues of A - magnitude/amt of stretch of LT from A Symmetric matrices have orthogonal eigenvectors and real eigenvalues covariance matrices are always symmetric","title":"Eigenvectors &amp; Eigenvalues"},{"location":"ml/pca/#tieing-them-together","text":"We can view the covariance matrix as a linear transformation The eigenvectors of \\Sigma indicate the directions of the variance of the data The eigenvalues of \\Sigma indicate the magnitude of the variance of the data along the direction of the eigenvectors Larger eigenvalues will indicate more variance is captured along the direction of the corresponding eigenvector","title":"Tieing them Together"},{"location":"ml/pca/#covariance-perspective","text":"Calculate the covariance matrix \\Sigma of the data Find the eigenvalues and corresponding eigenvectors of the covariance matrix Select the eigenvectors with the largest eigenvalues to be the basis of a smaller subspace to represent the data Eigenvectors w/ largest eigenvalues represent the directions in which the most variance of the data is capture In order to accurately represent the data in lower dimensional space, we want to preserve as much of the original variance as possible Can select a new basis based on desired dimension of the subspace or based on how much variance you want preserved (e.g. 80%) sum of eigenvalues of current selected eigenvectors / sum of all eigenvalues = variance preserved in current subspace sum of eigenvalues should equal the sum along the diagonal of the covariance matrix (sum of variability in dataset)","title":"Covariance Perspective"},{"location":"ml/pca/#svd-perspective","text":"Statistical Interpretation of SVD Gives us a heirirachial coordiante system (based on data) want to uncover dominant combinations of features that describe the data as much as possible X - each row is a sample assumption of gaussian distribution for the data compute mean row and make a giant mean matrix X' out of it that is the same size as X subtract the mean from the data matrix to get the mean centered matrix \\Beta = X - X' centers data at the origin Covariance matrix ( \\Sigma in SVD) of rows of \\Beta : C = \\Beta^T \\Beta Takeaway: Can compute principal components and loadings from the SVD of your mean subtracted data principal components: T = U \\Sigma","title":"SVD Perspective"},{"location":"ml/pca/#optimization-perspective","text":"We want compute the major axis of variation u of a mean normalized dataset \\max_u \\frac{1}{n} \\sum_{i=1}^n (x^{(i)^T} u)^2 subject to ||u||_2 = 1 x^Tu is the distance/variation from the origin (assumes the data's mean is at the origin) so we want to maximize it for all samples, subject to the constraint of u being a unit vector the problem expands to: \\max_u \\frac{1}{n} u^T \\Sigma u subject to u^Tu = 1 Can be solved using the method of lagrange multiplier to yield \\Sigma u = \\lambda u This means the top k eigenvectors of \\Sigma \\in \\mathbb{R}^{n \\times n} are the principal components that form a new orthogonal basis for the data in \\mathbb{R}^k Given x \\in \\mathbb{R}^n where n >> k , we can represent it in \\mathbb{R}^k using the k principal components u_i \\in \\mathbb{R}^n <script type=\"math/tex; mode=display\">\\begin{bmatrix} u_1^Tx \\\\ \\vdots \\\\ u_k^T x\\end{bmatrix} \\in \\mathbb{R}^k","title":"Optimization Perspective"},{"location":"ml/pca/#applications","text":"Noise Reduction Image Compression","title":"Applications"},{"location":"ml/pca/#resources_1","text":"PCA using SVD Video PCA Intuition Video Covariance Matrix Relationship btw SVD & PCA Tutorial on PCA CS 229 Notes","title":"Resources"},{"location":"ml/regression/","text":"Regression Simple Linear Regression Probabilistic Interpretation Multiple Linear Regression Polynomial Regression Scikit Learn Provides two approaches LinearRegression object- uses ordinary least squares solver from scipy to compite the closed form solution If enough memory for the matrices and inversions, this method is faster and easier SGDRegressor object- generic implementation of stochastic gradient descent so must set loss to L2 for linear regression penality to none for linear regression or L2 for ridge regression (this is the regularization mode) behaves better if loss function can be decomposed into additive terms Locally Weighted Linear Regression For a given query point x \\in \\mathbb{R}^n , we compute the weights of all other training points and use these weights to compute the optimal parameters \\theta \\in \\mathbb{R}^n . Each training sample has a weight w^{(i)} = \\exp (-\\frac{(x^{(i)} - x)^2}{2 \\tau^2}) The weights for the each training sample are placed along the diagonal of a matrix of zeros W \\in \\mathbb{R}^{m \\times m} Optimal parameters can be calculated using the closed form equation for ordinary least squares: \\theta = (X^T W X )^{-1} X^T Wy Must be recomputed for each new query point since the weights change for each query point (computationally expensive) h_\\theta(x) = \\theta^T x = x^T \\theta where x \\in \\mathbb{R}^n Note that the intercept term of x_0 = 1 is not used in LWLR \\tau is the bandwith parameter Increasing \\tau gives more equal weighting to all training samples, resulting in more underfitting Decreasing \\tau gives more weighting to nearby training samples, resulting in more overfitting","title":"Regression"},{"location":"ml/regression/#regression","text":"","title":"Regression"},{"location":"ml/regression/#simple-linear-regression","text":"","title":"Simple Linear Regression"},{"location":"ml/regression/#probabilistic-interpretation","text":"","title":"Probabilistic Interpretation"},{"location":"ml/regression/#multiple-linear-regression","text":"","title":"Multiple Linear Regression"},{"location":"ml/regression/#polynomial-regression","text":"","title":"Polynomial Regression"},{"location":"ml/regression/#scikit-learn","text":"Provides two approaches LinearRegression object- uses ordinary least squares solver from scipy to compite the closed form solution If enough memory for the matrices and inversions, this method is faster and easier SGDRegressor object- generic implementation of stochastic gradient descent so must set loss to L2 for linear regression penality to none for linear regression or L2 for ridge regression (this is the regularization mode) behaves better if loss function can be decomposed into additive terms","title":"Scikit Learn"},{"location":"ml/regression/#locally-weighted-linear-regression","text":"For a given query point x \\in \\mathbb{R}^n , we compute the weights of all other training points and use these weights to compute the optimal parameters \\theta \\in \\mathbb{R}^n . Each training sample has a weight w^{(i)} = \\exp (-\\frac{(x^{(i)} - x)^2}{2 \\tau^2}) The weights for the each training sample are placed along the diagonal of a matrix of zeros W \\in \\mathbb{R}^{m \\times m} Optimal parameters can be calculated using the closed form equation for ordinary least squares: \\theta = (X^T W X )^{-1} X^T Wy Must be recomputed for each new query point since the weights change for each query point (computationally expensive) h_\\theta(x) = \\theta^T x = x^T \\theta where x \\in \\mathbb{R}^n Note that the intercept term of x_0 = 1 is not used in LWLR \\tau is the bandwith parameter Increasing \\tau gives more equal weighting to all training samples, resulting in more underfitting Decreasing \\tau gives more weighting to nearby training samples, resulting in more overfitting","title":"Locally Weighted Linear Regression"},{"location":"ml/regularization/","text":"Regularization Coursera ML High Bias (underfitting) High variance (overfitting) As \\lambda \\to 0 we tend to overfit the data Larger \\lambda penalizes large weights more Linear Regression Logistic Regression","title":"Regularization"},{"location":"ml/regularization/#regularization","text":"Coursera ML High Bias (underfitting) High variance (overfitting) As \\lambda \\to 0 we tend to overfit the data Larger \\lambda penalizes large weights more","title":"Regularization"},{"location":"ml/regularization/#linear-regression","text":"","title":"Linear Regression"},{"location":"ml/regularization/#logistic-regression","text":"","title":"Logistic Regression"},{"location":"ml/reinforcement_learning/","text":"Reinforcement Learning The science of learning to make decisions from interaction Differs from other machine learning paradigms in that: No supervision, only a reward signal Feedback can be delayed, not instantaneous Time matters Earlier decisions affect later interactions Sequential decision problems can be solved w/ RL RL is a framework for how to think about these problems as well as a set of algorithms that can be used to solved these problems Core Concepts: Environment Reward Signal External to the learning algorithm even if its internal to the learning system as a whole Agent containing: Agent state Policy Value function (probably) Model (optionally) Rewards A reward R_t is a scalar feedback signal Indicates how well agent is doing at step t The agent's job is to maximize cumulative reward G_t = R_{t+1} + R_{t+2} + ... RL is based on the reward hypothesis Any goal can be formalized as the outcome of maximizing a cumulative reward Dense- reward on every step Sparse- reward only when the desired event happens Can be negative or positive rewads (Carrot vs. Stick in helping train the algorithm) Values Value - the expected cumulative reward from state s States use the v function to find their value v(s) = E[G_t | S_t = s] where G_t = R_{t+1} + R_{t+2} + ... Goal is to maximize value by picking suitable actions Rewards and values define desirability of state or acton Returns and values can be defined recursively G_t = R_{t+1} + G_{t+1} Actions Goal: Select actions to maximize value Actions may have long term consequences meaning rewards may be delayed Might be better to sacrific immediate reward to gain more long-term reward Ex: Financial investments might take months to mature Blocking opponent moves might help winning chances many moves in the future Policy - a mapping from states to actions Action Values It is possible to condition the value on actions q(s,a) = E[G_t | S_t = s, A_t = a] State action pairs use the Q-function to find their value Agent Components Agent State Policy Value Function Model State Actions depend on the state of the agent Both agent and environment may have an internal state In the simplest case, there is only one shared state by the environemnt and agent Often there are multiple (sometimes infinite) different states The agent's state is usually different than the environment's state The agent might not know the full state of the environment Environment State The environment's internal state Usually not visible to the agent May contain lots of irrelevant information if visible Agent State A history is a sequence of observations, action, rewards H_t = O_0,A_0,R_1,O_1,...,O_{t-1},A_{t-1},R_t,O_t The agent state S_t can be constructed from the history and is considerd to be a function of the history S_{t+1} = f(S_t,A_t,R_{t+1},O_{t+1}) where f is a state update function Means the next agent state is dependent on the current agent state, the action taken, the reward, and the observation A simple update function can be concatinating the previous states together to create the current state (Done w/ the Atari game agents by cocatenating frames together since frames are the state) Actions depend on this state Agent state is typically much smaller than the environment state and the full history Fully Observable Environments When the agent sees the full environment state observation = environment state Agent state could just be the observation S_t = O_t = environment state Then the agent is in a Markov Decision Process Ex: Single player board games in which the player can see the entire board Smart Pong is an example of fully observable environment (VERIFY) Markov Decision Processes MDPs provide a useful mathematical framework for talking about many RL topics Easier to reason about than the full problem (long markovian) Limited b/c of markov assumption Def- A decision process is Markov if the future is independent of the past given the present H_t => S_t => H_{t+1} Once the current state ( S_t ) is known , the history ( H_t ) may be thrown away (useful for space consideration) The current state gives enough information for the next state to be predicted The environment state is typically Markov The history is Markov Partially Observable Environments The agent gets parial information A robot w/ camera vision doesn't have its absolute location A poker playing agent only observes public cards Now the observation is not Markov Formally this is a partially observable Markov decision process (POMDP) The environment state can still be markov, but the agent does not know it The state should contain enough information for good policies/value predictions Policy Defines the agent's behavior A map from agent state to action Deterministic Policy - function that outputs an action based on an input agent state Stochastic Policy - a probability of selecting each action in each state Value Function: The actual value function is the expected return V_\\pi(s)=E[G_t|S_t=s,\\pi] = E[R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+... | S_t = s,\\pi] The return has a recursive form since G_t = R_{t+1}+\\gamma G_{t+1} Bellman Equation : V_\\pi (s) = E[R_{t+1} + \\gamma G_{t+1} | S_t = s,A_t \\sim \\pi (s)] where a \\sim \\pi (s) means action a is chosen by policy \\pi in state s Discount Factor ( \\gamma \\in [0,1] ) trades off importance of immediate vs. long-term rewards Closer to 1 means higher importane on immediate rewards (AKA discounting future rewards in favor of immediate rewards) The value depends on the policy Can be used to evaluate desirability of states Can be used to select btw actions","title":"Reinforcement Learning"},{"location":"ml/reinforcement_learning/#reinforcement-learning","text":"The science of learning to make decisions from interaction Differs from other machine learning paradigms in that: No supervision, only a reward signal Feedback can be delayed, not instantaneous Time matters Earlier decisions affect later interactions Sequential decision problems can be solved w/ RL RL is a framework for how to think about these problems as well as a set of algorithms that can be used to solved these problems","title":"Reinforcement Learning"},{"location":"ml/reinforcement_learning/#core-concepts","text":"Environment Reward Signal External to the learning algorithm even if its internal to the learning system as a whole Agent containing: Agent state Policy Value function (probably) Model (optionally)","title":"Core Concepts:"},{"location":"ml/reinforcement_learning/#rewards","text":"A reward R_t is a scalar feedback signal Indicates how well agent is doing at step t The agent's job is to maximize cumulative reward G_t = R_{t+1} + R_{t+2} + ... RL is based on the reward hypothesis Any goal can be formalized as the outcome of maximizing a cumulative reward Dense- reward on every step Sparse- reward only when the desired event happens Can be negative or positive rewads (Carrot vs. Stick in helping train the algorithm)","title":"Rewards"},{"location":"ml/reinforcement_learning/#values","text":"Value - the expected cumulative reward from state s States use the v function to find their value v(s) = E[G_t | S_t = s] where G_t = R_{t+1} + R_{t+2} + ... Goal is to maximize value by picking suitable actions Rewards and values define desirability of state or acton Returns and values can be defined recursively G_t = R_{t+1} + G_{t+1}","title":"Values"},{"location":"ml/reinforcement_learning/#actions","text":"Goal: Select actions to maximize value Actions may have long term consequences meaning rewards may be delayed Might be better to sacrific immediate reward to gain more long-term reward Ex: Financial investments might take months to mature Blocking opponent moves might help winning chances many moves in the future Policy - a mapping from states to actions","title":"Actions"},{"location":"ml/reinforcement_learning/#action-values","text":"It is possible to condition the value on actions q(s,a) = E[G_t | S_t = s, A_t = a] State action pairs use the Q-function to find their value","title":"Action Values"},{"location":"ml/reinforcement_learning/#agent-components","text":"Agent State Policy Value Function Model","title":"Agent Components"},{"location":"ml/reinforcement_learning/#state","text":"Actions depend on the state of the agent Both agent and environment may have an internal state In the simplest case, there is only one shared state by the environemnt and agent Often there are multiple (sometimes infinite) different states The agent's state is usually different than the environment's state The agent might not know the full state of the environment","title":"State"},{"location":"ml/reinforcement_learning/#environment-state","text":"The environment's internal state Usually not visible to the agent May contain lots of irrelevant information if visible","title":"Environment State"},{"location":"ml/reinforcement_learning/#agent-state","text":"A history is a sequence of observations, action, rewards H_t = O_0,A_0,R_1,O_1,...,O_{t-1},A_{t-1},R_t,O_t The agent state S_t can be constructed from the history and is considerd to be a function of the history S_{t+1} = f(S_t,A_t,R_{t+1},O_{t+1}) where f is a state update function Means the next agent state is dependent on the current agent state, the action taken, the reward, and the observation A simple update function can be concatinating the previous states together to create the current state (Done w/ the Atari game agents by cocatenating frames together since frames are the state) Actions depend on this state Agent state is typically much smaller than the environment state and the full history","title":"Agent State"},{"location":"ml/reinforcement_learning/#fully-observable-environments","text":"When the agent sees the full environment state observation = environment state Agent state could just be the observation S_t = O_t = environment state Then the agent is in a Markov Decision Process Ex: Single player board games in which the player can see the entire board Smart Pong is an example of fully observable environment (VERIFY)","title":"Fully Observable Environments"},{"location":"ml/reinforcement_learning/#markov-decision-processes","text":"MDPs provide a useful mathematical framework for talking about many RL topics Easier to reason about than the full problem (long markovian) Limited b/c of markov assumption Def- A decision process is Markov if the future is independent of the past given the present H_t => S_t => H_{t+1} Once the current state ( S_t ) is known , the history ( H_t ) may be thrown away (useful for space consideration) The current state gives enough information for the next state to be predicted The environment state is typically Markov The history is Markov","title":"Markov Decision Processes"},{"location":"ml/reinforcement_learning/#partially-observable-environments","text":"The agent gets parial information A robot w/ camera vision doesn't have its absolute location A poker playing agent only observes public cards Now the observation is not Markov Formally this is a partially observable Markov decision process (POMDP) The environment state can still be markov, but the agent does not know it The state should contain enough information for good policies/value predictions","title":"Partially Observable Environments"},{"location":"ml/reinforcement_learning/#policy","text":"Defines the agent's behavior A map from agent state to action Deterministic Policy - function that outputs an action based on an input agent state Stochastic Policy - a probability of selecting each action in each state","title":"Policy"},{"location":"ml/reinforcement_learning/#value-function","text":"The actual value function is the expected return V_\\pi(s)=E[G_t|S_t=s,\\pi] = E[R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+... | S_t = s,\\pi] The return has a recursive form since G_t = R_{t+1}+\\gamma G_{t+1} Bellman Equation : V_\\pi (s) = E[R_{t+1} + \\gamma G_{t+1} | S_t = s,A_t \\sim \\pi (s)] where a \\sim \\pi (s) means action a is chosen by policy \\pi in state s Discount Factor ( \\gamma \\in [0,1] ) trades off importance of immediate vs. long-term rewards Closer to 1 means higher importane on immediate rewards (AKA discounting future rewards in favor of immediate rewards) The value depends on the policy Can be used to evaluate desirability of states Can be used to select btw actions","title":"Value Function:"},{"location":"ml/statistical_learning/","text":"Statistical Learning Supervised Learning- building a statistical model for prediting/estimating an ouput based on some inputs. Basically is function approximation Regression- predicting continuous or quantitative outputs Least squares was the earliest form Classifiction- predicting discrete/categorial or qualitative outputs Linear discriminant analysis was the earliest form Unsupervised Learning- learn the relationships and strucuture from input data Clustering- want to group datapoints according to similarity Generalized Linear Model- describes a class of stat learning methods including both linear and logistic regression Only linear methods were used till the 80s becuase non-linear relationships were too computationally expensive to fit at the time In the 80s, computational power was sufficient for nonlinear methods to flourish Classification and Regression trees Generalized additive models Neural Networks Support Vector Machines (90s) In stat learning, inputs are referred to as predictors or independent vars (inputs/features in ML/CS) outputs are responses or dependent variables (ouputs/target in ML) Fitting Linear Models Let there be n datapoints where each datapoint has m features. We want to find the optimal parameters for f(x) = a_0 + \\sum_{i=1}^m a_i x_i . Linear regression of single var: model for making predictions is a line in 2D of 2 vars: model is a plane in 3D (for nonlinear models it would be a mesh/surface) of m vars: model is a hyperplane in the m+1 dimensional input-output space Least Squares Makes huge assumptions about structure of data and yields stable but possibly inaccurate predictions relies heavily on assumption that a linear model/decision boundary is appropriate low variance, high bias We fit a linear model to a set of training data by minimizing a cost function defined by the residual sum of squares RSS RSS(\\theta) = \\sum_{i=1}^n(y_i - x_i^T\\theta)^2 Vectorized: We can take the gradient of the cost function, set equal to zero and then solve for the parameters This way of computing the optimal paramters for a linear model is known as the normal equation Instead of the normal equation, could use gradient descent algorithm to iteratively find the minimum of the quadratic cost function k-nearest neighbor Makes very mild assumptions about structure of data and yields unstable but accurate predictions no assumptions on the underlying data like in least squares resulting in wiggly, unstable decision boundaries that depend on only a handful of neighboring points high variance, low bias Uses observations in the training set closest to the input to create predictions h(x) = \\frac{1}{k}\\sum_{x_i \\in N_k(x)} y_i N_k(x) is the neighborhood of x defined by the closest k points x_i in the training set Prediction is just the average of the k-closest datapoints in the training set How do we define closeness in building the neighborhood? Euclidean distance is nice Summary these two techniques are very popular (e.g. 1-nearest-neighbor is most used technique in low-dim problems) advancements/improvements: kernel methods use weights that decrease smoothly to zero as the distance increases from the target point (rather than the abrupt 0/1 used by k-nearest neighbors) distance kernels are modified to emphasize some variables more than others in high dimensional spaces Local regression fits linear models by locally weighted least squares Linear models fit to an expanded basis of the original inputs allow arbitrarily complex models idk why you would ever want this neural networks constist of sums of nonlinearly transformed linear models model selection & cross validation Given a good model for our training data, is the prediction's error on unseen data good or bad? k-fold cross validation better than simple train test split for estimating model prediction error divide dataset into k-sets For each subset: use it once as a test set and the other k-1 sets for training and record the results discard the model and start over again End result is k performance measures which can be averaged to get the models overall performance gives insight into which d is best for polynomial fit Common k = \\{2, 5, 10\\} better than hold-out leave one out cross validation (k = m) useful when m is small k = 5 or 10 is a good compromise select d based on training and validation best performer (hold out the test data) train final model on training + validation data and then measure performance on testing data Training Set: fit model to best parameters Validation Set: evaluate model with MSE At the end, retrain and measure performance with test set split into train and test set hold out test set for final evaluation (never used for training/model updates) variety of models with diff hyperparams train on training data and evaluate with validation data once the best model hyperparams have been selected, train on the training and validation data evaluate final model with test data that has never been seen before train, val, test = 60%, 20%, 20% of dataset as you increase d meaning the polynomial becomes more complex, it is able to fit the data better so the training loss will continue going down as d increses since essentially you reach a point where the curve is overfitting the data comparing the train loss to the validation loss and picking the d with the minimum validation loss is the best","title":"Statistical Learning"},{"location":"ml/statistical_learning/#statistical-learning","text":"Supervised Learning- building a statistical model for prediting/estimating an ouput based on some inputs. Basically is function approximation Regression- predicting continuous or quantitative outputs Least squares was the earliest form Classifiction- predicting discrete/categorial or qualitative outputs Linear discriminant analysis was the earliest form Unsupervised Learning- learn the relationships and strucuture from input data Clustering- want to group datapoints according to similarity Generalized Linear Model- describes a class of stat learning methods including both linear and logistic regression Only linear methods were used till the 80s becuase non-linear relationships were too computationally expensive to fit at the time In the 80s, computational power was sufficient for nonlinear methods to flourish Classification and Regression trees Generalized additive models Neural Networks Support Vector Machines (90s) In stat learning, inputs are referred to as predictors or independent vars (inputs/features in ML/CS) outputs are responses or dependent variables (ouputs/target in ML)","title":"Statistical Learning"},{"location":"ml/statistical_learning/#fitting-linear-models","text":"Let there be n datapoints where each datapoint has m features. We want to find the optimal parameters for f(x) = a_0 + \\sum_{i=1}^m a_i x_i . Linear regression of single var: model for making predictions is a line in 2D of 2 vars: model is a plane in 3D (for nonlinear models it would be a mesh/surface) of m vars: model is a hyperplane in the m+1 dimensional input-output space","title":"Fitting Linear Models"},{"location":"ml/statistical_learning/#least-squares","text":"Makes huge assumptions about structure of data and yields stable but possibly inaccurate predictions relies heavily on assumption that a linear model/decision boundary is appropriate low variance, high bias We fit a linear model to a set of training data by minimizing a cost function defined by the residual sum of squares RSS RSS(\\theta) = \\sum_{i=1}^n(y_i - x_i^T\\theta)^2 Vectorized: We can take the gradient of the cost function, set equal to zero and then solve for the parameters This way of computing the optimal paramters for a linear model is known as the normal equation Instead of the normal equation, could use gradient descent algorithm to iteratively find the minimum of the quadratic cost function","title":"Least Squares"},{"location":"ml/statistical_learning/#k-nearest-neighbor","text":"Makes very mild assumptions about structure of data and yields unstable but accurate predictions no assumptions on the underlying data like in least squares resulting in wiggly, unstable decision boundaries that depend on only a handful of neighboring points high variance, low bias Uses observations in the training set closest to the input to create predictions h(x) = \\frac{1}{k}\\sum_{x_i \\in N_k(x)} y_i N_k(x) is the neighborhood of x defined by the closest k points x_i in the training set Prediction is just the average of the k-closest datapoints in the training set How do we define closeness in building the neighborhood? Euclidean distance is nice","title":"k-nearest neighbor"},{"location":"ml/statistical_learning/#summary","text":"these two techniques are very popular (e.g. 1-nearest-neighbor is most used technique in low-dim problems) advancements/improvements: kernel methods use weights that decrease smoothly to zero as the distance increases from the target point (rather than the abrupt 0/1 used by k-nearest neighbors) distance kernels are modified to emphasize some variables more than others in high dimensional spaces Local regression fits linear models by locally weighted least squares Linear models fit to an expanded basis of the original inputs allow arbitrarily complex models idk why you would ever want this neural networks constist of sums of nonlinearly transformed linear models","title":"Summary"},{"location":"ml/statistical_learning/#model-selection-cross-validation","text":"Given a good model for our training data, is the prediction's error on unseen data good or bad? k-fold cross validation better than simple train test split for estimating model prediction error divide dataset into k-sets For each subset: use it once as a test set and the other k-1 sets for training and record the results discard the model and start over again End result is k performance measures which can be averaged to get the models overall performance gives insight into which d is best for polynomial fit Common k = \\{2, 5, 10\\} better than hold-out leave one out cross validation (k = m) useful when m is small k = 5 or 10 is a good compromise select d based on training and validation best performer (hold out the test data) train final model on training + validation data and then measure performance on testing data Training Set: fit model to best parameters Validation Set: evaluate model with MSE At the end, retrain and measure performance with test set split into train and test set hold out test set for final evaluation (never used for training/model updates) variety of models with diff hyperparams train on training data and evaluate with validation data once the best model hyperparams have been selected, train on the training and validation data evaluate final model with test data that has never been seen before train, val, test = 60%, 20%, 20% of dataset as you increase d meaning the polynomial becomes more complex, it is able to fit the data better so the training loss will continue going down as d increses since essentially you reach a point where the curve is overfitting the data comparing the train loss to the validation loss and picking the d with the minimum validation loss is the best","title":"model selection &amp; cross validation"},{"location":"ml/supervised_learning/","text":"Supervised Learning Regression- predicting continuous values Classification- predicting discrete values Function Approximation Function approximation is a technique for estimating an unknown underyling function using observations from the domain and their resulting image. Given a dataset of inputs and outputs, we can assume there is an unkwnown underyling function that maps the inputs to the outputs. We can use supervised learning techniques to approximate this function. Supervised learning achieves this by minimizing the error between predicted outputs and expected outputs from the domain by changing its parameters (the weights of the network). Thus, simple feedforward neural networks can be better thought of as function approximators rather than models of how the brain works. The true function mapping inputs to outputs is referred to as the target function since it is the target of the learning process. Thus, intuitively we can better get a sense of what the function is by observing more input-output data points. The universal approximation theorem states a feedforward NN with a linear output layer and at least 1 hidden layer with a nonlinear activation function can approximate any function mapping between two finite dimensional spaces with any desired non-zero amount of error (provided enough hidden units). Below is an example of y=x^2 being approximated by a simple feedforward NN with 2 hidden layers of 10 nodes with relu activation trained on 100 observations: . Resources Function Approximators","title":"Supervised Learning"},{"location":"ml/supervised_learning/#supervised-learning","text":"Regression- predicting continuous values Classification- predicting discrete values","title":"Supervised Learning"},{"location":"ml/supervised_learning/#function-approximation","text":"Function approximation is a technique for estimating an unknown underyling function using observations from the domain and their resulting image. Given a dataset of inputs and outputs, we can assume there is an unkwnown underyling function that maps the inputs to the outputs. We can use supervised learning techniques to approximate this function. Supervised learning achieves this by minimizing the error between predicted outputs and expected outputs from the domain by changing its parameters (the weights of the network). Thus, simple feedforward neural networks can be better thought of as function approximators rather than models of how the brain works. The true function mapping inputs to outputs is referred to as the target function since it is the target of the learning process. Thus, intuitively we can better get a sense of what the function is by observing more input-output data points. The universal approximation theorem states a feedforward NN with a linear output layer and at least 1 hidden layer with a nonlinear activation function can approximate any function mapping between two finite dimensional spaces with any desired non-zero amount of error (provided enough hidden units). Below is an example of y=x^2 being approximated by a simple feedforward NN with 2 hidden layers of 10 nodes with relu activation trained on 100 observations: .","title":"Function Approximation"},{"location":"ml/supervised_learning/#resources","text":"Function Approximators","title":"Resources"},{"location":"ml/svms/","text":"Kernel Methods Attributes - original input values Features - new set of quantities from the attributes A feature map \\phi maps attributes to features GD update becomes computationally expensive when the features are high dimensional since its computing \\theta := \\theta - \\alpha \\sum_{i=1}^n (y^{(i)} - \\theta^T \\phi(x^{(i)}))\\phi(x^{(i)}) Kernel Trick Avoids computing the explicit mapping needed to allow linear learning algorithms to learn a nonlinear decision boundary Dot products in the high-dimensional feature space can be computed as a kernel function K(x, x') = \\phi (x)^T \\phi(x') thus avoiding the need to actually compute \\phi (x) Kernels Dot products measure similarity of two vectors (tells us how parallel two vectors are) dot product projects a vector onto another and is the length of that projected vector Since kernels replace dot products, they are a similarity measure They are a class of functions (defined by mercer's theorem) that provably correspond to the dot product of some higher dimensional mapping Allow us to replace all dot products in the dual SVM computation with the kernel function that represents the data in a higher dimensional (and linearly separable) feature space Linear Just the basic dot product (no feature mapping) Can be used when the data is already linearly separable Polynomial K(x, x') = (x^Tx' + c )^d where c \\geq 0 and d \\geq 1 are parameters of the kernel. When c = 0 the kernel is called homogeneous Commonly applied to NLP problems with d = 2 (higher d usually results in overfitting on NLP problems) The mapped to feature space is equivalent to that of polynomial regression however the number of parameters to learn is decreased drastically Radial Basis Function / Gaussian K(x, x') = \\exp(-\\gamma || x - x'||^2) where \\gamma = \\frac{1}{2\\sigma^2} is a parameter of the kernel that controls the spread. The RBF kernel projects features into an infinite dimensional Euclidean space which is where it is able to linearly separate any originally nonlinearly seperable data (this is why it performs so well and is so often used) RBF Kernel as Projection into Infinite Dimensional Space Need to do feature scaling before using gaussian kernel Other Specialized to data type: String, Graph, Tree, Wavelet, etc. chi-square cosine similarity Sigmoid: K(x, x') = \\tanh (\\beta x^T x' + a) Support Vector Machines Formulated as an optimization problem to find the optimal parameters The dual form of the optimization problem depends only on the dot product of datapoints (similarity of the training examples) Replacing this dot product with a kernel function allows the algorithm to learn a nonlinear decision boundary in the original input space by projecting the low dimensional features into a higher dimensional feature space where they are linearly separable Using the kernel trick allowsus to leverage the advantages of the feature mapping without the computational costs of computing the mapping for each datapoint The cost function is convex so it guarantees the existance of a global extremum Resources AI Master Kernel SVM MIT Lecture (Great- builds up from basics!) svms want a decision boundary represented by a hyperplane for 2d, our hyperplane will be <w,x> + b = 0 ( w is the normal vector to the hyperplane and b is the bias so our hyperplanes don't have to pass through the origin) thus the decision rule will be h_w(z) = \\text{sign}(<w,x> + b) many possible separating hyperplanes for a given labeled training dataset we want to find the hyperplan that generalzies the best to new data we theorize the hyperplane that is as far away from any training point as possible is the one that generalizes best to the new data we define the margin of a datapoint for a given hyperplane defined by (w,b) to be <x , w> since x 's projection onto the normal of the hyperplane is simply its distance from the hyperplane the geometric margin of a hyperplane (w,b) wrt to a dataset D is the smallest distance from a training point x_i to the hyperplane linearizing the constrinats we want \\text{sign}(<x_i, w> +b ) = \\text{sign}(y_i) so we can multiply them together (if the signs agree, result is positive, otherwise negative) so the constraint for each training point becomes (<x_i, w> + b)y_i \\geq 0 linear constraint since y_i is a constant LHS is called the functional margin sign of the inner product is independent of w 's scaling so it doesn't have to be a unit vector","title":"SVMs"},{"location":"ml/svms/#kernel-methods","text":"Attributes - original input values Features - new set of quantities from the attributes A feature map \\phi maps attributes to features GD update becomes computationally expensive when the features are high dimensional since its computing \\theta := \\theta - \\alpha \\sum_{i=1}^n (y^{(i)} - \\theta^T \\phi(x^{(i)}))\\phi(x^{(i)})","title":"Kernel Methods"},{"location":"ml/svms/#kernel-trick","text":"Avoids computing the explicit mapping needed to allow linear learning algorithms to learn a nonlinear decision boundary Dot products in the high-dimensional feature space can be computed as a kernel function K(x, x') = \\phi (x)^T \\phi(x') thus avoiding the need to actually compute \\phi (x)","title":"Kernel Trick"},{"location":"ml/svms/#kernels","text":"Dot products measure similarity of two vectors (tells us how parallel two vectors are) dot product projects a vector onto another and is the length of that projected vector Since kernels replace dot products, they are a similarity measure They are a class of functions (defined by mercer's theorem) that provably correspond to the dot product of some higher dimensional mapping Allow us to replace all dot products in the dual SVM computation with the kernel function that represents the data in a higher dimensional (and linearly separable) feature space","title":"Kernels"},{"location":"ml/svms/#linear","text":"Just the basic dot product (no feature mapping) Can be used when the data is already linearly separable","title":"Linear"},{"location":"ml/svms/#polynomial","text":"K(x, x') = (x^Tx' + c )^d where c \\geq 0 and d \\geq 1 are parameters of the kernel. When c = 0 the kernel is called homogeneous Commonly applied to NLP problems with d = 2 (higher d usually results in overfitting on NLP problems) The mapped to feature space is equivalent to that of polynomial regression however the number of parameters to learn is decreased drastically","title":"Polynomial"},{"location":"ml/svms/#radial-basis-function-gaussian","text":"K(x, x') = \\exp(-\\gamma || x - x'||^2) where \\gamma = \\frac{1}{2\\sigma^2} is a parameter of the kernel that controls the spread. The RBF kernel projects features into an infinite dimensional Euclidean space which is where it is able to linearly separate any originally nonlinearly seperable data (this is why it performs so well and is so often used) RBF Kernel as Projection into Infinite Dimensional Space Need to do feature scaling before using gaussian kernel","title":"Radial Basis Function / Gaussian"},{"location":"ml/svms/#other","text":"Specialized to data type: String, Graph, Tree, Wavelet, etc. chi-square cosine similarity Sigmoid: K(x, x') = \\tanh (\\beta x^T x' + a)","title":"Other"},{"location":"ml/svms/#support-vector-machines","text":"Formulated as an optimization problem to find the optimal parameters The dual form of the optimization problem depends only on the dot product of datapoints (similarity of the training examples) Replacing this dot product with a kernel function allows the algorithm to learn a nonlinear decision boundary in the original input space by projecting the low dimensional features into a higher dimensional feature space where they are linearly separable Using the kernel trick allowsus to leverage the advantages of the feature mapping without the computational costs of computing the mapping for each datapoint The cost function is convex so it guarantees the existance of a global extremum","title":"Support Vector Machines"},{"location":"ml/svms/#resources","text":"AI Master Kernel SVM MIT Lecture (Great- builds up from basics!)","title":"Resources"},{"location":"ml/svms/#svms","text":"want a decision boundary represented by a hyperplane for 2d, our hyperplane will be <w,x> + b = 0 ( w is the normal vector to the hyperplane and b is the bias so our hyperplanes don't have to pass through the origin) thus the decision rule will be h_w(z) = \\text{sign}(<w,x> + b) many possible separating hyperplanes for a given labeled training dataset we want to find the hyperplan that generalzies the best to new data we theorize the hyperplane that is as far away from any training point as possible is the one that generalizes best to the new data we define the margin of a datapoint for a given hyperplane defined by (w,b) to be <x , w> since x 's projection onto the normal of the hyperplane is simply its distance from the hyperplane the geometric margin of a hyperplane (w,b) wrt to a dataset D is the smallest distance from a training point x_i to the hyperplane linearizing the constrinats we want \\text{sign}(<x_i, w> +b ) = \\text{sign}(y_i) so we can multiply them together (if the signs agree, result is positive, otherwise negative) so the constraint for each training point becomes (<x_i, w> + b)y_i \\geq 0 linear constraint since y_i is a constant LHS is called the functional margin sign of the inner product is independent of w 's scaling so it doesn't have to be a unit vector","title":"svms"},{"location":"multimedia/overview/","text":"Multimedia Overview Video and audio is stored in a compressed state and then decompressed when used Can be lossless compression or lossy compression depending on the encoding algorithm (codec) Compression is an NP-hard problem so approximation algorithms are often used Glossary Spatial Resolution - number of pixels in a single frame higher spatial resolution -> sharper image (more information) Pixel width x pixel height Standard Definition (SD)- 640 x 480 High Definition (HD)- 1280 x 720 Full HD (1080p)- 1920 x 1080 Ultra HD (4k)- 3840 x 2160 Color Depth - the number of bits used to represent the range of possible colors for a single pixel Our eyes can perceive more colors than 8-bit so in-between shades/colors get lost in videos using 8-bit or less color depth Framerate - number of images that make up 1 second of video Measured in frames per second (FPS) 24 FPS- standard for movies (feels smooth and cinematic) technically 23.98 FPS 30 FPS- TV broadcasts 48+ FPS can feel hyper-realistic as if you are there Framerate of a video has a major effect on how it is perceived by audience Raw data / sec = spatial resolution x color depth x frame rate Bitrate - data throughput in terms of bits / second higher bitrate ~ higher quality but larger files Mbps- megabits per second Kbps- kilobits per second bitrate and resolution are not exactly synonymous Resolution vs. Bitrate vs. FPS Video Coding Formats A video coding format is a specification that is implemented by a codec Transcoding - process of transforming an input from one format to another Advanced Video Coding (AVC)/H2.264 --> High Efficiency Video Coding (HEVC)/H.265 25-50% smaller video files at cost of triple the resources to encode Royalties for H.265 VP8 --> VP9 --> AV1 Open source and royalty free Audio Coding Formats MP3- saves space by taking advtange of what our ears do not hear Advnaced Audio Coding (AAC)- most popular and more efficient than MP3 AC-3- multiple audio channels (unlike AAC) Multimedia Contianers Hold the video & audio stream along with any metadata files for things like captions the video and audio are encoded using one of the above formats MP4 and AVI are popular ones Animation Animated films typically 24 FPS Animating on ones- different image for each frame Animating on twos- images are kept for 2 frames more crunchy feel longer and more pronounced poses Spiderman Into the Spiderverse used both animated on ones for faster more skilled seeming shors and on twos for slower more struggling shots used motion smearing instead of blurring to give more comic book feel Spider-man Into the Spiderverse Animation","title":"Overview"},{"location":"multimedia/overview/#multimedia-overview","text":"Video and audio is stored in a compressed state and then decompressed when used Can be lossless compression or lossy compression depending on the encoding algorithm (codec) Compression is an NP-hard problem so approximation algorithms are often used","title":"Multimedia Overview"},{"location":"multimedia/overview/#glossary","text":"Spatial Resolution - number of pixels in a single frame higher spatial resolution -> sharper image (more information) Pixel width x pixel height Standard Definition (SD)- 640 x 480 High Definition (HD)- 1280 x 720 Full HD (1080p)- 1920 x 1080 Ultra HD (4k)- 3840 x 2160 Color Depth - the number of bits used to represent the range of possible colors for a single pixel Our eyes can perceive more colors than 8-bit so in-between shades/colors get lost in videos using 8-bit or less color depth Framerate - number of images that make up 1 second of video Measured in frames per second (FPS) 24 FPS- standard for movies (feels smooth and cinematic) technically 23.98 FPS 30 FPS- TV broadcasts 48+ FPS can feel hyper-realistic as if you are there Framerate of a video has a major effect on how it is perceived by audience Raw data / sec = spatial resolution x color depth x frame rate Bitrate - data throughput in terms of bits / second higher bitrate ~ higher quality but larger files Mbps- megabits per second Kbps- kilobits per second bitrate and resolution are not exactly synonymous Resolution vs. Bitrate vs. FPS","title":"Glossary"},{"location":"multimedia/overview/#video-coding-formats","text":"A video coding format is a specification that is implemented by a codec Transcoding - process of transforming an input from one format to another Advanced Video Coding (AVC)/H2.264 --> High Efficiency Video Coding (HEVC)/H.265 25-50% smaller video files at cost of triple the resources to encode Royalties for H.265 VP8 --> VP9 --> AV1 Open source and royalty free","title":"Video Coding Formats"},{"location":"multimedia/overview/#audio-coding-formats","text":"MP3- saves space by taking advtange of what our ears do not hear Advnaced Audio Coding (AAC)- most popular and more efficient than MP3 AC-3- multiple audio channels (unlike AAC)","title":"Audio Coding Formats"},{"location":"multimedia/overview/#multimedia-contianers","text":"Hold the video & audio stream along with any metadata files for things like captions the video and audio are encoded using one of the above formats MP4 and AVI are popular ones","title":"Multimedia Contianers"},{"location":"multimedia/overview/#animation","text":"Animated films typically 24 FPS Animating on ones- different image for each frame Animating on twos- images are kept for 2 frames more crunchy feel longer and more pronounced poses Spiderman Into the Spiderverse used both animated on ones for faster more skilled seeming shors and on twos for slower more struggling shots used motion smearing instead of blurring to give more comic book feel Spider-man Into the Spiderverse Animation","title":"Animation"},{"location":"multimedia/streaming/","text":"Streaming Two types: On Demand Live Buffered- video segments downloaded to be played Rebuffering Event - the current point of being wathced in the video exceeds the amount of content buffered so the user must wait while the player re-buffers and downloads more of the video Playback Speed - increasing it from 1x to 2x means if the original video is provided at 60 FPS, the video is now only displayed with every other frame, meaning 30 frames are skipped per second (the 60 FPS remains the same, just more content is compressed in these frames since every other frame is removed meaning it takes 120 frames from the original playback speed to show 1 second at 2x playback speed) Pipeline Video encoded to a specific format using a codec A delivery method such as a CDN is used to get the content to a client Client uses a player to download the manifest file with video metadata and subscribe to the appropriate streams for the desired bitrate Note: live video regularly updates the manifest Protocols Protocol- set of rules defining how live video and audio travel through a network HTTP Live Streaming (HLS) most widely used in industry MPEG-Dynamic adaptive streaming over HTTP (MPEG-DASH) international standard Real-Time Messaging Protocol (RTMP) Using HTTP (e.g. 1 and 2) allows use of content delivery network (CDN) to help speed up delivery CDNs have caches located closer to the user that can serve the content faster than fetching it from the source HLS Designed by Apple to deliver videos to their devices wihout having to use Flash Player downloads a .m3u8 manifest file Contains url where each chunk of video encoded in each of the available bitrates is located Allows player to adaptively select the best bitrate for a specific chunk depending on the available bandwith Supported coding formats: audio: AAC and many others video: H.264, H.265 MPEG-DASH agnostic to video/audio coding format Adapative Bitrate Streaming (ABS) A video is published in streams of multiple bitrates Adpative player switches between the bitrates according to the bandwith available to the player Allows a stream to continue playing even during congested/fluctuating bandwith Lower bitrate is usually better than constant rebuffering for a higher bitrate Segmented WebVTT is used for providing subtitles in videos being streamed in chunks Key Performance Indicators (KPIs) Average Throughput Player logs on rebuffering events and dropped bitrate events CDN hit/miss ratio","title":"Streaming"},{"location":"multimedia/streaming/#streaming","text":"Two types: On Demand Live Buffered- video segments downloaded to be played Rebuffering Event - the current point of being wathced in the video exceeds the amount of content buffered so the user must wait while the player re-buffers and downloads more of the video Playback Speed - increasing it from 1x to 2x means if the original video is provided at 60 FPS, the video is now only displayed with every other frame, meaning 30 frames are skipped per second (the 60 FPS remains the same, just more content is compressed in these frames since every other frame is removed meaning it takes 120 frames from the original playback speed to show 1 second at 2x playback speed)","title":"Streaming"},{"location":"multimedia/streaming/#pipeline","text":"Video encoded to a specific format using a codec A delivery method such as a CDN is used to get the content to a client Client uses a player to download the manifest file with video metadata and subscribe to the appropriate streams for the desired bitrate Note: live video regularly updates the manifest","title":"Pipeline"},{"location":"multimedia/streaming/#protocols","text":"Protocol- set of rules defining how live video and audio travel through a network HTTP Live Streaming (HLS) most widely used in industry MPEG-Dynamic adaptive streaming over HTTP (MPEG-DASH) international standard Real-Time Messaging Protocol (RTMP) Using HTTP (e.g. 1 and 2) allows use of content delivery network (CDN) to help speed up delivery CDNs have caches located closer to the user that can serve the content faster than fetching it from the source","title":"Protocols"},{"location":"multimedia/streaming/#hls","text":"Designed by Apple to deliver videos to their devices wihout having to use Flash Player downloads a .m3u8 manifest file Contains url where each chunk of video encoded in each of the available bitrates is located Allows player to adaptively select the best bitrate for a specific chunk depending on the available bandwith Supported coding formats: audio: AAC and many others video: H.264, H.265","title":"HLS"},{"location":"multimedia/streaming/#mpeg-dash","text":"agnostic to video/audio coding format","title":"MPEG-DASH"},{"location":"multimedia/streaming/#adapative-bitrate-streaming-abs","text":"A video is published in streams of multiple bitrates Adpative player switches between the bitrates according to the bandwith available to the player Allows a stream to continue playing even during congested/fluctuating bandwith Lower bitrate is usually better than constant rebuffering for a higher bitrate Segmented WebVTT is used for providing subtitles in videos being streamed in chunks","title":"Adapative Bitrate Streaming (ABS)"},{"location":"multimedia/streaming/#key-performance-indicators-kpis","text":"Average Throughput Player logs on rebuffering events and dropped bitrate events CDN hit/miss ratio","title":"Key Performance Indicators (KPIs)"},{"location":"num_methods/factorization/","text":"Matrix Factorization/Decomposition Method for reducing a matrix into its constituent parts Can simplify complex matrix operations to make more efficient on computers Intro for ML LU Decomposition For a square matrix A \\in \\mathbb{R}^{n \\times n} , A = LU L is the lower triangle matrix U is the upper triangle matrix Other variations exist like LUP decomposition that are more numerically stable and work for more matrices","title":"Matrix Factorization"},{"location":"num_methods/factorization/#matrix-factorizationdecomposition","text":"Method for reducing a matrix into its constituent parts Can simplify complex matrix operations to make more efficient on computers Intro for ML","title":"Matrix Factorization/Decomposition"},{"location":"num_methods/factorization/#lu-decomposition","text":"For a square matrix A \\in \\mathbb{R}^{n \\times n} , A = LU L is the lower triangle matrix U is the upper triangle matrix Other variations exist like LUP decomposition that are more numerically stable and work for more matrices","title":"LU Decomposition"},{"location":"num_methods/lin_alg/","text":"Linear Algebra The column space of a matrix is the span of its column vectors rank(A) = dim(col(A)) elementary row operations are the matrix equivalent to the techniques used in the elimination method for solving systems of linear equations. therefore performing row operations on a matrix does not change the solution set of the corresponding linear equations Variational Viewpoint can recast many problems as optimization problems solvigng Ax = b can be treated as solving \\min_x ||Ax - b||^2","title":"Linear Algebra"},{"location":"num_methods/lin_alg/#linear-algebra","text":"The column space of a matrix is the span of its column vectors rank(A) = dim(col(A)) elementary row operations are the matrix equivalent to the techniques used in the elimination method for solving systems of linear equations. therefore performing row operations on a matrix does not change the solution set of the corresponding linear equations","title":"Linear Algebra"},{"location":"num_methods/lin_alg/#variational-viewpoint","text":"can recast many problems as optimization problems solvigng Ax = b can be treated as solving \\min_x ||Ax - b||^2","title":"Variational Viewpoint"},{"location":"num_methods/math/","text":"Math for ML Inner Products aka dot products Given a euclidean plane with a line L passing through the origin and a unit vector w perpendicular to L (the normal to the line) If you take any vector x , then the dot product x \\cdot w > 0 if x is on the same side of L as w and negative otherwise ( =0 if its on the line) Inner product is a linear function (sum of scalar multiplication) so it can be optimized easily The dot product as a decision rule in any n dimensional space is useful for the Kernel Trick where nonlinearly separable data is trasnformed into a linearly separable space with no additional computational cost since all that is needed in the formulas to make a decision is the dot product Inner Product as Decision Rule Positive Definite Positive definition matrix A has all positive eigenvalues a positive definite matrix means that for a vector x in the first quadrant, applying the transformation to it Ax , would result in a vector still in the first quadrant in other words the maximum angle between the two transformed vectors is < 90 degrees ( \\pi /2 rad)","title":"Important Ideas"},{"location":"num_methods/math/#math-for-ml","text":"","title":"Math for ML"},{"location":"num_methods/math/#inner-products","text":"aka dot products Given a euclidean plane with a line L passing through the origin and a unit vector w perpendicular to L (the normal to the line) If you take any vector x , then the dot product x \\cdot w > 0 if x is on the same side of L as w and negative otherwise ( =0 if its on the line) Inner product is a linear function (sum of scalar multiplication) so it can be optimized easily The dot product as a decision rule in any n dimensional space is useful for the Kernel Trick where nonlinearly separable data is trasnformed into a linearly separable space with no additional computational cost since all that is needed in the formulas to make a decision is the dot product Inner Product as Decision Rule","title":"Inner Products"},{"location":"num_methods/math/#positive-definite","text":"Positive definition matrix A has all positive eigenvalues a positive definite matrix means that for a vector x in the first quadrant, applying the transformation to it Ax , would result in a vector still in the first quadrant in other words the maximum angle between the two transformed vectors is < 90 degrees ( \\pi /2 rad)","title":"Positive Definite"},{"location":"optimization/convergence/","text":"Convergence Analysis We are interested in how fast the error goes to zero for a given iterative optimization method where \\lim_{k \\to \\infty} x_k = x^* . Define the error as e_k = ||x_k - x^*|| . Q-Rate Convergence Q-rate tells us how fast a sequence convergences to a value. x_k \\to x^* with q-rate r if there exists a constant c such that for any sufficiently large k : ||x_{k+1} - x^*|| \\leq c ||x_{k+1} -x_k||^r Also can be represented as ||e_{k+1}|| \\leq c||e_k||^r for sufficiently large k where e is the error btw the current point and optimal point at a given iteration. We can alternatively write that ||e_{k_1}|| = O(e_k) using big-o notation to represent asymptotic growth. Taking the negative logarithm of the error term will give us the number of decimal places of accuracy for that given iteration's approximation. For instance, let e_k = 10^{-6} , then the number of decimal places of accuracy is -\\log_{10}10^{-6} = 6 . We can take the negative logarithm of both sides of the above equation to get: -\\log_{10} e_{k+1} \\geq r (- \\log_{10} e_k) - \\log_{10} c This expression tells us how fast the number of decimal places of accuracy is increasing. Linear rate r = 1 and c < 1 Ex: 1, 1/2 1/4, 1/8, ... -> 0 for r = 1 and c = \\frac{1}{2} Superlinear r = 1 The constant c changes over time: c_k \\to 0 as k \\to 0 Quadratic r = 2 r is large enough that it swamps the effect of c no matter its value Ex: 10^{-1}, 10^{-2}, 10^{-4}, 10^{-8}, \\cdots \\to 0 for r= 2 and c = 1 Q-rate Limit Lemma Suppose r \\geq 1 and L exists where ( L < 1 if r = 1 ) L = \\lim_{k \\to \\infty} \\frac{||x_{k+1} - x^* ||}{||x_k - x^* ||^r} Then x_k \\to x^* with Q-rate r and a constant C > L R-Rate Convergence Tells us how fast the bounds on the error converges to 0. The error has a bounds that has a q-rate convergence x_k \\to x^* with r-rate r if ||e_k || \\leq b_k for all k where b_k \\to 0 with q-rate r Summary Linear: moderate to large c is slow small c is fast Superlinear: fast Quadratic: very fast","title":"Convergence"},{"location":"optimization/convergence/#convergence-analysis","text":"We are interested in how fast the error goes to zero for a given iterative optimization method where \\lim_{k \\to \\infty} x_k = x^* . Define the error as e_k = ||x_k - x^*|| .","title":"Convergence Analysis"},{"location":"optimization/convergence/#q-rate-convergence","text":"Q-rate tells us how fast a sequence convergences to a value. x_k \\to x^* with q-rate r if there exists a constant c such that for any sufficiently large k : ||x_{k+1} - x^*|| \\leq c ||x_{k+1} -x_k||^r Also can be represented as ||e_{k+1}|| \\leq c||e_k||^r for sufficiently large k where e is the error btw the current point and optimal point at a given iteration. We can alternatively write that ||e_{k_1}|| = O(e_k) using big-o notation to represent asymptotic growth. Taking the negative logarithm of the error term will give us the number of decimal places of accuracy for that given iteration's approximation. For instance, let e_k = 10^{-6} , then the number of decimal places of accuracy is -\\log_{10}10^{-6} = 6 . We can take the negative logarithm of both sides of the above equation to get: -\\log_{10} e_{k+1} \\geq r (- \\log_{10} e_k) - \\log_{10} c This expression tells us how fast the number of decimal places of accuracy is increasing.","title":"Q-Rate Convergence"},{"location":"optimization/convergence/#linear","text":"rate r = 1 and c < 1 Ex: 1, 1/2 1/4, 1/8, ... -> 0 for r = 1 and c = \\frac{1}{2}","title":"Linear"},{"location":"optimization/convergence/#superlinear","text":"r = 1 The constant c changes over time: c_k \\to 0 as k \\to 0","title":"Superlinear"},{"location":"optimization/convergence/#quadratic","text":"r = 2 r is large enough that it swamps the effect of c no matter its value Ex: 10^{-1}, 10^{-2}, 10^{-4}, 10^{-8}, \\cdots \\to 0 for r= 2 and c = 1","title":"Quadratic"},{"location":"optimization/convergence/#q-rate-limit-lemma","text":"Suppose r \\geq 1 and L exists where ( L < 1 if r = 1 ) L = \\lim_{k \\to \\infty} \\frac{||x_{k+1} - x^* ||}{||x_k - x^* ||^r} Then x_k \\to x^* with Q-rate r and a constant C > L","title":"Q-rate Limit Lemma"},{"location":"optimization/convergence/#r-rate-convergence","text":"Tells us how fast the bounds on the error converges to 0. The error has a bounds that has a q-rate convergence x_k \\to x^* with r-rate r if ||e_k || \\leq b_k for all k where b_k \\to 0 with q-rate r","title":"R-Rate Convergence"},{"location":"optimization/convergence/#summary","text":"Linear: moderate to large c is slow small c is fast Superlinear: fast Quadratic: very fast","title":"Summary"},{"location":"optimization/method-template/","text":"Method A brief overview including what info of the function is used (1st, 2nd, 3rd derivs, ) and any conditions Method Pros Cons","title":"Method"},{"location":"optimization/method-template/#method","text":"A brief overview including what info of the function is used (1st, 2nd, 3rd derivs, ) and any conditions","title":"Method"},{"location":"optimization/method-template/#method_1","text":"","title":"Method"},{"location":"optimization/method-template/#pros","text":"","title":"Pros"},{"location":"optimization/method-template/#cons","text":"","title":"Cons"},{"location":"optimization/overview/","text":"Overview Optimization is a huge field with a tremendous number of applications. It is also intertwined in ML so that is why its include in the ML notebook. Here is where I will try to keep a working glossary of areas I am being introduced to with a brief overview of what they are. Being able to map out how many pieces of a field fit together greatly helps me when diving deeper into any one area. What is Optimization? Optimizing simply stands for finding the maximum or minimum of a function. This max or min is often subject to a series of constraints. The form of the function being optimized and the constraints being adhered to (e.g. linear, nonlinear, continuous, etc.) determines the type of problem and thus the technique used to solve them. Here is the mathematical definition of an optimization problem: \\min f_0(x) subject to the contraints: f_i(x) \\leq b_i Here is the textbook on convex optimization used for reference. Linear Programming (LP) Optimizing a linear objective/cost function subject to linear equality/inequality constraints Nonlinear Programming (NLP) Optimizing an objective/cost function over a set of real variables subject to system of equations called constraints (more general class that includes LP) Quadtratic Programming (QP) Methods for optimizing a quadtratic objective function subject to linear constraints Sequential Programming Sequential Quadtratic Programming (SQP) Involves solving a series of subproblems where each is a quadratic program Sequential Linear Quadtratic Programming (SLQP) Involves solving a linear program and equality constrained quadratic program at each step Dynamic Programming (DP) Involves breaking down the main optimization problem into simpler sub-problems. The Bellman Equation describes the relationship between the value of the larger problem and the values of the sub-problems Piece Wise Affine Functions (PWAs) Approximates a function using a series of lines in 2D, planes in 3D, & hyperplanes in higher dimensional spaces. While the picture above shows the PWA given a known function, PWAs are most often used when there is a set of datapoints representing the functions inputs and outputs. The task is then to construct a PWA from the data such that it best approximates the true function that is mapping the inputs to the outputs. Once you have a PWA made from your dataset, you can then make predictions on new inputs as to what the true function would map to. Constraints A constraint is a condition of an optimization problem that the solution must satisfy Feasible Set - is the set of candidate solutions that satisfy all constraints A point is infeasible if it does not satisfy a constraint A constraint is binding if an inequality constraint holds with equality at the optimal point i.e. the point is at the edge of the feasible set and cannot move anymore in the direction of the constraint, even if doing so would improve the value of the objective function, since it would move outside the feasible set A constraint is non-binding if the point could be moved in the direction of the constraint i.e. the point is not at the edge of the feasible set and can be moved more in the direction of the constraint, however doing so would not be optimal This can mean under certain conditions that the optimization problem would have the same solution in the absence of the constraint since the objective function's minimum does not push up against the edge of the feasible set Slack Variable A variable added to an inequality constraint to transform it into an equality If the slack variable for a constraint is zero at a point, the constraint is binding there If the slack variable for a constraint is positive at a point, the constraint is non-binding there If the slack variable for a constraint is negative at a point, the point is infeasible as it does not satisfy the constraint (can be thought of as outside the feasible set) Slack variables can never be negative for most interior point and simplex solvers For example, introducing the slack variable y \\geq 0 , the inequality constraint of Ax \\leq b can be transformed into an equality of Ax + y = b Intuition: slack can be thought of like a distance from a candidate solution to the constraint boundary ( y = Ax - b ) A constraint of Ax > b will be transformed into two constraints of s = Ax - b and s > 0 that is used by most solvers Lagrange Multipliers KKT conditions generalize the method of lagrange multipliers and allow inequality constraints","title":"Overview"},{"location":"optimization/overview/#overview","text":"Optimization is a huge field with a tremendous number of applications. It is also intertwined in ML so that is why its include in the ML notebook. Here is where I will try to keep a working glossary of areas I am being introduced to with a brief overview of what they are. Being able to map out how many pieces of a field fit together greatly helps me when diving deeper into any one area.","title":"Overview"},{"location":"optimization/overview/#what-is-optimization","text":"Optimizing simply stands for finding the maximum or minimum of a function. This max or min is often subject to a series of constraints. The form of the function being optimized and the constraints being adhered to (e.g. linear, nonlinear, continuous, etc.) determines the type of problem and thus the technique used to solve them. Here is the mathematical definition of an optimization problem: \\min f_0(x) subject to the contraints: f_i(x) \\leq b_i Here is the textbook on convex optimization used for reference.","title":"What is Optimization?"},{"location":"optimization/overview/#linear-programming-lp","text":"Optimizing a linear objective/cost function subject to linear equality/inequality constraints","title":"Linear Programming (LP)"},{"location":"optimization/overview/#nonlinear-programming-nlp","text":"Optimizing an objective/cost function over a set of real variables subject to system of equations called constraints (more general class that includes LP)","title":"Nonlinear Programming (NLP)"},{"location":"optimization/overview/#quadtratic-programming-qp","text":"Methods for optimizing a quadtratic objective function subject to linear constraints","title":"Quadtratic Programming (QP)"},{"location":"optimization/overview/#sequential-programming","text":"","title":"Sequential Programming"},{"location":"optimization/overview/#sequential-quadtratic-programming-sqp","text":"Involves solving a series of subproblems where each is a quadratic program","title":"Sequential Quadtratic Programming (SQP)"},{"location":"optimization/overview/#sequential-linear-quadtratic-programming-slqp","text":"Involves solving a linear program and equality constrained quadratic program at each step","title":"Sequential Linear Quadtratic Programming (SLQP)"},{"location":"optimization/overview/#dynamic-programming-dp","text":"Involves breaking down the main optimization problem into simpler sub-problems. The Bellman Equation describes the relationship between the value of the larger problem and the values of the sub-problems","title":"Dynamic Programming (DP)"},{"location":"optimization/overview/#piece-wise-affine-functions-pwas","text":"Approximates a function using a series of lines in 2D, planes in 3D, & hyperplanes in higher dimensional spaces. While the picture above shows the PWA given a known function, PWAs are most often used when there is a set of datapoints representing the functions inputs and outputs. The task is then to construct a PWA from the data such that it best approximates the true function that is mapping the inputs to the outputs. Once you have a PWA made from your dataset, you can then make predictions on new inputs as to what the true function would map to.","title":"Piece Wise Affine Functions (PWAs)"},{"location":"optimization/overview/#constraints","text":"A constraint is a condition of an optimization problem that the solution must satisfy Feasible Set - is the set of candidate solutions that satisfy all constraints A point is infeasible if it does not satisfy a constraint A constraint is binding if an inequality constraint holds with equality at the optimal point i.e. the point is at the edge of the feasible set and cannot move anymore in the direction of the constraint, even if doing so would improve the value of the objective function, since it would move outside the feasible set A constraint is non-binding if the point could be moved in the direction of the constraint i.e. the point is not at the edge of the feasible set and can be moved more in the direction of the constraint, however doing so would not be optimal This can mean under certain conditions that the optimization problem would have the same solution in the absence of the constraint since the objective function's minimum does not push up against the edge of the feasible set","title":"Constraints"},{"location":"optimization/overview/#slack-variable","text":"A variable added to an inequality constraint to transform it into an equality If the slack variable for a constraint is zero at a point, the constraint is binding there If the slack variable for a constraint is positive at a point, the constraint is non-binding there If the slack variable for a constraint is negative at a point, the point is infeasible as it does not satisfy the constraint (can be thought of as outside the feasible set) Slack variables can never be negative for most interior point and simplex solvers For example, introducing the slack variable y \\geq 0 , the inequality constraint of Ax \\leq b can be transformed into an equality of Ax + y = b Intuition: slack can be thought of like a distance from a candidate solution to the constraint boundary ( y = Ax - b ) A constraint of Ax > b will be transformed into two constraints of s = Ax - b and s > 0 that is used by most solvers","title":"Slack Variable"},{"location":"optimization/overview/#lagrange-multipliers","text":"KKT conditions generalize the method of lagrange multipliers and allow inequality constraints","title":"Lagrange Multipliers"},{"location":"optimization/steepest-descent/","text":"Steepest Descent Used to find the minimizer of a function f Method Pros Cons","title":"Steepest Descent"},{"location":"optimization/steepest-descent/#steepest-descent","text":"Used to find the minimizer of a function f","title":"Steepest Descent"},{"location":"optimization/steepest-descent/#method","text":"","title":"Method"},{"location":"optimization/steepest-descent/#pros","text":"","title":"Pros"},{"location":"optimization/steepest-descent/#cons","text":"","title":"Cons"},{"location":"optimization/root-methods/bisection/","text":"Bisection Method Uses only g Uses only g = f' where f is an objective function in an optimization problem Roughly equivalent to binary search over a continuous domain instead of over a discerete list Method Choose a starting interval [a_0, b_0] such that g(a_0) g(b_0) < 0 (alternatively x^* \\in [a_0, b_0] where g(x^*) = 0 ) interval should contain the root different signs at the endpoints of the interval implies by the intermediate value theorem that a root exists in between them due to continuity of g Compute g(c_k) where c_k = \\frac{a_k + b_k}{2} (i.e. the midpoint of the interval) Determine the next subinterval [a_{k+1}, b_{k+1}] : If g(a_k) g(c_k) < 0 then a_{k+1} = a_k and b_{k+1} = c_k If g(b_k) g(c_k) < 0 then a_{k+1} = c_k and b_{k+1} = b_k Convergence Actual error is not gauranteed to go down in any iteration Only the bound on error is gauranteed to go down Therefore, we have R-linear convergence with c = 1/2 since the bound on the error is cut in half at each iteration Pros Requires no derivative information of g (only need f' of objective function) Reliable- guaranteed to converge in a predictable way given an initial interval that contains a root Can calculate the min number of iterations required to guarantee an error less than \\epsilon > 0 ( Link ) Cons Slow","title":"Bisection"},{"location":"optimization/root-methods/bisection/#bisection-method","text":"Uses only g Uses only g = f' where f is an objective function in an optimization problem Roughly equivalent to binary search over a continuous domain instead of over a discerete list","title":"Bisection Method"},{"location":"optimization/root-methods/bisection/#method","text":"Choose a starting interval [a_0, b_0] such that g(a_0) g(b_0) < 0 (alternatively x^* \\in [a_0, b_0] where g(x^*) = 0 ) interval should contain the root different signs at the endpoints of the interval implies by the intermediate value theorem that a root exists in between them due to continuity of g Compute g(c_k) where c_k = \\frac{a_k + b_k}{2} (i.e. the midpoint of the interval) Determine the next subinterval [a_{k+1}, b_{k+1}] : If g(a_k) g(c_k) < 0 then a_{k+1} = a_k and b_{k+1} = c_k If g(b_k) g(c_k) < 0 then a_{k+1} = c_k and b_{k+1} = b_k","title":"Method"},{"location":"optimization/root-methods/bisection/#convergence","text":"Actual error is not gauranteed to go down in any iteration Only the bound on error is gauranteed to go down Therefore, we have R-linear convergence with c = 1/2 since the bound on the error is cut in half at each iteration","title":"Convergence"},{"location":"optimization/root-methods/bisection/#pros","text":"Requires no derivative information of g (only need f' of objective function) Reliable- guaranteed to converge in a predictable way given an initial interval that contains a root Can calculate the min number of iterations required to guarantee an error less than \\epsilon > 0 ( Link )","title":"Pros"},{"location":"optimization/root-methods/bisection/#cons","text":"Slow","title":"Cons"},{"location":"optimization/root-methods/newtons/","text":"Newton's Method Finds the root of a function g i.e. finds x such that g(x) = 0 Uses g and g' In the context of optimization where g = f' , we would need first and second derivatives of the cost function f Method Given x_k we will approximate g(x) by the tangent line l_k(x) at x_k . This tangent line is the 1st order taylor polynomial of g at x_k and represents a linear approximation of g . l_k(k) = g(x_k) + g'(x_k)(x - x_k) If we let x_{k+1} solve l_k(x) = 0 we get the equation for the next step in the iterative process of finding the root: x_{k + 1} = x_k - \\frac{g(x_k)}{g'(x_k)} Convergence Q-quadratic convergence The constant C > \\frac{g''(x^*)}{2g'(x^*)} This tells us that that curvature of g around x^* in a scale invariant way Less curvature -> smaller C -> faster convergence. Pros Very fast Cons May diverge or converge to something unexpected Can get misdirected when g' is small (i.e. g is flat) when the cost function f doesn't change very rapidly, g will be flat and newton's method will not perform well due to g'(x_k) \\neq 0 in the denominator of the update step Requires g' which is the second derivative of the cost function in an optimization context, so this can be unfeasible for certain problems or computationally expensive to compute Other Notes Since we are using a linear approximation of g to find its roots, the actual curvature of g affects how fast Newton's method converges. For low curvature, the method is very fast.","title":"Newtons Method"},{"location":"optimization/root-methods/newtons/#newtons-method","text":"Finds the root of a function g i.e. finds x such that g(x) = 0 Uses g and g' In the context of optimization where g = f' , we would need first and second derivatives of the cost function f","title":"Newton's Method"},{"location":"optimization/root-methods/newtons/#method","text":"Given x_k we will approximate g(x) by the tangent line l_k(x) at x_k . This tangent line is the 1st order taylor polynomial of g at x_k and represents a linear approximation of g . l_k(k) = g(x_k) + g'(x_k)(x - x_k) If we let x_{k+1} solve l_k(x) = 0 we get the equation for the next step in the iterative process of finding the root: x_{k + 1} = x_k - \\frac{g(x_k)}{g'(x_k)}","title":"Method"},{"location":"optimization/root-methods/newtons/#convergence","text":"Q-quadratic convergence The constant C > \\frac{g''(x^*)}{2g'(x^*)} This tells us that that curvature of g around x^* in a scale invariant way Less curvature -> smaller C -> faster convergence.","title":"Convergence"},{"location":"optimization/root-methods/newtons/#pros","text":"Very fast","title":"Pros"},{"location":"optimization/root-methods/newtons/#cons","text":"May diverge or converge to something unexpected Can get misdirected when g' is small (i.e. g is flat) when the cost function f doesn't change very rapidly, g will be flat and newton's method will not perform well due to g'(x_k) \\neq 0 in the denominator of the update step Requires g' which is the second derivative of the cost function in an optimization context, so this can be unfeasible for certain problems or computationally expensive to compute","title":"Cons"},{"location":"optimization/root-methods/newtons/#other-notes","text":"Since we are using a linear approximation of g to find its roots, the actual curvature of g affects how fast Newton's method converges. For low curvature, the method is very fast.","title":"Other Notes"},{"location":"optimization/root-methods/regula_falsi/","text":"Regula Falsi Known as the method of false position Only uses g Bracketing method like Bisection to guaranteed to converge Method Construct a secant line using the the two interval endpoints Approximates g l_k(x) = g(a_k) + \\frac{g(b_k) - g(a_k)}{b_k - a_k}(x - a_k) Find the root of the line c_k = \\frac{a_k g(b_k) - b_k g(a_k)}{g(b_k) - g(a_k)} Determine the next subinterval [a_{k+1}, b_{k+1}] : If g(a_k) g(c_k) < 0 then a_{k+1} = a_k and b_{k+1} = c_k If g(b_k) g(c_k) < 0 then a_{k+1} = c_k and b_{k+1} = b_k Convergence Q-Linear convergence c depends on the curvature of g and how close a_0 is to x^* Since we are using a linear approximation of g , less curvature = faster convergence Pros Reliable given the interval encloses x^* Cons Slow convergence with a constant that depends on the curvature of g","title":"Regula Falsi"},{"location":"optimization/root-methods/regula_falsi/#regula-falsi","text":"Known as the method of false position Only uses g Bracketing method like Bisection to guaranteed to converge","title":"Regula Falsi"},{"location":"optimization/root-methods/regula_falsi/#method","text":"Construct a secant line using the the two interval endpoints Approximates g l_k(x) = g(a_k) + \\frac{g(b_k) - g(a_k)}{b_k - a_k}(x - a_k) Find the root of the line c_k = \\frac{a_k g(b_k) - b_k g(a_k)}{g(b_k) - g(a_k)} Determine the next subinterval [a_{k+1}, b_{k+1}] : If g(a_k) g(c_k) < 0 then a_{k+1} = a_k and b_{k+1} = c_k If g(b_k) g(c_k) < 0 then a_{k+1} = c_k and b_{k+1} = b_k","title":"Method"},{"location":"optimization/root-methods/regula_falsi/#convergence","text":"Q-Linear convergence c depends on the curvature of g and how close a_0 is to x^* Since we are using a linear approximation of g , less curvature = faster convergence","title":"Convergence"},{"location":"optimization/root-methods/regula_falsi/#pros","text":"Reliable given the interval encloses x^*","title":"Pros"},{"location":"optimization/root-methods/regula_falsi/#cons","text":"Slow convergence with a constant that depends on the curvature of g","title":"Cons"},{"location":"optimization/root-methods/secant/","text":"Secant Method Finds the root of a function g i.e. finds x such that g(x) = 0 Uses only g Method Use the two most recent points to construct a secant line l_k(x) Compute the root of the secant line to find the next point x_{k+1} = \\frac{x_{k-1}g(x_k) - x_kg(x_{k-1})}{g(x_k) - g(x_{k-1})} equivalent to x_{k+1} = x_k - \\frac{g(x_k)(x_{k-1} - x_k)}{g(x_k) - g(x_{k-1})} numerically less likely to lose preceision Convergence Superlinear convergence with a q-rate of 1.618 (golden ratio) Slower than newton's but faster than bisection and regula falls The constant C > \\frac{g''(x^*)}{2g'(x^*)} This tells us that that curvature of g around x^* in a scale invariant way Less curvature -> smaller C -> faster convergence. Pros Relatively fast Doesn't require g' Cons May diverge or converge to something unexpected Other Notes Since we are using a linear approximation of g to find its roots, the actual curvature of g affects how fast Newton's method converges. For low curvature, the method is very fast.","title":"Secant Method"},{"location":"optimization/root-methods/secant/#secant-method","text":"Finds the root of a function g i.e. finds x such that g(x) = 0 Uses only g","title":"Secant Method"},{"location":"optimization/root-methods/secant/#method","text":"Use the two most recent points to construct a secant line l_k(x) Compute the root of the secant line to find the next point x_{k+1} = \\frac{x_{k-1}g(x_k) - x_kg(x_{k-1})}{g(x_k) - g(x_{k-1})} equivalent to x_{k+1} = x_k - \\frac{g(x_k)(x_{k-1} - x_k)}{g(x_k) - g(x_{k-1})} numerically less likely to lose preceision","title":"Method"},{"location":"optimization/root-methods/secant/#convergence","text":"Superlinear convergence with a q-rate of 1.618 (golden ratio) Slower than newton's but faster than bisection and regula falls The constant C > \\frac{g''(x^*)}{2g'(x^*)} This tells us that that curvature of g around x^* in a scale invariant way Less curvature -> smaller C -> faster convergence.","title":"Convergence"},{"location":"optimization/root-methods/secant/#pros","text":"Relatively fast Doesn't require g'","title":"Pros"},{"location":"optimization/root-methods/secant/#cons","text":"May diverge or converge to something unexpected","title":"Cons"},{"location":"optimization/root-methods/secant/#other-notes","text":"Since we are using a linear approximation of g to find its roots, the actual curvature of g affects how fast Newton's method converges. For low curvature, the method is very fast.","title":"Other Notes"},{"location":"prog_langs/ch1/","text":"Introduction Why so many languages? Evolution- we have learned better ways of doing things over time Special Purposes- many are designed for specific problem domains Diverse Personal Preferences What makes a language successful? Ease of use for novice Expressive Power Ease of implementation Wide dissemination at minimal cost Excellent compilers (possible to quickly compile code to be very small) Backing of a powerful sponsor 1.1 Why Study Concepts of Progamming languages? Increased capacity to express ideas- diff languages have diff constructs Improved background for choosing appropriate languages Increased ability to learn new languages by understanding core concepts underyling all languages Better understanding of the signifigance of implementation (i.e understanding the choices btw language constructs and their consequences) Make it easier to design new languages Better use of languages you already know 1.2 Programming Domains Scientific Applications: large numbers of floating points computations and heavy use of arrays (e.g. Fortran) Business Applications: produce reports, use decimal numbers and characters (e.g. Cobol) AI: Maniuplate symbols rather than numbers and heavy use of linked lists (e.g. Lisp, Scheme (dialect of Lisp), Prolog) Web Software: Collection of different lanugages (markup, general purpose, & scripting) Domain Specific Language (DSL)- a language designed specifically to perform tasks in a certain domain Non-DSL: C, C++, COBOL, Fortran, Java Not small Large expressive power -> not restricted to specific domains DSL: CSS, SQL, UML Can be used by a domain expert who is not necessarily a seasoned programmer Can be created using Xtext framework or other similar tools Fortran was first high level language adopted by many 1.3 Language Evaluation Criteria Writability: simplciity Simplicity and Orthogonality orthogonality- a relatively small set of primitive constructs to build the control and data structures of the language Support for Abstraction Expressivity- a set of relatively convenient ways of specifying operations Strength and number of operators and predefined functions (e.g. Python, Matlab have powerful operators that reduce the amount of code you need to write) Readability Simplicity and orthogonality Minimal feature multiplicity (i.e. having more than one way to accomplish a particular operation) Minimal operating overloading Relative small set of primitive constructs Consistent set of rules for combining the primitive constructs Every possible combination is allowed and meaningful Orthogonality means constructs are independent of each other so there are not excpetions to languages rules like arrays of strings are not allowed but all other data types are Data Types- adequate predefined data types and structures (e.g. boolean instead of using 0 or 1) Syntax Considerations Reliability Type Checking at compile or runtime Preventing a bit-pattern representing one type of data from being interpreted as a different type of data Exception Handling to allow taking corrective measures for runtime error Aliasing is the presence of 2+ distinct referencing methods for the same memory location. This is a dangerous, but common, feature Cost Maintaining programs incurrs costs Poor reliability leads to high costs Portability Java code only needs to compile once and the resulting bytecode (instead of machine code) can be run on any OS with a java runtime system installed C++ is not very portable since the code needs to be recompiled for each architecture Generality: applicability to wide range of applications Well-definedness: the completeness and precision of the language's official definition 1.4 Influences on Language Design Computer Architecture Imperative Languages designed around von Neumann architecture data + programs stored in same memory so instructions and data must be piped to CPU and result piped back to memory (fetch-execute cycle) new paradigm of storing the program in the computer (stored-program computer) Central feature is variables that model memory cells, assignment operations which are based on piping operations Very efficient with iteration since instructions are stored adjacently in memory (thus discourages use of recursion for repetition) Functional Languages Primary means of computation is applying functions to given parameters Programming can be done without the variables, assignment statements, and iteration used in imperative languages Many benefits though they won't displace imperative languages until a non-von neumann computer is design that allows more efficient execution of programs in functional languages Programming Design Methodologies Influences: 50s and early 60s: simple applications worry about machine efficiency late 60s: people efficiency is became more important strucuted programming; top-down design and step-wise refinement (refining code in steps) late 70s: process-orientied to data-oriented data abstraction middle 80s: object-oriented programming data abstraction + inheritance + polymorphism Procedure Oriented (lack of control statements, extensive use of goto statements, incomplete type checking) --> Data Oriented (emphasis on abstract data types to solve problems) -- > Object Oriented New programming languages in the 70s to support data abstraction OOP developed with the new language Smalltalk that supported it Now OOP is feature of most imperative languages and even some functional languages Main Idea: As new programming design methodoligies evolved, languages evolved with them 1.5 Language Categories Imperative- variables, assignment statements, iteration (includes OOP languages and scripting languages) Functional- applying functions to given parameters (purest form is mathematical and has no memory, time, or state) Logic- rule based language where rules are specified in no particular order and the language implementation system chooses the order to apply the rules to produce a result (e.g. Prolog) program statements describe facts and rules computer's job is to construct a proof based on the given facts + rules 1.6 Language Design Tradeoffs Designing a language requires making criteria tradeoffs (e.g. efficiency for reliability with C not checking for in range indices) Conflict between writability and readability is common Reliability vs Cost of Execution 1.7 Implementation Methods Compilation- programs are translated into machine language Slow translation, fast execution when compared to interpretation Translation only occurs once, but program is executed many times Several Steps Lexical Anlaysis- converts characters in source program into lexical units Syntax Analysis- transforms lexical units into parse tree and check syntactic correctness Semantics Analysis- type checking and intermediate code generation (often in an assembly like language) Code Generation- machine code generated Pure Interpretation- programs are interpreted No translation into machine language, code is executed on the fly Rare for traditional high-level languages Pros: Execution is immediate Easier implementation of debugging programs (altough errors are not found until actually executed) Cons: 10 to 100 times slower execution than compiled programs Often requires more space Hybrid-high-level language translated to an intermediate language Translation can catch many errors early Interpeting much simpler byte code --> faster runtime Faster than pure interpretation Ex: Java compiles to intermediate byte code that is machine independent so it can be run on any machine with a run-time system (JVM) Just-in-Time Compilation (aka Dynamic Compilation): Method for improving the performance of interpreted programs During execution of the program, parts of the program that are used frequently may be compiled into native code to improve performance Ex: with java, the JVM runs the bytecode, but for certain functions that might be heavily used, they are compiled into machine code for the specific machine to increase performance Intermediate language (bytecode) methods are translated into machine code when they become hot (i.e. executed more often than a threshold) The machine code is then kept for subsequent calls Compile commonly used parts of program to machine code (e.g. Java, Matlab, .Net languages) Attempts to get the benefits of both an interpret and compiled program Java and C# have runtime environments (JVM, CLR) that can profile a program while it is being run to allow for more optimized code to be generated Many JIT compilers only compile the code paths frequently used to limit overhead of compilation during runtime","title":"Ch. 1 Introduction"},{"location":"prog_langs/ch1/#introduction","text":"Why so many languages? Evolution- we have learned better ways of doing things over time Special Purposes- many are designed for specific problem domains Diverse Personal Preferences What makes a language successful? Ease of use for novice Expressive Power Ease of implementation Wide dissemination at minimal cost Excellent compilers (possible to quickly compile code to be very small) Backing of a powerful sponsor","title":"Introduction"},{"location":"prog_langs/ch1/#11-why-study-concepts-of-progamming-languages","text":"Increased capacity to express ideas- diff languages have diff constructs Improved background for choosing appropriate languages Increased ability to learn new languages by understanding core concepts underyling all languages Better understanding of the signifigance of implementation (i.e understanding the choices btw language constructs and their consequences) Make it easier to design new languages Better use of languages you already know","title":"1.1 Why Study Concepts of Progamming languages?"},{"location":"prog_langs/ch1/#12-programming-domains","text":"Scientific Applications: large numbers of floating points computations and heavy use of arrays (e.g. Fortran) Business Applications: produce reports, use decimal numbers and characters (e.g. Cobol) AI: Maniuplate symbols rather than numbers and heavy use of linked lists (e.g. Lisp, Scheme (dialect of Lisp), Prolog) Web Software: Collection of different lanugages (markup, general purpose, & scripting) Domain Specific Language (DSL)- a language designed specifically to perform tasks in a certain domain Non-DSL: C, C++, COBOL, Fortran, Java Not small Large expressive power -> not restricted to specific domains DSL: CSS, SQL, UML Can be used by a domain expert who is not necessarily a seasoned programmer Can be created using Xtext framework or other similar tools Fortran was first high level language adopted by many","title":"1.2 Programming Domains"},{"location":"prog_langs/ch1/#13-language-evaluation-criteria","text":"Writability: simplciity Simplicity and Orthogonality orthogonality- a relatively small set of primitive constructs to build the control and data structures of the language Support for Abstraction Expressivity- a set of relatively convenient ways of specifying operations Strength and number of operators and predefined functions (e.g. Python, Matlab have powerful operators that reduce the amount of code you need to write) Readability Simplicity and orthogonality Minimal feature multiplicity (i.e. having more than one way to accomplish a particular operation) Minimal operating overloading Relative small set of primitive constructs Consistent set of rules for combining the primitive constructs Every possible combination is allowed and meaningful Orthogonality means constructs are independent of each other so there are not excpetions to languages rules like arrays of strings are not allowed but all other data types are Data Types- adequate predefined data types and structures (e.g. boolean instead of using 0 or 1) Syntax Considerations Reliability Type Checking at compile or runtime Preventing a bit-pattern representing one type of data from being interpreted as a different type of data Exception Handling to allow taking corrective measures for runtime error Aliasing is the presence of 2+ distinct referencing methods for the same memory location. This is a dangerous, but common, feature Cost Maintaining programs incurrs costs Poor reliability leads to high costs Portability Java code only needs to compile once and the resulting bytecode (instead of machine code) can be run on any OS with a java runtime system installed C++ is not very portable since the code needs to be recompiled for each architecture Generality: applicability to wide range of applications Well-definedness: the completeness and precision of the language's official definition","title":"1.3 Language Evaluation Criteria"},{"location":"prog_langs/ch1/#14-influences-on-language-design","text":"Computer Architecture Imperative Languages designed around von Neumann architecture data + programs stored in same memory so instructions and data must be piped to CPU and result piped back to memory (fetch-execute cycle) new paradigm of storing the program in the computer (stored-program computer) Central feature is variables that model memory cells, assignment operations which are based on piping operations Very efficient with iteration since instructions are stored adjacently in memory (thus discourages use of recursion for repetition) Functional Languages Primary means of computation is applying functions to given parameters Programming can be done without the variables, assignment statements, and iteration used in imperative languages Many benefits though they won't displace imperative languages until a non-von neumann computer is design that allows more efficient execution of programs in functional languages Programming Design Methodologies Influences: 50s and early 60s: simple applications worry about machine efficiency late 60s: people efficiency is became more important strucuted programming; top-down design and step-wise refinement (refining code in steps) late 70s: process-orientied to data-oriented data abstraction middle 80s: object-oriented programming data abstraction + inheritance + polymorphism Procedure Oriented (lack of control statements, extensive use of goto statements, incomplete type checking) --> Data Oriented (emphasis on abstract data types to solve problems) -- > Object Oriented New programming languages in the 70s to support data abstraction OOP developed with the new language Smalltalk that supported it Now OOP is feature of most imperative languages and even some functional languages Main Idea: As new programming design methodoligies evolved, languages evolved with them","title":"1.4 Influences on Language Design"},{"location":"prog_langs/ch1/#15-language-categories","text":"Imperative- variables, assignment statements, iteration (includes OOP languages and scripting languages) Functional- applying functions to given parameters (purest form is mathematical and has no memory, time, or state) Logic- rule based language where rules are specified in no particular order and the language implementation system chooses the order to apply the rules to produce a result (e.g. Prolog) program statements describe facts and rules computer's job is to construct a proof based on the given facts + rules","title":"1.5 Language Categories"},{"location":"prog_langs/ch1/#16-language-design-tradeoffs","text":"Designing a language requires making criteria tradeoffs (e.g. efficiency for reliability with C not checking for in range indices) Conflict between writability and readability is common Reliability vs Cost of Execution","title":"1.6 Language Design Tradeoffs"},{"location":"prog_langs/ch1/#17-implementation-methods","text":"Compilation- programs are translated into machine language Slow translation, fast execution when compared to interpretation Translation only occurs once, but program is executed many times Several Steps Lexical Anlaysis- converts characters in source program into lexical units Syntax Analysis- transforms lexical units into parse tree and check syntactic correctness Semantics Analysis- type checking and intermediate code generation (often in an assembly like language) Code Generation- machine code generated Pure Interpretation- programs are interpreted No translation into machine language, code is executed on the fly Rare for traditional high-level languages Pros: Execution is immediate Easier implementation of debugging programs (altough errors are not found until actually executed) Cons: 10 to 100 times slower execution than compiled programs Often requires more space Hybrid-high-level language translated to an intermediate language Translation can catch many errors early Interpeting much simpler byte code --> faster runtime Faster than pure interpretation Ex: Java compiles to intermediate byte code that is machine independent so it can be run on any machine with a run-time system (JVM) Just-in-Time Compilation (aka Dynamic Compilation): Method for improving the performance of interpreted programs During execution of the program, parts of the program that are used frequently may be compiled into native code to improve performance Ex: with java, the JVM runs the bytecode, but for certain functions that might be heavily used, they are compiled into machine code for the specific machine to increase performance Intermediate language (bytecode) methods are translated into machine code when they become hot (i.e. executed more often than a threshold) The machine code is then kept for subsequent calls Compile commonly used parts of program to machine code (e.g. Java, Matlab, .Net languages) Attempts to get the benefits of both an interpret and compiled program Java and C# have runtime environments (JVM, CLR) that can profile a program while it is being run to allow for more optimized code to be generated Many JIT compilers only compile the code paths frequently used to limit overhead of compilation during runtime","title":"1.7 Implementation Methods"},{"location":"prog_langs/ch15/","text":"Functional Languages Lambda expressions describe nameless functions Applied to parameters by placing the parameters after the expression Ex: (\\lambda(x) x * x * x)(2) evaluates to 8 Functional Form Higher order functions lambda expressions are also useful for creating functions to pass as parameters to other functions that expect to receive functions can return other functions Composition of Functions Takes two functions as input and returns a new function that is the result of the 1st function appleid to the second Ex: h := f \\odot g which means h(x) = f(g(x)) Inefficient execution on von neumann machines Simple syntax and semantics Programs written in funtional languages can automatically be made concurrent harder to write concurrent imperative languages LISP History Developed in 1958-59 for use in AI designed @ MIT by John McCarthy Fortran didnt have recursion, the ability to manipulate symbols, and ability to process data in linked lists rather than arrays Based on lambda calculus and mathematical functions Interpreted language with garbage collection Data Types Originally only atoms and lists Type is bound at runtime Names not variables (can't change value of a name after it has been defined) list form- parenthesized collection of atoms and/or sublists Interpretation function defintions, function applications, and data all have the same form (A, B, C) can be interpretted differently depending on the context A can be a function being called with params B and C A can be a function called on B evaluated at C It can be a list of three atoms A , B , C Syntax a series of symbolic expressions (or S-expressions) can be an atom or a list an atom can be a number or a symbol a symbol can be a sequence of characters a number can be integers, floats, or ratio of integers (allows us to maintain accuracy with division) a list is recursively defined in termso of s-expressions Grammar very simple grammar described by a short EBNF <s_expression> -> <atomic_symbol> | \"(\" <s_expression> \".\" <s_expression> \")\" | <list> <list> -> \"(\" <s_expression>* \")\" <atomic_symbol> -> <letter> <atom_part> <atom_part> -> empty | <letter> <atom_part> | <number> <atom_part> <letter> -> \"a\" | \"b\" | ... | \"z\" <number> -> \"1\" | \"2\" | ... | \"9\" Semantics 1st s-expression in a list is the name of a function Ex: (foo) or (foo a b c) in a function call, all arguments are evaluated first, then the function is applied to the result Prefix notation Primitive/Numeric Functions true: #T or #t false #F or #f = , > , < , <= , >= and , or , not equal? , even? , odd? , zero? , negative? , number? abs , sqrt , modulo , remainder , min , max , expt Special Forms Functions that don't evaluate their arguments lambda Expressions describe nameless/anonymous functions functions are first-class entities meaning they can be values of expressions, elements of lists, passed as parameters, and returned from functions functions can b (lambda(x) (* x x)) creates a special lambda function can be called by: ((lambda(x) (* x x)) 8) define 2 uses: bind a symbol to an expression: (define pi 3.14) bind names to lambda expressions (lambda is implicit): (define (square x) (* x x)) if two way selector function (if predicate then_exp else_exp) cond (cond [predicate1 expression1] [predicate2 expression2] ... [else expression]) else clause is optional synonymous with (#t expression) Lists Stored internally as singly-linked lists quote function (abbreviated w/ apostrophe prefix operator) takes one param and returns the param without evaluation '(A B) <=> (quote (A B)) car - returns first element of its list parameter cdr - returns the remainder of the list parameter after removing the 1st element cons - add a new head to the front of a list returns a new list with first argument inserted onto the front of the 2nd argument does not make copy of the second argument list - returns a new list of its parameters (list 'a 'b 'c 'd) -> '(a b c d)' (list '(A B) '(C D)) equivalent to (cons '(A B) (cons '(C D) '())) null? - tests for empty list (null? '()) -> #t (null? null) -> #t list? - tests if the function is a list (list? 'A) -> #f (list? '(A)) -> #t append - returns new list that contains all elements of the two list arguments the arguments must be lists unlike list and cons different result from list function (append '(a b) '(c d)) contractions are useful for doing a lot of work concisely (cadr lst) equivalent to (car (cdr lst) (i.e. getting 2nd element) (cdddr lst) equivalent to (cdr (cdr (cdr lst))) (i.e. removing first 3 elements) length - returns the length of a list Lists are processed in a recursive fashion process head of list, recurse down rest of list, base case is empty list Deep Recursion- recurse the list and also recurse down any sublists the equal function below is an example (define (equal list1 list2) (cond [(not (list? list1)) (eq? list1 list2)] [(not (list? list2)) #f] [(null? list1) (null? list2)] [(null? list2) #f] [(equal (car list1) (car list2)) (equal (cdr list1) (cdr list2))] [else #f])) Interpreter Infinite read-evalutate--print loop (REPL) similar to python and ruby parameters are evaluated in no particular order order of parameter evaluation doesn't matter since each function has no side-effects extensive use of parenthesis makes turning a program text into a parse tree very easy also no need for operator precedence History LISP -> Scheme (70s) -> racket lisp also broke off into a more complex language CommonLisp Scheme cleaner, more modern, and simpler than contemporary dialects of scheme only static scoping Local Bindings 4 ways to define local bindings (each w/ diff semantics): let - expressions are all evaluated in the environment from before the let expression let* - expressions are evaluated in the environment produced from the previous bindings (can use bindings from previous expressions) letrec - used for recursion define - nested local defines are preferred racket style but don't have the emphasis in the distinction use the one most convenient, but default to let Let-expressions can appear anywhere Help avoid doing repeated work in functions let is shorthand for a lambda expression applied to a parameter let ([alpha 7]) (5 alpha) equivalent to ((lambda (alpha) (* 5 alpha)) 7) Tail Recursion Recursion is the natural method of computation in functional languages Usually the overhead of function calls makes recursion slower than iteration Most functional languages can optimize tail recursive calls to make them as efficient as iteration C and Racket have tail recursion while python does not Tail Recursive Function- when there is nothing to do after the function returns except return its value Can be automatically converted by a compiler to use iteration (makes it faster) Normal Factorial Recursive: Each call must wait for the result of calling itself in order to do the work of multiplying with n (define (fact n) (if (<= n 0) 1 (* n (fact (- n 1))))) Factorial Tail Recursion: Each call's work is done once it calls itself again recursively (define (fact n) (define (helper n acc) (if (<= n 0) acc (helper (- n 1)(* n acc)) )) (helper n 1) ) Higher Order Functions A function that can take functions as parameters and/or return functions as results Map and reduce higher order functions form basis of MapReduce (Hadoop) for large scale computing tasks Compose combines two functions into a new function (define (g x) (* 3 x)) (define (f x) (+ 2 x)) (define h (compose f g)) (h 5) ; returns 17 can be written as (define (compose func1 func2) (lambda (x) (func1 (func2 (x)))) Filter takes a predicate function as its first param (often as lambda exp) returns a ist with those items from the param list that satisfy the predicate (define (smaller100 x) (< x 100)) (filter smaller100 '(25 1 711 50 100)) ; returns (25 1 50) Map Takes two params- a function and a list(s) Applies the function to each element on the list and returns a list of the results (define (map func lst) (if (null? lst) '() (cons (fun (car lst)) (map fun (cdr lst))))) the map function provided by racket is more general and powerful (map fun lst1 lst2 .. lstn) Foldr Combines all elements in a list by applying a binary operation Known as reduction or fold (foldr f b '(x1 x2 ... xn)) ; returns (f x1 (f x2 ... (f xn b) ...)) Thunks Delay the evaluation of an expression by wrapping it in a parameter-less function called a thunk thunk- a zero aragument function used to delay evaluation captures th expression and environment in which it was defined calling the function later will evaluate the expression in its original environment Eager Evaluation - In Racket, Java, & C function arguments are evaluated once before calling the function Haskell does not eagerly evaluate its arguments Lazy Evaluation - for conditionals, the condition is eagerly evaluated but the branches are not Example thunk: (lambda () + 3 4) calling the thunk: ((lambda () + 3 4)) Helpful for delaying evaluation and/or avoiding repeated computations Delayed execution is used to improve performance in functional programming Streams: infinite sequences of values where thunks are useful can't generate all values ahead of time we can generate the values as they are needed Key idea: use a thunk to delay creating most of the seuqunce Stream Producer knows how to create any number of values Stream consumer decides how many values to ask for Let a stream be a thunk that when called returns a pair: '(next-answer . next-thunk) Thunk always needs to be called using () get first element of stream s : (car (s)) next element: (car ((cdr (s)))) ; Creates a stream of powers of two (define power-of-two (letrec ([f (lambda (x) (cons x (lambda () (f (* x 2)))))]) (lambda () (f 2)))) (car (powers-of-two)) ; -> 2 (car ((cdr (powers-of-two)))) ; -> 4 ; Function that takes a stream and int n and returns nth val of stream (define (stream-nth s n) (let ([pr (s)]) (if (zero? n) (car pr) (stream-nth (cdr pr) (- n 1))))) (stream-nth powers-of-two 2) eval function used in the REPL tp evalauate an expression the interpreter is a user available function eval allows you to write functions that build code ; lst is a list of numbers to be added (define (adder lst) (cond [(null? lst) 0] [else (eval (cons '+ lst))])) ; (cons '+ lst) creates list '(+ 1 2 3) ; which is then passed to eval where the list is treated as a function call (eval (+ 1 2 3))","title":"Ch. 15 Functional Languages: Racket"},{"location":"prog_langs/ch15/#functional-languages","text":"Lambda expressions describe nameless functions Applied to parameters by placing the parameters after the expression Ex: (\\lambda(x) x * x * x)(2) evaluates to 8 Functional Form Higher order functions lambda expressions are also useful for creating functions to pass as parameters to other functions that expect to receive functions can return other functions Composition of Functions Takes two functions as input and returns a new function that is the result of the 1st function appleid to the second Ex: h := f \\odot g which means h(x) = f(g(x)) Inefficient execution on von neumann machines Simple syntax and semantics Programs written in funtional languages can automatically be made concurrent harder to write concurrent imperative languages","title":"Functional Languages"},{"location":"prog_langs/ch15/#lisp","text":"","title":"LISP"},{"location":"prog_langs/ch15/#history","text":"Developed in 1958-59 for use in AI designed @ MIT by John McCarthy Fortran didnt have recursion, the ability to manipulate symbols, and ability to process data in linked lists rather than arrays Based on lambda calculus and mathematical functions Interpreted language with garbage collection","title":"History"},{"location":"prog_langs/ch15/#data-types","text":"Originally only atoms and lists Type is bound at runtime Names not variables (can't change value of a name after it has been defined) list form- parenthesized collection of atoms and/or sublists","title":"Data Types"},{"location":"prog_langs/ch15/#interpretation","text":"function defintions, function applications, and data all have the same form (A, B, C) can be interpretted differently depending on the context A can be a function being called with params B and C A can be a function called on B evaluated at C It can be a list of three atoms A , B , C","title":"Interpretation"},{"location":"prog_langs/ch15/#syntax","text":"a series of symbolic expressions (or S-expressions) can be an atom or a list an atom can be a number or a symbol a symbol can be a sequence of characters a number can be integers, floats, or ratio of integers (allows us to maintain accuracy with division) a list is recursively defined in termso of s-expressions","title":"Syntax"},{"location":"prog_langs/ch15/#grammar","text":"very simple grammar described by a short EBNF <s_expression> -> <atomic_symbol> | \"(\" <s_expression> \".\" <s_expression> \")\" | <list> <list> -> \"(\" <s_expression>* \")\" <atomic_symbol> -> <letter> <atom_part> <atom_part> -> empty | <letter> <atom_part> | <number> <atom_part> <letter> -> \"a\" | \"b\" | ... | \"z\" <number> -> \"1\" | \"2\" | ... | \"9\"","title":"Grammar"},{"location":"prog_langs/ch15/#semantics","text":"1st s-expression in a list is the name of a function Ex: (foo) or (foo a b c) in a function call, all arguments are evaluated first, then the function is applied to the result Prefix notation","title":"Semantics"},{"location":"prog_langs/ch15/#primitivenumeric-functions","text":"true: #T or #t false #F or #f = , > , < , <= , >= and , or , not equal? , even? , odd? , zero? , negative? , number? abs , sqrt , modulo , remainder , min , max , expt","title":"Primitive/Numeric Functions"},{"location":"prog_langs/ch15/#special-forms","text":"Functions that don't evaluate their arguments","title":"Special Forms"},{"location":"prog_langs/ch15/#lambda-expressions","text":"describe nameless/anonymous functions functions are first-class entities meaning they can be values of expressions, elements of lists, passed as parameters, and returned from functions functions can b (lambda(x) (* x x)) creates a special lambda function can be called by: ((lambda(x) (* x x)) 8)","title":"lambda Expressions"},{"location":"prog_langs/ch15/#define","text":"2 uses: bind a symbol to an expression: (define pi 3.14) bind names to lambda expressions (lambda is implicit): (define (square x) (* x x))","title":"define"},{"location":"prog_langs/ch15/#if","text":"two way selector function (if predicate then_exp else_exp)","title":"if"},{"location":"prog_langs/ch15/#cond","text":"(cond [predicate1 expression1] [predicate2 expression2] ... [else expression]) else clause is optional synonymous with (#t expression)","title":"cond"},{"location":"prog_langs/ch15/#lists","text":"Stored internally as singly-linked lists quote function (abbreviated w/ apostrophe prefix operator) takes one param and returns the param without evaluation '(A B) <=> (quote (A B)) car - returns first element of its list parameter cdr - returns the remainder of the list parameter after removing the 1st element cons - add a new head to the front of a list returns a new list with first argument inserted onto the front of the 2nd argument does not make copy of the second argument list - returns a new list of its parameters (list 'a 'b 'c 'd) -> '(a b c d)' (list '(A B) '(C D)) equivalent to (cons '(A B) (cons '(C D) '())) null? - tests for empty list (null? '()) -> #t (null? null) -> #t list? - tests if the function is a list (list? 'A) -> #f (list? '(A)) -> #t append - returns new list that contains all elements of the two list arguments the arguments must be lists unlike list and cons different result from list function (append '(a b) '(c d)) contractions are useful for doing a lot of work concisely (cadr lst) equivalent to (car (cdr lst) (i.e. getting 2nd element) (cdddr lst) equivalent to (cdr (cdr (cdr lst))) (i.e. removing first 3 elements) length - returns the length of a list Lists are processed in a recursive fashion process head of list, recurse down rest of list, base case is empty list Deep Recursion- recurse the list and also recurse down any sublists the equal function below is an example (define (equal list1 list2) (cond [(not (list? list1)) (eq? list1 list2)] [(not (list? list2)) #f] [(null? list1) (null? list2)] [(null? list2) #f] [(equal (car list1) (car list2)) (equal (cdr list1) (cdr list2))] [else #f]))","title":"Lists"},{"location":"prog_langs/ch15/#interpreter","text":"Infinite read-evalutate--print loop (REPL) similar to python and ruby parameters are evaluated in no particular order order of parameter evaluation doesn't matter since each function has no side-effects extensive use of parenthesis makes turning a program text into a parse tree very easy also no need for operator precedence","title":"Interpreter"},{"location":"prog_langs/ch15/#history_1","text":"LISP -> Scheme (70s) -> racket lisp also broke off into a more complex language CommonLisp Scheme cleaner, more modern, and simpler than contemporary dialects of scheme only static scoping","title":"History"},{"location":"prog_langs/ch15/#local-bindings","text":"4 ways to define local bindings (each w/ diff semantics): let - expressions are all evaluated in the environment from before the let expression let* - expressions are evaluated in the environment produced from the previous bindings (can use bindings from previous expressions) letrec - used for recursion define - nested local defines are preferred racket style but don't have the emphasis in the distinction use the one most convenient, but default to let Let-expressions can appear anywhere Help avoid doing repeated work in functions let is shorthand for a lambda expression applied to a parameter let ([alpha 7]) (5 alpha) equivalent to ((lambda (alpha) (* 5 alpha)) 7)","title":"Local Bindings"},{"location":"prog_langs/ch15/#tail-recursion","text":"Recursion is the natural method of computation in functional languages Usually the overhead of function calls makes recursion slower than iteration Most functional languages can optimize tail recursive calls to make them as efficient as iteration C and Racket have tail recursion while python does not Tail Recursive Function- when there is nothing to do after the function returns except return its value Can be automatically converted by a compiler to use iteration (makes it faster) Normal Factorial Recursive: Each call must wait for the result of calling itself in order to do the work of multiplying with n (define (fact n) (if (<= n 0) 1 (* n (fact (- n 1))))) Factorial Tail Recursion: Each call's work is done once it calls itself again recursively (define (fact n) (define (helper n acc) (if (<= n 0) acc (helper (- n 1)(* n acc)) )) (helper n 1) )","title":"Tail Recursion"},{"location":"prog_langs/ch15/#higher-order-functions","text":"A function that can take functions as parameters and/or return functions as results Map and reduce higher order functions form basis of MapReduce (Hadoop) for large scale computing tasks","title":"Higher Order Functions"},{"location":"prog_langs/ch15/#compose","text":"combines two functions into a new function (define (g x) (* 3 x)) (define (f x) (+ 2 x)) (define h (compose f g)) (h 5) ; returns 17 can be written as (define (compose func1 func2) (lambda (x) (func1 (func2 (x))))","title":"Compose"},{"location":"prog_langs/ch15/#filter","text":"takes a predicate function as its first param (often as lambda exp) returns a ist with those items from the param list that satisfy the predicate (define (smaller100 x) (< x 100)) (filter smaller100 '(25 1 711 50 100)) ; returns (25 1 50)","title":"Filter"},{"location":"prog_langs/ch15/#map","text":"Takes two params- a function and a list(s) Applies the function to each element on the list and returns a list of the results (define (map func lst) (if (null? lst) '() (cons (fun (car lst)) (map fun (cdr lst))))) the map function provided by racket is more general and powerful (map fun lst1 lst2 .. lstn)","title":"Map"},{"location":"prog_langs/ch15/#foldr","text":"Combines all elements in a list by applying a binary operation Known as reduction or fold (foldr f b '(x1 x2 ... xn)) ; returns (f x1 (f x2 ... (f xn b) ...))","title":"Foldr"},{"location":"prog_langs/ch15/#thunks","text":"Delay the evaluation of an expression by wrapping it in a parameter-less function called a thunk thunk- a zero aragument function used to delay evaluation captures th expression and environment in which it was defined calling the function later will evaluate the expression in its original environment Eager Evaluation - In Racket, Java, & C function arguments are evaluated once before calling the function Haskell does not eagerly evaluate its arguments Lazy Evaluation - for conditionals, the condition is eagerly evaluated but the branches are not Example thunk: (lambda () + 3 4) calling the thunk: ((lambda () + 3 4)) Helpful for delaying evaluation and/or avoiding repeated computations Delayed execution is used to improve performance in functional programming","title":"Thunks"},{"location":"prog_langs/ch15/#streams","text":"infinite sequences of values where thunks are useful can't generate all values ahead of time we can generate the values as they are needed Key idea: use a thunk to delay creating most of the seuqunce Stream Producer knows how to create any number of values Stream consumer decides how many values to ask for Let a stream be a thunk that when called returns a pair: '(next-answer . next-thunk) Thunk always needs to be called using () get first element of stream s : (car (s)) next element: (car ((cdr (s)))) ; Creates a stream of powers of two (define power-of-two (letrec ([f (lambda (x) (cons x (lambda () (f (* x 2)))))]) (lambda () (f 2)))) (car (powers-of-two)) ; -> 2 (car ((cdr (powers-of-two)))) ; -> 4 ; Function that takes a stream and int n and returns nth val of stream (define (stream-nth s n) (let ([pr (s)]) (if (zero? n) (car pr) (stream-nth (cdr pr) (- n 1))))) (stream-nth powers-of-two 2)","title":"Streams:"},{"location":"prog_langs/ch15/#eval-function","text":"used in the REPL tp evalauate an expression the interpreter is a user available function eval allows you to write functions that build code ; lst is a list of numbers to be added (define (adder lst) (cond [(null? lst) 0] [else (eval (cons '+ lst))])) ; (cons '+ lst) creates list '(+ 1 2 3) ; which is then passed to eval where the list is treated as a function call (eval (+ 1 2 3))","title":"eval function"},{"location":"prog_langs/ch16/","text":"Logical Languages Programs are expressed in a form of symbolic logic Use logical inferencing process to produce results Declarative rather than procedural you describe a result/goal and you get it via a blackbox compared to procedural where you describe the steps to get to a result Declarative vs. Procedural Symbolic Logic Express propositions Express relationships btw propositions Describe how new propositions can be inferred from other propositions First Order Predicate Calculus is the form symbolic logic used for logic programming Operators: connect 2+ atomic propositions conjunction, disjunction, negation, implication Quantifiers: include variables in propositions universal \\forall existential \\exists Clausal Form A standard form for propositions that helps with organization Restriction on how statements can be formatted allows logic programming systems to prove theorems mechanically If all A's are true, then at least one B is true B_1 \\cup \\dots \\cup B_m \\subset A_1 \\cap \\dots \\cap A_n Horn Clauses Further restriction that insists all statements be in the form of a head (LHS) and a body (RHS) the head is a single atomic proosition (or term in prolog) the body is a list of atomic propositions (or terms in prolog) the conjuction of the terms in the body implies the head B \\subset A_1 \\cap \\dots A_n a clause with no body is a fact a clause with both sides is a rule a clause with no head is a goal/query Resolution Principle Formalized by Alan Robinson in 1965 How implications can be combined to obtain new implications Ex: If clause1 implies clause2 and clause2 implies clause3 then clause1 also implies clause3 Prolog First appeared in 1972 Provide facts/axioms (the knowledge base) rules/theorems (if condition, then also conclusion) goals/hypothesis (queries) Can be thought of declaratively or imperatively parent(kim, holly) defines a predicate parent of arity 2 (sometimes written as parent/2 ) Terms Process State a series of facts and rules that the interpreter collects in its DATABASE Pose a query/goal and Prolog attempts to find inference steps (and assignments of values to variables) that allow it to prove your query starting from the facts Facts Knowledge base to build new rules from (aka the world or the universe) Horn clauses with no body mother(mary, fred). % predictate making mary a mother of fred Rules Describe known implications/relations Rules are theorems that allow the interpreter to infer things Horn clauses with both a head and body To be interesting, rules generally contian variables Ex: If X barks, then X is a dog Horn Clause: dog(X) \\subset barks(X) Prolog Syntax: dog(X) :- barks(X). Ex: For all X, X is emplyed if there exists a Y such that Y employs X employed(X) :- employs(Y, X) Does NOT say that X is employed only if threre is a Y that employs X Goals Query/reasoning about the world Prolog attempts to satisfy the goal Unification Process by which compatible statements are merged Query asked is the interpreter's original goal In an attempt to satisfy the goal, interpreter looks for facts or rules with which the goal can be unified Trivial unification: goal can be unified with itself A variable without a value yet but which corresponds to a constant/value in another clause gets instantiated with that value Ex: studies(charlie, X) is unified with the fact studies(charlie, cs3270) and the variable X is instantiated to cs3270 SWI Prolog Prompt a query with ?- consult is a predefined pedicate to read a program from a file into the database (load in a knowledge base and rules from a .PL file) ?- consult('database.pl') Goal: ?- barks(X). X = fido. ?- dog(fido). true. woman(jean). % fact man(fred). % fact wealthy(jean). % fact happy(Person) :- woman(Perosn), wealthy(Person) jean and fred are constants/atoms b/c they start w/ lowercase letter Person is a variable b/c it starts w/ uppercase letter (could also just be an underscore) Wil return first answer it finds to a query Press Y or Enter if thats all you want Press ; N or Spacebar if you want prolog to continue searching for other possible answers Pressing a aborts anything and returns you to the prompt When entering a query if the value of an arugment doesn't matter to you use _ Conjunction & Disjunction Rules & Conjunction (AND): B(X) :- A(X), C(X), D(X). Rules & Disjunction (OR): B(X) :- A(X). B(X) :- C(X). B(X) :- D(X). Can combine disjunction and conjunction using the above syntax Variable Scope Variable scope is the clause in which it appears appears first on LHS -> universal quantifier appears first on RHS -> existential quantifier Ex: grandmother(A, C) :- mother(A, B), mother(B, C) For all A, C [A is the grandmother of C if there exists a B s.t. A is the mother of B and B is the mother of C] How Prolog Works Interpreter starts at beginning of database and looks for soemthing to answer current goal with If it finds a fact, it succeedds If it finds a rule, it attempts to satisfy the terms (or subgoals) in the body/rhs left-to-right and depth first this ordering is prolog specific, not logic programming in general when attempting resolutions interpreter pushes current goal onto a stack makes the first term/subgoal in the body the current goal Goes back to the beginning of the database and starts looking again if interpreter gets thorugh first term/goal of a body succesfully, it continue with the next one if interpreter gets all the way through the body, the goal is satisfied and backs up a level and proceeds if interpreter fails to satisfy the terms in the body of a rule, the interpreter undoes the unification of the lhs (includes uninstantiating any variables given values as a result of the unification) backtracks and keeps looking through the database for something else with which to unify if interpreter gets to end of database without succeeding, it backs out a level and continue from there Ordering of database and left-to-right pursuit of subgoals makes prolog not purely declarative changing order of statements in database can give different results (including infinite loops or less efficiency) Infinite Recursion Can occur since order matters in rule evaluation Can usually avoid by following 2 best practices: make rules right recursive put base cases first List Processing Enclosed in squre brackets w/ elements separated by commas | operator separates head of list from rest of list = means unification ?- [H | T] = [1, 2, 3, 4, 5]. H = 1. T = [2, 3, 4, 5]. Can construct litss using the same syntax as destructing lists: ?- Lst = [1 | [2, 3, 4, 5]]. Lst = [1, 2, 3, 4, 5]. predicates for list processing: member - performs a membership test implemented as: member(X, [X|_]). member(X, [_|Xs]) :- member(X,Xs) append - append 2 lists remove - remove 1st occurence from a list filter - keep only elements that satisfy a predicate Assign H1 and H2 to the first two elements of a list ?- [H1 | [H2 | T]] = [1, 2, 3, 4] H1 = 1, H2 = 2, T = [3, 4]. % or ?- [H1,H2|T] = [1, 2, 3, 4]. H1 = 1, H2 = 2, T = [3, 4]. Prolog predicates only return true/false depending on whether the predicate can be satisifed or not To return a value from a rule/predicate, an additional parameter is needed to carry back the result Ex: append([a,b,c], [d,e,f], Lst) Lst is the output paremeter that contains the two input lists appended together % my_append -- Appends two lists. my_append([], Lst2, Lst2). my_append([Head|Tail], Lst2, [Head|Result]) :- my_append(Tail, Lst2, Result). % my_remove -- Remove the first occurrence of an item from a list. my_remove(_, [], []). my_remove(Item, [Item|Tail], Tail). my_remove(Item, [Head|Tail], [Head|Result]) :- Item \\== Head, my_remove(Item, Tail, Result). Logical Problems Prolog is great for solving logic problems also known as constraint programming 8 Queens Problem Represent a queen's position with queen predicate (e.g. queen(2, 5) means there is a queen at position (2,5) on the board) We want a list containing 8 elements with the position of each queen nocheck(_, []). # base case of empty list nocheck(X/Y, [X1/Y1 | Rest]) :- X =\\= X1, #not in same row Y =\\= Y1, #not in same column abs(X - X1) =\\= abs(Y - Y1), # not in same diagonal nocheck(X/Y, Rest). legal([]). # base case of empty list legal([X/Y | Rest]) :- legal(Rest), # try all possible positions of (x,y) member(X, [1, 2, 3, 4, 5, 6, 7, 8]), member(Y, [1, 2, 3, 4, 5, 6, 7, 8]), nocheck(X/Y, Rest). # we want only the lists of size 8 (dont return all the others) X = [_, _, _, _, _, _, _, _], legal(X). # further restrict outputs to be in the desired order X = [1/_, 2/_, 3/_, 4/_, 5/_, 6/_, 7/_, 8/_], legal(X).","title":"Ch. 16 Logical Languages: Prolog"},{"location":"prog_langs/ch16/#logical-languages","text":"Programs are expressed in a form of symbolic logic Use logical inferencing process to produce results Declarative rather than procedural you describe a result/goal and you get it via a blackbox compared to procedural where you describe the steps to get to a result Declarative vs. Procedural","title":"Logical Languages"},{"location":"prog_langs/ch16/#symbolic-logic","text":"Express propositions Express relationships btw propositions Describe how new propositions can be inferred from other propositions First Order Predicate Calculus is the form symbolic logic used for logic programming Operators: connect 2+ atomic propositions conjunction, disjunction, negation, implication Quantifiers: include variables in propositions universal \\forall existential \\exists","title":"Symbolic Logic"},{"location":"prog_langs/ch16/#clausal-form","text":"A standard form for propositions that helps with organization Restriction on how statements can be formatted allows logic programming systems to prove theorems mechanically If all A's are true, then at least one B is true B_1 \\cup \\dots \\cup B_m \\subset A_1 \\cap \\dots \\cap A_n","title":"Clausal Form"},{"location":"prog_langs/ch16/#horn-clauses","text":"Further restriction that insists all statements be in the form of a head (LHS) and a body (RHS) the head is a single atomic proosition (or term in prolog) the body is a list of atomic propositions (or terms in prolog) the conjuction of the terms in the body implies the head B \\subset A_1 \\cap \\dots A_n a clause with no body is a fact a clause with both sides is a rule a clause with no head is a goal/query","title":"Horn Clauses"},{"location":"prog_langs/ch16/#resolution-principle","text":"Formalized by Alan Robinson in 1965 How implications can be combined to obtain new implications Ex: If clause1 implies clause2 and clause2 implies clause3 then clause1 also implies clause3","title":"Resolution Principle"},{"location":"prog_langs/ch16/#prolog","text":"First appeared in 1972 Provide facts/axioms (the knowledge base) rules/theorems (if condition, then also conclusion) goals/hypothesis (queries) Can be thought of declaratively or imperatively parent(kim, holly) defines a predicate parent of arity 2 (sometimes written as parent/2 )","title":"Prolog"},{"location":"prog_langs/ch16/#terms","text":"","title":"Terms"},{"location":"prog_langs/ch16/#process","text":"State a series of facts and rules that the interpreter collects in its DATABASE Pose a query/goal and Prolog attempts to find inference steps (and assignments of values to variables) that allow it to prove your query starting from the facts","title":"Process"},{"location":"prog_langs/ch16/#facts","text":"Knowledge base to build new rules from (aka the world or the universe) Horn clauses with no body mother(mary, fred). % predictate making mary a mother of fred","title":"Facts"},{"location":"prog_langs/ch16/#rules","text":"Describe known implications/relations Rules are theorems that allow the interpreter to infer things Horn clauses with both a head and body To be interesting, rules generally contian variables Ex: If X barks, then X is a dog Horn Clause: dog(X) \\subset barks(X) Prolog Syntax: dog(X) :- barks(X). Ex: For all X, X is emplyed if there exists a Y such that Y employs X employed(X) :- employs(Y, X) Does NOT say that X is employed only if threre is a Y that employs X","title":"Rules"},{"location":"prog_langs/ch16/#goals","text":"Query/reasoning about the world Prolog attempts to satisfy the goal","title":"Goals"},{"location":"prog_langs/ch16/#unification","text":"Process by which compatible statements are merged Query asked is the interpreter's original goal In an attempt to satisfy the goal, interpreter looks for facts or rules with which the goal can be unified Trivial unification: goal can be unified with itself A variable without a value yet but which corresponds to a constant/value in another clause gets instantiated with that value Ex: studies(charlie, X) is unified with the fact studies(charlie, cs3270) and the variable X is instantiated to cs3270","title":"Unification"},{"location":"prog_langs/ch16/#swi-prolog","text":"Prompt a query with ?- consult is a predefined pedicate to read a program from a file into the database (load in a knowledge base and rules from a .PL file) ?- consult('database.pl') Goal: ?- barks(X). X = fido. ?- dog(fido). true. woman(jean). % fact man(fred). % fact wealthy(jean). % fact happy(Person) :- woman(Perosn), wealthy(Person) jean and fred are constants/atoms b/c they start w/ lowercase letter Person is a variable b/c it starts w/ uppercase letter (could also just be an underscore) Wil return first answer it finds to a query Press Y or Enter if thats all you want Press ; N or Spacebar if you want prolog to continue searching for other possible answers Pressing a aborts anything and returns you to the prompt When entering a query if the value of an arugment doesn't matter to you use _","title":"SWI Prolog"},{"location":"prog_langs/ch16/#conjunction-disjunction","text":"Rules & Conjunction (AND): B(X) :- A(X), C(X), D(X). Rules & Disjunction (OR): B(X) :- A(X). B(X) :- C(X). B(X) :- D(X). Can combine disjunction and conjunction using the above syntax","title":"Conjunction &amp; Disjunction"},{"location":"prog_langs/ch16/#variable-scope","text":"Variable scope is the clause in which it appears appears first on LHS -> universal quantifier appears first on RHS -> existential quantifier Ex: grandmother(A, C) :- mother(A, B), mother(B, C) For all A, C [A is the grandmother of C if there exists a B s.t. A is the mother of B and B is the mother of C]","title":"Variable Scope"},{"location":"prog_langs/ch16/#how-prolog-works","text":"Interpreter starts at beginning of database and looks for soemthing to answer current goal with If it finds a fact, it succeedds If it finds a rule, it attempts to satisfy the terms (or subgoals) in the body/rhs left-to-right and depth first this ordering is prolog specific, not logic programming in general when attempting resolutions interpreter pushes current goal onto a stack makes the first term/subgoal in the body the current goal Goes back to the beginning of the database and starts looking again if interpreter gets thorugh first term/goal of a body succesfully, it continue with the next one if interpreter gets all the way through the body, the goal is satisfied and backs up a level and proceeds if interpreter fails to satisfy the terms in the body of a rule, the interpreter undoes the unification of the lhs (includes uninstantiating any variables given values as a result of the unification) backtracks and keeps looking through the database for something else with which to unify if interpreter gets to end of database without succeeding, it backs out a level and continue from there Ordering of database and left-to-right pursuit of subgoals makes prolog not purely declarative changing order of statements in database can give different results (including infinite loops or less efficiency)","title":"How Prolog Works"},{"location":"prog_langs/ch16/#infinite-recursion","text":"Can occur since order matters in rule evaluation Can usually avoid by following 2 best practices: make rules right recursive put base cases first","title":"Infinite Recursion"},{"location":"prog_langs/ch16/#list-processing","text":"Enclosed in squre brackets w/ elements separated by commas | operator separates head of list from rest of list = means unification ?- [H | T] = [1, 2, 3, 4, 5]. H = 1. T = [2, 3, 4, 5]. Can construct litss using the same syntax as destructing lists: ?- Lst = [1 | [2, 3, 4, 5]]. Lst = [1, 2, 3, 4, 5]. predicates for list processing: member - performs a membership test implemented as: member(X, [X|_]). member(X, [_|Xs]) :- member(X,Xs) append - append 2 lists remove - remove 1st occurence from a list filter - keep only elements that satisfy a predicate Assign H1 and H2 to the first two elements of a list ?- [H1 | [H2 | T]] = [1, 2, 3, 4] H1 = 1, H2 = 2, T = [3, 4]. % or ?- [H1,H2|T] = [1, 2, 3, 4]. H1 = 1, H2 = 2, T = [3, 4]. Prolog predicates only return true/false depending on whether the predicate can be satisifed or not To return a value from a rule/predicate, an additional parameter is needed to carry back the result Ex: append([a,b,c], [d,e,f], Lst) Lst is the output paremeter that contains the two input lists appended together % my_append -- Appends two lists. my_append([], Lst2, Lst2). my_append([Head|Tail], Lst2, [Head|Result]) :- my_append(Tail, Lst2, Result). % my_remove -- Remove the first occurrence of an item from a list. my_remove(_, [], []). my_remove(Item, [Item|Tail], Tail). my_remove(Item, [Head|Tail], [Head|Result]) :- Item \\== Head, my_remove(Item, Tail, Result).","title":"List Processing"},{"location":"prog_langs/ch16/#logical-problems","text":"Prolog is great for solving logic problems also known as constraint programming","title":"Logical Problems"},{"location":"prog_langs/ch16/#8-queens-problem","text":"Represent a queen's position with queen predicate (e.g. queen(2, 5) means there is a queen at position (2,5) on the board) We want a list containing 8 elements with the position of each queen nocheck(_, []). # base case of empty list nocheck(X/Y, [X1/Y1 | Rest]) :- X =\\= X1, #not in same row Y =\\= Y1, #not in same column abs(X - X1) =\\= abs(Y - Y1), # not in same diagonal nocheck(X/Y, Rest). legal([]). # base case of empty list legal([X/Y | Rest]) :- legal(Rest), # try all possible positions of (x,y) member(X, [1, 2, 3, 4, 5, 6, 7, 8]), member(Y, [1, 2, 3, 4, 5, 6, 7, 8]), nocheck(X/Y, Rest). # we want only the lists of size 8 (dont return all the others) X = [_, _, _, _, _, _, _, _], legal(X). # further restrict outputs to be in the desired order X = [1/_, 2/_, 3/_, 4/_, 5/_, 6/_, 7/_, 8/_], legal(X).","title":"8 Queens Problem"},{"location":"prog_langs/ch2/","text":"Ch. 2 History of Programming Languages 2.3 Fortran Environment of development (1954): unreliable computers with small memories focus on scientific applications no programming methodology or tools (writing code in assembly) machine efficiency was most important concern Fortran I was released in april of 1957 after 18 years of work code was very fast quickly became widely used programs >400 lines didnt compile correctly due to unreliable machines Features: Do loop three-way selection statement: if (expression) negative, zero, positive user-defined subprograms (no seperate compilation though) only six chars for names no data typing statements (types depended on first letter of name) John Backus won 1977 Turing Award for his work on Fortran Fortran II came out in 1958 with independent compilation Fortran IV came out during 60-62 with explicit type declarations, logical if statements, and subprograms allow passing names as paraemters ANSI standard in 1966 (Fortran 66) Fortran 77- character string handling, lgoical loop control statement, if-then-else statement Fortran 90 introduced: modules, dynamic arrays, case-statement, pointers, recursion, parameter type checking All Fortran Features: do loop 3 way selection statemenent subprograms logical if statements explicit type declarations character string handling logical loop control statement if else statement modules dynamic arrays case statements pointers recursion param type checking 2.5 ALGOL Environment of development fortran had barely arrived for IBM 70x many other languages were being developed for specific machines no portable, machie independent languages so Algol was the result of rtrying to design a universal language Early Design Process Goals: close to math notation good for describing algorithms must be mechanically translatable to machine code Not very succesfful variations such as MAD and JOVIAL (used by air force for 25 years) IBM dropped support Algol 58 Features: formalized concept of data types compound staatements else-if clause parameters seperated by mode (passed in vs. passed out) Algol 60 features: subprogram recursion (new for imperative languages) two parameter passing methods (pass by value, by name) nested functions stack storage allocation Successes: form base of all following imperative languages first machine-independent language first language with standard syntax (BNF) Failures: never widely used lack of IO definition made programs not portable since different machines had different ways of doing IO too flexible making it hard to implement so few compilers implemented the whole language formal syntax definition (BNF) seemed too complex 2.8 PL/1 Development Environment: Cobol and Fortran existing by 1963 scientific users wanted more elaborate I/O and business users wanted floats and arrays Features unit-level concurrency exception handling recursion toggled on/off for faster execution pointers as a data type cross sections fo arrays Successes used in both business and scientifc applications in the 70s subset of language taught in colleges Failurse many new features were poorly designed too large and complex 2.11 Algol 68 Design baedon concept of orthogonality a few basic concepts + a few combining mechanisms Source of several new ideas Features user defined data types dynamic arrays 2.12 Pascal Developed by a member of Algol 68 committee Simple, Small, and used for teaching from mid 70s to mid 90s Easy to use toolkit on any platform provides a compiler that produces p-code so all the user needs to do is write a p-code interpreter in assembly to be able to use Pascal (relatively simpler compared to setting up other languages at the time) Features: enumeration types subrange types 2.12 C Designed for systems programming at bell labs by dennies ritchie and ken thompson evolved from BCPL, B, and also ALGOL 68 Poor type checking but rich set of operators Good for writing systems-level software (OS, etc.) Initially spread though UNIX, which included a C compiler Bootstrapping: C compilers can be written in c so that only a smaller compiler written in assembly needs to be written to compile the compiler 2.15 Smalltalk Developed at Xerox PARC in the 70s by Alan Kay First full implementation of an OOP language (data abstraction, inheritance, dynamic binding) Also pinoreed GUI design 2.16 C++ Developed at Bell labs by Bjarne Srtoustrup in 1980 Evolved from C and SIMULA67 (where OOP ideas came from) Large and complex language because it supports both procedural (backwards support for C code) and OOP 2.17 Java Developed at Sun in early 1990s b/c C & C++ were not good for embedded devices Based on C++ simpler removed unsafe things like pointer arithmetic and left safe thing like references garbage collected memory management JVM concept and JIT compilers Use increased faster than any previous language due to companies and academics banding together for an alternative from microsoft","title":"Ch. 2 History"},{"location":"prog_langs/ch2/#ch-2-history-of-programming-languages","text":"","title":"Ch. 2 History of Programming Languages"},{"location":"prog_langs/ch2/#23-fortran","text":"Environment of development (1954): unreliable computers with small memories focus on scientific applications no programming methodology or tools (writing code in assembly) machine efficiency was most important concern Fortran I was released in april of 1957 after 18 years of work code was very fast quickly became widely used programs >400 lines didnt compile correctly due to unreliable machines Features: Do loop three-way selection statement: if (expression) negative, zero, positive user-defined subprograms (no seperate compilation though) only six chars for names no data typing statements (types depended on first letter of name) John Backus won 1977 Turing Award for his work on Fortran Fortran II came out in 1958 with independent compilation Fortran IV came out during 60-62 with explicit type declarations, logical if statements, and subprograms allow passing names as paraemters ANSI standard in 1966 (Fortran 66) Fortran 77- character string handling, lgoical loop control statement, if-then-else statement Fortran 90 introduced: modules, dynamic arrays, case-statement, pointers, recursion, parameter type checking All Fortran Features: do loop 3 way selection statemenent subprograms logical if statements explicit type declarations character string handling logical loop control statement if else statement modules dynamic arrays case statements pointers recursion param type checking","title":"2.3 Fortran"},{"location":"prog_langs/ch2/#25-algol","text":"Environment of development fortran had barely arrived for IBM 70x many other languages were being developed for specific machines no portable, machie independent languages so Algol was the result of rtrying to design a universal language Early Design Process Goals: close to math notation good for describing algorithms must be mechanically translatable to machine code Not very succesfful variations such as MAD and JOVIAL (used by air force for 25 years) IBM dropped support Algol 58 Features: formalized concept of data types compound staatements else-if clause parameters seperated by mode (passed in vs. passed out) Algol 60 features: subprogram recursion (new for imperative languages) two parameter passing methods (pass by value, by name) nested functions stack storage allocation Successes: form base of all following imperative languages first machine-independent language first language with standard syntax (BNF) Failures: never widely used lack of IO definition made programs not portable since different machines had different ways of doing IO too flexible making it hard to implement so few compilers implemented the whole language formal syntax definition (BNF) seemed too complex","title":"2.5 ALGOL"},{"location":"prog_langs/ch2/#28-pl1","text":"Development Environment: Cobol and Fortran existing by 1963 scientific users wanted more elaborate I/O and business users wanted floats and arrays Features unit-level concurrency exception handling recursion toggled on/off for faster execution pointers as a data type cross sections fo arrays Successes used in both business and scientifc applications in the 70s subset of language taught in colleges Failurse many new features were poorly designed too large and complex","title":"2.8 PL/1"},{"location":"prog_langs/ch2/#211-algol-68","text":"Design baedon concept of orthogonality a few basic concepts + a few combining mechanisms Source of several new ideas Features user defined data types dynamic arrays","title":"2.11 Algol 68"},{"location":"prog_langs/ch2/#212-pascal","text":"Developed by a member of Algol 68 committee Simple, Small, and used for teaching from mid 70s to mid 90s Easy to use toolkit on any platform provides a compiler that produces p-code so all the user needs to do is write a p-code interpreter in assembly to be able to use Pascal (relatively simpler compared to setting up other languages at the time) Features: enumeration types subrange types","title":"2.12 Pascal"},{"location":"prog_langs/ch2/#212-c","text":"Designed for systems programming at bell labs by dennies ritchie and ken thompson evolved from BCPL, B, and also ALGOL 68 Poor type checking but rich set of operators Good for writing systems-level software (OS, etc.) Initially spread though UNIX, which included a C compiler Bootstrapping: C compilers can be written in c so that only a smaller compiler written in assembly needs to be written to compile the compiler","title":"2.12 C"},{"location":"prog_langs/ch2/#215-smalltalk","text":"Developed at Xerox PARC in the 70s by Alan Kay First full implementation of an OOP language (data abstraction, inheritance, dynamic binding) Also pinoreed GUI design","title":"2.15 Smalltalk"},{"location":"prog_langs/ch2/#216-c","text":"Developed at Bell labs by Bjarne Srtoustrup in 1980 Evolved from C and SIMULA67 (where OOP ideas came from) Large and complex language because it supports both procedural (backwards support for C code) and OOP","title":"2.16 C++"},{"location":"prog_langs/ch2/#217-java","text":"Developed at Sun in early 1990s b/c C & C++ were not good for embedded devices Based on C++ simpler removed unsafe things like pointer arithmetic and left safe thing like references garbage collected memory management JVM concept and JIT compilers Use increased faster than any previous language due to companies and academics banding together for an alternative from microsoft","title":"2.17 Java"},{"location":"prog_langs/ch3/","text":"Ch. 3 Describing Syntax and Semantics 3.1 Introduction Syntax - the form/structure of the expressions, statements, and program units Semantics - the meaning of the expressions, statements, and program units Syntax and semantics provide a language's definition Semantics should follow from syntax in a well designed programming language Language Definition Users: Initial evaluaors (language designers) Implementers (compiler writers) Programmers (language users) 3.2 Describing Syntax A language is a set of strings of characters from some alphabet Sentences/Statements are the strigns of a language Describing a language with english can lead to many issues (e.g. Fortran) Meta-Language - a language used to define other languages Grammar - a meta-lanugage used to define the syntax of a language A sentence can be syntactically correct but not semantically correct Lexical Analysis Lexical specification is usually seperate from syntactic description lexemes include literals, operators, keywords, etc. programs are strings of lexemes Converting characters in the source program into lexical units Lexical analyzer splits source code into tokens Token- syntactic category that forms a class of lexemes identifiers (names of vars, methods, classes) , literals, keywords, operators, punctuation Lexeme- a sequence of characters that matches the pattern for a token Formal Definition of Languages Two ways: Recognizer- reads input strings over the alphabet of the language and decides whether the input strings belong to the language produces a yes/no answer as to whether the input string is a valid sentence in the language Syntax analysis is a recognizer Generator- generates random valid sentences in a specific language Neither on their own are useful in learning a language Used together they form the basis of computational theory 3.3 Formal Methods of Describing Syntax Grammars- used to descirbe the syntax of programming languages Context Free Grammars Developed by Noam Chomsky (a linguist) 4 classes of generative devices or grammars that define 4 classes of languages 2 of them, context-free and regular grammars, were later useful for describing the syntax of programming languages forms of tokens in PLs can be described by regular grammars syntax of whole languages can be described by context-free grammars Backus-Naur Form (BNF) Invented by John Backus to describe Algol 58 A natural notation for describing syntax Equivalent to context-free grammars Metalanguage for PLs Grammar consists of: Start symbol Finite set of production rules Finite set of terminal symbols Finite set of nonterminal symbols Uses abstractions for syntactic structures <assign> -> <var> = <expression> is a definition of the assign abstraction where the LHS of the arrow is the abstraction being defined and the RHS of the arrow consists of a mixture of tokens, lexemes, and references to other abstractions the definition is called a production rule nonterminal symbols- the abstractions in a BNF description can have 2+ distinct definitions (represent 2+ possible syntactic forms in the language) multiple definitions can be written as a single rule seperated by a | meaning logical OR terminal symbols- lexemes and tokens of the rules BNF Description/Grammar- a collection of rules Simple but sufficiently powerful to describe syntax of PLs Lists (utilizes recursion): <identifier_list> -> identifier | identifier, <identifier_list> ordering, nested structures of any depth, operator precedence and associativity Grammar- generative device for defining languages Start with a special nonterminal start symbol and then apply a sequence of rules in a derivation start symbol is usually <program> Sentential Form- every string of nonterminal or terminal symbols in a derivation Sentence- a sentential form that has only terminal symbols Leftmost derivation- leftmost nonterminal in each sentential form is the one that is expanded next derivation could be rightmost or in neither leftmost or rightmost since derivation order has no effect on the generated language Most languages are infinite so all sentences in the language cannot be generated in finite time Parse Tree A hierarchial representation of a derivation every internal node is nonterminal symbol every leaf node is a terminal symbol Ambiguity A grammar is ambiguous iff it generates a sentital form that has 2+ distinct parse trees bad for compilers that need 1 unique parse tree If we use parse tree to indicate precedence levels of the operators, we cannot have ambiguity operator associativity can also be indicated by a grammar Ex: <expr> -> <expr> + const | const indicates left associativity of the + operator (left recursion -> left associativity) Dangling Else Ambiguity if (<logic_expr>) if (<logic_expr>) <stmt> else <stmt> is ambiguous as to which if statement the else belongs to Rewrite grammar to restirct what can appear inside a nested if-statement Use <matched> and <unmatched> abstractions to handle the different types of if-else statements <stmt> \u2192 <matched> | <unmatched> <matched> \u2192 if (<logic_expr>) <matched> else <matched> |any non-if statement <unmatched> \u2192 if (<logic_expr>) <stmt> | if (<logic_expr>) <matched> else <unmatched> Can also use an explicit delimiter to end every conditional Extended BNF More concise Equally powerful/expressive Defect standard for defining PLs optional parts placed in brackets [] <proc_call> -> <ident> ([<expr_list>]) alternative in BNF: <pc> -> <id> () | <id> (<el>) alternative parts of rhs are placed inside parenthesies and seperated by vertical vertical bars <term> -> <term> (+ | -) const Repetitions (0 or more) are placed inside baces {} <identifier_list> -> <identifier> {, <identifier>} Semantics No single widely accepeted way of describing semantics","title":"Ch. 3 Syntax & Semantics"},{"location":"prog_langs/ch3/#ch-3-describing-syntax-and-semantics","text":"","title":"Ch. 3 Describing Syntax and Semantics"},{"location":"prog_langs/ch3/#31-introduction","text":"Syntax - the form/structure of the expressions, statements, and program units Semantics - the meaning of the expressions, statements, and program units Syntax and semantics provide a language's definition Semantics should follow from syntax in a well designed programming language Language Definition Users: Initial evaluaors (language designers) Implementers (compiler writers) Programmers (language users)","title":"3.1 Introduction"},{"location":"prog_langs/ch3/#32-describing-syntax","text":"A language is a set of strings of characters from some alphabet Sentences/Statements are the strigns of a language Describing a language with english can lead to many issues (e.g. Fortran) Meta-Language - a language used to define other languages Grammar - a meta-lanugage used to define the syntax of a language A sentence can be syntactically correct but not semantically correct","title":"3.2 Describing Syntax"},{"location":"prog_langs/ch3/#lexical-analysis","text":"Lexical specification is usually seperate from syntactic description lexemes include literals, operators, keywords, etc. programs are strings of lexemes Converting characters in the source program into lexical units Lexical analyzer splits source code into tokens Token- syntactic category that forms a class of lexemes identifiers (names of vars, methods, classes) , literals, keywords, operators, punctuation Lexeme- a sequence of characters that matches the pattern for a token","title":"Lexical Analysis"},{"location":"prog_langs/ch3/#formal-definition-of-languages","text":"Two ways: Recognizer- reads input strings over the alphabet of the language and decides whether the input strings belong to the language produces a yes/no answer as to whether the input string is a valid sentence in the language Syntax analysis is a recognizer Generator- generates random valid sentences in a specific language Neither on their own are useful in learning a language Used together they form the basis of computational theory","title":"Formal Definition of Languages"},{"location":"prog_langs/ch3/#33-formal-methods-of-describing-syntax","text":"Grammars- used to descirbe the syntax of programming languages","title":"3.3 Formal Methods of Describing Syntax"},{"location":"prog_langs/ch3/#context-free-grammars","text":"Developed by Noam Chomsky (a linguist) 4 classes of generative devices or grammars that define 4 classes of languages 2 of them, context-free and regular grammars, were later useful for describing the syntax of programming languages forms of tokens in PLs can be described by regular grammars syntax of whole languages can be described by context-free grammars","title":"Context Free Grammars"},{"location":"prog_langs/ch3/#backus-naur-form-bnf","text":"Invented by John Backus to describe Algol 58 A natural notation for describing syntax Equivalent to context-free grammars Metalanguage for PLs Grammar consists of: Start symbol Finite set of production rules Finite set of terminal symbols Finite set of nonterminal symbols Uses abstractions for syntactic structures <assign> -> <var> = <expression> is a definition of the assign abstraction where the LHS of the arrow is the abstraction being defined and the RHS of the arrow consists of a mixture of tokens, lexemes, and references to other abstractions the definition is called a production rule nonterminal symbols- the abstractions in a BNF description can have 2+ distinct definitions (represent 2+ possible syntactic forms in the language) multiple definitions can be written as a single rule seperated by a | meaning logical OR terminal symbols- lexemes and tokens of the rules BNF Description/Grammar- a collection of rules Simple but sufficiently powerful to describe syntax of PLs Lists (utilizes recursion): <identifier_list> -> identifier | identifier, <identifier_list> ordering, nested structures of any depth, operator precedence and associativity Grammar- generative device for defining languages Start with a special nonterminal start symbol and then apply a sequence of rules in a derivation start symbol is usually <program> Sentential Form- every string of nonterminal or terminal symbols in a derivation Sentence- a sentential form that has only terminal symbols Leftmost derivation- leftmost nonterminal in each sentential form is the one that is expanded next derivation could be rightmost or in neither leftmost or rightmost since derivation order has no effect on the generated language Most languages are infinite so all sentences in the language cannot be generated in finite time","title":"Backus-Naur Form (BNF)"},{"location":"prog_langs/ch3/#parse-tree","text":"A hierarchial representation of a derivation every internal node is nonterminal symbol every leaf node is a terminal symbol","title":"Parse Tree"},{"location":"prog_langs/ch3/#ambiguity","text":"A grammar is ambiguous iff it generates a sentital form that has 2+ distinct parse trees bad for compilers that need 1 unique parse tree If we use parse tree to indicate precedence levels of the operators, we cannot have ambiguity operator associativity can also be indicated by a grammar Ex: <expr> -> <expr> + const | const indicates left associativity of the + operator (left recursion -> left associativity)","title":"Ambiguity"},{"location":"prog_langs/ch3/#dangling-else-ambiguity","text":"if (<logic_expr>) if (<logic_expr>) <stmt> else <stmt> is ambiguous as to which if statement the else belongs to Rewrite grammar to restirct what can appear inside a nested if-statement Use <matched> and <unmatched> abstractions to handle the different types of if-else statements <stmt> \u2192 <matched> | <unmatched> <matched> \u2192 if (<logic_expr>) <matched> else <matched> |any non-if statement <unmatched> \u2192 if (<logic_expr>) <stmt> | if (<logic_expr>) <matched> else <unmatched> Can also use an explicit delimiter to end every conditional","title":"Dangling Else Ambiguity"},{"location":"prog_langs/ch3/#extended-bnf","text":"More concise Equally powerful/expressive Defect standard for defining PLs optional parts placed in brackets [] <proc_call> -> <ident> ([<expr_list>]) alternative in BNF: <pc> -> <id> () | <id> (<el>) alternative parts of rhs are placed inside parenthesies and seperated by vertical vertical bars <term> -> <term> (+ | -) const Repetitions (0 or more) are placed inside baces {} <identifier_list> -> <identifier> {, <identifier>}","title":"Extended BNF"},{"location":"prog_langs/ch3/#semantics","text":"No single widely accepeted way of describing semantics","title":"Semantics"},{"location":"prog_langs/ch5/","text":"Ch. 5 5.3 Variables Variable is a sextuple of attributes name, address, type, value, lifetime, scope Names most PLs are case senstive (C based languages) reduces readability but following naming conventions fixes this mostly some are case insensitive (Ada, Fortran, Pascal, SQL) Semantically meaningful capitalization sometimes exists (e.g. Go using capitals to access members of packages) reserved word- special word that can't be used in user-defined names None: PL/1 Many: COBOL keyword- special only in certain contexts Address memory address a var is associated with var may have diff addresses at diff times during execution Referred to as the L-value of a variable by compiler writers Aliases- 2+ vars refer to same memory address hinders readability Type Determines: the range of values of variables the set of operations defined for values of that type Value The contents of the memory location Referred to as the r-value of a variable 5.4 Binding Attributes to Variables A binding is an association between an attribute and an entity (e.g. btw a var and its type or val, or btw an operation and a symbol) binding time- time at which a binding takes place (can be runtime , compile time, language design time, or language implementation time) Static Binding- bindings that first occur before runtime and remain unchanged throughout execution Dynamic Binding- bindings that first occur during execution or can change during execution of the program Type Binding Static Type Binding Explicit Declaration- type information supplied in source code (e.g. statically typed languages like C, Java) Implicit Declaration- type specification through default conventions (e.g. FORTRAN, Perl) Type Inferencing- static typing without having to declare explciti types (e.g. use of auto in C++ will have compiler infer the type) Dynamic Type Binding Variable is bound to a type when its assigned a value in an assignment statement Increased flexibility High cost of runt-time type checking and interpretation JavaScript, Lisp, Python, PHP, matlab Storage and Lifetime Bindings Static Variables bound to memory cells before execution begins and remains bound to same memory cell throughout execution Pros: Direct addressing is very efficient Globally accessible History sensitive subprogram support Cons: Lack of flexibility (no recursion) No shared storage Stack-Dynamic Variables Storage bindings created for variables when their declaration statements are elaborated (i.e. executed) pros: allows recursion Conserves storage cons: overhead of allocation and deallocation subprograms not history-sensitive since stack vars are deallocated after use indirect addressing is inefficient (go to address of stack pointer and then traverse to correct adress in the stack frame for the variable of interest) Explicit Heap-Dynamic Variables Allocated and deallocated by explicit directives from the programmer (take effect during execution) Dynamic objects in C++ via new and delete , all objects in Java Pros: Provides for dynamic storage managemet Cons: ineffient indirect addressing unreliable (error prone) complex storage management implementation Implicit Heap-Dynamic Variables allocation and deallocation caused by assignment statements all variables in lis; all strings/arrays in JS, Perl, & PHP pros: flexibility (generic code) cons: inefficient since all attributes are dnyamic Lifetime storage bindings allocation- getting a cell from pool of available cells deallocation- putting a cell back into the pool Types of Variables Summary static - bound to mem cells before execution and remains throughout stack-dynamic - bound when declaration statements elaborated explicit heap-dynamic - allocated and deallocated by new and delete implicit heap-dynamic - allocation and deallocation caused by assignment statements 5.5 Scope Static Scope based on program text referencing environment: local variables + all variables in all enclosing scopes aka Lexical Scope Finding nonlocal variables- search declarations in increasingly larger enclosing scopes until one is found for the given name Static Ancestors- enclosing static scopes Static Parent- nearest static ancestor pros: works well for most situations programs easy to read and reason about Cons: too much access is possible want variables to be accessed only where needed as a program evolves, initial structure is destroyed (local vars tend towards being global variables) Dynamic Scope based on calling sequences of program units referencing environemnt: the local variables + all visible variables in all active subprograms Finding nonlocal variables- search declarations back through the chain of subprogram calls Not used in modern PLs except for exception handling Pros: convenience since the called subprogram is executed in the context of the caller Cons: poor readability no static type checking (must be done dynamically) all variables from caller are visible to called subprogram","title":"Ch. 5 Names, Bindings, & Scope"},{"location":"prog_langs/ch5/#ch-5","text":"","title":"Ch. 5"},{"location":"prog_langs/ch5/#53-variables","text":"Variable is a sextuple of attributes name, address, type, value, lifetime, scope","title":"5.3 Variables"},{"location":"prog_langs/ch5/#names","text":"most PLs are case senstive (C based languages) reduces readability but following naming conventions fixes this mostly some are case insensitive (Ada, Fortran, Pascal, SQL) Semantically meaningful capitalization sometimes exists (e.g. Go using capitals to access members of packages) reserved word- special word that can't be used in user-defined names None: PL/1 Many: COBOL keyword- special only in certain contexts","title":"Names"},{"location":"prog_langs/ch5/#address","text":"memory address a var is associated with var may have diff addresses at diff times during execution Referred to as the L-value of a variable by compiler writers Aliases- 2+ vars refer to same memory address hinders readability","title":"Address"},{"location":"prog_langs/ch5/#type","text":"Determines: the range of values of variables the set of operations defined for values of that type","title":"Type"},{"location":"prog_langs/ch5/#value","text":"The contents of the memory location Referred to as the r-value of a variable","title":"Value"},{"location":"prog_langs/ch5/#54-binding-attributes-to-variables","text":"A binding is an association between an attribute and an entity (e.g. btw a var and its type or val, or btw an operation and a symbol) binding time- time at which a binding takes place (can be runtime , compile time, language design time, or language implementation time) Static Binding- bindings that first occur before runtime and remain unchanged throughout execution Dynamic Binding- bindings that first occur during execution or can change during execution of the program","title":"5.4 Binding Attributes to Variables"},{"location":"prog_langs/ch5/#type-binding","text":"","title":"Type Binding"},{"location":"prog_langs/ch5/#static-type-binding","text":"Explicit Declaration- type information supplied in source code (e.g. statically typed languages like C, Java) Implicit Declaration- type specification through default conventions (e.g. FORTRAN, Perl) Type Inferencing- static typing without having to declare explciti types (e.g. use of auto in C++ will have compiler infer the type)","title":"Static Type Binding"},{"location":"prog_langs/ch5/#dynamic-type-binding","text":"Variable is bound to a type when its assigned a value in an assignment statement Increased flexibility High cost of runt-time type checking and interpretation JavaScript, Lisp, Python, PHP, matlab","title":"Dynamic Type Binding"},{"location":"prog_langs/ch5/#storage-and-lifetime-bindings","text":"","title":"Storage and Lifetime Bindings"},{"location":"prog_langs/ch5/#static-variables","text":"bound to memory cells before execution begins and remains bound to same memory cell throughout execution Pros: Direct addressing is very efficient Globally accessible History sensitive subprogram support Cons: Lack of flexibility (no recursion) No shared storage","title":"Static Variables"},{"location":"prog_langs/ch5/#stack-dynamic-variables","text":"Storage bindings created for variables when their declaration statements are elaborated (i.e. executed) pros: allows recursion Conserves storage cons: overhead of allocation and deallocation subprograms not history-sensitive since stack vars are deallocated after use indirect addressing is inefficient (go to address of stack pointer and then traverse to correct adress in the stack frame for the variable of interest)","title":"Stack-Dynamic Variables"},{"location":"prog_langs/ch5/#explicit-heap-dynamic-variables","text":"Allocated and deallocated by explicit directives from the programmer (take effect during execution) Dynamic objects in C++ via new and delete , all objects in Java Pros: Provides for dynamic storage managemet Cons: ineffient indirect addressing unreliable (error prone) complex storage management implementation","title":"Explicit Heap-Dynamic Variables"},{"location":"prog_langs/ch5/#implicit-heap-dynamic-variables","text":"allocation and deallocation caused by assignment statements all variables in lis; all strings/arrays in JS, Perl, & PHP pros: flexibility (generic code) cons: inefficient since all attributes are dnyamic","title":"Implicit Heap-Dynamic Variables"},{"location":"prog_langs/ch5/#lifetime","text":"storage bindings allocation- getting a cell from pool of available cells deallocation- putting a cell back into the pool","title":"Lifetime"},{"location":"prog_langs/ch5/#types-of-variables-summary","text":"static - bound to mem cells before execution and remains throughout stack-dynamic - bound when declaration statements elaborated explicit heap-dynamic - allocated and deallocated by new and delete implicit heap-dynamic - allocation and deallocation caused by assignment statements","title":"Types of Variables Summary"},{"location":"prog_langs/ch5/#55-scope","text":"","title":"5.5 Scope"},{"location":"prog_langs/ch5/#static-scope","text":"based on program text referencing environment: local variables + all variables in all enclosing scopes aka Lexical Scope Finding nonlocal variables- search declarations in increasingly larger enclosing scopes until one is found for the given name Static Ancestors- enclosing static scopes Static Parent- nearest static ancestor pros: works well for most situations programs easy to read and reason about Cons: too much access is possible want variables to be accessed only where needed as a program evolves, initial structure is destroyed (local vars tend towards being global variables)","title":"Static Scope"},{"location":"prog_langs/ch5/#dynamic-scope","text":"based on calling sequences of program units referencing environemnt: the local variables + all visible variables in all active subprograms Finding nonlocal variables- search declarations back through the chain of subprogram calls Not used in modern PLs except for exception handling Pros: convenience since the called subprogram is executed in the context of the caller Cons: poor readability no static type checking (must be done dynamically) all variables from caller are visible to called subprogram","title":"Dynamic Scope"},{"location":"prog_langs/ch6/","text":"Data Types Defines a set of possible values (the domain) and the pre-defined operations Defines how to interpret bit strings of various lengths Primitive Integer - almost always an exact reflection of hardware python has unlimited precision ints (other languages limit based on number of bits) Floats - model real numbers (but only as approximations) IEEE Floating Point Standard 754 float- usually 32 bits double- double the precision so often 64 bits Complex - two floats (1 real, 1 complex) Decimal - attempts were made to store a fixed number of decimal digits in coded form (Binary Coded Decimal) where each digit is encoded separately but was overall a failure Pros: increased accuracy since each digit is represented by 4 bits Cons: limited range, wastes memory, not all CPUs have direct hardware support Used by business applications for representing money (e.g. C# has a double and decimal type which has more precision) Boolean - implemented as a byte due to byte-addressable memory (can't address single bits) Pros: readability in logic expressions (as opposed to interpreting numeric expressions) Character- ASCII is a 7-bit character set which is limited and inadequate in the modern age UNICODE initially fixed 16-bit representation includes the base multilingual plane for non-roman characters backwards compatible with ASCII still inadequate UTF-8 variable length for bit representation most widely used Strings Static Length compile time descriptor includes the length Descriptor- collection of attributes of a variable can be static- maintained by compiler (e.g. C++) or can be dynamic- managed at runtime (e.g. Python) Limited Dynamic Length run time descriptor includes the maximum length and the current length Dynamic Length Ordinal Types Type in which the range of possible values can be easily mapped to the set of positive integers primitive ordinals in java: integer, char, boolean Enumeration Types user-defined ordinal type all possible values, which are amed constants, are provided in the definition Pros: readability reliability- compiler can perform checks Array Types Array- an aggregate of homogeneous data elements where individual elements are identified by position relative to the first indexing/subscripting an array is a mapping from indices to elements some languages like Ada, Fortran, and Matlab use () instead of [] index range checking is done: by default: C#, Java, Go Not at all: C, C++, Fortran heterogeneous array - one in which elements need not be the same type JS, Perl, Python, Ruby heap-dynamic arrays oftentimes array elements only contain references to the data stored Subscript Binding & Array Categories Static Statically bound subscript ranges Static storage allocation Increased efficiency b/c no dynamic (de)allocation C, C++ arrays that include static Fixed Stack-Dynamic Statically bound subscript ranges Storage allocation done at declaration elaboration time Increased space efficiency b/c space can be reused during runtime C, C++ arrays without static Fixed Heap-Dynamic Static binding of subscript ranges Dynamic storage binding when requested at runtime Heap-Dynamic Dynamic binding of subscript ranges Dynamic storage allocation Can change any number of times (more flexible) Array Implementation access function for single-dim array: address(a[k]) = address(arr[lower_bound]) + ((k - lower_bound) * element_size) access function for multi-dim array: address(a[i,j]) = address(a[row_lb, col_lb]) + (((i - row_lb) * n) + (j - col_lb)) * element_size the lower bounds are zero in 0-indexed languages and 1 in 1-indexed languages Storing Arrays in Memory: Row-Major order (used by most languages) Column-Major order (Fortran & Matlab) knowing which affects speed of code row major order means you should process by row to reduce cache misses since cache might store only 1 row at a time cache misses and even page swaps are expensive with large matrices Associative Arrays Unordered collection of data elements indexed by keys maps arbitrary indices to values elements are (key, value) pairs often implemented as hash tables Composite Types Aggregate of possibly different data elements in whih the individual elements are identified by names struct in c/c++ & go, named tuple in python from OOP pov, classes are a composite type Union Type type whose variables are allowed to store different type values at different times during execution free union- when there is no language support for type checking in the union construct (e.g. C, C++) so it allows you to create unsafe code reason why C,C++ are not strongly typed discriminant- type indicator required to be included in a union in certain languages like ML, Haskell, F# Java and C# don't support unions due to safety concerns Pointer Types Variable that takes on values of memory addresses or a special value null Indirect addressing- using a pointer to step through an array Dynamic memory- can access memory locaitions on the heap 2 operations: Assignment- set a pointer variable's value to a memory address Dereferencing- get the value stored at the memory address represented by pointer's value Can be done explicitly or implicitly Dangers: Dangling Pointers- pointer points to heap-dynamic variable that has been deallocated Memory Leak- allocated heap-dynamic variable that is no longer acessible to the user program Buffer Overflows- no bounds checking on pointers when using with arrays Necessary for dynamic data structures Reference Types C++ has special kind of pointer type that is used primarily for formal parameters has the advantages of both pass-by-pointer and pass-by-value Java uses only references and replaces pointers entirely C# uses references but also allows pointers in unsafe methods Solutions for Dangling Pointers Tombstones An extra heap cell is allocated as a pointer to the actual heap-dynamic variable Any pointers pointing to the heap-dynamic variable actually point at its tombstone If any pointer deallocates the variable, the tombstone is set to null so other pointers now point to null instead of a re-allocated memory address (safer but can still get nullptr dereferencing errors) Costly in time and space Similar idea to smart pointers Locks-and-Keys Pointer values are represented as (key, address) pairs Heap-dynamic variables are represented as variable plus a cell for an integer lock value When a variable is allocated, the lock value is created and plaed in the lock cell and the key of the pointer Each dereference must compare the key and the lock No explicit deallocation permited by the language (e.g. Rust & Java) Heap Management/Garbage Collection Complex runtime process Two approaches: Eager- reclamation is gradual/continual (e.g. referenece counters) Lazy- reclamation occurs when the list of variable space becomes empty or low (e.g. mark-sweeep & stop-n-copy) Java uses combination of both techniques Reference Counter Maintain a counter in every cell which stores the number of pointers currently pointing at the cell Reclaim cells when their count drops to zero Pros: Incremental, so no significant delays in app's execution Cons: Space Required Execution time required Complications for cells connected in a cycle Mark-and-Sweep Recursively follow all \"live\" pointers, marking all discovered structures as useful Sweep over the entire heap and reclaim any structures not marked as useful (turn off markers in prep for next time) Pros: Cons: space required execution time required Stop-and-Copy Splits heap memory in half All new allocations go into the active half At collection time, recursively follow all live pointers and copy all discovered structures to the other half, which becomes the active half The inactive half now only contains garbge and is reclaimed all at once Generational Copiers Exploit fact that many objects have short lives while others have long lives Keep track of lifetimes (how many collection passes they have survived) and collect long lifetime objects less frequently Escape Analysis Determines if any references to a value escape the function where the value i declared If no references escape, the value can be stored on the stack Values stored on the stack don't need to be allocated/freed Java and Go do this // car object would be stored on the stack public String getCarDesc(){ Car car = new Car(); String desc = car.genDesc(); return desc; } Type Checking ensure operands of an operator are of compatible types include subprogram parameters and assignment statements If type bindings are static, type checking can be static (i.e. at compile time) If type bindings are dynamic, type checking must be dynamic Compatible Type- type that is legal for the operator or can be coerced (implicitly converted) by compiler generated code to a legal type Strongly Typed Languages- type errors are always detected at compile time or run time No: C, C++ Almost: Java, C# (allow explicit type conversion which can fail at runtime but pass compiler) Yes: F#, ML, Rust","title":"Ch. 6 Data Types"},{"location":"prog_langs/ch6/#data-types","text":"Defines a set of possible values (the domain) and the pre-defined operations Defines how to interpret bit strings of various lengths","title":"Data Types"},{"location":"prog_langs/ch6/#primitive","text":"Integer - almost always an exact reflection of hardware python has unlimited precision ints (other languages limit based on number of bits) Floats - model real numbers (but only as approximations) IEEE Floating Point Standard 754 float- usually 32 bits double- double the precision so often 64 bits Complex - two floats (1 real, 1 complex) Decimal - attempts were made to store a fixed number of decimal digits in coded form (Binary Coded Decimal) where each digit is encoded separately but was overall a failure Pros: increased accuracy since each digit is represented by 4 bits Cons: limited range, wastes memory, not all CPUs have direct hardware support Used by business applications for representing money (e.g. C# has a double and decimal type which has more precision) Boolean - implemented as a byte due to byte-addressable memory (can't address single bits) Pros: readability in logic expressions (as opposed to interpreting numeric expressions) Character- ASCII is a 7-bit character set which is limited and inadequate in the modern age UNICODE initially fixed 16-bit representation includes the base multilingual plane for non-roman characters backwards compatible with ASCII still inadequate UTF-8 variable length for bit representation most widely used","title":"Primitive"},{"location":"prog_langs/ch6/#strings","text":"Static Length compile time descriptor includes the length Descriptor- collection of attributes of a variable can be static- maintained by compiler (e.g. C++) or can be dynamic- managed at runtime (e.g. Python) Limited Dynamic Length run time descriptor includes the maximum length and the current length Dynamic Length","title":"Strings"},{"location":"prog_langs/ch6/#ordinal-types","text":"Type in which the range of possible values can be easily mapped to the set of positive integers primitive ordinals in java: integer, char, boolean","title":"Ordinal Types"},{"location":"prog_langs/ch6/#enumeration-types","text":"user-defined ordinal type all possible values, which are amed constants, are provided in the definition Pros: readability reliability- compiler can perform checks","title":"Enumeration Types"},{"location":"prog_langs/ch6/#array-types","text":"Array- an aggregate of homogeneous data elements where individual elements are identified by position relative to the first indexing/subscripting an array is a mapping from indices to elements some languages like Ada, Fortran, and Matlab use () instead of [] index range checking is done: by default: C#, Java, Go Not at all: C, C++, Fortran heterogeneous array - one in which elements need not be the same type JS, Perl, Python, Ruby heap-dynamic arrays oftentimes array elements only contain references to the data stored","title":"Array Types"},{"location":"prog_langs/ch6/#subscript-binding-array-categories","text":"","title":"Subscript Binding &amp; Array Categories"},{"location":"prog_langs/ch6/#static","text":"Statically bound subscript ranges Static storage allocation Increased efficiency b/c no dynamic (de)allocation C, C++ arrays that include static","title":"Static"},{"location":"prog_langs/ch6/#fixed-stack-dynamic","text":"Statically bound subscript ranges Storage allocation done at declaration elaboration time Increased space efficiency b/c space can be reused during runtime C, C++ arrays without static","title":"Fixed Stack-Dynamic"},{"location":"prog_langs/ch6/#fixed-heap-dynamic","text":"Static binding of subscript ranges Dynamic storage binding when requested at runtime","title":"Fixed Heap-Dynamic"},{"location":"prog_langs/ch6/#heap-dynamic","text":"Dynamic binding of subscript ranges Dynamic storage allocation Can change any number of times (more flexible)","title":"Heap-Dynamic"},{"location":"prog_langs/ch6/#array-implementation","text":"access function for single-dim array: address(a[k]) = address(arr[lower_bound]) + ((k - lower_bound) * element_size) access function for multi-dim array: address(a[i,j]) = address(a[row_lb, col_lb]) + (((i - row_lb) * n) + (j - col_lb)) * element_size the lower bounds are zero in 0-indexed languages and 1 in 1-indexed languages Storing Arrays in Memory: Row-Major order (used by most languages) Column-Major order (Fortran & Matlab) knowing which affects speed of code row major order means you should process by row to reduce cache misses since cache might store only 1 row at a time cache misses and even page swaps are expensive with large matrices","title":"Array Implementation"},{"location":"prog_langs/ch6/#associative-arrays","text":"Unordered collection of data elements indexed by keys maps arbitrary indices to values elements are (key, value) pairs often implemented as hash tables","title":"Associative Arrays"},{"location":"prog_langs/ch6/#composite-types","text":"Aggregate of possibly different data elements in whih the individual elements are identified by names struct in c/c++ & go, named tuple in python from OOP pov, classes are a composite type","title":"Composite Types"},{"location":"prog_langs/ch6/#union-type","text":"type whose variables are allowed to store different type values at different times during execution free union- when there is no language support for type checking in the union construct (e.g. C, C++) so it allows you to create unsafe code reason why C,C++ are not strongly typed discriminant- type indicator required to be included in a union in certain languages like ML, Haskell, F# Java and C# don't support unions due to safety concerns","title":"Union Type"},{"location":"prog_langs/ch6/#pointer-types","text":"Variable that takes on values of memory addresses or a special value null Indirect addressing- using a pointer to step through an array Dynamic memory- can access memory locaitions on the heap 2 operations: Assignment- set a pointer variable's value to a memory address Dereferencing- get the value stored at the memory address represented by pointer's value Can be done explicitly or implicitly Dangers: Dangling Pointers- pointer points to heap-dynamic variable that has been deallocated Memory Leak- allocated heap-dynamic variable that is no longer acessible to the user program Buffer Overflows- no bounds checking on pointers when using with arrays Necessary for dynamic data structures","title":"Pointer Types"},{"location":"prog_langs/ch6/#reference-types","text":"C++ has special kind of pointer type that is used primarily for formal parameters has the advantages of both pass-by-pointer and pass-by-value Java uses only references and replaces pointers entirely C# uses references but also allows pointers in unsafe methods","title":"Reference Types"},{"location":"prog_langs/ch6/#solutions-for-dangling-pointers","text":"Tombstones An extra heap cell is allocated as a pointer to the actual heap-dynamic variable Any pointers pointing to the heap-dynamic variable actually point at its tombstone If any pointer deallocates the variable, the tombstone is set to null so other pointers now point to null instead of a re-allocated memory address (safer but can still get nullptr dereferencing errors) Costly in time and space Similar idea to smart pointers Locks-and-Keys Pointer values are represented as (key, address) pairs Heap-dynamic variables are represented as variable plus a cell for an integer lock value When a variable is allocated, the lock value is created and plaed in the lock cell and the key of the pointer Each dereference must compare the key and the lock No explicit deallocation permited by the language (e.g. Rust & Java)","title":"Solutions for Dangling Pointers"},{"location":"prog_langs/ch6/#heap-managementgarbage-collection","text":"Complex runtime process Two approaches: Eager- reclamation is gradual/continual (e.g. referenece counters) Lazy- reclamation occurs when the list of variable space becomes empty or low (e.g. mark-sweeep & stop-n-copy) Java uses combination of both techniques","title":"Heap Management/Garbage Collection"},{"location":"prog_langs/ch6/#reference-counter","text":"Maintain a counter in every cell which stores the number of pointers currently pointing at the cell Reclaim cells when their count drops to zero Pros: Incremental, so no significant delays in app's execution Cons: Space Required Execution time required Complications for cells connected in a cycle","title":"Reference Counter"},{"location":"prog_langs/ch6/#mark-and-sweep","text":"Recursively follow all \"live\" pointers, marking all discovered structures as useful Sweep over the entire heap and reclaim any structures not marked as useful (turn off markers in prep for next time) Pros: Cons: space required execution time required","title":"Mark-and-Sweep"},{"location":"prog_langs/ch6/#stop-and-copy","text":"Splits heap memory in half All new allocations go into the active half At collection time, recursively follow all live pointers and copy all discovered structures to the other half, which becomes the active half The inactive half now only contains garbge and is reclaimed all at once","title":"Stop-and-Copy"},{"location":"prog_langs/ch6/#generational-copiers","text":"Exploit fact that many objects have short lives while others have long lives Keep track of lifetimes (how many collection passes they have survived) and collect long lifetime objects less frequently","title":"Generational Copiers"},{"location":"prog_langs/ch6/#escape-analysis","text":"Determines if any references to a value escape the function where the value i declared If no references escape, the value can be stored on the stack Values stored on the stack don't need to be allocated/freed Java and Go do this // car object would be stored on the stack public String getCarDesc(){ Car car = new Car(); String desc = car.genDesc(); return desc; }","title":"Escape Analysis"},{"location":"prog_langs/ch6/#type-checking","text":"ensure operands of an operator are of compatible types include subprogram parameters and assignment statements If type bindings are static, type checking can be static (i.e. at compile time) If type bindings are dynamic, type checking must be dynamic Compatible Type- type that is legal for the operator or can be coerced (implicitly converted) by compiler generated code to a legal type Strongly Typed Languages- type errors are always detected at compile time or run time No: C, C++ Almost: Java, C# (allow explicit type conversion which can fail at runtime but pass compiler) Yes: F#, ML, Rust","title":"Type Checking"},{"location":"prog_langs/ch7/","text":"Expressions fundamental means of specifying computations in a programming language unary, binary, ternary indicates number of operands for an operator infix vs prefix notation (prefix notation has no precedence concerns or associativity concerns) Functional Side Effects: functional side effects: when a function changes one of its parametrs or a global variable solutions: disallow functional side effects in language definition demand operand evaluation order be fixed ex: java requires operands appear to be evaluated in left-to-right order Referential Transparency proprty that describes a program if any two expressions in a program that have the same value can be substituuted for one another anywhere in the program, without affecting the action of the program opposite of functional side effects","title":"Ch. 7 Expression"},{"location":"prog_langs/ch7/#expressions","text":"fundamental means of specifying computations in a programming language unary, binary, ternary indicates number of operands for an operator infix vs prefix notation (prefix notation has no precedence concerns or associativity concerns)","title":"Expressions"},{"location":"prog_langs/ch7/#functional-side-effects","text":"functional side effects: when a function changes one of its parametrs or a global variable solutions: disallow functional side effects in language definition demand operand evaluation order be fixed ex: java requires operands appear to be evaluated in left-to-right order","title":"Functional Side Effects:"},{"location":"prog_langs/ch7/#referential-transparency","text":"proprty that describes a program if any two expressions in a program that have the same value can be substituuted for one another anywhere in the program, without affecting the action of the program opposite of functional side effects","title":"Referential Transparency"},{"location":"prog_langs/ch9/","text":"Ch. 9 Subprograms subprogram definition describes the actions represented by the subprogram subprograms can either be functions or procedures procedures can modify state local variables in subprograms can be stack-dynamic or static 3 models of parameter passing: in mode, out mode, and inout mode Some languages allow operator overloading Subprograms can be generic A closure is a subprogram and its referencing environment subprogram characteristics single entry point calling program unit is suspended during execution of called subprogram (i.e. 1 subprogram in execution at any given time) control always returns to the caller when the subprogram execution terminates *not true for coroutines parameters positional- binding of actual parameters to formal parameters is by position safe + effective Keyword- name of formal parameter to which an acutal parameter is to be bound is specified w/ the actual parameter pro: parameters can appear in any order and avoid param correspondence errors con: users must know the formal parameter's names in mode- data is received from the actual parameter pass-by-value- transmit a data value by copying it pass-by-reference- transmit an access path (pointer/reference) to the data value out mode- data is returned from the actual parameter pass-by-result- copy value to caller's actual parameter (equivalent of pass-by-value for in mode) inout mode- data is transferred in both directions pass-by-value-result (aka pass-by-copy)- combo of by value and by result since we copy in the value at the start and copy it back out at the end pass-by-reference (aka pass-by-sharing)- effiecient passing (no copy) but slower access to extra level of indirection pass-by-name-unevaluated expressions can be passed to formal parameter to be evaluated when the formal parameter is used 2 types of subprograms Procedure- expected to produce side effects (can reutrn values only by affecting globals or parameters) Function- expected to reutrn a value and produce no side effects local referencing environments stack-dynamic local variables (+) support for recursion (+) storage for local vars is shared among some subprograms (-) allocation/de-allocation and initialization overhead for each call (-) indirect addressing (-) subprograms cannot be history sensitive Static local variables have te opposite pros and cons of stack-dynamic local variables closure a subprogram and the referencing environment where it was defined only needed if a subprogram can access variables in nesting scopes and it can be called from anywhere static-scoped language that doesn't permit nested subprograms doesn't need closures // anonymous fn returned by makeAdder must be a closure function makeAdder(x) { return function(y) {return x + y;} }","title":"Ch. 9 Subprograms"},{"location":"prog_langs/ch9/#ch-9-subprograms","text":"subprogram definition describes the actions represented by the subprogram subprograms can either be functions or procedures procedures can modify state local variables in subprograms can be stack-dynamic or static 3 models of parameter passing: in mode, out mode, and inout mode Some languages allow operator overloading Subprograms can be generic A closure is a subprogram and its referencing environment","title":"Ch. 9 Subprograms"},{"location":"prog_langs/ch9/#subprogram-characteristics","text":"single entry point calling program unit is suspended during execution of called subprogram (i.e. 1 subprogram in execution at any given time) control always returns to the caller when the subprogram execution terminates *not true for coroutines","title":"subprogram characteristics"},{"location":"prog_langs/ch9/#parameters","text":"positional- binding of actual parameters to formal parameters is by position safe + effective Keyword- name of formal parameter to which an acutal parameter is to be bound is specified w/ the actual parameter pro: parameters can appear in any order and avoid param correspondence errors con: users must know the formal parameter's names in mode- data is received from the actual parameter pass-by-value- transmit a data value by copying it pass-by-reference- transmit an access path (pointer/reference) to the data value out mode- data is returned from the actual parameter pass-by-result- copy value to caller's actual parameter (equivalent of pass-by-value for in mode) inout mode- data is transferred in both directions pass-by-value-result (aka pass-by-copy)- combo of by value and by result since we copy in the value at the start and copy it back out at the end pass-by-reference (aka pass-by-sharing)- effiecient passing (no copy) but slower access to extra level of indirection pass-by-name-unevaluated expressions can be passed to formal parameter to be evaluated when the formal parameter is used","title":"parameters"},{"location":"prog_langs/ch9/#2-types-of-subprograms","text":"Procedure- expected to produce side effects (can reutrn values only by affecting globals or parameters) Function- expected to reutrn a value and produce no side effects","title":"2 types of subprograms"},{"location":"prog_langs/ch9/#local-referencing-environments","text":"stack-dynamic local variables (+) support for recursion (+) storage for local vars is shared among some subprograms (-) allocation/de-allocation and initialization overhead for each call (-) indirect addressing (-) subprograms cannot be history sensitive Static local variables have te opposite pros and cons of stack-dynamic local variables","title":"local referencing environments"},{"location":"prog_langs/ch9/#closure","text":"a subprogram and the referencing environment where it was defined only needed if a subprogram can access variables in nesting scopes and it can be called from anywhere static-scoped language that doesn't permit nested subprograms doesn't need closures // anonymous fn returned by makeAdder must be a closure function makeAdder(x) { return function(y) {return x + y;} }","title":"closure"},{"location":"prog_langs/oop/","text":"Object Oriented Programming: What is a Class: A blueprint Fields (instance variables) What an object knows Methods(Functions) What an object does What is Inheritance: Parent/Super class that shares fields/methods with its subclasses that also have their own fields & methods Subclasses abstract out the super class's features Subclasses can override or extend methods that don't work Subclasses only define the changes since the super's fields & methods are already defined when you extend the super class Use is A? principle to decide whether to extend a class Ex: Is a Dog an Animal? Yes, so Dog extends Animal Ex: Is a Dog a cat? No, so Dog doesn't extend Cat Use inheritance when a subclass needs most of the methods in the superclass Do not use inheritance just to reuse code if is A? doesn't work class Animal{ private String name; private double height; private int weight; private String sound; public void setName(String newName){ name = newName; } public void setSound(String newSound){ sound = newSound; } } class Dog extends Animal{ public Dog(){ super(); //Calls super constructor setSound(\"Bark\"); } public void digHole(){ System.out.println(\"Hole dug\"); } } What is Encapsulation: Protects data Use private fields Do not set fields directly Use public getter & setter functions to access & change the data Setter = Mutator Getter = Accessor class Dog{ private double height; public void setHeight(newHeight){ if(newHeight > 0){ height = newHeight; } else{ //Throw an Error } } } Instance vs. Local Variables: Instance Variable(AKA fields) are declared in a class Local Variables are declared in a method What is Polymorphism: Allows you to write methods that don't need to change if new subclasses are created Ex: Dog can add a new method w/o changing Animal Allows you to put diff subclasses in one array Animal doggy = new Dog(); Animal kitty = new Cat(); Animal[] animals = [doggy,kitty]; kitty.getSound(); //Returns Meow doggy.digHole(); //Would not work ((Dog)doggy).digHole(); //Would Work You can't access methods this way if they are only in the subclass Need to cast the object to the subclass that contains that method Cannot reference non-static variables or non-static-methods(w/o an object) in a static method Cannot access private methods outside of a subclass/class What is an Abstract Class: Gives power of polymorphism w/o all the work There are no abstract fields but can have protected variables that are rewritten as private fields in subclasses All methods do not have to be abstract w/in an abstract class You can have static methods w/in abstract classes Cannot create objects from abstract classes but subclasses can extend them and be made into objects Have to override abstract methods in the subclass in order to extend the class abstract public Class Creature{ protected String name; public abstract void setName(newName); } What is an Interface: A class w/ only abstract methods Can implement as many interfaces to a class as you want Can only use public static and final fields Provide the ultimate flexibility Classes from different inheritance trees can use a common interface Avoid using interfaces just to force the creation of a method public interface Living { public void setName(String newName); } public class Monkey implements Living{ private name; public void setName(String newName){ name = newName; } }","title":"Oop"},{"location":"prog_langs/oop/#object-oriented-programming","text":"","title":"Object Oriented Programming:"},{"location":"prog_langs/oop/#what-is-a-class","text":"A blueprint Fields (instance variables) What an object knows Methods(Functions) What an object does","title":"What is a Class:"},{"location":"prog_langs/oop/#what-is-inheritance","text":"Parent/Super class that shares fields/methods with its subclasses that also have their own fields & methods Subclasses abstract out the super class's features Subclasses can override or extend methods that don't work Subclasses only define the changes since the super's fields & methods are already defined when you extend the super class Use is A? principle to decide whether to extend a class Ex: Is a Dog an Animal? Yes, so Dog extends Animal Ex: Is a Dog a cat? No, so Dog doesn't extend Cat Use inheritance when a subclass needs most of the methods in the superclass Do not use inheritance just to reuse code if is A? doesn't work class Animal{ private String name; private double height; private int weight; private String sound; public void setName(String newName){ name = newName; } public void setSound(String newSound){ sound = newSound; } } class Dog extends Animal{ public Dog(){ super(); //Calls super constructor setSound(\"Bark\"); } public void digHole(){ System.out.println(\"Hole dug\"); } }","title":"What is Inheritance:"},{"location":"prog_langs/oop/#what-is-encapsulation","text":"Protects data Use private fields Do not set fields directly Use public getter & setter functions to access & change the data Setter = Mutator Getter = Accessor class Dog{ private double height; public void setHeight(newHeight){ if(newHeight > 0){ height = newHeight; } else{ //Throw an Error } } }","title":"What is Encapsulation:"},{"location":"prog_langs/oop/#instance-vs-local-variables","text":"Instance Variable(AKA fields) are declared in a class Local Variables are declared in a method","title":"Instance vs. Local Variables:"},{"location":"prog_langs/oop/#what-is-polymorphism","text":"Allows you to write methods that don't need to change if new subclasses are created Ex: Dog can add a new method w/o changing Animal Allows you to put diff subclasses in one array Animal doggy = new Dog(); Animal kitty = new Cat(); Animal[] animals = [doggy,kitty]; kitty.getSound(); //Returns Meow doggy.digHole(); //Would not work ((Dog)doggy).digHole(); //Would Work You can't access methods this way if they are only in the subclass Need to cast the object to the subclass that contains that method Cannot reference non-static variables or non-static-methods(w/o an object) in a static method Cannot access private methods outside of a subclass/class","title":"What is Polymorphism:"},{"location":"prog_langs/oop/#what-is-an-abstract-class","text":"Gives power of polymorphism w/o all the work There are no abstract fields but can have protected variables that are rewritten as private fields in subclasses All methods do not have to be abstract w/in an abstract class You can have static methods w/in abstract classes Cannot create objects from abstract classes but subclasses can extend them and be made into objects Have to override abstract methods in the subclass in order to extend the class abstract public Class Creature{ protected String name; public abstract void setName(newName); }","title":"What is an Abstract Class:"},{"location":"prog_langs/oop/#what-is-an-interface","text":"A class w/ only abstract methods Can implement as many interfaces to a class as you want Can only use public static and final fields Provide the ultimate flexibility Classes from different inheritance trees can use a common interface Avoid using interfaces just to force the creation of a method public interface Living { public void setName(String newName); } public class Monkey implements Living{ private name; public void setName(String newName){ name = newName; } }","title":"What is an Interface:"},{"location":"prog_langs/paradigms/","text":"What is a Programming Paradigm? A style of programming/way of thinking about software architecture A way/methodology, not a language Some languages are better for some paradigms than others Functional Programming (FP): Treats computation as the the evaluation of math functions and avoids changing-state and mutable data Passing data from function to function to get a result Functions are threatened as data (you can use them as parameters, return them, build functions from other functions, and build custom functions Have to be pure functions- not dependent on local/global states Good for modularity since each function will return the same output given the same input Object Oriented Programming (OOP): Based on the concept of \u201cobjects\u201d which may contain data in the form of fields/attributes and code in the form of procedures/methods Encapsulating data & behavior into objects that interact with other elements and can perform certain actions Read more here Procedural Programming (PP): Based on the concept of procedure call where procedures/routines/subroutines/functions simply contain a series of computational steps to be carried out \u2022 AKA inline programming and it takes a top-down approach \u2022 Writing a list of instructions to tell the computer what to do step by step Relies on procedures/routines Resource","title":"Programming Paradigms"},{"location":"prog_langs/paradigms/#what-is-a-programming-paradigm","text":"A style of programming/way of thinking about software architecture A way/methodology, not a language Some languages are better for some paradigms than others","title":"What is a Programming Paradigm?"},{"location":"prog_langs/paradigms/#functional-programming-fp","text":"Treats computation as the the evaluation of math functions and avoids changing-state and mutable data Passing data from function to function to get a result Functions are threatened as data (you can use them as parameters, return them, build functions from other functions, and build custom functions Have to be pure functions- not dependent on local/global states Good for modularity since each function will return the same output given the same input","title":"Functional Programming (FP):"},{"location":"prog_langs/paradigms/#object-oriented-programming-oop","text":"Based on the concept of \u201cobjects\u201d which may contain data in the form of fields/attributes and code in the form of procedures/methods Encapsulating data & behavior into objects that interact with other elements and can perform certain actions Read more here","title":"Object Oriented Programming (OOP):"},{"location":"prog_langs/paradigms/#procedural-programming-pp","text":"Based on the concept of procedure call where procedures/routines/subroutines/functions simply contain a series of computational steps to be carried out \u2022 AKA inline programming and it takes a top-down approach \u2022 Writing a list of instructions to tell the computer what to do step by step Relies on procedures/routines Resource","title":"Procedural Programming (PP):"},{"location":"python/classes/","text":"Classes class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance The global scope associated with a method is the module containing its definition. A class is never used as a global scope Use isinstance() to check an instance\u2019s type: isinstance(obj, int) will be True only if obj.__class__ is int or some class derived from int No private instance variables Convention: _var treats member as non-public part of API iterators iter() on a container object returns an iterator object that defines a __next__() method to access elements in the container one at a time __next__() raises a StopIteration exception when no more elements, which indicates the for loop to terminate __next__() and __iter__() can be called with next() and iter() generators __iter__() and __next__() are created automatically for a generator function that uses the yield keyword Easy way to create an iterator by just writing a regular functio Generator expressions are similar to list comprehensions except more memory friendly useful when the generator is used immediately by the enclosing function sum(i * i for i in range(10)) , unique_words = set(word for line in page for word in line.split())","title":"Classes"},{"location":"python/classes/#classes","text":"class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance The global scope associated with a method is the module containing its definition. A class is never used as a global scope Use isinstance() to check an instance\u2019s type: isinstance(obj, int) will be True only if obj.__class__ is int or some class derived from int No private instance variables Convention: _var treats member as non-public part of API","title":"Classes"},{"location":"python/classes/#iterators","text":"iter() on a container object returns an iterator object that defines a __next__() method to access elements in the container one at a time __next__() raises a StopIteration exception when no more elements, which indicates the for loop to terminate __next__() and __iter__() can be called with next() and iter()","title":"iterators"},{"location":"python/classes/#generators","text":"__iter__() and __next__() are created automatically for a generator function that uses the yield keyword Easy way to create an iterator by just writing a regular functio Generator expressions are similar to list comprehensions except more memory friendly useful when the generator is used immediately by the enclosing function sum(i * i for i in range(10)) , unique_words = set(word for line in page for word in line.split())","title":"generators"},{"location":"python/concurrency/","text":"Concurrency Threading Daemon Threads- background threads that do not prevent program from exiting once there are no non-daemon threads remaining A thread defaults to its parent process's status of being a daemon thread which for the main thread is false If you .join() a thread (daemonic or non-daemonic), the statement will wait until the thread is finished Multiprocessing Asyncio write concurrent code using async / await syntax good for IO-bound code high-level api is able to concurrently run/control python coroutinues/functions work with IO streams control subprocesses distribute tasks via queues synchronize concurrent code debug by passing debug=True to asyncio.run() . Coroutines import asyncio async def main(): print('hello') await asyncio.sleep(1) print('world') asyncio.run(main()) calling main() does not execute the coroutine since it is a coroutine object can run a coroutine in 3 ways: asyncio.run(coroutine()) await coroutine() asyncio.create_task(coroutine()) and then await the task 3 types of awaitable objects: coroutines, tasks, and futures asyncio.wait_for(awaitable, timeout) raises a asyncio.TimeoutError","title":"Concurrency"},{"location":"python/concurrency/#concurrency","text":"","title":"Concurrency"},{"location":"python/concurrency/#threading","text":"Daemon Threads- background threads that do not prevent program from exiting once there are no non-daemon threads remaining A thread defaults to its parent process's status of being a daemon thread which for the main thread is false If you .join() a thread (daemonic or non-daemonic), the statement will wait until the thread is finished","title":"Threading"},{"location":"python/concurrency/#multiprocessing","text":"","title":"Multiprocessing"},{"location":"python/concurrency/#asyncio","text":"write concurrent code using async / await syntax good for IO-bound code high-level api is able to concurrently run/control python coroutinues/functions work with IO streams control subprocesses distribute tasks via queues synchronize concurrent code debug by passing debug=True to asyncio.run() .","title":"Asyncio"},{"location":"python/concurrency/#coroutines","text":"import asyncio async def main(): print('hello') await asyncio.sleep(1) print('world') asyncio.run(main()) calling main() does not execute the coroutine since it is a coroutine object can run a coroutine in 3 ways: asyncio.run(coroutine()) await coroutine() asyncio.create_task(coroutine()) and then await the task 3 types of awaitable objects: coroutines, tasks, and futures asyncio.wait_for(awaitable, timeout) raises a asyncio.TimeoutError","title":"Coroutines"},{"location":"python/dunders/","text":"Dunder Methods __call__() Allows an instantiated class to be called like a function Similar to Functor in C++ Examples from Stack Overflow class Factorial: def __init__(self): self.cache = {} def __call__(self, n): if n not in self.cache: if n == 0: self.cache[n] = 1 else: self.cache[n] = n * self.__call__(n-1) return self.cache[n] fact = Factorial() import hashlib class Hasher: \"\"\" A wrapper around the hashlib hash algorithms that allows an entire file to be hashed in a chunked manner. \"\"\" def __init__(self, algorithm): self.algorithm = algorithm def __call__(self, file): hash = self.algorithm() with open(file, 'rb') as f: for chunk in iter(lambda: f.read(4096), ''): hash.update(chunk) return hash.hexdigest() md5 = Hasher(hashlib.md5) sha1 = Hasher(hashlib.sha1) sha224 = Hasher(hashlib.sha224) sha256 = Hasher(hashlib.sha256) sha384 = Hasher(hashlib.sha384) sha512 = Hasher(hashlib.sha512) print(sha1('somefile.txt'))","title":"Dunder Methods"},{"location":"python/dunders/#dunder-methods","text":"","title":"Dunder Methods"},{"location":"python/dunders/#__call__","text":"Allows an instantiated class to be called like a function Similar to Functor in C++ Examples from Stack Overflow class Factorial: def __init__(self): self.cache = {} def __call__(self, n): if n not in self.cache: if n == 0: self.cache[n] = 1 else: self.cache[n] = n * self.__call__(n-1) return self.cache[n] fact = Factorial() import hashlib class Hasher: \"\"\" A wrapper around the hashlib hash algorithms that allows an entire file to be hashed in a chunked manner. \"\"\" def __init__(self, algorithm): self.algorithm = algorithm def __call__(self, file): hash = self.algorithm() with open(file, 'rb') as f: for chunk in iter(lambda: f.read(4096), ''): hash.update(chunk) return hash.hexdigest() md5 = Hasher(hashlib.md5) sha1 = Hasher(hashlib.sha1) sha224 = Hasher(hashlib.sha224) sha256 = Hasher(hashlib.sha256) sha384 = Hasher(hashlib.sha384) sha512 = Hasher(hashlib.sha512) print(sha1('somefile.txt'))","title":"__call__()"},{"location":"python/logging/","text":"Logging basicConfig can only be called once (configures root logger) logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s') Msg formatting: example msg: root - INFO - this is a logged msg default formating: ERROR:root:This is an error message All attributes that can be used in a format useful format: %(asctime)s - %(module)s - %(funcName)s - %(lineno)d - %(levelname)s - %(message)s Can also include process id or process name same as with thread id and thread name to increase visibility into concurrent programs Logs from External Packages Assuming they use python logging package Will default to whatever level is set by root Can do more specific things with the logs from external packages like below: # for azure.identity pkg logger = logging.getLogger('azure.identity') logger.setLevel(logging.DEBUG) handler = logging.FileHandler(filename=f'test.log') # or for logging to a stream: handler = logging.StreamHandler(stream=sys.stdout) logger.addHandler(handler)","title":"Logging"},{"location":"python/logging/#logging","text":"basicConfig can only be called once (configures root logger) logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s') Msg formatting: example msg: root - INFO - this is a logged msg default formating: ERROR:root:This is an error message All attributes that can be used in a format useful format: %(asctime)s - %(module)s - %(funcName)s - %(lineno)d - %(levelname)s - %(message)s Can also include process id or process name same as with thread id and thread name to increase visibility into concurrent programs","title":"Logging"},{"location":"python/logging/#logs-from-external-packages","text":"Assuming they use python logging package Will default to whatever level is set by root Can do more specific things with the logs from external packages like below: # for azure.identity pkg logger = logging.getLogger('azure.identity') logger.setLevel(logging.DEBUG) handler = logging.FileHandler(filename=f'test.log') # or for logging to a stream: handler = logging.StreamHandler(stream=sys.stdout) logger.addHandler(handler)","title":"Logs from External Packages"},{"location":"python/overview/","text":"Python Ternary Conditionals condition = True x = 1 if condition else 0 Number Formatting num1 = 1_000_000_000 num2 = 10_000_000 total = num1 + num2 print(f'{total:,}') #Uses f-string to format output w/ commas Context Managers Manage resources such as IO connections, threads, db connections, etc. by opening & closing resources automatically with open('test.txt','r') as f: file_contents = f.read() Enumerate Functions names = ['Bob','Steve','Jim'] for index,name in enumerate(names): print(index,name) for index,name in enumerate(names, start=1): #Can specify starting index value print(index,name) Zip Function Loops over n lists at once. When lists are different lengths, it stops at the end of the shortest list for name, hero, universe in zip(names, heroes, universes): print(name,hero) for value in zip(names, heroes, universes): print(value) #Value is a tuple of the results of the 3 lists Unpacking a,b = (1,2) print(a) #1 print(b) #2 c,_ = (4,5) #use underscore when you don't want to use a variable print(c) #4 x,y,*z = (1,2,3,5,6,7) print(x) #1 print(y) #2 print(z) #[3,5,6,7] x,y,*_, z = (1,2,3,4,6,7,) #ignores all values after 1 & 2 but until 7, which is stored in z Requests Library import requests url_params = {'page' : 2, 'count' : 25} r = requests.get(\"https://httpbin.org/get\", params=url_params) body = {'username' : 'corey', 'password' : 'testing'} r = requests.post(\"https://httpbin.org/post\", data=body, timeout=3) #include the timeout argument to Raise a ReadTimeout Error if the website does not respond in time r_dict = r.json() Environment Variables MacOS terminal: - export <var-name>=<var-value> (add new env var) - export <existing-var-name>=<var-value>:$<existing-var-name> (prepend values to an existing env var) - unset <var-name> (remove env var) os.environ acts like a python dictionary If you have other scripts updating the environment while your python script is running, calling os.environ again will not reflect the latest values since the mapping is only read when the python script is initially run. import os os.environ['DB_USER'] = str(123) # env vars must always be strings db_user = os.environ['DB_USER'] db_user = os.environ.get('DB_USER') # safe way of accessing potentially undefined env vars Memoization/Caching Examples calculate the nth term of the fibonacci sequence Basic implementation with dictionary fibonacci_cache = {} def fibonacci(n): if n in fibonacci_cache: return fibonacci_cache[n] elif n == 1 or n == 2: value = 1 else: value = fibonacci(n-1) + fibonacci(n-2) fibonacci_cache[n] = value return value Optimized implementation with function tools from functools import lru_cache @lru_cache(maxsize=1000) def fibonacci(n): if n == 1 or n ==2: return 1 else: return fibonacci(n-1)+fibonacci(n-2) Config Parser Documentation . Configuration file format: [section] option1 = value1 option2 = value2 Reading the configuration file: from configparser import ConfigParser parser = ConfigParser() parser.read('file.ini') if parser.has_section('database'): items = parser.items('database') Its good to store things that could change in the configuration file (e.g. endpoints, db logins/tables/sprocs) CSV Files import csv with open(file1, 'r'), open(file2, 'w') as f1, f2: csv_read = csv.reader(f1) csv_writer = csv.writer(f2) next(csv_read) # Skip header row for line in csv_reader: csv_writer.writerow([line[0],\"extra col\"]) Matplotlib figure acts as a contianer for all plot elements axes contains most of the figures elements and sets the coordinate system will usually contain 2 axis elements that control the ticks import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.axis('equal') # makes it so patches are not stretched ax.set_xlim(0,100) # sets the x limits on the graph # Add a line from matplotlib.lines import Line2D line = Line2D([x0,x1], [y0,y1]) ax.add_line(line) # Add Shapes/Patches from matplotlib.patches import Rectangle, Circle r = Rectangle(top_left, width, height, fill=False) ax.add_patch(r) c = Circle((x_center,y_center), radius, fill=False) ax.add_patch(c) ax.scatter(x,y,facecolors='none',edgecolors='purple') # empty circles with an edge color plt.show() Python Executable MacOS installs python 2.7 by default and should not be deleted /usr/bin/python and /usr/bin/python2 are symlinks to default install: System/Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7 Python 3+ versions are installed in /usr/local/bin/python3 is a symlink to version 3.5 installed in /Library/Frameworks/Python.framework/Versions/3.5 by downloading python from internet /usr/local/bin/python3.9 is a symlink to version 3.9 installed in /usr/local/Cellar by homebrew (same goes for pip3.9 ) /usr/bin/python3 is the actual install of version 3.8. Note sure how it got there but it is currently looked at on the path after the other version of python3 in the local/bin so it is not found unless the version is being explicitly looked for All 3 versions of python3 are needed for ROS stuff so thats fun python3 -m module_name Searches the path for the module and excecutes its contents as the main module (Runs the specified module even if it isnt in the cwd) Note: find symlinks using ls -l Virtual Environments A common directory location for a virtual environment is .venv . This name keeps the directory typically hidden in your shell and thus out of the way while giving it a name that explains why the directory exists. It also prevents clashing with .env environment variable definition files that some tooling supports.","title":"Overview"},{"location":"python/overview/#python","text":"","title":"Python"},{"location":"python/overview/#ternary-conditionals","text":"condition = True x = 1 if condition else 0","title":"Ternary Conditionals"},{"location":"python/overview/#number-formatting","text":"num1 = 1_000_000_000 num2 = 10_000_000 total = num1 + num2 print(f'{total:,}') #Uses f-string to format output w/ commas","title":"Number Formatting"},{"location":"python/overview/#context-managers","text":"Manage resources such as IO connections, threads, db connections, etc. by opening & closing resources automatically with open('test.txt','r') as f: file_contents = f.read()","title":"Context Managers"},{"location":"python/overview/#enumerate-functions","text":"names = ['Bob','Steve','Jim'] for index,name in enumerate(names): print(index,name) for index,name in enumerate(names, start=1): #Can specify starting index value print(index,name)","title":"Enumerate Functions"},{"location":"python/overview/#zip-function","text":"Loops over n lists at once. When lists are different lengths, it stops at the end of the shortest list for name, hero, universe in zip(names, heroes, universes): print(name,hero) for value in zip(names, heroes, universes): print(value) #Value is a tuple of the results of the 3 lists","title":"Zip Function"},{"location":"python/overview/#unpacking","text":"a,b = (1,2) print(a) #1 print(b) #2 c,_ = (4,5) #use underscore when you don't want to use a variable print(c) #4 x,y,*z = (1,2,3,5,6,7) print(x) #1 print(y) #2 print(z) #[3,5,6,7] x,y,*_, z = (1,2,3,4,6,7,) #ignores all values after 1 & 2 but until 7, which is stored in z","title":"Unpacking"},{"location":"python/overview/#requests-library","text":"import requests url_params = {'page' : 2, 'count' : 25} r = requests.get(\"https://httpbin.org/get\", params=url_params) body = {'username' : 'corey', 'password' : 'testing'} r = requests.post(\"https://httpbin.org/post\", data=body, timeout=3) #include the timeout argument to Raise a ReadTimeout Error if the website does not respond in time r_dict = r.json()","title":"Requests Library"},{"location":"python/overview/#environment-variables","text":"MacOS terminal: - export <var-name>=<var-value> (add new env var) - export <existing-var-name>=<var-value>:$<existing-var-name> (prepend values to an existing env var) - unset <var-name> (remove env var) os.environ acts like a python dictionary If you have other scripts updating the environment while your python script is running, calling os.environ again will not reflect the latest values since the mapping is only read when the python script is initially run. import os os.environ['DB_USER'] = str(123) # env vars must always be strings db_user = os.environ['DB_USER'] db_user = os.environ.get('DB_USER') # safe way of accessing potentially undefined env vars","title":"Environment Variables"},{"location":"python/overview/#memoizationcaching","text":"Examples calculate the nth term of the fibonacci sequence Basic implementation with dictionary fibonacci_cache = {} def fibonacci(n): if n in fibonacci_cache: return fibonacci_cache[n] elif n == 1 or n == 2: value = 1 else: value = fibonacci(n-1) + fibonacci(n-2) fibonacci_cache[n] = value return value Optimized implementation with function tools from functools import lru_cache @lru_cache(maxsize=1000) def fibonacci(n): if n == 1 or n ==2: return 1 else: return fibonacci(n-1)+fibonacci(n-2)","title":"Memoization/Caching"},{"location":"python/overview/#config-parser","text":"Documentation . Configuration file format: [section] option1 = value1 option2 = value2 Reading the configuration file: from configparser import ConfigParser parser = ConfigParser() parser.read('file.ini') if parser.has_section('database'): items = parser.items('database') Its good to store things that could change in the configuration file (e.g. endpoints, db logins/tables/sprocs)","title":"Config Parser"},{"location":"python/overview/#csv-files","text":"import csv with open(file1, 'r'), open(file2, 'w') as f1, f2: csv_read = csv.reader(f1) csv_writer = csv.writer(f2) next(csv_read) # Skip header row for line in csv_reader: csv_writer.writerow([line[0],\"extra col\"])","title":"CSV Files"},{"location":"python/overview/#matplotlib","text":"figure acts as a contianer for all plot elements axes contains most of the figures elements and sets the coordinate system will usually contain 2 axis elements that control the ticks import matplotlib.pyplot as plt fig, ax = plt.subplots() ax.axis('equal') # makes it so patches are not stretched ax.set_xlim(0,100) # sets the x limits on the graph # Add a line from matplotlib.lines import Line2D line = Line2D([x0,x1], [y0,y1]) ax.add_line(line) # Add Shapes/Patches from matplotlib.patches import Rectangle, Circle r = Rectangle(top_left, width, height, fill=False) ax.add_patch(r) c = Circle((x_center,y_center), radius, fill=False) ax.add_patch(c) ax.scatter(x,y,facecolors='none',edgecolors='purple') # empty circles with an edge color plt.show()","title":"Matplotlib"},{"location":"python/overview/#python-executable","text":"MacOS installs python 2.7 by default and should not be deleted /usr/bin/python and /usr/bin/python2 are symlinks to default install: System/Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7 Python 3+ versions are installed in /usr/local/bin/python3 is a symlink to version 3.5 installed in /Library/Frameworks/Python.framework/Versions/3.5 by downloading python from internet /usr/local/bin/python3.9 is a symlink to version 3.9 installed in /usr/local/Cellar by homebrew (same goes for pip3.9 ) /usr/bin/python3 is the actual install of version 3.8. Note sure how it got there but it is currently looked at on the path after the other version of python3 in the local/bin so it is not found unless the version is being explicitly looked for All 3 versions of python3 are needed for ROS stuff so thats fun python3 -m module_name Searches the path for the module and excecutes its contents as the main module (Runs the specified module even if it isnt in the cwd) Note: find symlinks using ls -l","title":"Python Executable"},{"location":"python/overview/#virtual-environments","text":"A common directory location for a virtual environment is .venv . This name keeps the directory typically hidden in your shell and thus out of the way while giving it a name that explains why the directory exists. It also prevents clashing with .env environment variable definition files that some tooling supports.","title":"Virtual Environments"},{"location":"python/style/","text":"Style Guide PEP8 Style Guide Google Style Guide Exceptions ValueError - indicate a programming mistake like a violated pre-condition Don't use catch-all except : statements make code in try/except blocks as small as possible General Avoid global variables due to their potential to change module behavior during import If needed, declare them at module level and make internal to module by prepending _ to name Nested functions are fine, however they should have read-only access to variables defined in enclosing scope Try to avoid in general and make helper functions private to module with _ so they can still be tested Use if foo is not None instead of if foo b/c foo could be another value python evaluates as false (e.g 0 ) numpy arrays can raise exception in implicit boolean context -> test emptiness of np.array using if not arry.size Avoid using @staticmethod and instead write a module level function instead max line length of 80 chars","title":"Style"},{"location":"python/style/#style-guide","text":"PEP8 Style Guide Google Style Guide","title":"Style Guide"},{"location":"python/style/#exceptions","text":"ValueError - indicate a programming mistake like a violated pre-condition Don't use catch-all except : statements make code in try/except blocks as small as possible","title":"Exceptions"},{"location":"python/style/#general","text":"Avoid global variables due to their potential to change module behavior during import If needed, declare them at module level and make internal to module by prepending _ to name Nested functions are fine, however they should have read-only access to variables defined in enclosing scope Try to avoid in general and make helper functions private to module with _ so they can still be tested Use if foo is not None instead of if foo b/c foo could be another value python evaluates as false (e.g 0 ) numpy arrays can raise exception in implicit boolean context -> test emptiness of np.array using if not arry.size Avoid using @staticmethod and instead write a module level function instead max line length of 80 chars","title":"General"},{"location":"python/time/","text":"Time & Datetime unix timestamp to datetime: datetime_obj = datetime.fromtimestamp(unix_ts) datetime to unix timestamp: unix_ts = datetime_obj.timestamp() Format a datetime object: datetime_obj.strftime(\"%Y-%m-%d-%H-%M-%S\") Timing Functions timeit.timeit(code_str, number=n) is the core timing functionality that will give you average time for code to complete example below gets the time for a neural network inference import torch from learning_warmstarts.neural_nets.models import FFNet import timeit n = 10000 model = FFNet((13,1024,2048,240), torch.nn.functional.relu) model.eval() model.load_state_dict(torch.load('SOA.pt')) with torch.no_grad(): dummy_input = torch.randn((13),dtype=torch.float) total_time = timeit.timeit('model(dummy_input)',number=n, globals=globals()) print(f'{total_time / n}')","title":"Dates & Time"},{"location":"python/time/#time-datetime","text":"unix timestamp to datetime: datetime_obj = datetime.fromtimestamp(unix_ts) datetime to unix timestamp: unix_ts = datetime_obj.timestamp() Format a datetime object: datetime_obj.strftime(\"%Y-%m-%d-%H-%M-%S\")","title":"Time &amp; Datetime"},{"location":"python/time/#timing-functions","text":"timeit.timeit(code_str, number=n) is the core timing functionality that will give you average time for code to complete example below gets the time for a neural network inference import torch from learning_warmstarts.neural_nets.models import FFNet import timeit n = 10000 model = FFNet((13,1024,2048,240), torch.nn.functional.relu) model.eval() model.load_state_dict(torch.load('SOA.pt')) with torch.no_grad(): dummy_input = torch.randn((13),dtype=torch.float) total_time = timeit.timeit('model(dummy_input)',number=n, globals=globals()) print(f'{total_time / n}')","title":"Timing Functions"},{"location":"python/types/","text":"Types Code samples from DeepMind's Robotics Repo Best practice to define all types for a package in a types.py Good type names reduces the need for building context in programmer's brain, makes it easier to read, and decreases the need for documentation Document design decisions, not what the code does (this can be inferred by reading it) Typing Can create complex type annotations: from typing import Mapping, Optional, Sequence, Tuple MaskPoints = Sequence[Sequence[Tuple[int, int]]] Centers = Mapping[str, Optional[np.ndarray]] Detections = Mapping[str, Optional[np.ndarray]] Dataclasses Setting frozen option makes the types immutable upon being instantiated Inheritance Can make the types more readable, even if no additional fields are added code serves as documentation import dataclasses @dataclasses.dataclass(frozen=True) class ValueRange: \"\"\"A generic N-dimensional range of values in terms of lower and upper bounds. Attributes: lower: A ND array with the lower values of the range. upper: A ND array with the upper values of the range. \"\"\" lower: np.ndarray upper: np.ndarray @dataclasses.dataclass(frozen=True) class ColorRange(ValueRange): \"\"\"A range of colors in terms of lower and upper bounds. Typical usage example: # A YUV color range (cuboid) ColorRange(lower=np.array[0., 0.25, 0.25], upper=np.array[1., 0.75, 0.75]) Attributes: lower: A 3D array with the lower values of the color range. upper: A 3D array with the upper values of the color range. \"\"\" Optional Fields and Default Values import dataclasses from typing import Optional @dataclasses.dataclass(frozen=True) class Camera: \"\"\"Camera parameters. Attributes: width: image width. height: image height. extrinsics: camera extrinsics. intrinsics: camera intrinsics. \"\"\" width: int height: int extrinsics: Optional[Extrinsics] = None intrinsics: Optional[Intrinsics] = None Typing Module list instead of List is only 3.9+ Type alias: Vector = list[float] so those two are interchangeable useful for simplifying complex type signatures NewType creates distinct types to catch logical errors declares a type to be a subtype of another ```python from typing import NewType UserId = NewType('UserId', int) some_id = UserId(524313) ``` Frameworks expecting callback functions of specific signatures: Callable[[Arg1Type, Arg2Type], ReturnType] Callable[..., ReturnType] if you don't care about call signature Enums","title":"Types"},{"location":"python/types/#types","text":"Code samples from DeepMind's Robotics Repo Best practice to define all types for a package in a types.py Good type names reduces the need for building context in programmer's brain, makes it easier to read, and decreases the need for documentation Document design decisions, not what the code does (this can be inferred by reading it)","title":"Types"},{"location":"python/types/#typing","text":"Can create complex type annotations: from typing import Mapping, Optional, Sequence, Tuple MaskPoints = Sequence[Sequence[Tuple[int, int]]] Centers = Mapping[str, Optional[np.ndarray]] Detections = Mapping[str, Optional[np.ndarray]]","title":"Typing"},{"location":"python/types/#dataclasses","text":"Setting frozen option makes the types immutable upon being instantiated","title":"Dataclasses"},{"location":"python/types/#inheritance","text":"Can make the types more readable, even if no additional fields are added code serves as documentation import dataclasses @dataclasses.dataclass(frozen=True) class ValueRange: \"\"\"A generic N-dimensional range of values in terms of lower and upper bounds. Attributes: lower: A ND array with the lower values of the range. upper: A ND array with the upper values of the range. \"\"\" lower: np.ndarray upper: np.ndarray @dataclasses.dataclass(frozen=True) class ColorRange(ValueRange): \"\"\"A range of colors in terms of lower and upper bounds. Typical usage example: # A YUV color range (cuboid) ColorRange(lower=np.array[0., 0.25, 0.25], upper=np.array[1., 0.75, 0.75]) Attributes: lower: A 3D array with the lower values of the color range. upper: A 3D array with the upper values of the color range. \"\"\"","title":"Inheritance"},{"location":"python/types/#optional-fields-and-default-values","text":"import dataclasses from typing import Optional @dataclasses.dataclass(frozen=True) class Camera: \"\"\"Camera parameters. Attributes: width: image width. height: image height. extrinsics: camera extrinsics. intrinsics: camera intrinsics. \"\"\" width: int height: int extrinsics: Optional[Extrinsics] = None intrinsics: Optional[Intrinsics] = None","title":"Optional Fields and Default Values"},{"location":"python/types/#typing-module","text":"list instead of List is only 3.9+ Type alias: Vector = list[float] so those two are interchangeable useful for simplifying complex type signatures NewType creates distinct types to catch logical errors declares a type to be a subtype of another ```python from typing import NewType UserId = NewType('UserId', int) some_id = UserId(524313) ``` Frameworks expecting callback functions of specific signatures: Callable[[Arg1Type, Arg2Type], ReturnType] Callable[..., ReturnType] if you don't care about call signature","title":"Typing Module"},{"location":"python/types/#enums","text":"","title":"Enums"},{"location":"robotics/13-mobile-robots/","text":"Ch. 13 Wheeled Mobile Robots Kinematic Model- how wheel speed maps to robot velocities Dynamic Model- how wheel torques map to robot accelerations nonholonomic robot- cannot move directly sideways (velocity constraint)","title":"Mobile Robots"},{"location":"robotics/13-mobile-robots/#ch-13-wheeled-mobile-robots","text":"Kinematic Model- how wheel speed maps to robot velocities Dynamic Model- how wheel torques map to robot accelerations nonholonomic robot- cannot move directly sideways (velocity constraint)","title":"Ch. 13 Wheeled Mobile Robots"},{"location":"robotics/behavior-trees/","text":"Behavior Trees Used to program complex behaviors in AI, games, and robotics. Nodes are executed (ticked) with a given frequency child will immediatly return running to parent if the execution is under way success if it has achieved its goal failure otherwise Choosing what logic to encapsulate in the BT versus the actions is an important design decision Advantages More expressive than FSMs Efficient creation of complex systems in a modular and reactive fashion Used often in robotic manipulation tasks since they allow individual behaviors to be reused in the context of another higher level behavior Control Flow Nodes Sequence - ticks each child node in order returns running upon ticking a node that returns running returns failure upon ticking a node that returns failure exits if failure or running are reached and doesnt tick any of the nodes after it returns success only if all the children return success Fallback - ticks each child node in order Returns succes or running upon reaching a child that returns one of them Returns failure if all the children it ticks return failure AKA selector/priority selector nodes Parallel - set a success threshold ticks all the children from left to right returns success if the number of children that return success is past the set threshold return failure if the number of children that return failure is greater than N - M otherwise returns running if any of the children are still running Decorator - manipulates the return status of the child according to a user-defined rule has a single child selectively ticks the child according to a predefined rule Examples: Invert- inverts success/failure status max-N-tries only lets its child fail N times then will always return Failure without ticking the child useful if you dont want to keep calling a command on a system that went down Max-T-Sec lets the child run for T seconds then if it is still runnning will return failure without ticking the child Control flow nodes can have memory meaning they remember what a child returned success or failure in order to avoid re-exceution until a whole sequence or fallback finishes Execution Nodes Leaf nodes are execution nodes (2 types) Action- executes a command when it is ticked returns success if the action is correctly completed returns failure if the action has failed returns running while its running Condition- checks a proposition when ticked returns success or failure depending on if the proposition holds never returns running Other Control Flow Architectures Petri Nets provide an alternative to FSMs that supports design of concurent systems FSMs Pros Common Intuitive and easy to understand Easy to implement Cons Poor maintainability/scalability since they are essentially goto statements Less modular and harder to maintain since they use one-way control transfer (state transitions) just like go to statements This means removing a state from a machine requires changing all transitions to that state Poor reusability since transitions often depend on many internal variables Scalable Hierarchial FSMs (HFSMs) aka state charts uses super states that contain many substates to simplify transitions Subsumption Architecture related to behavior-based robot architecture have several controllers, each implementing a task, running in parallel controllers are ordered in priorty by user and the highest priorty controller out of a list of ones that want to control the robot is given access to the actuators w Teleo-Reactive Approach Decision Trees directed tree representing a list of nested if then clauses to derive decisions leaf nodes- decisions/conclusions/actions to be done Non-leaf nodes- predicates to be evaluated","title":"Behavior Trees"},{"location":"robotics/behavior-trees/#behavior-trees","text":"Used to program complex behaviors in AI, games, and robotics. Nodes are executed (ticked) with a given frequency child will immediatly return running to parent if the execution is under way success if it has achieved its goal failure otherwise Choosing what logic to encapsulate in the BT versus the actions is an important design decision","title":"Behavior Trees"},{"location":"robotics/behavior-trees/#advantages","text":"More expressive than FSMs Efficient creation of complex systems in a modular and reactive fashion Used often in robotic manipulation tasks since they allow individual behaviors to be reused in the context of another higher level behavior","title":"Advantages"},{"location":"robotics/behavior-trees/#control-flow-nodes","text":"Sequence - ticks each child node in order returns running upon ticking a node that returns running returns failure upon ticking a node that returns failure exits if failure or running are reached and doesnt tick any of the nodes after it returns success only if all the children return success Fallback - ticks each child node in order Returns succes or running upon reaching a child that returns one of them Returns failure if all the children it ticks return failure AKA selector/priority selector nodes Parallel - set a success threshold ticks all the children from left to right returns success if the number of children that return success is past the set threshold return failure if the number of children that return failure is greater than N - M otherwise returns running if any of the children are still running Decorator - manipulates the return status of the child according to a user-defined rule has a single child selectively ticks the child according to a predefined rule Examples: Invert- inverts success/failure status max-N-tries only lets its child fail N times then will always return Failure without ticking the child useful if you dont want to keep calling a command on a system that went down Max-T-Sec lets the child run for T seconds then if it is still runnning will return failure without ticking the child Control flow nodes can have memory meaning they remember what a child returned success or failure in order to avoid re-exceution until a whole sequence or fallback finishes","title":"Control Flow Nodes"},{"location":"robotics/behavior-trees/#execution-nodes","text":"Leaf nodes are execution nodes (2 types) Action- executes a command when it is ticked returns success if the action is correctly completed returns failure if the action has failed returns running while its running Condition- checks a proposition when ticked returns success or failure depending on if the proposition holds never returns running","title":"Execution Nodes"},{"location":"robotics/behavior-trees/#other-control-flow-architectures","text":"Petri Nets provide an alternative to FSMs that supports design of concurent systems FSMs Pros Common Intuitive and easy to understand Easy to implement Cons Poor maintainability/scalability since they are essentially goto statements Less modular and harder to maintain since they use one-way control transfer (state transitions) just like go to statements This means removing a state from a machine requires changing all transitions to that state Poor reusability since transitions often depend on many internal variables Scalable Hierarchial FSMs (HFSMs) aka state charts uses super states that contain many substates to simplify transitions Subsumption Architecture related to behavior-based robot architecture have several controllers, each implementing a task, running in parallel controllers are ordered in priorty by user and the highest priorty controller out of a list of ones that want to control the robot is given access to the actuators w Teleo-Reactive Approach Decision Trees directed tree representing a list of nested if then clauses to derive decisions leaf nodes- decisions/conclusions/actions to be done Non-leaf nodes- predicates to be evaluated","title":"Other Control Flow Architectures"},{"location":"robotics/control/","text":"Control Systems Open-Loop Control- control action from controller is independent of the process variable Ex: central heating boiler controlled only by timer Closed-Loop Control- control action from the controller is dependent on the desired and actual/measured process variable Ex: central heating boiler controlled by signal from thermostat in the building to maintain a desired temperature AKA feedback controllers","title":"Control"},{"location":"robotics/control/#control-systems","text":"Open-Loop Control- control action from controller is independent of the process variable Ex: central heating boiler controlled only by timer Closed-Loop Control- control action from the controller is dependent on the desired and actual/measured process variable Ex: central heating boiler controlled by signal from thermostat in the building to maintain a desired temperature AKA feedback controllers","title":"Control Systems"},{"location":"robotics/hardware/","text":"3D Modeling and Printing Process Design or download a model (.stl file) Import the stl file(s) to slicing software (e.g. IdeaMaker) Slice the object Slicing takes the model and does the math on it to create gcode instructions for the 3D printer Export the gcode instructions to a usb drive or SD card depending on the printer Plug in drive to printer and begin the 3D print Notes PLA is a common plastic used b/c it is softer (less wear & tear on printer) and needs less heat to be melted ABS is a harder plastic that is used and thus requires more heat to melt it A variety of different filaments can be used to print things Tiny errors in a 3D printer\u2019s movement results in big errors with the print b/c movements are done hundreds of times Raspberry Pi Board Structure Set of GPIO pins (General purpose input-output pins) Read More Serial pin on TX (GPIO14) and RX (GPIO15) Can print out this and place on pi for reference Interactive GPIO Guide Pi Camera Watch out, static can kill it FIX PI CAMERA DETECTION ERROR by enabling the I2C Interface in preferences --> raspberry pi configuration","title":"Hardware"},{"location":"robotics/hardware/#3d-modeling-and-printing","text":"","title":"3D Modeling and Printing"},{"location":"robotics/hardware/#process","text":"Design or download a model (.stl file) Import the stl file(s) to slicing software (e.g. IdeaMaker) Slice the object Slicing takes the model and does the math on it to create gcode instructions for the 3D printer Export the gcode instructions to a usb drive or SD card depending on the printer Plug in drive to printer and begin the 3D print","title":"Process"},{"location":"robotics/hardware/#notes","text":"PLA is a common plastic used b/c it is softer (less wear & tear on printer) and needs less heat to be melted ABS is a harder plastic that is used and thus requires more heat to melt it A variety of different filaments can be used to print things Tiny errors in a 3D printer\u2019s movement results in big errors with the print b/c movements are done hundreds of times","title":"Notes"},{"location":"robotics/hardware/#raspberry-pi","text":"","title":"Raspberry Pi"},{"location":"robotics/hardware/#board-structure","text":"Set of GPIO pins (General purpose input-output pins) Read More Serial pin on TX (GPIO14) and RX (GPIO15) Can print out this and place on pi for reference Interactive GPIO Guide","title":"Board Structure"},{"location":"robotics/hardware/#pi-camera","text":"Watch out, static can kill it FIX PI CAMERA DETECTION ERROR by enabling the I2C Interface in preferences --> raspberry pi configuration","title":"Pi Camera"},{"location":"robotics/mpc/","text":"Model Predictive Control Relies on a dynamic model to make predictions for future values of the controlled variables of the system. It then solves a contrained optimization problem to calculate the optimal control action that minimizes the difference between the predicted controlled values and the desired/set control values. Main limitation: High computational cost since this optimization problem must be solved at each time step The computational cost increases even more as the time horizon over which to predict future control values increases. The computational cost becomes intractable to run realtime as the number of states and contraints grows (NN approximation could fix this) Explicit MPC (eMPC) and learning-based NN approaches have been proposed to overcome this Takes on many forms: one-norm, infinite norm, PWA model, tracking Explicit MPC Goal is to rewrite the optimization problem as a multi-parametric quadtratic programming (mpQP) This is possible for linear systems but cannot be extended to nonlinear systems An explicit solution to the mpQP has been demonstrated and it is of the form of a PWA function The PWA function defined over the state space will act as a fast prediction/lookup function for control policies given a input state meaning there is no need to solve the optimization problem online! This result was achieved by Bemporad et al. (2002) Resources: ( Brief mention ) Optimality: Not always feasible to run the optimization process to complete convergence for the most optimal control output (especially when running online) Therefore, optimality is sometimes relaxed to only require a sufficient decrease in the cost/objective function Then the optimization problem would be terminated at a feasible but sub-optimal stage Recursive Feasability: MPC controllers are not gauranteed to be stabilizing (linear quadratic control is gauranted to be stabilizing) Stability must be built in when defining the optimization problem The optimization problem\u2019s feasbility can be lost when the state is driven to a region in which the optimization problem has no solution typical approach to solve this is to append constrainst to the optimization problem to guarantee that loss of feasability cannot occur (that is what was done in the papers I have read so far) When this is done, an MPC controller is said to be recursively feasible meaning it cannot put the state in a place with no solution to the optimization problem Constructing an MPC controller with the theoretical (a-priori) guarantee of recursive feasability is not always desirable or easy to do Sometimes we might have a situation where given an MPC controller and the goal is to determine if it is recursively feasbile The goal is primarly to invalidate the controller by detecting problematic states where the recursive feasability is lost Second objective is to find certificates of guaranteed recursive feasability DEF: The MPC controller is recursively feasible if and only if for all ini- tially feasible x0 and for all optimal sequences of control inputs the MPC optimization problem remains feasible for all time. DEF: The MPC controller is strongly recursively feasible if and only if for all initially feasible x0 and for all sequences of feasible control inputs the MPC optimization problem remains feasible for all time. Resource (analysis tool for determining recursive feasability of an MPC controller)","title":"MPC"},{"location":"robotics/mpc/#model-predictive-control","text":"Relies on a dynamic model to make predictions for future values of the controlled variables of the system. It then solves a contrained optimization problem to calculate the optimal control action that minimizes the difference between the predicted controlled values and the desired/set control values. Main limitation: High computational cost since this optimization problem must be solved at each time step The computational cost increases even more as the time horizon over which to predict future control values increases. The computational cost becomes intractable to run realtime as the number of states and contraints grows (NN approximation could fix this) Explicit MPC (eMPC) and learning-based NN approaches have been proposed to overcome this Takes on many forms: one-norm, infinite norm, PWA model, tracking","title":"Model Predictive Control"},{"location":"robotics/mpc/#explicit-mpc","text":"Goal is to rewrite the optimization problem as a multi-parametric quadtratic programming (mpQP) This is possible for linear systems but cannot be extended to nonlinear systems An explicit solution to the mpQP has been demonstrated and it is of the form of a PWA function The PWA function defined over the state space will act as a fast prediction/lookup function for control policies given a input state meaning there is no need to solve the optimization problem online! This result was achieved by Bemporad et al. (2002) Resources: ( Brief mention )","title":"Explicit MPC"},{"location":"robotics/mpc/#optimality","text":"Not always feasible to run the optimization process to complete convergence for the most optimal control output (especially when running online) Therefore, optimality is sometimes relaxed to only require a sufficient decrease in the cost/objective function Then the optimization problem would be terminated at a feasible but sub-optimal stage","title":"Optimality:"},{"location":"robotics/mpc/#recursive-feasability","text":"MPC controllers are not gauranteed to be stabilizing (linear quadratic control is gauranted to be stabilizing) Stability must be built in when defining the optimization problem The optimization problem\u2019s feasbility can be lost when the state is driven to a region in which the optimization problem has no solution typical approach to solve this is to append constrainst to the optimization problem to guarantee that loss of feasability cannot occur (that is what was done in the papers I have read so far) When this is done, an MPC controller is said to be recursively feasible meaning it cannot put the state in a place with no solution to the optimization problem Constructing an MPC controller with the theoretical (a-priori) guarantee of recursive feasability is not always desirable or easy to do Sometimes we might have a situation where given an MPC controller and the goal is to determine if it is recursively feasbile The goal is primarly to invalidate the controller by detecting problematic states where the recursive feasability is lost Second objective is to find certificates of guaranteed recursive feasability DEF: The MPC controller is recursively feasible if and only if for all ini- tially feasible x0 and for all optimal sequences of control inputs the MPC optimization problem remains feasible for all time. DEF: The MPC controller is strongly recursively feasible if and only if for all initially feasible x0 and for all sequences of feasible control inputs the MPC optimization problem remains feasible for all time. Resource (analysis tool for determining recursive feasability of an MPC controller)","title":"Recursive Feasability:"},{"location":"software_design/cpp/big3/","text":"Classes Separate the public interface from the specifics of the implementation Everything is private by default (public in a struct) public interface provides the abstraction Encapsulation separates the implementation details from the public interface Data Hiding- one of type of encapsulation where we use private data members/functions Base Member Initialization List Every variable will be constructed before getting into the body of the constructor as a result of the compiler. Therefore we want to use the BMI to prevent doubling the work. Initialize all variables in the BMI (lots of things are able to be initialized including arrays). Order of initialization in BMI should be the same as order declared in the header (compiler doesn't care but good for consistency). Note the upper most base class is always initialized first. Initialization is the process of turning raw storage into an object. Assignment is the process of replacing the existing state of a well-defined object with a new state (never performed on raw storage). Big 3 Destructor Copy Constructor Copy Assignment Operator When one of the big 3 needs custom behavior, all of them probably will. Best practice to explicitly define the behavior of the big 3 even if it uses default functionality (serves as documentation). Resource Destructor Purpose: destroy items that are allocated onto the heap Default destructor does not cause memory leaks for primitve data types. Default destructor causes memory leaks when using pointers in complex data types because the data at the allocated memory address is not freed up (memory leak) Should not be called explicitly Called by compiler when object goes out of scope or when delete is called on an object Called in reverse order of the constructors for a heierachy of base classes Copy Constructor Purpose: Creates a new object instance with same values as existing object Different from the assignment operator in that it creates a new object instead of just setting existing objects to be equal to another Copying involves allocating memory for the data members and then initializing the data members to be the same as those of the referenced object. Called in 3 instances: 1. Traditional use c++ SomeClass a; SomeClass b(a); 2. Assignment operator is not called because b hasn't been initialized c++ SomeClass a; SomeClass b = a; 3. Passing or returning an object by value creates a copy of that object Default copy constructor does member wise copy which results in a shallow copies when dealing with pointers. Therefore, we define our own copy ctor for most classes we write Example Copy Constructor: An object of the same type is passed by constant (don't want to change existing object) reference (can't be passed by value since that would require copy constructor). SomeClass(const SomeClass &rhs ) { // Any pointer manipulation to prevent shallow copies } Copy Assignment Operator Purpose: set an existing object to be the same as another existing object of the same type Often overloaded to eliminate the problems caused by memberwise assignment when using pointers. Assignment involves: 1. Check for self assignment (assignining an object to itself) 2. Deleting the original items stored in the object's data members 3. Allocating memory for new items 4. Copying the other object's data members to the current object - Best practice to use copy constructor to keep code DRY 5. Return the object (allows for chaining assignment operators) Specifying Default and Delete Behavior Set copy ctor or assignment operatort to equal delete in the header to make it clear the user should not use them Will generate a compiler error if used Prevents the compiler from generating default implementations Certain cases (e.g. cout and files) its not acceptable to make copies or assignments Stack(const Stack &rhs) = delete; Stack &operator=(const Stack &rhs) = delete; Set copy ctor or assignment operatort to equal default in the header to make it clear the compiler will generate default implementations Serves as good documentation for user of the class Stack(const Stack &rhs) = default; Stack &operator=(const Stack &rhs) = default; Garbage Collection A program's executable includes automatic behavior that at various intervals finds all unreachable allocated memory locations (e.g., by comparing all reachable memory with all previously-allocated memory), and automatically frees such unreachable memory Can reduce the impact of memory leaks at the expense of runtime overhead Not implemented in standard C++ but is used in higher-level languages like Python and Java All C++ does is call destructor when variables/objects go out of the scope they were initialized in Therefore, C++ doesn't call the destructor on reference variables passed into functions when that function's scope ends Destructors for primitive data types works fine but destructors for more complex objects must be defined by user","title":"The Big 3"},{"location":"software_design/cpp/big3/#classes","text":"Separate the public interface from the specifics of the implementation Everything is private by default (public in a struct) public interface provides the abstraction Encapsulation separates the implementation details from the public interface Data Hiding- one of type of encapsulation where we use private data members/functions","title":"Classes"},{"location":"software_design/cpp/big3/#base-member-initialization-list","text":"Every variable will be constructed before getting into the body of the constructor as a result of the compiler. Therefore we want to use the BMI to prevent doubling the work. Initialize all variables in the BMI (lots of things are able to be initialized including arrays). Order of initialization in BMI should be the same as order declared in the header (compiler doesn't care but good for consistency). Note the upper most base class is always initialized first. Initialization is the process of turning raw storage into an object. Assignment is the process of replacing the existing state of a well-defined object with a new state (never performed on raw storage).","title":"Base Member Initialization List"},{"location":"software_design/cpp/big3/#big-3","text":"Destructor Copy Constructor Copy Assignment Operator When one of the big 3 needs custom behavior, all of them probably will. Best practice to explicitly define the behavior of the big 3 even if it uses default functionality (serves as documentation). Resource","title":"Big 3"},{"location":"software_design/cpp/big3/#destructor","text":"Purpose: destroy items that are allocated onto the heap Default destructor does not cause memory leaks for primitve data types. Default destructor causes memory leaks when using pointers in complex data types because the data at the allocated memory address is not freed up (memory leak) Should not be called explicitly Called by compiler when object goes out of scope or when delete is called on an object Called in reverse order of the constructors for a heierachy of base classes","title":"Destructor"},{"location":"software_design/cpp/big3/#copy-constructor","text":"Purpose: Creates a new object instance with same values as existing object Different from the assignment operator in that it creates a new object instead of just setting existing objects to be equal to another Copying involves allocating memory for the data members and then initializing the data members to be the same as those of the referenced object. Called in 3 instances: 1. Traditional use c++ SomeClass a; SomeClass b(a); 2. Assignment operator is not called because b hasn't been initialized c++ SomeClass a; SomeClass b = a; 3. Passing or returning an object by value creates a copy of that object Default copy constructor does member wise copy which results in a shallow copies when dealing with pointers. Therefore, we define our own copy ctor for most classes we write Example Copy Constructor: An object of the same type is passed by constant (don't want to change existing object) reference (can't be passed by value since that would require copy constructor). SomeClass(const SomeClass &rhs ) { // Any pointer manipulation to prevent shallow copies }","title":"Copy Constructor"},{"location":"software_design/cpp/big3/#copy-assignment-operator","text":"Purpose: set an existing object to be the same as another existing object of the same type Often overloaded to eliminate the problems caused by memberwise assignment when using pointers. Assignment involves: 1. Check for self assignment (assignining an object to itself) 2. Deleting the original items stored in the object's data members 3. Allocating memory for new items 4. Copying the other object's data members to the current object - Best practice to use copy constructor to keep code DRY 5. Return the object (allows for chaining assignment operators)","title":"Copy Assignment Operator"},{"location":"software_design/cpp/big3/#specifying-default-and-delete-behavior","text":"Set copy ctor or assignment operatort to equal delete in the header to make it clear the user should not use them Will generate a compiler error if used Prevents the compiler from generating default implementations Certain cases (e.g. cout and files) its not acceptable to make copies or assignments Stack(const Stack &rhs) = delete; Stack &operator=(const Stack &rhs) = delete; Set copy ctor or assignment operatort to equal default in the header to make it clear the compiler will generate default implementations Serves as good documentation for user of the class Stack(const Stack &rhs) = default; Stack &operator=(const Stack &rhs) = default;","title":"Specifying Default and Delete Behavior"},{"location":"software_design/cpp/big3/#garbage-collection","text":"A program's executable includes automatic behavior that at various intervals finds all unreachable allocated memory locations (e.g., by comparing all reachable memory with all previously-allocated memory), and automatically frees such unreachable memory Can reduce the impact of memory leaks at the expense of runtime overhead Not implemented in standard C++ but is used in higher-level languages like Python and Java All C++ does is call destructor when variables/objects go out of the scope they were initialized in Therefore, C++ doesn't call the destructor on reference variables passed into functions when that function's scope ends Destructors for primitive data types works fine but destructors for more complex objects must be defined by user","title":"Garbage Collection"},{"location":"software_design/cpp/cmake/","text":"Cmake Build tool for C and C++ Target - the binary executable we want to build source code into Properties - anything such as compiler options and dependencies needed to create the target cmake_minimum_required(VERSION <version-num>) specifies the minimum cmake version to use Modern CMAKE is 3.0+ project (<project-name> VERSION 1.0 DESCRIPTION \"stuff\" LANGUAGES CXX) # CXX stands for Cpp add_executable(<name> src/file1.h src/file1.cpp \u2026 ) target_compile_features(<exe-name> PRIVATE cxx_std_20) #private makes it not able to be included as a library Dependency Management find_library(LIBRARY_SDL, sdl) will search your system for a sdl named library and will store the path in LIBRAY_SDL find_library(LIBRARY_SDL, sdl) if (LIBRARY_SDL) target_link_libraries(myApp PRIVATE ${LIBRARY_SDL}) else() # throw an error or enable compilation without the library endif() find_package(<pkg-name>) is better than find_library and can load CMAKE modules","title":"Cmake"},{"location":"software_design/cpp/cmake/#cmake","text":"Build tool for C and C++ Target - the binary executable we want to build source code into Properties - anything such as compiler options and dependencies needed to create the target cmake_minimum_required(VERSION <version-num>) specifies the minimum cmake version to use Modern CMAKE is 3.0+ project (<project-name> VERSION 1.0 DESCRIPTION \"stuff\" LANGUAGES CXX) # CXX stands for Cpp add_executable(<name> src/file1.h src/file1.cpp \u2026 ) target_compile_features(<exe-name> PRIVATE cxx_std_20) #private makes it not able to be included as a library","title":"Cmake"},{"location":"software_design/cpp/cmake/#dependency-management","text":"find_library(LIBRARY_SDL, sdl) will search your system for a sdl named library and will store the path in LIBRAY_SDL find_library(LIBRARY_SDL, sdl) if (LIBRARY_SDL) target_link_libraries(myApp PRIVATE ${LIBRARY_SDL}) else() # throw an error or enable compilation without the library endif() find_package(<pkg-name>) is better than find_library and can load CMAKE modules","title":"Dependency Management"},{"location":"software_design/cpp/exceptions/","text":"Exception Handling Purpose: permit the program to catch and handle errors rather than let it occur and suffer the consequences Used when system can recover from the error causing the exception Exception Handler- recovery procedure If no catch function, the terminate function is called (terminate calls abort function that aborts the program) Properly written exception safe code employs relatively few try blocks try { throw std::overflow_error(\"overflow error in push\") } catch (std::overflow_error &excep) { // exception handler is here std::cout << excep.what() << std::endl; } catch (...) { std::cout << \"Unknown exception\" << std::endl; } Throw Can throw anything but error types in standard library are typically used If a function throws a const object, the catch handler argument type must be declared const Throw lists for functions are bad practice but you will see them in legacy code Unwinding the stack refers to when an expection is thrown void func(int x) { char* fizz = new char[1024]; std::string s(\"Test\"); if(x) throw std::runtime_error(\"explosion\"); delete[] test; } In the above example, memory allocated for fizz will be leaked if an exception is thrown b/c delete[] fizz is never reached. However, memory allocated for s will be properly destructed b/c throwing an exception unwinds the stack meaning the destructor will be called on objects in each of the stack frames until a try catch block is reached. Since std::string has a properly defined destructor, s will not create a memory leak when an exception is thrown. Constructors & Destructors Exceptions thrown in constructors will cause the destructors to be called for any objects built as part of the object being constructed before the exception is thrown Don't throw exceptions in a destructor","title":"Exception Handling"},{"location":"software_design/cpp/exceptions/#exception-handling","text":"Purpose: permit the program to catch and handle errors rather than let it occur and suffer the consequences Used when system can recover from the error causing the exception Exception Handler- recovery procedure If no catch function, the terminate function is called (terminate calls abort function that aborts the program) Properly written exception safe code employs relatively few try blocks try { throw std::overflow_error(\"overflow error in push\") } catch (std::overflow_error &excep) { // exception handler is here std::cout << excep.what() << std::endl; } catch (...) { std::cout << \"Unknown exception\" << std::endl; }","title":"Exception Handling"},{"location":"software_design/cpp/exceptions/#throw","text":"Can throw anything but error types in standard library are typically used If a function throws a const object, the catch handler argument type must be declared const Throw lists for functions are bad practice but you will see them in legacy code Unwinding the stack refers to when an expection is thrown void func(int x) { char* fizz = new char[1024]; std::string s(\"Test\"); if(x) throw std::runtime_error(\"explosion\"); delete[] test; } In the above example, memory allocated for fizz will be leaked if an exception is thrown b/c delete[] fizz is never reached. However, memory allocated for s will be properly destructed b/c throwing an exception unwinds the stack meaning the destructor will be called on objects in each of the stack frames until a try catch block is reached. Since std::string has a properly defined destructor, s will not create a memory leak when an exception is thrown.","title":"Throw"},{"location":"software_design/cpp/exceptions/#constructors-destructors","text":"Exceptions thrown in constructors will cause the destructors to be called for any objects built as part of the object being constructed before the exception is thrown Don't throw exceptions in a destructor","title":"Constructors &amp; Destructors"},{"location":"software_design/cpp/functors/","text":"Functors Any class that has overriden the parens/function operator operator() Allows an instance of the class to be called as a function Can do multiple overridings of operator() as long as they have different signatures Functors are just regular classes Can have constructors & destructores Can have private member variables and functions Can be a template class STL algorithms will return a copy of the functor being passed in so that we can access the final state after all iterations Functions vs Functors The below code demonstrates how the same functionality would be implemented differently between just using a function and using a functor void printIt(int i) { std::cout << i << \":\"; } std::for_each(intArray.begin(), intArray.end(), printIt()); std::cout << std::endl; class PrintIt { public: // overloading the parens operator lets us treat an instance of this class as a function void operator() (int i) { std::cout << i << \":\"; } }; // creates instance of PrintIt for each integer in the array and call it as a function std::for_each(intArray.begin(), intArray.end(), PrintIt()); std::cout << std::endl; Maintaining State Functors allow us to better maintain state through an STL algorithm's iteration compared to regular functions Encapsulates the state within a class, preventing pollution of the global namespace with global state variables All state is encapsulated in normal class instance lifecycle: 1) Constructor: initial state 2) operator(): state mutation 3) Accessor methods: state querying 4) Destructor: state cleanup (as needed)","title":"Functors"},{"location":"software_design/cpp/functors/#functors","text":"Any class that has overriden the parens/function operator operator() Allows an instance of the class to be called as a function Can do multiple overridings of operator() as long as they have different signatures Functors are just regular classes Can have constructors & destructores Can have private member variables and functions Can be a template class STL algorithms will return a copy of the functor being passed in so that we can access the final state after all iterations","title":"Functors"},{"location":"software_design/cpp/functors/#functions-vs-functors","text":"The below code demonstrates how the same functionality would be implemented differently between just using a function and using a functor void printIt(int i) { std::cout << i << \":\"; } std::for_each(intArray.begin(), intArray.end(), printIt()); std::cout << std::endl; class PrintIt { public: // overloading the parens operator lets us treat an instance of this class as a function void operator() (int i) { std::cout << i << \":\"; } }; // creates instance of PrintIt for each integer in the array and call it as a function std::for_each(intArray.begin(), intArray.end(), PrintIt()); std::cout << std::endl;","title":"Functions vs Functors"},{"location":"software_design/cpp/functors/#maintaining-state","text":"Functors allow us to better maintain state through an STL algorithm's iteration compared to regular functions Encapsulates the state within a class, preventing pollution of the global namespace with global state variables All state is encapsulated in normal class instance lifecycle: 1) Constructor: initial state 2) operator(): state mutation 3) Accessor methods: state querying 4) Destructor: state cleanup (as needed)","title":"Maintaining State"},{"location":"software_design/cpp/inheritance/","text":"Inheritance Single Inheritance: occurs when a derived class inherits from only one parent class Multiple Inheritance: allows a class to inherit from multiple classes Error prone and should be avoided Big 3 are not inherited from a base class by a derived class Assignment operator is not inherited from the base class Will be provided with compiler generated one if used and not implemented by the user B publicly inheriting A creates the relationship: B is an instance of A private and protected inheritance do not create the same \"is a\" relationship Derived Classes Have access to base class' public and protected behaviors Protected- used for inheritance. Allows derived class access to something not public class A{ } class B: protected A { // everything public in A becomes protected in B } class C: private A { // everything public/private in A becomes private in B } Defines new attributes and behaviors may override the behaviors of the base class intended to be more specific than the base class constructor for the base class must be called from the derived class constructor in order to initialzie the base class members in the derived class Non explicitly calling it will result in the default constructor being called implicitly DerviedClass::DerivedClass(parameters) : BaseClass(parameters) {} virtual double func1() const { return 0.0; } default returns 0.0 virtual void func() const = 0; forces the derived class to implement the function Example implementation: void func() const override { //do something } Constructor & Destructor When derived class constructor is called 1) Base Class constructor is called to create an instance of the base class (done implicitly or explicitly) 2) Constructor for the derived class is executed Think of an onion (build up dervied object, layer by layer) When derived class destructor is called 1) Derived class destructor is executed 2) Base class destructor function is executed Reverse order of ctor, destroy the onion layer by layer Overriding Dervied version must have same function signature as base version Dervied version may include a call to the base version Provides more functionality specific to the derived class Abstract Class A base class that will never have an object instantiated from it Provides a generic interface Defined as any class that contains at least one pure virtual function (declare but provide no implementation of) Pure virtual function: virtual void func() const = 0; The equals zero makes the func pure virtual instead of just virtual Virtual Function A function that is expected to be overriden by a derived class Incudes full method signature, return type, and may provide default implementation Declared in public portion of the class Must not be static or a friend of another class Pure virtual functions must be overridden If derived class doesn't implement a pure virtual function, the derived class is also an abstract base class Non-pure virtual functions can be overidden but do not have to be A function defined as virtual in the base class makes it virutal for all classes derived from the base class Class with virtual functions should contain a virtual destructor Ensures the correct sequence of destructors is called Base class dtor must be virtual Should be accessed using pointer or reference of base class type to achieve run time polymorphism Why use Virtual Functions? Basic inheritance and overriding gives us the expected behavior with concrete instances Virtual functions allow us to work with a pointer to the base class Virtual functions defined in the base classes permit dynamic binding allowing runtime polymorphism Dynamic Binding A virtual function invoked using a reference to an objcet Allows program to choose appropraite method designed to identify the method for a particular object type at runtime Static binding requires object type to be defined at compile time Achieved using vtables Polymorphism Occurs whens multiple objects from different classes are related by inheritance from the same base class Most useful when there are a series of related objects that need to be treated in a uniform manner Polymorphic means having many forms Can have multiple behaviors for the same function depending on the context Achieved by using virtual functions and overriding these methods in derived classes Virtual Function Table Created at compile time and put in static memory Used at runtime to achieve dynamic binding and runtime polymorphism Compiler generates a vtable for each class with at least one method marked as virtual Only virtual methods are included in the vtable Example vtable for the shape example code from lecture 9: Shape Class ~Shape local or {} local implementation area() const {} local implementation volume() const {} local implementation pShapeName() const =0 pure virtual print() const = 0 pure virtual Shape class is abstract since there are pure virtual methods in the vtable Point Class ~Point local {} local implementation area() const Shape::area implementation in shape class volume() const Shape::volume implementation in shape class pShapeName() const {} own implementation print() const {} own implementation Point class is concrete since there are no pure virtual methods in the vtable Circle Class ~Circle local {} local implementation area() const {} local implementation volume() const Shape::volume implementation in shape class pShapeName() const {} local implementation print() const {} local implementation Point class is concrete since there are no pure virtual methods in the vtable When an object of a class containing virtual functions is instantiated, the compiler attaches a pointer to the class's vtable at the front of the object Memory and processing costs associated with virtual functions Increased size of object to hold vtable's address Increased compile time to create the vtable for each class with virtual functions More efficient to compute lookup table at compile time rather than determining these relationships at runtime For each function call, there is an extra step of looking up the address in the table to the correct implementation If marked virtual but not pure virtual, the class will provide its own implementation for it Derived class inherits all of the virtual functions from base class Polymorphism and use of vtable will be used when the method is marked as virtual and the method is called via a pointer or reference. This means functions in base class with same name will not be hidden like they are when doing override and using concrete instances Design Considerations Only use inheritance where additional layers of abstraction makes sense Class hierarchies promote code reuse Stand alone class --> bsase classes can make refactoring difficult Can create issues with slicing as a result of concrete base classes being able to be instantiated Should make base classes abstract Clarifications Overloading is creating a method with the same name as an existing method but with different parameters Overriding is creating a method in a derived class with the same name and parameters (same signature) as an existing method in its base class Polymorphism- ability of different object to be accessed by a common interface Polymorphism and overloading are related but not the same Standard hiding of methods of the same name in the base class will occur when the derived class has a concrete instance created Dynamic binding and runtime polymorphism occurs when using pointers/references of the base class to point to instances of the derived classes (gives standard interface to access different, but related objects --> definition of polymorphism)","title":"Inheritance"},{"location":"software_design/cpp/inheritance/#inheritance","text":"Single Inheritance: occurs when a derived class inherits from only one parent class Multiple Inheritance: allows a class to inherit from multiple classes Error prone and should be avoided Big 3 are not inherited from a base class by a derived class Assignment operator is not inherited from the base class Will be provided with compiler generated one if used and not implemented by the user B publicly inheriting A creates the relationship: B is an instance of A private and protected inheritance do not create the same \"is a\" relationship","title":"Inheritance"},{"location":"software_design/cpp/inheritance/#derived-classes","text":"Have access to base class' public and protected behaviors Protected- used for inheritance. Allows derived class access to something not public class A{ } class B: protected A { // everything public in A becomes protected in B } class C: private A { // everything public/private in A becomes private in B } Defines new attributes and behaviors may override the behaviors of the base class intended to be more specific than the base class constructor for the base class must be called from the derived class constructor in order to initialzie the base class members in the derived class Non explicitly calling it will result in the default constructor being called implicitly DerviedClass::DerivedClass(parameters) : BaseClass(parameters) {} virtual double func1() const { return 0.0; } default returns 0.0 virtual void func() const = 0; forces the derived class to implement the function Example implementation: void func() const override { //do something }","title":"Derived Classes"},{"location":"software_design/cpp/inheritance/#constructor-destructor","text":"When derived class constructor is called 1) Base Class constructor is called to create an instance of the base class (done implicitly or explicitly) 2) Constructor for the derived class is executed Think of an onion (build up dervied object, layer by layer) When derived class destructor is called 1) Derived class destructor is executed 2) Base class destructor function is executed Reverse order of ctor, destroy the onion layer by layer","title":"Constructor &amp; Destructor"},{"location":"software_design/cpp/inheritance/#overriding","text":"Dervied version must have same function signature as base version Dervied version may include a call to the base version Provides more functionality specific to the derived class","title":"Overriding"},{"location":"software_design/cpp/inheritance/#abstract-class","text":"A base class that will never have an object instantiated from it Provides a generic interface Defined as any class that contains at least one pure virtual function (declare but provide no implementation of) Pure virtual function: virtual void func() const = 0; The equals zero makes the func pure virtual instead of just virtual","title":"Abstract Class"},{"location":"software_design/cpp/inheritance/#virtual-function","text":"A function that is expected to be overriden by a derived class Incudes full method signature, return type, and may provide default implementation Declared in public portion of the class Must not be static or a friend of another class Pure virtual functions must be overridden If derived class doesn't implement a pure virtual function, the derived class is also an abstract base class Non-pure virtual functions can be overidden but do not have to be A function defined as virtual in the base class makes it virutal for all classes derived from the base class Class with virtual functions should contain a virtual destructor Ensures the correct sequence of destructors is called Base class dtor must be virtual Should be accessed using pointer or reference of base class type to achieve run time polymorphism","title":"Virtual Function"},{"location":"software_design/cpp/inheritance/#why-use-virtual-functions","text":"Basic inheritance and overriding gives us the expected behavior with concrete instances Virtual functions allow us to work with a pointer to the base class Virtual functions defined in the base classes permit dynamic binding allowing runtime polymorphism","title":"Why use Virtual Functions?"},{"location":"software_design/cpp/inheritance/#dynamic-binding","text":"A virtual function invoked using a reference to an objcet Allows program to choose appropraite method designed to identify the method for a particular object type at runtime Static binding requires object type to be defined at compile time Achieved using vtables","title":"Dynamic Binding"},{"location":"software_design/cpp/inheritance/#polymorphism","text":"Occurs whens multiple objects from different classes are related by inheritance from the same base class Most useful when there are a series of related objects that need to be treated in a uniform manner Polymorphic means having many forms Can have multiple behaviors for the same function depending on the context Achieved by using virtual functions and overriding these methods in derived classes","title":"Polymorphism"},{"location":"software_design/cpp/inheritance/#virtual-function-table","text":"Created at compile time and put in static memory Used at runtime to achieve dynamic binding and runtime polymorphism Compiler generates a vtable for each class with at least one method marked as virtual Only virtual methods are included in the vtable Example vtable for the shape example code from lecture 9: Shape Class ~Shape local or {} local implementation area() const {} local implementation volume() const {} local implementation pShapeName() const =0 pure virtual print() const = 0 pure virtual Shape class is abstract since there are pure virtual methods in the vtable Point Class ~Point local {} local implementation area() const Shape::area implementation in shape class volume() const Shape::volume implementation in shape class pShapeName() const {} own implementation print() const {} own implementation Point class is concrete since there are no pure virtual methods in the vtable Circle Class ~Circle local {} local implementation area() const {} local implementation volume() const Shape::volume implementation in shape class pShapeName() const {} local implementation print() const {} local implementation Point class is concrete since there are no pure virtual methods in the vtable When an object of a class containing virtual functions is instantiated, the compiler attaches a pointer to the class's vtable at the front of the object Memory and processing costs associated with virtual functions Increased size of object to hold vtable's address Increased compile time to create the vtable for each class with virtual functions More efficient to compute lookup table at compile time rather than determining these relationships at runtime For each function call, there is an extra step of looking up the address in the table to the correct implementation If marked virtual but not pure virtual, the class will provide its own implementation for it Derived class inherits all of the virtual functions from base class Polymorphism and use of vtable will be used when the method is marked as virtual and the method is called via a pointer or reference. This means functions in base class with same name will not be hidden like they are when doing override and using concrete instances","title":"Virtual Function Table"},{"location":"software_design/cpp/inheritance/#design-considerations","text":"Only use inheritance where additional layers of abstraction makes sense Class hierarchies promote code reuse Stand alone class --> bsase classes can make refactoring difficult Can create issues with slicing as a result of concrete base classes being able to be instantiated Should make base classes abstract","title":"Design Considerations"},{"location":"software_design/cpp/inheritance/#clarifications","text":"Overloading is creating a method with the same name as an existing method but with different parameters Overriding is creating a method in a derived class with the same name and parameters (same signature) as an existing method in its base class Polymorphism- ability of different object to be accessed by a common interface Polymorphism and overloading are related but not the same Standard hiding of methods of the same name in the base class will occur when the derived class has a concrete instance created Dynamic binding and runtime polymorphism occurs when using pointers/references of the base class to point to instances of the derived classes (gives standard interface to access different, but related objects --> definition of polymorphism)","title":"Clarifications"},{"location":"software_design/cpp/iterators/","text":"Iterators Allow a program to access aggregated data in a container Allow us to write programs that do not depend on the type of container (e.g. array, vector, tree, etc.) The details of accessing the aggregated data iis hidden via the iterator interface Our code then interacts with the iterator, not the container directly Every container has its own class for its iterator Iterator Design Pattern Intent Access elements of a container (aggregate) without exposing its representation Applicability Require multiple traversal algorthims over a container Require a uniform traversal interface over different containers When container classes and traversal algorithms must vary independently Structure Aggregate is an abstract base class used for creating containers. ConcreteAggregate is a derived class that is a specific type of container (e.g. tree, hash map, list, etc.) Iterator is an abstract base class used for creating iterators on containers ConcreteIterator is a derived class that is a specific iterator implementation corresponding to the strucutre of a concrete container The use of Aggregate and Iterator abstract base classes lets client code be written against any generic container with an iterator Looping directly over linear containers like arrays make assumption on the subscript operators definition meaning it interacts directly with the container Using iterators makes algorithms more general and independent of the container since the iterators handle differencs between data structures such as linear vs tree STL Iterators C++ implementation of the iterator pattern Generalization of pointers since they are objects that point to other objects Central to generic programming b/c they are an interface btw containers and algorithms STL algorithms typically take iterators as arugments A container only needs to provide a way to access its elements using iterators Useful to add iterators to your own classes so they can be used with STL algorithms Not all containers support random-access (e.g. specifying the ith item to access) Containers that support random-access iterators can be used with all STL algos Input Iterators Used to read from a container Dereferenced to refer to some object Incremented to obtain next iterator in a sequence Must allow following operations: Copy Ctor and assignment operator == and != for comparison with other iterators of the same type * and ++ for incrementing which object is being pointed to Can be const prefix and postfix Output Iterators Used to write to a container More restrictive interface: = , == , and != don't need to be defined Must support non-const operator* Iterator Types Iterator categories depend on type parameterization rather than inheritance Iterator categories are hierarchical with more refined categories adding constraints Forward - start to end of container (supports ++ ) Bidirectional - iterate through elements forward and backward (supports ++ , -- ) list, set, multiset, map, & multimap Random Access - go forward n elements, get nth element (supports [] ) vector and deque Using Iterators begin() is the first element end() is whatever it means to be just after the last element begin()/end() are used to traverse front to back rbegin()/rend() are used to traverse back to front Range based for loops use iterators to easily go through containers: vector<int> = {1,2,3,4}; for(int i : v) { std::cout << i << std::endl; }","title":"Iterators"},{"location":"software_design/cpp/iterators/#iterators","text":"Allow a program to access aggregated data in a container Allow us to write programs that do not depend on the type of container (e.g. array, vector, tree, etc.) The details of accessing the aggregated data iis hidden via the iterator interface Our code then interacts with the iterator, not the container directly Every container has its own class for its iterator","title":"Iterators"},{"location":"software_design/cpp/iterators/#iterator-design-pattern","text":"","title":"Iterator Design Pattern"},{"location":"software_design/cpp/iterators/#intent","text":"Access elements of a container (aggregate) without exposing its representation","title":"Intent"},{"location":"software_design/cpp/iterators/#applicability","text":"Require multiple traversal algorthims over a container Require a uniform traversal interface over different containers When container classes and traversal algorithms must vary independently","title":"Applicability"},{"location":"software_design/cpp/iterators/#structure","text":"Aggregate is an abstract base class used for creating containers. ConcreteAggregate is a derived class that is a specific type of container (e.g. tree, hash map, list, etc.) Iterator is an abstract base class used for creating iterators on containers ConcreteIterator is a derived class that is a specific iterator implementation corresponding to the strucutre of a concrete container The use of Aggregate and Iterator abstract base classes lets client code be written against any generic container with an iterator Looping directly over linear containers like arrays make assumption on the subscript operators definition meaning it interacts directly with the container Using iterators makes algorithms more general and independent of the container since the iterators handle differencs between data structures such as linear vs tree","title":"Structure"},{"location":"software_design/cpp/iterators/#stl-iterators","text":"C++ implementation of the iterator pattern Generalization of pointers since they are objects that point to other objects Central to generic programming b/c they are an interface btw containers and algorithms STL algorithms typically take iterators as arugments A container only needs to provide a way to access its elements using iterators Useful to add iterators to your own classes so they can be used with STL algorithms Not all containers support random-access (e.g. specifying the ith item to access) Containers that support random-access iterators can be used with all STL algos","title":"STL Iterators"},{"location":"software_design/cpp/iterators/#input-iterators","text":"Used to read from a container Dereferenced to refer to some object Incremented to obtain next iterator in a sequence Must allow following operations: Copy Ctor and assignment operator == and != for comparison with other iterators of the same type * and ++ for incrementing which object is being pointed to Can be const prefix and postfix","title":"Input Iterators"},{"location":"software_design/cpp/iterators/#output-iterators","text":"Used to write to a container More restrictive interface: = , == , and != don't need to be defined Must support non-const operator*","title":"Output Iterators"},{"location":"software_design/cpp/iterators/#iterator-types","text":"Iterator categories depend on type parameterization rather than inheritance Iterator categories are hierarchical with more refined categories adding constraints Forward - start to end of container (supports ++ ) Bidirectional - iterate through elements forward and backward (supports ++ , -- ) list, set, multiset, map, & multimap Random Access - go forward n elements, get nth element (supports [] ) vector and deque","title":"Iterator Types"},{"location":"software_design/cpp/iterators/#using-iterators","text":"begin() is the first element end() is whatever it means to be just after the last element begin()/end() are used to traverse front to back rbegin()/rend() are used to traverse back to front Range based for loops use iterators to easily go through containers: vector<int> = {1,2,3,4}; for(int i : v) { std::cout << i << std::endl; }","title":"Using Iterators"},{"location":"software_design/cpp/lambda/","text":"Lambda Functions Introduced in C++11 Create light-weight functions in place Designed to replace functors Behind the scenes, the compiler rewrites the lambda to be a functor (so lambdas are just syntax simplification of functors) Easy to use with STL std::for_each(int_list, int_list+8, [](int i) { std::cout << i << \":\"; }); Generic Lambdas Introduced in C++14 Compiler can infer input types Allows generic lambdas (since we don't have templates for lambdas) Variable Capture Can bring in variables from an external scope into the lambda scope Can be done by copy or reference Should be done by reference if we want the updated variables outside the scope of the lambda (use by reference to persist state) [int_var, dbl_var] () { int i = 7; cout << int_var << ' ' << dbl_var << ' ' << i << endl; } (); Lambdaas and Member Functions Bring this into scope, not class member variables Lets you use the class member variables with the implicit this->","title":"Lambda Functions"},{"location":"software_design/cpp/lambda/#lambda-functions","text":"Introduced in C++11 Create light-weight functions in place Designed to replace functors Behind the scenes, the compiler rewrites the lambda to be a functor (so lambdas are just syntax simplification of functors) Easy to use with STL std::for_each(int_list, int_list+8, [](int i) { std::cout << i << \":\"; });","title":"Lambda Functions"},{"location":"software_design/cpp/lambda/#generic-lambdas","text":"Introduced in C++14 Compiler can infer input types Allows generic lambdas (since we don't have templates for lambdas)","title":"Generic Lambdas"},{"location":"software_design/cpp/lambda/#variable-capture","text":"Can bring in variables from an external scope into the lambda scope Can be done by copy or reference Should be done by reference if we want the updated variables outside the scope of the lambda (use by reference to persist state) [int_var, dbl_var] () { int i = 7; cout << int_var << ' ' << dbl_var << ' ' << i << endl; } ();","title":"Variable Capture"},{"location":"software_design/cpp/lambda/#lambdaas-and-member-functions","text":"Bring this into scope, not class member variables Lets you use the class member variables with the implicit this->","title":"Lambdaas and Member Functions"},{"location":"software_design/cpp/misc/","text":"C++ Compiler 4 Steps: 1. Preprocessor: deletes comments, expands macros (anything with # prefix), replace file includes and constants with the values - #include brings in lots of files to create a larger temp file with everything needed - Summary: Pull together all needed code 2. Compiler: takes the code and produces architecture dependent assembly code (type, syntax, grammar rules are applied here) 3. Assembler: takes the assembly code and translates it to machine code - No commnon errors at this step 4. Linker: takes all seperate translation units and tries to link them together - Common Errors: symbol missing (declare and call a method but never define it), couldn't open output file (tried to build while debugger was running on the old executable) Clang and Gcc compiler will be used. Undefined behaviors are different between C++ compilers Forward Declarations LinkedList will often depend on LinkedListIter which itself depends on LinkedList . This mutual depenedency causes an issue when trying to compile doing the standard #include 'LinkedList.h' at the top. Forward declarations help get around this issue by declaring the dependency class exists without providing any of the details yet. The class's details are provided later to the compiler by moving #include to the bottom of the file so that the compiler will go back into the placeholder and fill in the missing symbols. Here is what LinkedList.h that depends on the LinkedListIter class would look like: class LinkedListIter; class LinkedList { ... } #include 'LinkedListIter.h' Command Line Arguments int main(int argc, char **argv) { } argc is the number of command line arguments (strings) **argv is a pointer to an array (a pointer) containing pointers to the command line strings Always one argument (the name of your program itself) When running a program the OS loader finds the executable on disk and passes in any additional arguments from the command line to the main function Explicit vs. Automatic Conversions A single argument constructor provides the ability to convert the value of the argument to the clas type. Implicit conversion converts the statement to a Class A { public: A(); A(int); A(const char*, int=0); } // implicit conversion: A c = 1; // same as A c = A(1) A c = \"someword\" // same as A c = A(\"someword\") Class A { public: A(); // don't need to give params names in the header but its helpful, only required in the cpp implementation explicit A(int); explicit A(const char*, int=0); } // implicit conversion no longer allowed A c = 1; // will now throw compiler errors A c = \"someword\" // same as A c = A(\"someword\") // allows: A a1; A a2 = A(1); A a3(1); A a4 = A(\"Test\"); A a6 = static_cast<A>(1); A* p = new A(1); Reference Another name for an existing object Not a pointer and doesn't behave like a pointer 3 Major differences from a pointer: 1) No null references 2) All references require initialization when they are declared 3) A reference always refers to the object with which it is initialized (cannot be made to refer to a different object later) References and Const reference to a non const cannot be initialized with a literal or temporary value a refernce to a const can be initialized with a literal or a temporary value double &cd = 12.3; // error! const double &cd = 12.3; //no error Function Calls: 1) Pass by value: calls copy constructor 2) Pass by pointer: Function call must send address of the variable: f(&<var-name>) Function def must use * to create an alias for the variable: <return-type> f(<data-type>* <var-name>) { ... } int test(char* letter) { return int(*letter) } char testLetter = 'a'; std::cout << test(&testLetter) << std::endl; // prints a 3) Pass by reference: allow Types not matching causes an attempt to implicitly cast to the correct type which effectively causes a copy call when making a temp copy Debugger Can set breakpoints to run the program until a certain line Can set watch points to run the program until a certain condition LLVM/GDB debuggers can be used from the terminal","title":"Misc"},{"location":"software_design/cpp/misc/#c-compiler","text":"4 Steps: 1. Preprocessor: deletes comments, expands macros (anything with # prefix), replace file includes and constants with the values - #include brings in lots of files to create a larger temp file with everything needed - Summary: Pull together all needed code 2. Compiler: takes the code and produces architecture dependent assembly code (type, syntax, grammar rules are applied here) 3. Assembler: takes the assembly code and translates it to machine code - No commnon errors at this step 4. Linker: takes all seperate translation units and tries to link them together - Common Errors: symbol missing (declare and call a method but never define it), couldn't open output file (tried to build while debugger was running on the old executable) Clang and Gcc compiler will be used. Undefined behaviors are different between C++ compilers","title":"C++ Compiler"},{"location":"software_design/cpp/misc/#forward-declarations","text":"LinkedList will often depend on LinkedListIter which itself depends on LinkedList . This mutual depenedency causes an issue when trying to compile doing the standard #include 'LinkedList.h' at the top. Forward declarations help get around this issue by declaring the dependency class exists without providing any of the details yet. The class's details are provided later to the compiler by moving #include to the bottom of the file so that the compiler will go back into the placeholder and fill in the missing symbols. Here is what LinkedList.h that depends on the LinkedListIter class would look like: class LinkedListIter; class LinkedList { ... } #include 'LinkedListIter.h'","title":"Forward Declarations"},{"location":"software_design/cpp/misc/#command-line-arguments","text":"int main(int argc, char **argv) { } argc is the number of command line arguments (strings) **argv is a pointer to an array (a pointer) containing pointers to the command line strings Always one argument (the name of your program itself) When running a program the OS loader finds the executable on disk and passes in any additional arguments from the command line to the main function","title":"Command Line Arguments"},{"location":"software_design/cpp/misc/#explicit-vs-automatic-conversions","text":"A single argument constructor provides the ability to convert the value of the argument to the clas type. Implicit conversion converts the statement to a Class A { public: A(); A(int); A(const char*, int=0); } // implicit conversion: A c = 1; // same as A c = A(1) A c = \"someword\" // same as A c = A(\"someword\") Class A { public: A(); // don't need to give params names in the header but its helpful, only required in the cpp implementation explicit A(int); explicit A(const char*, int=0); } // implicit conversion no longer allowed A c = 1; // will now throw compiler errors A c = \"someword\" // same as A c = A(\"someword\") // allows: A a1; A a2 = A(1); A a3(1); A a4 = A(\"Test\"); A a6 = static_cast<A>(1); A* p = new A(1);","title":"Explicit vs. Automatic Conversions"},{"location":"software_design/cpp/misc/#reference","text":"Another name for an existing object Not a pointer and doesn't behave like a pointer 3 Major differences from a pointer: 1) No null references 2) All references require initialization when they are declared 3) A reference always refers to the object with which it is initialized (cannot be made to refer to a different object later)","title":"Reference"},{"location":"software_design/cpp/misc/#references-and-const","text":"reference to a non const cannot be initialized with a literal or temporary value a refernce to a const can be initialized with a literal or a temporary value double &cd = 12.3; // error! const double &cd = 12.3; //no error","title":"References and Const"},{"location":"software_design/cpp/misc/#function-calls","text":"1) Pass by value: calls copy constructor 2) Pass by pointer: Function call must send address of the variable: f(&<var-name>) Function def must use * to create an alias for the variable: <return-type> f(<data-type>* <var-name>) { ... } int test(char* letter) { return int(*letter) } char testLetter = 'a'; std::cout << test(&testLetter) << std::endl; // prints a 3) Pass by reference: allow Types not matching causes an attempt to implicitly cast to the correct type which effectively causes a copy call when making a temp copy","title":"Function Calls:"},{"location":"software_design/cpp/misc/#debugger","text":"Can set breakpoints to run the program until a certain line Can set watch points to run the program until a certain condition LLVM/GDB debuggers can be used from the terminal","title":"Debugger"},{"location":"software_design/cpp/move-semantics/","text":"Move Semantics makes code faster by adding to code rvalue references Allow programmers to avoid unnecessary copying and to provide perfect forwarding functions Move constructor: MyClass::MyClass(MyClass&& other); does not allocate new resources, simply takes the resources from other and sets other to its default ctor state much faster than a copy ctor b/c it doesn't allocate memory and doesn't copy memory buffers only a handful of machine instructions compared to possibly thousands of machine instructions to allocate new memory any temp or unnamed variables will be rvalues (determined by compiler) assignment of the result of a function is would be 2 copies if move semantics were not used (very costly) move ctor is more exception safe than copy ctor move semantics are safe since we are not grabbing more resources","title":"Move Semantics"},{"location":"software_design/cpp/move-semantics/#move-semantics","text":"makes code faster by adding to code","title":"Move Semantics"},{"location":"software_design/cpp/move-semantics/#rvalue-references","text":"Allow programmers to avoid unnecessary copying and to provide perfect forwarding functions Move constructor: MyClass::MyClass(MyClass&& other); does not allocate new resources, simply takes the resources from other and sets other to its default ctor state much faster than a copy ctor b/c it doesn't allocate memory and doesn't copy memory buffers only a handful of machine instructions compared to possibly thousands of machine instructions to allocate new memory any temp or unnamed variables will be rvalues (determined by compiler) assignment of the result of a function is would be 2 copies if move semantics were not used (very costly) move ctor is more exception safe than copy ctor move semantics are safe since we are not grabbing more resources","title":"rvalue references"},{"location":"software_design/cpp/operator-overloading/","text":"Operator Overloading Allows a programmer to define behaviors when built-in operators are applied to user defined types operator<symbol> is used for the function name of the operator to be overloaded class String { public: String &operator=(const String &); // assignment: returns by referenceto allow chaining/compounding assignments String operator+(const String &) const; // addition: const method b/c it does not alter the object, but returns a new one String operator-() const; // unary negator ... }; a = b // equivalent a.operator=(b) Compiler generates default implementation for assignment ( = ) and address ( & ) operator Cannot overload . , .* , :: , ?: , and sizeof operators Overloading an operator does not change: Operator precedence Associativity of the operator (important for unary operator) Arity of the operator (can't turn unary operator into a binary operator or vice versa) Meaning of how the operator works on objects of built-in types Overloading = and - operators does not overload -= operator An overloaded operator must have at least one operand that is a user defined type Cannot be used to create new operator symbols Overloaded oeprators must adhere to syntax of original operator Operator functions: 1) Member functions- usually use the this pointer implicity 2) Non-member functions- made friends so they have access to internal state of the user defined object Friendship Used for sharing private data members between classes class A{ public: int operator+(const B &rhs) { return this->foo + } private: int foo; } class B { public: friend class A; // any object A and all of its functions have access to private members in class B friend int A::operator+(const B &rhs); // grants only this method in class A access to private member variables in class B private: int bar; } Implementing an operator function as a non-member function of a class (e.g. overloading the insertion/extraction operator): // .h class A{ public: A(std::string a, std::string b, std::string c); friend std::ostream &operator<<(std::ostream &lhs, const A &rhs); // gives method access to the private member variables private: std::string a, b, c; } std::ostream &operator<<(std::ostream &lhs, const A &rhs); // .cpp A:A(std::string a, std::string b, std::string c): a(a), b(b), c(c) {} // returns a reference to the ostream that was passed in and modified by adding the data from the rhs object which is not modified in the process std::ostream &operator<<(std::ostream &lhs, const A &rhs) { lhs << rhs.a << \" \" << rhs.b << \" \" << rhs.c <<std::endl; return lhs; } Overloading Unary Operators Preference is to make the operator functions class members rather than non-member friend functions Prefix (increment and return the incremented value) and postfix (increment and return the value before it was incremented) Prefix is faster b/c it doesn't have to make a temp copy class A { public: A &operator++(); // prefix const A operator++(int) // postfix- called as A.operator(0); A &operator--(); // prefix const A operator--(int) // postfix } A &A::operator++() { ++*this; return this; } const A A::operator++(int) { A temp(*this); ++*this; return temp; } ++ and -- are often overloaded to support iterators and smart pointers When overloading ++ and -- , both prefix and postfix must be overloaded and each version will have a distinct signature due to the use of dummy parameters in the postfix operators Subscript Operator operator [] can be overloadded to return an object of a new class or return an element of the original array Usually a const and non-const version for reading and writing Can use const_cast to reduce code duplication and increase maintainability class TextBlock { public: ... const char& operator[](std::size_t position) const { // bounds checking // log access data // verify data integrity return text[position]; } char& operator[](std::size_t position) { return const_cast<char&>( const_cast<const TextBlock&>(*this)][position] ); // 1) adds const to *this // 2) calls const operator[] // 3) cast away const from returned value } ... } Overloading vs. Overriding Overloading - multiple functions w/ same name in same scope, but different signatures (e.g. different argument/return types, different parameters, etc.) When overloading functions, use the copy constructor to create new objects Overriding - derived class function has the same name and signature as a base class virtual function Overrriden mthods in a derived class will cause any methods of the same name (regardless of signature) in the base class to be hidden meaning they can't be used by the derived class Can override this default hiding behavior with a using class::method; line inside the derived class class A { public: bool process(Credit &); bool process(Acceptance &); } class B : public A{ public: using A::process; // no hiding of A's process methods bool process(Rejection &) }","title":"Operator Overloading"},{"location":"software_design/cpp/operator-overloading/#operator-overloading","text":"Allows a programmer to define behaviors when built-in operators are applied to user defined types operator<symbol> is used for the function name of the operator to be overloaded class String { public: String &operator=(const String &); // assignment: returns by referenceto allow chaining/compounding assignments String operator+(const String &) const; // addition: const method b/c it does not alter the object, but returns a new one String operator-() const; // unary negator ... }; a = b // equivalent a.operator=(b) Compiler generates default implementation for assignment ( = ) and address ( & ) operator Cannot overload . , .* , :: , ?: , and sizeof operators Overloading an operator does not change: Operator precedence Associativity of the operator (important for unary operator) Arity of the operator (can't turn unary operator into a binary operator or vice versa) Meaning of how the operator works on objects of built-in types Overloading = and - operators does not overload -= operator An overloaded operator must have at least one operand that is a user defined type Cannot be used to create new operator symbols Overloaded oeprators must adhere to syntax of original operator Operator functions: 1) Member functions- usually use the this pointer implicity 2) Non-member functions- made friends so they have access to internal state of the user defined object","title":"Operator Overloading"},{"location":"software_design/cpp/operator-overloading/#friendship","text":"Used for sharing private data members between classes class A{ public: int operator+(const B &rhs) { return this->foo + } private: int foo; } class B { public: friend class A; // any object A and all of its functions have access to private members in class B friend int A::operator+(const B &rhs); // grants only this method in class A access to private member variables in class B private: int bar; } Implementing an operator function as a non-member function of a class (e.g. overloading the insertion/extraction operator): // .h class A{ public: A(std::string a, std::string b, std::string c); friend std::ostream &operator<<(std::ostream &lhs, const A &rhs); // gives method access to the private member variables private: std::string a, b, c; } std::ostream &operator<<(std::ostream &lhs, const A &rhs); // .cpp A:A(std::string a, std::string b, std::string c): a(a), b(b), c(c) {} // returns a reference to the ostream that was passed in and modified by adding the data from the rhs object which is not modified in the process std::ostream &operator<<(std::ostream &lhs, const A &rhs) { lhs << rhs.a << \" \" << rhs.b << \" \" << rhs.c <<std::endl; return lhs; }","title":"Friendship"},{"location":"software_design/cpp/operator-overloading/#overloading-unary-operators","text":"Preference is to make the operator functions class members rather than non-member friend functions Prefix (increment and return the incremented value) and postfix (increment and return the value before it was incremented) Prefix is faster b/c it doesn't have to make a temp copy class A { public: A &operator++(); // prefix const A operator++(int) // postfix- called as A.operator(0); A &operator--(); // prefix const A operator--(int) // postfix } A &A::operator++() { ++*this; return this; } const A A::operator++(int) { A temp(*this); ++*this; return temp; } ++ and -- are often overloaded to support iterators and smart pointers When overloading ++ and -- , both prefix and postfix must be overloaded and each version will have a distinct signature due to the use of dummy parameters in the postfix operators","title":"Overloading Unary Operators"},{"location":"software_design/cpp/operator-overloading/#subscript-operator","text":"operator [] can be overloadded to return an object of a new class or return an element of the original array Usually a const and non-const version for reading and writing Can use const_cast to reduce code duplication and increase maintainability class TextBlock { public: ... const char& operator[](std::size_t position) const { // bounds checking // log access data // verify data integrity return text[position]; } char& operator[](std::size_t position) { return const_cast<char&>( const_cast<const TextBlock&>(*this)][position] ); // 1) adds const to *this // 2) calls const operator[] // 3) cast away const from returned value } ... }","title":"Subscript Operator"},{"location":"software_design/cpp/operator-overloading/#overloading-vs-overriding","text":"Overloading - multiple functions w/ same name in same scope, but different signatures (e.g. different argument/return types, different parameters, etc.) When overloading functions, use the copy constructor to create new objects Overriding - derived class function has the same name and signature as a base class virtual function Overrriden mthods in a derived class will cause any methods of the same name (regardless of signature) in the base class to be hidden meaning they can't be used by the derived class Can override this default hiding behavior with a using class::method; line inside the derived class class A { public: bool process(Credit &); bool process(Acceptance &); } class B : public A{ public: using A::process; // no hiding of A's process methods bool process(Rejection &) }","title":"Overloading vs. Overriding"},{"location":"software_design/cpp/pointers/","text":"Pointers A pointer is a variable that contains a memory address as its value Memory address points to the actual data Has a data type that indicates the type of data being stored at the memory address Declared using * operator like: int* a; Refrence/Address Operator: & obtains a variable's memory address Dereference Operator: * retrieves the data at the memory address a pointer stores When declared, pointers hold an unknown address until initialized To indicate pointing at nothing, use nullptr Why use them? Pointers are all 8-bytes (64-bits on 64-bit machines, 32-bits on 32-bit) so it is much more efficient to use memory addresses of large objects like images or videos than to actually move around the object and make copies of it when doing things like passing them to a function. Common Errors Syntax Using the dereference operator when initializing a pointer int* a; int b = 20; *a = &b; // error b/c using derefence operator a = &b // correct The 3rd line is an error b/c *a refers to data being stored at the unknown memory address a was initialized to. This will set the data at a to the memory address of b instead of making a point at b 's memory address. Note this will note cause a compiler error, just a tricky to find bug. However, this is valid and perform the desired functionality because * is not being used for dereferencing but rather declaring a pointer: int b = 20; int *a = &b; Forgetting the * before each pointer when declaring multiple on the same line int* ptr1, ptr2; // ptr1 will be an int pointer but ptr2 will just be an int int *ptr1, *ptr2; // makes both of them int pointers Good practice to declare one pointer per line to avoid this. Runtime Using a derefence operator * when the pointer has not been intialized. This causes undefined behavior meaning the program could crash if the pointer holds an address the program is not allowed to access. Dereferencing a null pointer. This causes the program to crash. Memory overflow can be dangerous b/c it results in overwriting data anywhere in memory (can be OS, other programs, etc.) Aliasing- changing the memory address a pointer points to Dereferencing Derefencing a pointer means accessing the value stored at the memory address the pointer contains char* p = \"abc\" // stores 'a', 'b', 'c' in 3 continuous chunks of memory and p points to the location of a // Pointer arithmetic can be used to access b and c assert(*p == 'a'); // The first character at address p will be 'a' assert(p[1] == 'b'); // p[1] actually dereferences the pointer: p + 1 * (size of p in memory) assert(*(p + 1) == 'b'); // Another notation for p[1] Change data at the address pointed to by derferencing the pointer: *p = 'z' // now the string of chars is zbc assert(*p = 'z') Move pointers through the data: ++p; // Increment p so now it points to 'b' assert(*p == 'b'); Member Access Operator struct SomeStruct {int a;}; SomeStruct s; SomeStruct* structPtr = s; structPtr->a = 1; // is cleaner than: (*structPtr).a = 1; Arrays Represented internally as a pointer to the first element Accessing elements using indexing is actually just using pointer arithmetic A variable declared as an array is the same as a variable declared as a pointer When passing an array to a function, only the address of the array is copied into the parameter so any changes to the array in the function will cause a change to the original array b/c its shared void f1(int array[]) = void f1(int *array) [] and * are effectively the same but [] provides better documentation/readability Array of pointers (multi-dimensional arrays): ** or *[] can be used to declare arrays of pointers Allows a program to contain elements that vary in size (saves memory which is important for programs using large data objects) Strings represented internally as a character array ending with the null character \\0 since it is a character array, pointer arithmetic and everything can be done on strings Const const ensures data cannot be modified and the compiler will enforce this constraint Use as much as possible const int num; num = 10; // error! const char let = 'a'; // good! let = 'b'; // error New and Delete Operators new allocates memory for the given type and returns a pointer to the allocated memory If the type is a class, it calls the constructor after allocating memory for the class's data members Can pass arguments to the constructor by passing them in parentheses after the class name (ex: ClassA a = new ClassA(\"Test\") ) To allocate a continuous chunk of memory for an array of objects use new SomeClass[size] Default constructor called for each object in array (class must have a constructor that can take 0 arguments otherwise a compiler error will occur) delete deallocates/frees a block of memory allocated with new No effect if used on nullptr Dereferencing after using delete will cause undefined behavior if pointer is not set to nullptr Calling delete on pointer not allocated with new has undefined behavior and is a logic error Must be called on a pointer to memory allocated using new Doesn't set a pointer to nullptr just frees the memory (must be done manually) To delete an array of objects use delete[] array Calling destructor instead of delete fails to actually free up the memory Memory Regions Memory has 3 different regions: data, stack, and heap. There are 3 types of memory allocation: static, dynamic, and automatic A program's memory usage includes 3 different regions: Static - global & static local variables are allocated at compilation time (fixed size) Reserved at compile time in the program's data segment Allocated as a fixed block of memory Stores any global and static local variables Stores the actual code Allocated when program starts and deallocated when program exists Automatic - each function call allocates a new block of memory called a stack frame to holds its local variables. The stack frames are part of the stack Starts where static memory ends and grows towards the end of memory Allocated on the program's execution stack Allocated at run time as control flow enters and deallocated as flow exits Managed by the run-time system Dynamic Memory - where the new operator allocates memory and the delete operator deallocates memory during runtime Managed by the programmer (aka the free store) Dynamic memory is stored on the heap Can only have as much physical memory as the machine or OS can make available (mismanaged memory in large programs can lead to it running out of memory and crashing) In classical architectures, the stack and heap grow toward each other to maximize the available space Memory Leaks Occur when a program that allocates memory loses the ability to access the allocated memory Typically due to failure to properly destroy/free dynamically allocated memory that is no longer being used Can cause a program to occupy more and more memory as the program runs, slowing its runtime Can cause a program to fail if memory becomes completely full and additional memory cannot be allocated Programs left running for long periods such as web browsers suffer from known memory leaks Occur at the program level so when the program terminates, all the memory allocated by the program is freed const and pointers A const pointer cannot be changed to point at something else const data cannot be modified char greeting[] = \"Hello\"; char *p = greeting; // non-const pointer, non-const data (unfixed at what it points to & read/write) const char *p = greeting; // non-const pointer, const data (unfixed at what it points to & readonly) const * char p = greeting; // const pointerm, non-const data (fixed at what it points to & read/write) const char * const p = greeting // const pointer, const data (fixed at what it points & readonly) // const anywhere to the left of * means its const data void f1(const Widget *pw) // preferred void f2(Widget const *pw ) // same as above non-const --> const is common const --> non-const is bad and should be avoided this pointer this pointer in a non-const member function of a class X is type: X * const (can change the data of the class but can't change where this is pointing) constant pointer to non-constant object returning objects Objects can be returned from functions Resources (Stack Overflow) Dereferencing Pointers (Reference) Access Operators (Slides) Pointers (Article) Weird Pointer Expressions","title":"Pointers"},{"location":"software_design/cpp/pointers/#pointers","text":"A pointer is a variable that contains a memory address as its value Memory address points to the actual data Has a data type that indicates the type of data being stored at the memory address Declared using * operator like: int* a; Refrence/Address Operator: & obtains a variable's memory address Dereference Operator: * retrieves the data at the memory address a pointer stores When declared, pointers hold an unknown address until initialized To indicate pointing at nothing, use nullptr","title":"Pointers"},{"location":"software_design/cpp/pointers/#why-use-them","text":"Pointers are all 8-bytes (64-bits on 64-bit machines, 32-bits on 32-bit) so it is much more efficient to use memory addresses of large objects like images or videos than to actually move around the object and make copies of it when doing things like passing them to a function.","title":"Why use them?"},{"location":"software_design/cpp/pointers/#common-errors","text":"","title":"Common Errors"},{"location":"software_design/cpp/pointers/#syntax","text":"Using the dereference operator when initializing a pointer int* a; int b = 20; *a = &b; // error b/c using derefence operator a = &b // correct The 3rd line is an error b/c *a refers to data being stored at the unknown memory address a was initialized to. This will set the data at a to the memory address of b instead of making a point at b 's memory address. Note this will note cause a compiler error, just a tricky to find bug. However, this is valid and perform the desired functionality because * is not being used for dereferencing but rather declaring a pointer: int b = 20; int *a = &b; Forgetting the * before each pointer when declaring multiple on the same line int* ptr1, ptr2; // ptr1 will be an int pointer but ptr2 will just be an int int *ptr1, *ptr2; // makes both of them int pointers Good practice to declare one pointer per line to avoid this.","title":"Syntax"},{"location":"software_design/cpp/pointers/#runtime","text":"Using a derefence operator * when the pointer has not been intialized. This causes undefined behavior meaning the program could crash if the pointer holds an address the program is not allowed to access. Dereferencing a null pointer. This causes the program to crash. Memory overflow can be dangerous b/c it results in overwriting data anywhere in memory (can be OS, other programs, etc.) Aliasing- changing the memory address a pointer points to","title":"Runtime"},{"location":"software_design/cpp/pointers/#dereferencing","text":"Derefencing a pointer means accessing the value stored at the memory address the pointer contains char* p = \"abc\" // stores 'a', 'b', 'c' in 3 continuous chunks of memory and p points to the location of a // Pointer arithmetic can be used to access b and c assert(*p == 'a'); // The first character at address p will be 'a' assert(p[1] == 'b'); // p[1] actually dereferences the pointer: p + 1 * (size of p in memory) assert(*(p + 1) == 'b'); // Another notation for p[1] Change data at the address pointed to by derferencing the pointer: *p = 'z' // now the string of chars is zbc assert(*p = 'z') Move pointers through the data: ++p; // Increment p so now it points to 'b' assert(*p == 'b');","title":"Dereferencing"},{"location":"software_design/cpp/pointers/#member-access-operator","text":"struct SomeStruct {int a;}; SomeStruct s; SomeStruct* structPtr = s; structPtr->a = 1; // is cleaner than: (*structPtr).a = 1;","title":"Member Access Operator"},{"location":"software_design/cpp/pointers/#arrays","text":"Represented internally as a pointer to the first element Accessing elements using indexing is actually just using pointer arithmetic A variable declared as an array is the same as a variable declared as a pointer When passing an array to a function, only the address of the array is copied into the parameter so any changes to the array in the function will cause a change to the original array b/c its shared void f1(int array[]) = void f1(int *array) [] and * are effectively the same but [] provides better documentation/readability Array of pointers (multi-dimensional arrays): ** or *[] can be used to declare arrays of pointers Allows a program to contain elements that vary in size (saves memory which is important for programs using large data objects)","title":"Arrays"},{"location":"software_design/cpp/pointers/#strings","text":"represented internally as a character array ending with the null character \\0 since it is a character array, pointer arithmetic and everything can be done on strings","title":"Strings"},{"location":"software_design/cpp/pointers/#const","text":"const ensures data cannot be modified and the compiler will enforce this constraint Use as much as possible const int num; num = 10; // error! const char let = 'a'; // good! let = 'b'; // error","title":"Const"},{"location":"software_design/cpp/pointers/#new-and-delete-operators","text":"new allocates memory for the given type and returns a pointer to the allocated memory If the type is a class, it calls the constructor after allocating memory for the class's data members Can pass arguments to the constructor by passing them in parentheses after the class name (ex: ClassA a = new ClassA(\"Test\") ) To allocate a continuous chunk of memory for an array of objects use new SomeClass[size] Default constructor called for each object in array (class must have a constructor that can take 0 arguments otherwise a compiler error will occur) delete deallocates/frees a block of memory allocated with new No effect if used on nullptr Dereferencing after using delete will cause undefined behavior if pointer is not set to nullptr Calling delete on pointer not allocated with new has undefined behavior and is a logic error Must be called on a pointer to memory allocated using new Doesn't set a pointer to nullptr just frees the memory (must be done manually) To delete an array of objects use delete[] array Calling destructor instead of delete fails to actually free up the memory","title":"New and Delete Operators"},{"location":"software_design/cpp/pointers/#memory-regions","text":"Memory has 3 different regions: data, stack, and heap. There are 3 types of memory allocation: static, dynamic, and automatic A program's memory usage includes 3 different regions: Static - global & static local variables are allocated at compilation time (fixed size) Reserved at compile time in the program's data segment Allocated as a fixed block of memory Stores any global and static local variables Stores the actual code Allocated when program starts and deallocated when program exists Automatic - each function call allocates a new block of memory called a stack frame to holds its local variables. The stack frames are part of the stack Starts where static memory ends and grows towards the end of memory Allocated on the program's execution stack Allocated at run time as control flow enters and deallocated as flow exits Managed by the run-time system Dynamic Memory - where the new operator allocates memory and the delete operator deallocates memory during runtime Managed by the programmer (aka the free store) Dynamic memory is stored on the heap Can only have as much physical memory as the machine or OS can make available (mismanaged memory in large programs can lead to it running out of memory and crashing) In classical architectures, the stack and heap grow toward each other to maximize the available space","title":"Memory Regions"},{"location":"software_design/cpp/pointers/#memory-leaks","text":"Occur when a program that allocates memory loses the ability to access the allocated memory Typically due to failure to properly destroy/free dynamically allocated memory that is no longer being used Can cause a program to occupy more and more memory as the program runs, slowing its runtime Can cause a program to fail if memory becomes completely full and additional memory cannot be allocated Programs left running for long periods such as web browsers suffer from known memory leaks Occur at the program level so when the program terminates, all the memory allocated by the program is freed","title":"Memory Leaks"},{"location":"software_design/cpp/pointers/#const-and-pointers","text":"A const pointer cannot be changed to point at something else const data cannot be modified char greeting[] = \"Hello\"; char *p = greeting; // non-const pointer, non-const data (unfixed at what it points to & read/write) const char *p = greeting; // non-const pointer, const data (unfixed at what it points to & readonly) const * char p = greeting; // const pointerm, non-const data (fixed at what it points to & read/write) const char * const p = greeting // const pointer, const data (fixed at what it points & readonly) // const anywhere to the left of * means its const data void f1(const Widget *pw) // preferred void f2(Widget const *pw ) // same as above non-const --> const is common const --> non-const is bad and should be avoided","title":"const and pointers"},{"location":"software_design/cpp/pointers/#this-pointer","text":"this pointer in a non-const member function of a class X is type: X * const (can change the data of the class but can't change where this is pointing) constant pointer to non-constant object","title":"this pointer"},{"location":"software_design/cpp/pointers/#returning-objects","text":"Objects can be returned from functions","title":"returning objects"},{"location":"software_design/cpp/pointers/#resources","text":"(Stack Overflow) Dereferencing Pointers (Reference) Access Operators (Slides) Pointers (Article) Weird Pointer Expressions","title":"Resources"},{"location":"software_design/cpp/smart-pointers/","text":"Smart Pointers Class type that look and act like a raw pointer but with additional capabilities Allows programmer to control the following pointer behaviors: Construction and Destruction: Copy and assignment Shallow copy, deep copy, or no copy Dereferencing Primarily used for RAII to make programs using pointers exception safe unique_ptr Smart pointer that cleans up after itself Advantages: Very efficient When it goes out of scope, the destructor frees pointed to object Disadvantages: Retains sole ownership of an objct Cannot copy or copy-assign Two instances cannot manage the same object Typical uses: Guarantees deletion (helpful for exception safety) Passing ownership of uniquely-owned objects into methods Acquiring ownership of uniquely-owned objects from methods Managing ownership: release() reset() swap() Can be used w/ arrays shared_ptr reference-counting smart pointer Track how many objects point to a particular resource Deletes the resource when no pointers point to the resource anymore assignment and copy construction are how shared_ptrs keep track of the number of references constructing the pointers seperately would result in two different shared_ptrs using std::shared_ptr; Circle *foo = new Circle(); shared_ptr<Shape> aShape(foo); shared_ptr<Shape> aNewShape(aShape) // copy constructor creates new smart pointer and increments reference count aShape = aNewShape; // nothing changes shared_ptr<Shape> aNewPtr(foo); // creates an entirely new shared_ptr with seperate reference count than the above shared_ptrs","title":"Smart Pointers"},{"location":"software_design/cpp/smart-pointers/#smart-pointers","text":"Class type that look and act like a raw pointer but with additional capabilities Allows programmer to control the following pointer behaviors: Construction and Destruction: Copy and assignment Shallow copy, deep copy, or no copy Dereferencing Primarily used for RAII to make programs using pointers exception safe","title":"Smart Pointers"},{"location":"software_design/cpp/smart-pointers/#unique_ptr","text":"Smart pointer that cleans up after itself Advantages: Very efficient When it goes out of scope, the destructor frees pointed to object Disadvantages: Retains sole ownership of an objct Cannot copy or copy-assign Two instances cannot manage the same object Typical uses: Guarantees deletion (helpful for exception safety) Passing ownership of uniquely-owned objects into methods Acquiring ownership of uniquely-owned objects from methods Managing ownership: release() reset() swap() Can be used w/ arrays","title":"unique_ptr"},{"location":"software_design/cpp/smart-pointers/#shared_ptr","text":"reference-counting smart pointer Track how many objects point to a particular resource Deletes the resource when no pointers point to the resource anymore assignment and copy construction are how shared_ptrs keep track of the number of references constructing the pointers seperately would result in two different shared_ptrs using std::shared_ptr; Circle *foo = new Circle(); shared_ptr<Shape> aShape(foo); shared_ptr<Shape> aNewShape(aShape) // copy constructor creates new smart pointer and increments reference count aShape = aNewShape; // nothing changes shared_ptr<Shape> aNewPtr(foo); // creates an entirely new shared_ptr with seperate reference count than the above shared_ptrs","title":"shared_ptr"},{"location":"software_design/cpp/stl/","text":"Standard Template Library Contains generic template classes and functions for containers, iterators, & algorithms Allows for development of generic programs that are independent of the underlying container STL Containers Are abstract data types (ADTs) that hold data for manipulation 3 types 1) Sequential - arrange data in a linear manner vector, deque, list 2) Associative - maintain data in structures suitable for fast associative operations set, multiset, map, multimap Implemented as balanced binary trees Supports efficient operations on elements using keys ordered by operator< Provide efficient, direct accessto store and retrieve elements via a key Keys are maintained in ascending order 3) Adaptors - provide different ways to access sequential and associative containers stack, queue, priority queue vector Can change size dynamically (resizable array) Provides best random-access performance Supports random access iterator Insertions/deletions at the back of the vector ( push_back() and pop_back() ) push_back - used when we can only copy emplace_back - used when we do not need to copy for speed increase Pros: Const time access elements by index Linear time iteration over all elements Const amortized (avg) time for adding/removing elements from the end O(N)/N Cons: consume more memory than arrays due to automatic resizing Memory is gauranteed to be contiguous so can use pointer arithmetic deque Pronounced \"deck\" Double ended queue Advantages: Provides efficient index access to data Efficient insertions/deletions at both front and back of queue push_back() , push_front() , pop_back() , pop_front() Uses a index lookup table to optimize memory and lookup efficiency Vector will be slightly faster b/c it doesnt need the lookup table due to only pushing back Elements not guaranteeed to be in contiguous storage locations so pointer arithmetic not safe list Implements a doubly linked-list Advantages: Const time insertion/removal of elements anywhere in the container Const time moving elements and blocks of elements within the container or even between different containers It just requires pointer assignments instead of copying values and allocating new arrays Disadvantages: No support for random-access iterator set provides rapid look-up but does not permit duplicates O(logn) amortized time complexity for insertion and deletion Because its stored as a balanced binary tree- usually a red-black tree // Create an output stream iterator with \" \" as a delimeter std::ostream_iterator<double> output(std::cout, \" \"); std::set<double> doubleSet; // insert on a set returns a pair: an iterator to the value and T if it was inserted, F if it already existed std::pair<std::set<double>::const_iterator, bool> pairValue; pairValue = doubleSet.insert(13.2) // or simply use auto to infer the type auto pairValue = doubleSet.insert(13.2) std::cout << *(pairValue.first) << (pairValue.second ? \"was\" : \"was not\") << \"inserted\" << std::endl; std::cout << \"Set contains: \"; std::copy(doubleSet.begin(),doubleSet.end(),output); multiset provides rapid look-up but permits duplicates Order of data determined by a comparator function std::multiset<int> intMultiSet; // insert on a multiset just returns an iterator intMultiSet.insert(1); // check for an item if (intMultiSet.find(2) == intMultiSet.end()) std::cout << \"Not found\" map Provides lookup using a rapid key based lookup Each value is associated with a unique key (no duplicate keys) AKA associative array Implemented as either a hashtable or red-black tree depending on the compiler multimap Allows duplicate keys No index operator notation since ambiguity in which key is being referred to STL Algorithms Operate over iterators, not containers Composing an algorithm with a container by invoking the algorithm with the iterators for that container Templates provide compile-time type safety when combining containers, iterators, algorithms Primary categories: Non-mutating Mutating Sorting and Sets : sort or search ranges of elements and act on sorted ranges by testing values Ex: sort() , nth_element() , binary_search() Numeric : produce generally numeric results Ex: min() min_element() , next_permutation() Mutating Remove packs all the valid elements to the front of the container Doesn't actually remove the element Must be followed by a container specific call to actually remove the element and change the size of the container Generate calls the passed in function to create a new value and then puts it into the container (does this for a range) generate_n does this n times instead of for a range remove transform() is an important and commonly used algo takes from one domain to another domain applies a function (takes in type of input container and returns type of output container) to elements int the input container and adds them to an output container expects there to be space in the output container (space must be preallocated which can be done since its a 1:1 mapping from the input container to the output container) many algorithms we don't know the output of so we cant presize/preallocate back_inserter is a adaptor that grows the size of the container by calling push_back (more flexible in that we don't need to presize anything) corresponds to MapReduce another version has a function that takes two inputs and returns 1 output to write back to the same input container understand 4 and 5 parameter versions bind prob not on quiz random notes boolean/predicate function- returns T/F based on a condition. usually passed to STL algorithms such as find_if() sort() is performed inplace. can pass a different operator than < for the comparator erase is just doing smush copying (behavior is not what you would expect)","title":"STL"},{"location":"software_design/cpp/stl/#standard-template-library","text":"Contains generic template classes and functions for containers, iterators, & algorithms Allows for development of generic programs that are independent of the underlying container","title":"Standard Template Library"},{"location":"software_design/cpp/stl/#stl-containers","text":"Are abstract data types (ADTs) that hold data for manipulation 3 types 1) Sequential - arrange data in a linear manner vector, deque, list 2) Associative - maintain data in structures suitable for fast associative operations set, multiset, map, multimap Implemented as balanced binary trees Supports efficient operations on elements using keys ordered by operator< Provide efficient, direct accessto store and retrieve elements via a key Keys are maintained in ascending order 3) Adaptors - provide different ways to access sequential and associative containers stack, queue, priority queue","title":"STL Containers"},{"location":"software_design/cpp/stl/#vector","text":"Can change size dynamically (resizable array) Provides best random-access performance Supports random access iterator Insertions/deletions at the back of the vector ( push_back() and pop_back() ) push_back - used when we can only copy emplace_back - used when we do not need to copy for speed increase Pros: Const time access elements by index Linear time iteration over all elements Const amortized (avg) time for adding/removing elements from the end O(N)/N Cons: consume more memory than arrays due to automatic resizing Memory is gauranteed to be contiguous so can use pointer arithmetic","title":"vector"},{"location":"software_design/cpp/stl/#deque","text":"Pronounced \"deck\" Double ended queue Advantages: Provides efficient index access to data Efficient insertions/deletions at both front and back of queue push_back() , push_front() , pop_back() , pop_front() Uses a index lookup table to optimize memory and lookup efficiency Vector will be slightly faster b/c it doesnt need the lookup table due to only pushing back Elements not guaranteeed to be in contiguous storage locations so pointer arithmetic not safe","title":"deque"},{"location":"software_design/cpp/stl/#list","text":"Implements a doubly linked-list Advantages: Const time insertion/removal of elements anywhere in the container Const time moving elements and blocks of elements within the container or even between different containers It just requires pointer assignments instead of copying values and allocating new arrays Disadvantages: No support for random-access iterator","title":"list"},{"location":"software_design/cpp/stl/#set","text":"provides rapid look-up but does not permit duplicates O(logn) amortized time complexity for insertion and deletion Because its stored as a balanced binary tree- usually a red-black tree // Create an output stream iterator with \" \" as a delimeter std::ostream_iterator<double> output(std::cout, \" \"); std::set<double> doubleSet; // insert on a set returns a pair: an iterator to the value and T if it was inserted, F if it already existed std::pair<std::set<double>::const_iterator, bool> pairValue; pairValue = doubleSet.insert(13.2) // or simply use auto to infer the type auto pairValue = doubleSet.insert(13.2) std::cout << *(pairValue.first) << (pairValue.second ? \"was\" : \"was not\") << \"inserted\" << std::endl; std::cout << \"Set contains: \"; std::copy(doubleSet.begin(),doubleSet.end(),output);","title":"set"},{"location":"software_design/cpp/stl/#multiset","text":"provides rapid look-up but permits duplicates Order of data determined by a comparator function std::multiset<int> intMultiSet; // insert on a multiset just returns an iterator intMultiSet.insert(1); // check for an item if (intMultiSet.find(2) == intMultiSet.end()) std::cout << \"Not found\"","title":"multiset"},{"location":"software_design/cpp/stl/#map","text":"Provides lookup using a rapid key based lookup Each value is associated with a unique key (no duplicate keys) AKA associative array Implemented as either a hashtable or red-black tree depending on the compiler","title":"map"},{"location":"software_design/cpp/stl/#multimap","text":"Allows duplicate keys No index operator notation since ambiguity in which key is being referred to","title":"multimap"},{"location":"software_design/cpp/stl/#stl-algorithms","text":"Operate over iterators, not containers Composing an algorithm with a container by invoking the algorithm with the iterators for that container Templates provide compile-time type safety when combining containers, iterators, algorithms Primary categories: Non-mutating Mutating Sorting and Sets : sort or search ranges of elements and act on sorted ranges by testing values Ex: sort() , nth_element() , binary_search() Numeric : produce generally numeric results Ex: min() min_element() , next_permutation()","title":"STL Algorithms"},{"location":"software_design/cpp/stl/#mutating","text":"Remove packs all the valid elements to the front of the container Doesn't actually remove the element Must be followed by a container specific call to actually remove the element and change the size of the container Generate calls the passed in function to create a new value and then puts it into the container (does this for a range) generate_n does this n times instead of for a range remove transform() is an important and commonly used algo takes from one domain to another domain applies a function (takes in type of input container and returns type of output container) to elements int the input container and adds them to an output container expects there to be space in the output container (space must be preallocated which can be done since its a 1:1 mapping from the input container to the output container) many algorithms we don't know the output of so we cant presize/preallocate back_inserter is a adaptor that grows the size of the container by calling push_back (more flexible in that we don't need to presize anything) corresponds to MapReduce another version has a function that takes two inputs and returns 1 output to write back to the same input container understand 4 and 5 parameter versions bind prob not on quiz","title":"Mutating"},{"location":"software_design/cpp/stl/#random-notes","text":"boolean/predicate function- returns T/F based on a condition. usually passed to STL algorithms such as find_if() sort() is performed inplace. can pass a different operator than < for the comparator erase is just doing smush copying (behavior is not what you would expect)","title":"random notes"},{"location":"software_design/cpp/strong-exception-safety/","text":"Strong Exception Safety Very large and old software systems with ad hoc resource managment cannot use exceptions Noexcept Specfication Functions that guarantee they will not throw an exception should specify that like so: void foo (...) noexcept; Can also be used as an operator that returns true at compile time if a given expression is guaranteed to not throw an exception delete , return and std::swap are all noexcept General Principles Can design every function to: 1) Complete successfully 2) Fail in a well-defined manner Assume every function that can throw an exception will throw one and incorporate it into your code/design Never delete a peice of information before the replacement info is ready for use Basic Tools: Try-blocks Support from Resource Acquisition Is Initialization (RAII) technique Throw and catch exceptions only when absolutely necessary When exception is thrown: Leak no resources Don't permit data structures to become corrupted Golden Rule: when an exception is propagated, try to leave the object in the state it had when the function was called Avoid side effects in expressions that may propagate exceptions Standard Exception Class Heierarchy exception logic_error domain_error length_error invalid_argument out_of_range runtime_error range_error overflow_error underflow_error Mutex Mu tual ex clusion object An object that allows multiple program threads to share the same resource (e.g. file access) but not simultaneously Mutex is locked when being used and unlocked when no longer needed std::lock_guard<std::mutex> mutex(exMutex) will automatically lock and unlock the mutex when Strong exception safety because mutex will be unlocked if exception is thrown and will not freeze program b/c of never reaching the unlock call Example of using RAII to destroy local variables when they go out of scope Exception Safety Exception safe functions provide one of four guarantees for if an exception is thrown: No Safety- code is in bad place Weak/Basic- everything in function remains in a valid state, but exact state may be unknown Strong- state of program is unchanged Nothrow- function always works and never throws an exception Arithmetic operations on primitive types do not throw exceptions delete is no throw because we need to be able to reliably delete things For same reason, destructors should be nothrow Operating overloading can cause exceptions on user defined types because they are function calls Combining operating overloading with templates makes things very complicated since depending on whether the type is a primitive or user defined, exceptions may be possible with simple operator calls Resource Acquisition Is Initialization (RAII) Only code guaranteed to be executed after an exception is thrown are the destructors of objects residing on the stack (local variables) Vital to writing exception safe C++ code Required so that resources are released before permitting exceptions to propagate (in order to avoid resource leaks) Source code of std::lock_gaurd demonstrating wrapping a resource in a class that can be used as a local variable so that its destructor is called when exceptions are thrown and the resource is properly dealt with: namespace std{ template <typename MUTEX> class lock_gaurd { public: lock_guard(MUTEX &m) : m(m) {m.lock();} ~lock_guard() {m.unlock();} private: MUTEX &m; } } RAII is used with strings, vectors, list, etc. std::shared_ptr and std::unique_ptr is the same concept and is a local variable that destroys what is being pointed to when they go out of scope Exception Handling Guidlines always rethrow an exception caught in catch(...) if another catch can deal with the exception Don't strip info from the exception and","title":"Strong Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#strong-exception-safety","text":"Very large and old software systems with ad hoc resource managment cannot use exceptions","title":"Strong Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#noexcept-specfication","text":"Functions that guarantee they will not throw an exception should specify that like so: void foo (...) noexcept; Can also be used as an operator that returns true at compile time if a given expression is guaranteed to not throw an exception delete , return and std::swap are all noexcept","title":"Noexcept Specfication"},{"location":"software_design/cpp/strong-exception-safety/#general-principles","text":"Can design every function to: 1) Complete successfully 2) Fail in a well-defined manner Assume every function that can throw an exception will throw one and incorporate it into your code/design Never delete a peice of information before the replacement info is ready for use Basic Tools: Try-blocks Support from Resource Acquisition Is Initialization (RAII) technique Throw and catch exceptions only when absolutely necessary When exception is thrown: Leak no resources Don't permit data structures to become corrupted Golden Rule: when an exception is propagated, try to leave the object in the state it had when the function was called Avoid side effects in expressions that may propagate exceptions","title":"General Principles"},{"location":"software_design/cpp/strong-exception-safety/#standard-exception-class-heierarchy","text":"exception logic_error domain_error length_error invalid_argument out_of_range runtime_error range_error overflow_error underflow_error","title":"Standard Exception Class Heierarchy"},{"location":"software_design/cpp/strong-exception-safety/#mutex","text":"Mu tual ex clusion object An object that allows multiple program threads to share the same resource (e.g. file access) but not simultaneously Mutex is locked when being used and unlocked when no longer needed std::lock_guard<std::mutex> mutex(exMutex) will automatically lock and unlock the mutex when Strong exception safety because mutex will be unlocked if exception is thrown and will not freeze program b/c of never reaching the unlock call Example of using RAII to destroy local variables when they go out of scope","title":"Mutex"},{"location":"software_design/cpp/strong-exception-safety/#exception-safety","text":"Exception safe functions provide one of four guarantees for if an exception is thrown: No Safety- code is in bad place Weak/Basic- everything in function remains in a valid state, but exact state may be unknown Strong- state of program is unchanged Nothrow- function always works and never throws an exception Arithmetic operations on primitive types do not throw exceptions delete is no throw because we need to be able to reliably delete things For same reason, destructors should be nothrow Operating overloading can cause exceptions on user defined types because they are function calls Combining operating overloading with templates makes things very complicated since depending on whether the type is a primitive or user defined, exceptions may be possible with simple operator calls","title":"Exception Safety"},{"location":"software_design/cpp/strong-exception-safety/#resource-acquisition-is-initialization-raii","text":"Only code guaranteed to be executed after an exception is thrown are the destructors of objects residing on the stack (local variables) Vital to writing exception safe C++ code Required so that resources are released before permitting exceptions to propagate (in order to avoid resource leaks) Source code of std::lock_gaurd demonstrating wrapping a resource in a class that can be used as a local variable so that its destructor is called when exceptions are thrown and the resource is properly dealt with: namespace std{ template <typename MUTEX> class lock_gaurd { public: lock_guard(MUTEX &m) : m(m) {m.lock();} ~lock_guard() {m.unlock();} private: MUTEX &m; } } RAII is used with strings, vectors, list, etc. std::shared_ptr and std::unique_ptr is the same concept and is a local variable that destroys what is being pointed to when they go out of scope","title":"Resource Acquisition Is Initialization (RAII)"},{"location":"software_design/cpp/strong-exception-safety/#exception-handling-guidlines","text":"always rethrow an exception caught in catch(...) if another catch can deal with the exception Don't strip info from the exception and","title":"Exception Handling Guidlines"},{"location":"software_design/cpp/templates/","text":"Templates Permit the definition of a template class or template function that can be used with multiple data types Requires only a single definition Permits reuse Compiler will create specific versions when functions are used with specific types Save time and avoid code replication One class template that is instantiated for N specific classes with X associated member functions Instead of writing N * X member functions, you only write X Can result in code bloat (source code looks small but object code/binaries are large) Need to be recompiled for each translation unit (can dramatically increase compile time) Need to do a commonality and variability analysis Look for replication to idenfity when a template could instead be instantiated multiple times Example A.h for templatized A class: template <typename T> class A { ... } #include '../src/A.cpp' Function Templates Define a specific behavior that can be applied to any data type Method overloading can be used to provide functionality for each data type Parameters and return type may be template types template <typename T> void functionName(T paramName, ...){ ... } When program runs and a call to the function template is encountered: 1) compiler substitutes the appropriate type(s) for the template params 2) compiler compiles this version of the function Multiple copies of function templates are created (one for each data type used) Function templates : specify a range of related functinos with a single code segment Written by programmer Template functions : the individually compiled versions of the function tempalte Generated by compiler Class Templates Allow the program to contain a generic class definition that can be instantiated into a type specific object cpp files for template classes cannot be compiled on their own Need to have types inserted to be compiled (must create an object to compile a template class) .h file for the template class will #include '<name>.cpp' So the template's cpp file should be left out of the CMake list Seperating interface from the implementation is good practice Common way is to implement everything in the .h for template classes (will see this in libraries often) Can pass a literal as a template parameter such as the int parameter below: // ClassName.h file template<typename T, typename T2, int x> class ClassName { public: ... private: ... } // ClassName.cpp file template<typename T, typename T2, > ClassName<T, T2, X>::ClassName(...) { .. } ... // main.cpp file int main() { ClassName<datatype, datatypeT2, int> objectName(); ... } Class templates : specify a range of related classes with a single definition (not compileable) Defined by programmer Template classes : the individual instantiated versions of the class template that are compileable Created by compiler Can set defaults types or values for template parameters: template<typename T=int, int x=10> Template classes Can be used as arguments to other templates since they are valid types once compiled Compiler doesn't evaluate class templates unless they are used (methods could be uncompiled if class not instantiated) Specialization In the below version, a seperate version of sum() is provided for string types while the generic template version of sum() is provided for other types. This reduces code bloat b/c only the necessary implementation will be compiled if a class of that type is instantiated You can specialize a method as many times as needed A non-specialized version should still be provided as well template <> std::string Stack<std::string>::sum() const { std::string value; for (uint32_t i = 0; i < stackTop; ++i) { value = stack[i] + value; } return value; } template <typename T> T Stack<T>::sum() const { T value = T(); for (uint32_t i = 0; i < stackTop; ++i) { value += stack[i]; } return value; }","title":"Templates"},{"location":"software_design/cpp/templates/#templates","text":"Permit the definition of a template class or template function that can be used with multiple data types Requires only a single definition Permits reuse Compiler will create specific versions when functions are used with specific types Save time and avoid code replication One class template that is instantiated for N specific classes with X associated member functions Instead of writing N * X member functions, you only write X Can result in code bloat (source code looks small but object code/binaries are large) Need to be recompiled for each translation unit (can dramatically increase compile time) Need to do a commonality and variability analysis Look for replication to idenfity when a template could instead be instantiated multiple times Example A.h for templatized A class: template <typename T> class A { ... } #include '../src/A.cpp'","title":"Templates"},{"location":"software_design/cpp/templates/#function-templates","text":"Define a specific behavior that can be applied to any data type Method overloading can be used to provide functionality for each data type Parameters and return type may be template types template <typename T> void functionName(T paramName, ...){ ... } When program runs and a call to the function template is encountered: 1) compiler substitutes the appropriate type(s) for the template params 2) compiler compiles this version of the function Multiple copies of function templates are created (one for each data type used) Function templates : specify a range of related functinos with a single code segment Written by programmer Template functions : the individually compiled versions of the function tempalte Generated by compiler","title":"Function Templates"},{"location":"software_design/cpp/templates/#class-templates","text":"Allow the program to contain a generic class definition that can be instantiated into a type specific object cpp files for template classes cannot be compiled on their own Need to have types inserted to be compiled (must create an object to compile a template class) .h file for the template class will #include '<name>.cpp' So the template's cpp file should be left out of the CMake list Seperating interface from the implementation is good practice Common way is to implement everything in the .h for template classes (will see this in libraries often) Can pass a literal as a template parameter such as the int parameter below: // ClassName.h file template<typename T, typename T2, int x> class ClassName { public: ... private: ... } // ClassName.cpp file template<typename T, typename T2, > ClassName<T, T2, X>::ClassName(...) { .. } ... // main.cpp file int main() { ClassName<datatype, datatypeT2, int> objectName(); ... } Class templates : specify a range of related classes with a single definition (not compileable) Defined by programmer Template classes : the individual instantiated versions of the class template that are compileable Created by compiler Can set defaults types or values for template parameters: template<typename T=int, int x=10> Template classes Can be used as arguments to other templates since they are valid types once compiled Compiler doesn't evaluate class templates unless they are used (methods could be uncompiled if class not instantiated)","title":"Class Templates"},{"location":"software_design/cpp/templates/#specialization","text":"In the below version, a seperate version of sum() is provided for string types while the generic template version of sum() is provided for other types. This reduces code bloat b/c only the necessary implementation will be compiled if a class of that type is instantiated You can specialize a method as many times as needed A non-specialized version should still be provided as well template <> std::string Stack<std::string>::sum() const { std::string value; for (uint32_t i = 0; i < stackTop; ++i) { value = stack[i] + value; } return value; } template <typename T> T Stack<T>::sum() const { T value = T(); for (uint32_t i = 0; i < stackTop; ++i) { value += stack[i]; } return value; }","title":"Specialization"},{"location":"software_design/patterns/adapter/","text":"Adapter Pattern Also known as wrapper. Intent Convert a class interface into an interface expected by the cleints Allows classes to work together that cannot otherwise work together due to incompatible interfaces Applicability When there is a need to use an existing class, but its interface doesn't match the one needed When a class should be reusable so that it can cooperate with unrelated and unforeseen classes When there is a need to use several existing subclasses, but its not practical to adapt their interfaces by subclassing each one Structure Participants Target - the domain specific interface a client uses Adaptee - the existing interface that needs adapting Adapter - class that adapts the existing interface to the target interface Collaborations Clients will call operations on an Adapter instance which in turn calls adaptee operations to carry out the request Consequences (+) A single adapter can work with multiple adaptees (-) Can make it harder to override adaptee behavior Implementation Considerations: How much adapting to do? Focus on a good client experience Pluggable adapters- dynamically create and change different types of adapters at runtime Sample Code Legacy Interface: class Alpha { public: // No hope of polymorphism ~Alpha() { std::cout << \"Alpha::dtor\" << std::endl; } void doThis() { std::cout << \"Alpha::doThis()\" << std::endl; } }; class Beta { public: ~Beta() { std::cout << \"Beta::dtor\" << std::endl; } void doThat() { std::cout << \"Beta::doThat()\" << std::endl; } }; class Gamma { public: ~Gamma() { std::cout << \"Gamma::dtor\" << std::endl; } void doTheOther() { std::cout << \"Gamma::doTheOther()\" << std::endl; } }; Target Interface: - Client will only see an interface with an execute method // Abstract base class acts as the target interface class TargetInterface { public: virtual ~TargetInterface() = default; // The new interface that clients will call virtual void execute() = 0; }; Poor Adapter: - (-) Client has to know the mapping (very difficult to use) // Design a \"wrapper\" or \"adapter\" class template <typename T> class SimpleAdapter : public TargetInterface { public: // Constructor accepts an instance and a method pointer SimpleAdapter(T *o, void (T::*m)()) : object(o), method(m) {} ~SimpleAdapter() override { delete object; } // The adapter/wrapper \"maps\" the new to the legacy implementation void execute() override { (object->*method)(); } private: T *object; // ptr-to-object void (T::*method)(); // ptr-to-member-function }; // client code that uses the adpater: // client has to have a lot of insight into how the mapping works int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new SimpleAdapter<Alpha>(new Alpha(), &Alpha::doThis); objects[1] = new SimpleAdapter<Beta>(new Beta(), &Beta::doThat); objects[2] = new SimpleAdapter<Gamma>(new Gamma(), &Gamma::doTheOther); for (int i = 0; i < count; i++) { // Client doesn't have to know which legacy type it is calling - just calls // execute objects[i]->execute(); } // Again, client uses the new interface // polymorphic destruction for (int i = 0; i < 3; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Outputs: Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Better Adapter: - (+) Easier client experience since they don't need to know the mapping (the adapter takes care of it) - (-) Have to modify the adapter to include any new adaptees - Usually a good tradeoff since main focus is better client experience template <typename T> class BetterAdapter : public TargetInterface { public: explicit BetterAdapter(T *obj) : object(obj) {}; ~BetterAdapter() override { delete object; }; void execute() override { // using runtime type information (RTTI) and the typeid part of the vtable to determine the type of object at runtime if (typeid(*object) == typeid(Alpha)) { // need the cast to pass compile time type checking // reinterpret_cast gives compile time errors while a strict cast would force the cast and not do additional checks reinterpret_cast<Alpha *>(object)->doThis(); } else if (typeid(*object) == typeid(Beta)) { reinterpret_cast<Beta *>(object)->doThat(); } else if (typeid(*object) == typeid(Gamma)) { reinterpret_cast<Gamma *>(object)->doTheOther(); } else { throw; } } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new BetterAdapter<Alpha>(new Alpha()); objects[1] = new BetterAdapter<Beta>(new Beta()); objects[2] = new BetterAdapter<Gamma>(new Gamma()); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Best Adapter: - (+) Default adaptees - (+) Easy to use client experience - (+) Compile time execution and code synthesis (all work is done at compile time) - (+) Fast and lightweight - (+) Adding new adaptees would not require too much work template <typename T = Alpha> class BestAdapter : public TargetInterface { public: explicit BestAdapter() : object(new T()){}; ~BestAdapter() override { delete object; }; void execute() override { if constexpr (std::is_same<T, Alpha>::value) object->doThis(); else if constexpr (std::is_same<T, Beta>::value) object->doThat(); else if constexpr (std::is_same<T, Gamma>::value) object->doTheOther(); // could use a compile time assert here to raise type issues at compilation else std::cout << \"Unknown type\\n\"; } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; // can use defaults if adaptee not specified objects[0] = new BestAdapter<>(); objects[1] = new BestAdapter<Beta>(); objects[2] = new BestAdapter<Gamma>(); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ constexpr ( ) code can be executed at compile time meaning the else ifs in the block above will get evaluated at compile time and the appropriate line of code will get inserted/synthesized. Lots of the STL can be executed at compile time (e.g. allocating vectors, sorting containers, etc.) std::is_same<> is for compile time type checking Known Uses New interfaces to legacy code Stack and Queue in the STL are adapters of vector and list class Related Patterns Bridge has a similar structure but has a different intent of separating an interface from its implementation so they can vary independently Adapter is meant to change the interface of an existing object","title":"Adapter"},{"location":"software_design/patterns/adapter/#adapter-pattern","text":"Also known as wrapper.","title":"Adapter Pattern"},{"location":"software_design/patterns/adapter/#intent","text":"Convert a class interface into an interface expected by the cleints Allows classes to work together that cannot otherwise work together due to incompatible interfaces","title":"Intent"},{"location":"software_design/patterns/adapter/#applicability","text":"When there is a need to use an existing class, but its interface doesn't match the one needed When a class should be reusable so that it can cooperate with unrelated and unforeseen classes When there is a need to use several existing subclasses, but its not practical to adapt their interfaces by subclassing each one","title":"Applicability"},{"location":"software_design/patterns/adapter/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/adapter/#participants","text":"Target - the domain specific interface a client uses Adaptee - the existing interface that needs adapting Adapter - class that adapts the existing interface to the target interface","title":"Participants"},{"location":"software_design/patterns/adapter/#collaborations","text":"Clients will call operations on an Adapter instance which in turn calls adaptee operations to carry out the request","title":"Collaborations"},{"location":"software_design/patterns/adapter/#consequences","text":"(+) A single adapter can work with multiple adaptees (-) Can make it harder to override adaptee behavior","title":"Consequences"},{"location":"software_design/patterns/adapter/#implementation","text":"Considerations: How much adapting to do? Focus on a good client experience Pluggable adapters- dynamically create and change different types of adapters at runtime","title":"Implementation"},{"location":"software_design/patterns/adapter/#sample-code","text":"Legacy Interface: class Alpha { public: // No hope of polymorphism ~Alpha() { std::cout << \"Alpha::dtor\" << std::endl; } void doThis() { std::cout << \"Alpha::doThis()\" << std::endl; } }; class Beta { public: ~Beta() { std::cout << \"Beta::dtor\" << std::endl; } void doThat() { std::cout << \"Beta::doThat()\" << std::endl; } }; class Gamma { public: ~Gamma() { std::cout << \"Gamma::dtor\" << std::endl; } void doTheOther() { std::cout << \"Gamma::doTheOther()\" << std::endl; } }; Target Interface: - Client will only see an interface with an execute method // Abstract base class acts as the target interface class TargetInterface { public: virtual ~TargetInterface() = default; // The new interface that clients will call virtual void execute() = 0; }; Poor Adapter: - (-) Client has to know the mapping (very difficult to use) // Design a \"wrapper\" or \"adapter\" class template <typename T> class SimpleAdapter : public TargetInterface { public: // Constructor accepts an instance and a method pointer SimpleAdapter(T *o, void (T::*m)()) : object(o), method(m) {} ~SimpleAdapter() override { delete object; } // The adapter/wrapper \"maps\" the new to the legacy implementation void execute() override { (object->*method)(); } private: T *object; // ptr-to-object void (T::*method)(); // ptr-to-member-function }; // client code that uses the adpater: // client has to have a lot of insight into how the mapping works int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new SimpleAdapter<Alpha>(new Alpha(), &Alpha::doThis); objects[1] = new SimpleAdapter<Beta>(new Beta(), &Beta::doThat); objects[2] = new SimpleAdapter<Gamma>(new Gamma(), &Gamma::doTheOther); for (int i = 0; i < count; i++) { // Client doesn't have to know which legacy type it is calling - just calls // execute objects[i]->execute(); } // Again, client uses the new interface // polymorphic destruction for (int i = 0; i < 3; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Outputs: Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Better Adapter: - (+) Easier client experience since they don't need to know the mapping (the adapter takes care of it) - (-) Have to modify the adapter to include any new adaptees - Usually a good tradeoff since main focus is better client experience template <typename T> class BetterAdapter : public TargetInterface { public: explicit BetterAdapter(T *obj) : object(obj) {}; ~BetterAdapter() override { delete object; }; void execute() override { // using runtime type information (RTTI) and the typeid part of the vtable to determine the type of object at runtime if (typeid(*object) == typeid(Alpha)) { // need the cast to pass compile time type checking // reinterpret_cast gives compile time errors while a strict cast would force the cast and not do additional checks reinterpret_cast<Alpha *>(object)->doThis(); } else if (typeid(*object) == typeid(Beta)) { reinterpret_cast<Beta *>(object)->doThat(); } else if (typeid(*object) == typeid(Gamma)) { reinterpret_cast<Gamma *>(object)->doTheOther(); } else { throw; } } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; objects[0] = new BetterAdapter<Alpha>(new Alpha()); objects[1] = new BetterAdapter<Beta>(new Beta()); objects[2] = new BetterAdapter<Gamma>(new Gamma()); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ Best Adapter: - (+) Default adaptees - (+) Easy to use client experience - (+) Compile time execution and code synthesis (all work is done at compile time) - (+) Fast and lightweight - (+) Adding new adaptees would not require too much work template <typename T = Alpha> class BestAdapter : public TargetInterface { public: explicit BestAdapter() : object(new T()){}; ~BestAdapter() override { delete object; }; void execute() override { if constexpr (std::is_same<T, Alpha>::value) object->doThis(); else if constexpr (std::is_same<T, Beta>::value) object->doThat(); else if constexpr (std::is_same<T, Gamma>::value) object->doTheOther(); // could use a compile time assert here to raise type issues at compilation else std::cout << \"Unknown type\\n\"; } private: T *object; }; int main() { uint32_t count = 3; auto objects = new TargetInterface *[count]; // can use defaults if adaptee not specified objects[0] = new BestAdapter<>(); objects[1] = new BestAdapter<Beta>(); objects[2] = new BestAdapter<Gamma>(); for (int i = 0; i < count; i++) { objects[i]->execute(); } // Client uses the new interface (polymorphism) for (int i = 0; i < count; i++) { delete objects[i]; } delete[] objects; return 0; } /**** Alpha::doThis() Beta::doThat() Gamma::doTheOther() Alpha::dtor Beta::dtor Gamma::dtor *****/ constexpr ( ) code can be executed at compile time meaning the else ifs in the block above will get evaluated at compile time and the appropriate line of code will get inserted/synthesized. Lots of the STL can be executed at compile time (e.g. allocating vectors, sorting containers, etc.) std::is_same<> is for compile time type checking","title":"Sample Code"},{"location":"software_design/patterns/adapter/#known-uses","text":"New interfaces to legacy code Stack and Queue in the STL are adapters of vector and list class","title":"Known Uses"},{"location":"software_design/patterns/adapter/#related-patterns","text":"Bridge has a similar structure but has a different intent of separating an interface from its implementation so they can vary independently Adapter is meant to change the interface of an existing object","title":"Related Patterns"},{"location":"software_design/patterns/bridge/","text":"Bridge Pattern Also known as Handle/Body Intent Decouple an abstraction interface from its physical implementation(s) so that the two can vary independently Motivation When an abstraction can have multiple implementations, a common approach is to use inheritance. An abstract class defines the interface to the abstraction and the concrete subclasses implement it in different ways. However, using inheritance is not always the best solution since it can be cumbersome to modify, extend, and reuse abstractions and implementations independently. Bridge pattern addresses the problems of strict inheritance by putting the abstract interface and the implmentation in their own class hierarchies. The relationship between the abstraction and the implementation is known as the bridge. Applicability Use the bridge pattern when: You want to avoid permanent binding between an abstraction and its implementation e.g. when the implementation must be selected/switched at runtime Both the abstractions and their implementations should be extensible by subclassing Changes in the implementation should have no impact on the abstraction interface and client code that uses the interface You need a uniform interface to interchangeable class hierarchies Structure Participants Abstraction defines the abstraction's interface maintains a reference to an object of type Implementor RefinedAbstraction Extends the interface defined by Abstraction Implementor defines the interface for implementation classes does not have to correspond exactly to Abstraction's interface (can be quite different) Implementor interface provides only primitive operations and Abstraction defines higher-level operations based on these primitives ConcreteImplementor implements the Implementor interface and defines its concrete implementation Collaborations Abstraction forwards client requests to its Implementor object Consequences (+) Decoupled abstract interface and implementation (+) Implementations can vary dynamically (i.e. at runtime) (+) Eliminates compile-time dependencies on the implementation (e.g. changing implementation class doesn't require recompiling abstraction class and its clients) (+) Improved extensibility- can extend the Abstraction and Implementor hierarchies independently (+) Hiding implementation details from clients- you can shield clients from implmentation details (+) Can be used transparently with STL algorithms and containers Implementation The following implementation issues should be considered when applying the bridge pattern: Creating an abstract implementor class is unnecessary when there is only one implementation If sharing implementors a form of reference counting needs to be implemented Determining the right implementor to create for the use case Decision can be made in constructor based on passed in params Decision can also be made by outside object such as a factory Sample Code class Abstraction { public: Abstraction(); virtual void doSomething(); ... protected: Implementor* getImp(); private: Implementor* _imp; } class Implementor { public: virtual void someFunc(); ... protected: Implementor(); } Related Patterns an abstract factory can create and configure a bridge the adapter pattern is geared toward making unrelated classes work together (usually applied to systems after they are designed) bridge is used up-front in a design","title":"Bridge"},{"location":"software_design/patterns/bridge/#bridge-pattern","text":"Also known as Handle/Body","title":"Bridge Pattern"},{"location":"software_design/patterns/bridge/#intent","text":"Decouple an abstraction interface from its physical implementation(s) so that the two can vary independently","title":"Intent"},{"location":"software_design/patterns/bridge/#motivation","text":"When an abstraction can have multiple implementations, a common approach is to use inheritance. An abstract class defines the interface to the abstraction and the concrete subclasses implement it in different ways. However, using inheritance is not always the best solution since it can be cumbersome to modify, extend, and reuse abstractions and implementations independently. Bridge pattern addresses the problems of strict inheritance by putting the abstract interface and the implmentation in their own class hierarchies. The relationship between the abstraction and the implementation is known as the bridge.","title":"Motivation"},{"location":"software_design/patterns/bridge/#applicability","text":"Use the bridge pattern when: You want to avoid permanent binding between an abstraction and its implementation e.g. when the implementation must be selected/switched at runtime Both the abstractions and their implementations should be extensible by subclassing Changes in the implementation should have no impact on the abstraction interface and client code that uses the interface You need a uniform interface to interchangeable class hierarchies","title":"Applicability"},{"location":"software_design/patterns/bridge/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/bridge/#participants","text":"Abstraction defines the abstraction's interface maintains a reference to an object of type Implementor RefinedAbstraction Extends the interface defined by Abstraction Implementor defines the interface for implementation classes does not have to correspond exactly to Abstraction's interface (can be quite different) Implementor interface provides only primitive operations and Abstraction defines higher-level operations based on these primitives ConcreteImplementor implements the Implementor interface and defines its concrete implementation","title":"Participants"},{"location":"software_design/patterns/bridge/#collaborations","text":"Abstraction forwards client requests to its Implementor object","title":"Collaborations"},{"location":"software_design/patterns/bridge/#consequences","text":"(+) Decoupled abstract interface and implementation (+) Implementations can vary dynamically (i.e. at runtime) (+) Eliminates compile-time dependencies on the implementation (e.g. changing implementation class doesn't require recompiling abstraction class and its clients) (+) Improved extensibility- can extend the Abstraction and Implementor hierarchies independently (+) Hiding implementation details from clients- you can shield clients from implmentation details (+) Can be used transparently with STL algorithms and containers","title":"Consequences"},{"location":"software_design/patterns/bridge/#implementation","text":"The following implementation issues should be considered when applying the bridge pattern: Creating an abstract implementor class is unnecessary when there is only one implementation If sharing implementors a form of reference counting needs to be implemented Determining the right implementor to create for the use case Decision can be made in constructor based on passed in params Decision can also be made by outside object such as a factory","title":"Implementation"},{"location":"software_design/patterns/bridge/#sample-code","text":"class Abstraction { public: Abstraction(); virtual void doSomething(); ... protected: Implementor* getImp(); private: Implementor* _imp; } class Implementor { public: virtual void someFunc(); ... protected: Implementor(); }","title":"Sample Code"},{"location":"software_design/patterns/bridge/#related-patterns","text":"an abstract factory can create and configure a bridge the adapter pattern is geared toward making unrelated classes work together (usually applied to systems after they are designed) bridge is used up-front in a design","title":"Related Patterns"},{"location":"software_design/patterns/builder/","text":"Builder Pattern Intent Separate the construction of a complex object from its representation so that the same construction process can create different representations Applicability When the algorthim for creating a complex object should be independent of the parts that make up the object When the construction process must allow different representations for the object that's constructed Ex: multiplication in an expression tree can also be represented as repeated addtion Structure Participants Builder -specifies an abstract interface for creating parts of a product object ConcreteBuilder - constructs and assembles parts of the product by implementing the Builder interface Director - constructs an object using the Builder interface Product - represents the complex object under construction Collaborations Client creates the Director object and configures it with the desired builder object Director notifies the builder whenever a part of the product should be built Builder handles requests from the director and adds parts to the product Client retrieves the product from the builder Consequences (+) Can vary a product's internal representation (all you need to do is define a new builder) (+) Isolates code for construction and representation (+) Finer control over the construction process (-) May involve lots of classes Implementation Usually no abstract class for products since they each may differ so much in their representation Related Patterns Abstract Factory also creates complex objects but the difference is that builder pattern focuses on creting the complex object step by step while the abstract factory's focus is on families of product objects Builder often builds a Composite","title":"Builder"},{"location":"software_design/patterns/builder/#builder-pattern","text":"","title":"Builder Pattern"},{"location":"software_design/patterns/builder/#intent","text":"Separate the construction of a complex object from its representation so that the same construction process can create different representations","title":"Intent"},{"location":"software_design/patterns/builder/#applicability","text":"When the algorthim for creating a complex object should be independent of the parts that make up the object When the construction process must allow different representations for the object that's constructed Ex: multiplication in an expression tree can also be represented as repeated addtion","title":"Applicability"},{"location":"software_design/patterns/builder/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/builder/#participants","text":"Builder -specifies an abstract interface for creating parts of a product object ConcreteBuilder - constructs and assembles parts of the product by implementing the Builder interface Director - constructs an object using the Builder interface Product - represents the complex object under construction","title":"Participants"},{"location":"software_design/patterns/builder/#collaborations","text":"Client creates the Director object and configures it with the desired builder object Director notifies the builder whenever a part of the product should be built Builder handles requests from the director and adds parts to the product Client retrieves the product from the builder","title":"Collaborations"},{"location":"software_design/patterns/builder/#consequences","text":"(+) Can vary a product's internal representation (all you need to do is define a new builder) (+) Isolates code for construction and representation (+) Finer control over the construction process (-) May involve lots of classes","title":"Consequences"},{"location":"software_design/patterns/builder/#implementation","text":"Usually no abstract class for products since they each may differ so much in their representation","title":"Implementation"},{"location":"software_design/patterns/builder/#related-patterns","text":"Abstract Factory also creates complex objects but the difference is that builder pattern focuses on creting the complex object step by step while the abstract factory's focus is on families of product objects Builder often builds a Composite","title":"Related Patterns"},{"location":"software_design/patterns/command/","text":"Command Pattern Also known as Action or Transaction Intent Encapsulate a request for a service as an object Motivation Part of an application that may issue a command (e.g. a button click) might not be able to execute the command itself (e.g. performing the action of the button click would be done by a different part of the application). The comand pattern allows commands to be created and passed around as objects so that a receiver/target with the proper scope can execute commands issued by any part of the application. Applicability To parameterize objects with an action to perform To specify, queue, and execute requests at different times Command object can have a lifetime independent of the original request so if the receiver/target can be stored indepedently of the caller, then command object can be transfered to a different process and executed there are the proper time For multilevel undo/redo The execute operation can store state for reversing its effects Can log changes to be reapplied in case of a system crash Structure Participants Command declares an interface for executing an operation ConcreteCommand (ex: PasteCommand, OpenCommand) defines a binding between a receiver object and an action implements Execute by invoking the corresponding operations on Target Client (ex: Application) Creates a ConcreteCommand object and sets its target Invoker (ex: MenuItem) asks the command to carry out the request Receiver/Target (ex: Document, Application) knows how to perform the operations associated with carrying out a request (e.g. Document knows how to handle the paste command by adding the contents of the clipboard to the document) Any class may serve as a target/receiver The diagram below shows the interactions between the objects and how Command decouples the invoker from the receiver and the request it carries out Collaborations The client creates a ConcreteCommand object and specifies its receiver An Invoker object stores the ConcreteCommand object The invoker issues a request by calling execute on the command The ConcreteCommand object invokes operations on its receiver to carry out the request Consequences (+) Decouple the object that invokes the operation from the one that knows how to perform it (+) Commands are first-class objects that can be manipulated and extended like any other object (+) Can assemble commands into a composite command (e.g macros) (+) Can easily add new commands (+) Supports arbitrary-level undo/redo (-) May result in lots of trivial command subclasses --> doesn't scale well to hundreds or thousands of commands (-) Excessive memory may be needed to support long time horizons of undo/redo operations Implementation Supporting undo and redo requires a ConcreteCommand to store additional state Possible state: The receiver, thearguments to the operation, and/or original values in the receiver that changed due to the command Place each executed command onto a stack Each command has the required state to restore a previous version of the application (the state can be light or heavy depending on the application) Popping from the stack restores other versions of the application Handling hysteresis Want to watch out for the accumulation of error in the undo/redo process that causes the application's state to diverge from its original value The pattern can be used to support transactions Sample Code class Command { public: virtual ~Command(); virtual void execute() = 0; protected: Command(); } class ConcreteCommand : public Command { public: ConcreteCommand(Client*); virtual void execute(); private: Target* _target; } ConcreteCommand::ConcreteCommand(Target* target) : _target(target) {} ConcreteCommand::execute() { _target->doSomething(); } Related Patterns Composite pattern can be used to implement MacroCommands A Memento can keep state the command requires to undo its effect A command that must be copied before being placed on the history list acts as a prototype","title":"Command"},{"location":"software_design/patterns/command/#command-pattern","text":"Also known as Action or Transaction","title":"Command Pattern"},{"location":"software_design/patterns/command/#intent","text":"Encapsulate a request for a service as an object","title":"Intent"},{"location":"software_design/patterns/command/#motivation","text":"Part of an application that may issue a command (e.g. a button click) might not be able to execute the command itself (e.g. performing the action of the button click would be done by a different part of the application). The comand pattern allows commands to be created and passed around as objects so that a receiver/target with the proper scope can execute commands issued by any part of the application.","title":"Motivation"},{"location":"software_design/patterns/command/#applicability","text":"To parameterize objects with an action to perform To specify, queue, and execute requests at different times Command object can have a lifetime independent of the original request so if the receiver/target can be stored indepedently of the caller, then command object can be transfered to a different process and executed there are the proper time For multilevel undo/redo The execute operation can store state for reversing its effects Can log changes to be reapplied in case of a system crash","title":"Applicability"},{"location":"software_design/patterns/command/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/command/#participants","text":"Command declares an interface for executing an operation ConcreteCommand (ex: PasteCommand, OpenCommand) defines a binding between a receiver object and an action implements Execute by invoking the corresponding operations on Target Client (ex: Application) Creates a ConcreteCommand object and sets its target Invoker (ex: MenuItem) asks the command to carry out the request Receiver/Target (ex: Document, Application) knows how to perform the operations associated with carrying out a request (e.g. Document knows how to handle the paste command by adding the contents of the clipboard to the document) Any class may serve as a target/receiver The diagram below shows the interactions between the objects and how Command decouples the invoker from the receiver and the request it carries out","title":"Participants"},{"location":"software_design/patterns/command/#collaborations","text":"The client creates a ConcreteCommand object and specifies its receiver An Invoker object stores the ConcreteCommand object The invoker issues a request by calling execute on the command The ConcreteCommand object invokes operations on its receiver to carry out the request","title":"Collaborations"},{"location":"software_design/patterns/command/#consequences","text":"(+) Decouple the object that invokes the operation from the one that knows how to perform it (+) Commands are first-class objects that can be manipulated and extended like any other object (+) Can assemble commands into a composite command (e.g macros) (+) Can easily add new commands (+) Supports arbitrary-level undo/redo (-) May result in lots of trivial command subclasses --> doesn't scale well to hundreds or thousands of commands (-) Excessive memory may be needed to support long time horizons of undo/redo operations","title":"Consequences"},{"location":"software_design/patterns/command/#implementation","text":"Supporting undo and redo requires a ConcreteCommand to store additional state Possible state: The receiver, thearguments to the operation, and/or original values in the receiver that changed due to the command Place each executed command onto a stack Each command has the required state to restore a previous version of the application (the state can be light or heavy depending on the application) Popping from the stack restores other versions of the application Handling hysteresis Want to watch out for the accumulation of error in the undo/redo process that causes the application's state to diverge from its original value The pattern can be used to support transactions","title":"Implementation"},{"location":"software_design/patterns/command/#sample-code","text":"class Command { public: virtual ~Command(); virtual void execute() = 0; protected: Command(); } class ConcreteCommand : public Command { public: ConcreteCommand(Client*); virtual void execute(); private: Target* _target; } ConcreteCommand::ConcreteCommand(Target* target) : _target(target) {} ConcreteCommand::execute() { _target->doSomething(); }","title":"Sample Code"},{"location":"software_design/patterns/command/#related-patterns","text":"Composite pattern can be used to implement MacroCommands A Memento can keep state the command requires to undo its effect A command that must be copied before being placed on the history list acts as a prototype","title":"Related Patterns"},{"location":"software_design/patterns/composite/","text":"Composite Pattern Intent Compose objects into tree structures to represent part-whole hierarchies. Allows clients to treat individual objects and multiple, recursively-composed objects uniformly. Applicability Tree structure Objects must be composed recursively No distinction between individual and composed elements (root node is itself a tree) Objects in strcutre can be treated uniformly Structure Participants Component - declares the interface for objects in the composition implements any default behavior common for all classes declares an interface for accessing and managing its child components Leaf - represents leaf objects in the composition (no children) Composite - defines behavior for components having children stores child components implements child-related operations Client - manipulates objects in the composition through the component interface Collaborations Requests are usually forwarded through composite components to the leaves where the requests are handled. Consequences (+) Easy to use for the client (+) Easy to add new components (-) Overhead: might be prohibitive as the number of objects increases (e.g. impractical for linux kernel with 30+ million lines of code) (-) Awkward designs: may need to treat leaves as lobotomized composites Implementation Do components need to know their parents? If so, add a parent pointer to components Does there need to be a uniform interface for both leaves and composites? Need to decide who has the responsibility for deleting children Do we allocate storage for children in component base class In the expression tree, someone outside the tree will do this actual creation of children nodes (i.e. the interpreter) Related Patterns Iterator pattern can be used to traverse composites Visitor pattern can be used to localize operations/behavior that would otherwise be distributed across composite and leaf classes","title":"Composite"},{"location":"software_design/patterns/composite/#composite-pattern","text":"","title":"Composite Pattern"},{"location":"software_design/patterns/composite/#intent","text":"Compose objects into tree structures to represent part-whole hierarchies. Allows clients to treat individual objects and multiple, recursively-composed objects uniformly.","title":"Intent"},{"location":"software_design/patterns/composite/#applicability","text":"Tree structure Objects must be composed recursively No distinction between individual and composed elements (root node is itself a tree) Objects in strcutre can be treated uniformly","title":"Applicability"},{"location":"software_design/patterns/composite/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/composite/#participants","text":"Component - declares the interface for objects in the composition implements any default behavior common for all classes declares an interface for accessing and managing its child components Leaf - represents leaf objects in the composition (no children) Composite - defines behavior for components having children stores child components implements child-related operations Client - manipulates objects in the composition through the component interface","title":"Participants"},{"location":"software_design/patterns/composite/#collaborations","text":"Requests are usually forwarded through composite components to the leaves where the requests are handled.","title":"Collaborations"},{"location":"software_design/patterns/composite/#consequences","text":"(+) Easy to use for the client (+) Easy to add new components (-) Overhead: might be prohibitive as the number of objects increases (e.g. impractical for linux kernel with 30+ million lines of code) (-) Awkward designs: may need to treat leaves as lobotomized composites","title":"Consequences"},{"location":"software_design/patterns/composite/#implementation","text":"Do components need to know their parents? If so, add a parent pointer to components Does there need to be a uniform interface for both leaves and composites? Need to decide who has the responsibility for deleting children Do we allocate storage for children in component base class In the expression tree, someone outside the tree will do this actual creation of children nodes (i.e. the interpreter)","title":"Implementation"},{"location":"software_design/patterns/composite/#related-patterns","text":"Iterator pattern can be used to traverse composites Visitor pattern can be used to localize operations/behavior that would otherwise be distributed across composite and leaf classes","title":"Related Patterns"},{"location":"software_design/patterns/factory/","text":"Factory Method Pattern Intent Provide an interface for creating an object, but let subclasses decide which class to instantiate. Applicability When a class cannot anticipate the objects it must create When a class wants its subclasses to specify the objects it creates When a standard interface for creating objects is useful in enforcing rules on how objects are created Structure Participants Product (ex: Document) defines the interface of objects the factory method cretes ConcreteProduct (ex: MyDocument) implements the product interface Creator (Ex: Application) declares the factory method which returns an object of type Product (may also provide default implementation that returns a default ConcreteProduct) may call the factory method to create a Product object ConcreteCreator (ex: MyApplication) overrides the factory method to return an instance of a ConcreteProduct Collaborations Creator relies on its subclasses to define the factory method so that it returns the appropriate ConcreteProduct instance Consequences (+) Client code becomes more flexible since we avoid specifying the class name of the concerete class Resilient to adding more objects or changing how objects are made (+) Client is only dependent on the interface Remove burden of knowing how to create things from the user and give user a simple interface for making new objects (-) Construction of objects requires one additional class in some cases Implementation 2 choices: 1) Creator class is abstract and doesn't implement creation methods meaning it must be subclassed 2) Creator class is concrete and provides a default implementation meaning it can optionally be subclassed Can create multiple types of products by parameterizing the factory method Should be parameterized if a factory method needs to be able to create different variants Known Uses All STL containers are factories Database connectors (a standard way of creating a database connection that only has to be changed in one place instead of across the application) Related Patterns Abstract Factory is often implemented with factory methods Abstract Factory Pattern Intent Provide an interface for creating families of related or dependent objects without specifying their concrete classes Applicability When a system should be independent of how its products are created, composed, and represented When a system should be configured with one of multiple families of products When a family of related product objects is designed to be used together and you need to enforce this constraint When you want to provide a class library of products without revealing their implementations Structure Participants AbstractFactory declares an interface for operations that create abstract product objects ConcreteFactory implements the operations to create concrete product objects Abstract Product declares an interface for a type of product object Concrete Product implements the AbstractProduct interface and defines a product object to be created by the corresponding ConcreteFactory Client uses only the interfaces defined by AbstractFactory and AbstractProduct classes Collaborations Normally a single instance of a ConcreteFactory is created at runtime AbstractFactory defers creation of product objects to its ConcreteFactory subclasses Consequences (+) Flexibility: remove type/subclass dependencies from clients (+) Abstraction and semantic checking: hides product's composition (-) Hard to extend interface to create new products Implementation Factories are usually best implemented as a singleton Parameterization as a way of controlling the interface's size Configuration with Prototypes (i.e. determines who creates the factories) Essentially groups of factory methods","title":"Factory"},{"location":"software_design/patterns/factory/#factory-method-pattern","text":"","title":"Factory Method Pattern"},{"location":"software_design/patterns/factory/#intent","text":"Provide an interface for creating an object, but let subclasses decide which class to instantiate.","title":"Intent"},{"location":"software_design/patterns/factory/#applicability","text":"When a class cannot anticipate the objects it must create When a class wants its subclasses to specify the objects it creates When a standard interface for creating objects is useful in enforcing rules on how objects are created","title":"Applicability"},{"location":"software_design/patterns/factory/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/factory/#participants","text":"Product (ex: Document) defines the interface of objects the factory method cretes ConcreteProduct (ex: MyDocument) implements the product interface Creator (Ex: Application) declares the factory method which returns an object of type Product (may also provide default implementation that returns a default ConcreteProduct) may call the factory method to create a Product object ConcreteCreator (ex: MyApplication) overrides the factory method to return an instance of a ConcreteProduct","title":"Participants"},{"location":"software_design/patterns/factory/#collaborations","text":"Creator relies on its subclasses to define the factory method so that it returns the appropriate ConcreteProduct instance","title":"Collaborations"},{"location":"software_design/patterns/factory/#consequences","text":"(+) Client code becomes more flexible since we avoid specifying the class name of the concerete class Resilient to adding more objects or changing how objects are made (+) Client is only dependent on the interface Remove burden of knowing how to create things from the user and give user a simple interface for making new objects (-) Construction of objects requires one additional class in some cases","title":"Consequences"},{"location":"software_design/patterns/factory/#implementation","text":"2 choices: 1) Creator class is abstract and doesn't implement creation methods meaning it must be subclassed 2) Creator class is concrete and provides a default implementation meaning it can optionally be subclassed Can create multiple types of products by parameterizing the factory method Should be parameterized if a factory method needs to be able to create different variants","title":"Implementation"},{"location":"software_design/patterns/factory/#known-uses","text":"All STL containers are factories Database connectors (a standard way of creating a database connection that only has to be changed in one place instead of across the application)","title":"Known Uses"},{"location":"software_design/patterns/factory/#related-patterns","text":"Abstract Factory is often implemented with factory methods","title":"Related Patterns"},{"location":"software_design/patterns/factory/#abstract-factory-pattern","text":"","title":"Abstract Factory Pattern"},{"location":"software_design/patterns/factory/#intent_1","text":"Provide an interface for creating families of related or dependent objects without specifying their concrete classes","title":"Intent"},{"location":"software_design/patterns/factory/#applicability_1","text":"When a system should be independent of how its products are created, composed, and represented When a system should be configured with one of multiple families of products When a family of related product objects is designed to be used together and you need to enforce this constraint When you want to provide a class library of products without revealing their implementations","title":"Applicability"},{"location":"software_design/patterns/factory/#structure_1","text":"","title":"Structure"},{"location":"software_design/patterns/factory/#participants_1","text":"AbstractFactory declares an interface for operations that create abstract product objects ConcreteFactory implements the operations to create concrete product objects Abstract Product declares an interface for a type of product object Concrete Product implements the AbstractProduct interface and defines a product object to be created by the corresponding ConcreteFactory Client uses only the interfaces defined by AbstractFactory and AbstractProduct classes","title":"Participants"},{"location":"software_design/patterns/factory/#collaborations_1","text":"Normally a single instance of a ConcreteFactory is created at runtime AbstractFactory defers creation of product objects to its ConcreteFactory subclasses","title":"Collaborations"},{"location":"software_design/patterns/factory/#consequences_1","text":"(+) Flexibility: remove type/subclass dependencies from clients (+) Abstraction and semantic checking: hides product's composition (-) Hard to extend interface to create new products","title":"Consequences"},{"location":"software_design/patterns/factory/#implementation_1","text":"Factories are usually best implemented as a singleton Parameterization as a way of controlling the interface's size Configuration with Prototypes (i.e. determines who creates the factories) Essentially groups of factory methods","title":"Implementation"},{"location":"software_design/patterns/interpreter/","text":"Interpreter Pattern Intent Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences in the languages Applicability When there is a language to interpret and statements in the language can be represented as abstract syntax trees Works best when: The grammar is simple and relatively stable (e.g. don't use for a programming language like C++) Expression can be interpreted without building abstract syntax trees (saves space and time) Efficiency is not a critical concern (other techniques for efficient interpreters) Structure Participants AbstractExpression - declares an abstract Interpret operation that is common to all nodes in the abstract syntax tree TerminalExpression - implements an Interpret operation associated with terminal symbols in the grammar NonTerminalExpression - one such class is required for every rule in the grammar Maintains references to other AbstractExpressions to represent the remaining subexpressions to be interpreted Interpret operation typically calls itself recursively on the variables representing each of the rules Context - contains information that is global to the interpreter Client - calls the Interpret operation in order to build an abstract syntax tree representing a particular sentence in the language defined by the grammar Collaborations The client builds the sentence as an abstract syntax tree of Terminal and Nonterminal expression instances. The client then initializes the content and invokes the Interpret operation NonTerminal expressions define Interpret in term of Interpret on each subexpression Interpret operations use the context to store and access the state of the interpreter Consequences (+) Simple grammars are easy to change and extend All rules are represented by distinct classes in an orderly manner (+) Adding another rule adds another class (-) Complex grammars are hard to maintain More interdependent rules yield more interdependent classes Parser or compiler generators are more appropriate for complex grammars Implementation Doesn't explain how to create an abstract syntax tree (doesn't address parsing) Express the language rules, one per class Alternations, repetitions, or sequences expressed as nonterminal expressions Literal translations expressed as terminal expressions Create interpret method to lead the context through the interpretation classes Sample Code Known Uses Regular expression (regex) is a language for searching for patterns in strings so that custom algorithms are not needed for each proble (the problem is so often occuring that it made sense to develop a simple grammar and interpeter that can parse sentences of the language) Related Patterns The abstract syntax tree is an instance of the composite pattern An iterator can be used to traverse the structure The visitor pattern can be used to maintain the behavior in each node in the syntax tree in one class","title":"Interpreter"},{"location":"software_design/patterns/interpreter/#interpreter-pattern","text":"","title":"Interpreter Pattern"},{"location":"software_design/patterns/interpreter/#intent","text":"Given a language, define a representation for its grammar along with an interpreter that uses the representation to interpret sentences in the languages","title":"Intent"},{"location":"software_design/patterns/interpreter/#applicability","text":"When there is a language to interpret and statements in the language can be represented as abstract syntax trees Works best when: The grammar is simple and relatively stable (e.g. don't use for a programming language like C++) Expression can be interpreted without building abstract syntax trees (saves space and time) Efficiency is not a critical concern (other techniques for efficient interpreters)","title":"Applicability"},{"location":"software_design/patterns/interpreter/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/interpreter/#participants","text":"AbstractExpression - declares an abstract Interpret operation that is common to all nodes in the abstract syntax tree TerminalExpression - implements an Interpret operation associated with terminal symbols in the grammar NonTerminalExpression - one such class is required for every rule in the grammar Maintains references to other AbstractExpressions to represent the remaining subexpressions to be interpreted Interpret operation typically calls itself recursively on the variables representing each of the rules Context - contains information that is global to the interpreter Client - calls the Interpret operation in order to build an abstract syntax tree representing a particular sentence in the language defined by the grammar","title":"Participants"},{"location":"software_design/patterns/interpreter/#collaborations","text":"The client builds the sentence as an abstract syntax tree of Terminal and Nonterminal expression instances. The client then initializes the content and invokes the Interpret operation NonTerminal expressions define Interpret in term of Interpret on each subexpression Interpret operations use the context to store and access the state of the interpreter","title":"Collaborations"},{"location":"software_design/patterns/interpreter/#consequences","text":"(+) Simple grammars are easy to change and extend All rules are represented by distinct classes in an orderly manner (+) Adding another rule adds another class (-) Complex grammars are hard to maintain More interdependent rules yield more interdependent classes Parser or compiler generators are more appropriate for complex grammars","title":"Consequences"},{"location":"software_design/patterns/interpreter/#implementation","text":"Doesn't explain how to create an abstract syntax tree (doesn't address parsing) Express the language rules, one per class Alternations, repetitions, or sequences expressed as nonterminal expressions Literal translations expressed as terminal expressions Create interpret method to lead the context through the interpretation classes","title":"Implementation"},{"location":"software_design/patterns/interpreter/#sample-code","text":"","title":"Sample Code"},{"location":"software_design/patterns/interpreter/#known-uses","text":"Regular expression (regex) is a language for searching for patterns in strings so that custom algorithms are not needed for each proble (the problem is so often occuring that it made sense to develop a simple grammar and interpeter that can parse sentences of the language)","title":"Known Uses"},{"location":"software_design/patterns/interpreter/#related-patterns","text":"The abstract syntax tree is an instance of the composite pattern An iterator can be used to traverse the structure The visitor pattern can be used to maintain the behavior in each node in the syntax tree in one class","title":"Related Patterns"},{"location":"software_design/patterns/iterator/","text":"Iterator Pattern Also known as cursor Intent Access elements of a container without exposing its representation Applicability Require multiple traversal algorithms over a container Require a uniform traversal interface over different containers When container classes and traversal algorithm must vary independently Structure Participants Iterator - defines an interface for accessing and traversing elements ConcreteIterator - implements the Iterator interface and a specific type of traversal Aggregate - container interface that defines method for creating an Iterator object ConcreteAggregate - specific container implementation that implements the create iterator method to return an instance of the correct ConcreteIterator Collaborations ConcreteIterator keeps track of the current object in the Aggregate and can compute the succeeding object in the traversal Consequences (+) Flexibility: container and traversal are independent (+) Multiple iterators and multiple traversal algorithms (-) Additional communication overhead between iterator and container Problematic for iterators in concurrent or distributed systems Implementation Internval versus external iterators Internal- when the iterator controls the iteration External- when the client controls the iteration (more flexible) Violating the object structure's encapsulation Robust iterators- ensure insertions/removals won't interfere with traversal Synchronization overhead in multi-threaded programs Batching in distributed and concurrent programs Related Patterns Iterators are often applied to Composite structures","title":"Iterator"},{"location":"software_design/patterns/iterator/#iterator-pattern","text":"Also known as cursor","title":"Iterator Pattern"},{"location":"software_design/patterns/iterator/#intent","text":"Access elements of a container without exposing its representation","title":"Intent"},{"location":"software_design/patterns/iterator/#applicability","text":"Require multiple traversal algorithms over a container Require a uniform traversal interface over different containers When container classes and traversal algorithm must vary independently","title":"Applicability"},{"location":"software_design/patterns/iterator/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/iterator/#participants","text":"Iterator - defines an interface for accessing and traversing elements ConcreteIterator - implements the Iterator interface and a specific type of traversal Aggregate - container interface that defines method for creating an Iterator object ConcreteAggregate - specific container implementation that implements the create iterator method to return an instance of the correct ConcreteIterator","title":"Participants"},{"location":"software_design/patterns/iterator/#collaborations","text":"ConcreteIterator keeps track of the current object in the Aggregate and can compute the succeeding object in the traversal","title":"Collaborations"},{"location":"software_design/patterns/iterator/#consequences","text":"(+) Flexibility: container and traversal are independent (+) Multiple iterators and multiple traversal algorithms (-) Additional communication overhead between iterator and container Problematic for iterators in concurrent or distributed systems","title":"Consequences"},{"location":"software_design/patterns/iterator/#implementation","text":"Internval versus external iterators Internal- when the iterator controls the iteration External- when the client controls the iteration (more flexible) Violating the object structure's encapsulation Robust iterators- ensure insertions/removals won't interfere with traversal Synchronization overhead in multi-threaded programs Batching in distributed and concurrent programs","title":"Implementation"},{"location":"software_design/patterns/iterator/#related-patterns","text":"Iterators are often applied to Composite structures","title":"Related Patterns"},{"location":"software_design/patterns/observer/","text":"Observer Pattern Also known as the pub/sub Intent Define a one-to-many dependency between objects so that when one object changes state, all dependents are notified and updated Applicability When an abstraction has two aspects, one dependent on the other When a change to one object requires changing untold others When an object should notify unknown other objects Structure Subject base class implements all interactions with observers This means it does not necessarily have to be an abstract base class Concrete subject class only needs to call notify to send updates to all the observers Can have multiple different concrete observers that use the subject's data in different ways Participants Subject - object being watched for state changes. Knows its observers and provides an interface for attaching and detaching observer objects Observer - defines an updating interface for objects that should be notified of changes in a subject Concrete Subject - stores the state of interest to ConcreteObserver objects Sends a notification to its observers when its state changes Concrete Observer - maintains a reference to a concrete subject Implements the Observer's updating interface to keep its state consistent with the subject's Collaborations The observers do not communicate with each other. A higher level of abstraction is thus required to keep track of things such as repeat observers. Consequences (+) Modularity- subject and observers can vary independently Subject only knows it has a list of Observers, doesn't know their concrete types (loosely coupled) (+) Extensibility- can define and add any number of different observers (+) Customizability- different observers offer different views of the subject (-) Unexpected updates- Observers don't know about each other (-) High update overhead (especially in large networks of observers) Can be reduced using hints or filtering Implementation Can filter the data an observer receives to decrease the update overhead Observers can register what data from the subject they are interested so not all the data needs to be sent to each observer An observer can be a subject that updates its own observers Can create large networks with high update overhead Can also create accidental update cycles (common in enterprise software) Need to handle dangling references left by observers that suddenly crash or get deleted Push vs. Pull models Pull model- subject sends message saying its data changed and observers can optionally request the updated data Allows observers to pull the data at varying rates Can implement both with pull model for certain observers and push for other observers Sample Code Below we define a simple abstract base class that has a method to be called when an event happens to the object being observed template <typename T> class Observer { public: virtual void handleEvent(const T &) = 0; }; Below we define a simple base class for any objects that we want to be subjects (observable) template <typename T> class Subject { public: /** * Default constructor */ Subject() = default; /** * Add an observer to this subject * @param ref New observer to notify of changes */ void add(Observer<T> &ref) { observers.insert(&ref); } /** * Remove an observer * @param ref Observer to stop notifying of changes */ void remove(Observer<T> &ref) { observers.erase(&ref); } protected: /** * Notify all observers of change * @param obj Object that has changed */ void Notify(T &obj) { for (auto observer : observers) observer->handleEvent(obj); } private: /** * Set of recorded observers */ std::set<Observer<T> *> observers; }; Here is the github repo with the example code from lecture. Known Uses MVC Smart phone event frameworks Pub/sub middleware (ROS, DDS, JAva Message Service, etc.) Mailing lists","title":"Observer"},{"location":"software_design/patterns/observer/#observer-pattern","text":"Also known as the pub/sub","title":"Observer Pattern"},{"location":"software_design/patterns/observer/#intent","text":"Define a one-to-many dependency between objects so that when one object changes state, all dependents are notified and updated","title":"Intent"},{"location":"software_design/patterns/observer/#applicability","text":"When an abstraction has two aspects, one dependent on the other When a change to one object requires changing untold others When an object should notify unknown other objects","title":"Applicability"},{"location":"software_design/patterns/observer/#structure","text":"Subject base class implements all interactions with observers This means it does not necessarily have to be an abstract base class Concrete subject class only needs to call notify to send updates to all the observers Can have multiple different concrete observers that use the subject's data in different ways","title":"Structure"},{"location":"software_design/patterns/observer/#participants","text":"Subject - object being watched for state changes. Knows its observers and provides an interface for attaching and detaching observer objects Observer - defines an updating interface for objects that should be notified of changes in a subject Concrete Subject - stores the state of interest to ConcreteObserver objects Sends a notification to its observers when its state changes Concrete Observer - maintains a reference to a concrete subject Implements the Observer's updating interface to keep its state consistent with the subject's","title":"Participants"},{"location":"software_design/patterns/observer/#collaborations","text":"The observers do not communicate with each other. A higher level of abstraction is thus required to keep track of things such as repeat observers.","title":"Collaborations"},{"location":"software_design/patterns/observer/#consequences","text":"(+) Modularity- subject and observers can vary independently Subject only knows it has a list of Observers, doesn't know their concrete types (loosely coupled) (+) Extensibility- can define and add any number of different observers (+) Customizability- different observers offer different views of the subject (-) Unexpected updates- Observers don't know about each other (-) High update overhead (especially in large networks of observers) Can be reduced using hints or filtering","title":"Consequences"},{"location":"software_design/patterns/observer/#implementation","text":"Can filter the data an observer receives to decrease the update overhead Observers can register what data from the subject they are interested so not all the data needs to be sent to each observer An observer can be a subject that updates its own observers Can create large networks with high update overhead Can also create accidental update cycles (common in enterprise software) Need to handle dangling references left by observers that suddenly crash or get deleted Push vs. Pull models Pull model- subject sends message saying its data changed and observers can optionally request the updated data Allows observers to pull the data at varying rates Can implement both with pull model for certain observers and push for other observers","title":"Implementation"},{"location":"software_design/patterns/observer/#sample-code","text":"Below we define a simple abstract base class that has a method to be called when an event happens to the object being observed template <typename T> class Observer { public: virtual void handleEvent(const T &) = 0; }; Below we define a simple base class for any objects that we want to be subjects (observable) template <typename T> class Subject { public: /** * Default constructor */ Subject() = default; /** * Add an observer to this subject * @param ref New observer to notify of changes */ void add(Observer<T> &ref) { observers.insert(&ref); } /** * Remove an observer * @param ref Observer to stop notifying of changes */ void remove(Observer<T> &ref) { observers.erase(&ref); } protected: /** * Notify all observers of change * @param obj Object that has changed */ void Notify(T &obj) { for (auto observer : observers) observer->handleEvent(obj); } private: /** * Set of recorded observers */ std::set<Observer<T> *> observers; }; Here is the github repo with the example code from lecture.","title":"Sample Code"},{"location":"software_design/patterns/observer/#known-uses","text":"MVC Smart phone event frameworks Pub/sub middleware (ROS, DDS, JAva Message Service, etc.) Mailing lists","title":"Known Uses"},{"location":"software_design/patterns/patterns/","text":"Design Patterns Design patterns are simply object oriented software designs that often recurr as the solution to certain problems when designing large and complex software. The commonality in these recurring designs is distilled into patterns that codify these good practices for solving common problems. Each design pattern systematically names, explains, and evaluates an important and recurring design in object-oriented systems. Design patterns help us decide what should be an object and what its responsibilities should be. Goals Codify good object oriented design and implementation practices Distill and generalize experience to aid novices and experts alike Design structures with explicit names create a common vocab & reduce complexity Capture/preserve design and implementation knowledge Articulate key decisions succintctly Improve documentation Facilitate restructuring/refactoring Types Purpose - what a pattern does Creational - concern the process of object creation Structural - deal with the composition of classes/objects Behavioral - characterize the ways in which classes/objects interact and distribute responsibility Scope - specifies whether the pattern applies primarily to classes or objects Class patterns - focus on relationships between classes and their subclasses which are defined through inheritance so they are fixed at compile time Object patterns - deal with object relationships which can be changed at runtime and are more dynamic Creational class patterns defer some part of object creation to subclasses, while Creational object patterns defer it to another object. The Structural class patterns use inheritance to compose classes, while the Structural object patterns describe ways to assemble objects. The Behavioral class patterns use inheritance to describe algorithms and flow of control, whereas the Behavioral object patterns describe how a group of objects cooperate to perform a task that no single object can carry out alone. Organization Patterns often reference each other so a graph can be another useful way of organizing the different patterns: Design aspects that design patterns let you vary: OMT Object Model Notation Used in the diagrams Precursor to UML dashed arrowhead line: class instantiates an object of the class being pointed to triangle: inheritance abstract class- italicized names filled triangle indicates a virtual base class plain arrowhead line: class keeps a reference to the class being pointed at diamond on one end, arrow on the other: aggregation of the class being pointed at filled black circle- multiplicity empty circle- optional multiplicity","title":"Overview"},{"location":"software_design/patterns/patterns/#design-patterns","text":"Design patterns are simply object oriented software designs that often recurr as the solution to certain problems when designing large and complex software. The commonality in these recurring designs is distilled into patterns that codify these good practices for solving common problems. Each design pattern systematically names, explains, and evaluates an important and recurring design in object-oriented systems. Design patterns help us decide what should be an object and what its responsibilities should be.","title":"Design Patterns"},{"location":"software_design/patterns/patterns/#goals","text":"Codify good object oriented design and implementation practices Distill and generalize experience to aid novices and experts alike Design structures with explicit names create a common vocab & reduce complexity Capture/preserve design and implementation knowledge Articulate key decisions succintctly Improve documentation Facilitate restructuring/refactoring","title":"Goals"},{"location":"software_design/patterns/patterns/#types","text":"Purpose - what a pattern does Creational - concern the process of object creation Structural - deal with the composition of classes/objects Behavioral - characterize the ways in which classes/objects interact and distribute responsibility Scope - specifies whether the pattern applies primarily to classes or objects Class patterns - focus on relationships between classes and their subclasses which are defined through inheritance so they are fixed at compile time Object patterns - deal with object relationships which can be changed at runtime and are more dynamic Creational class patterns defer some part of object creation to subclasses, while Creational object patterns defer it to another object. The Structural class patterns use inheritance to compose classes, while the Structural object patterns describe ways to assemble objects. The Behavioral class patterns use inheritance to describe algorithms and flow of control, whereas the Behavioral object patterns describe how a group of objects cooperate to perform a task that no single object can carry out alone.","title":"Types"},{"location":"software_design/patterns/patterns/#organization","text":"Patterns often reference each other so a graph can be another useful way of organizing the different patterns: Design aspects that design patterns let you vary:","title":"Organization"},{"location":"software_design/patterns/patterns/#omt-object-model-notation","text":"Used in the diagrams Precursor to UML dashed arrowhead line: class instantiates an object of the class being pointed to triangle: inheritance abstract class- italicized names filled triangle indicates a virtual base class plain arrowhead line: class keeps a reference to the class being pointed at diamond on one end, arrow on the other: aggregation of the class being pointed at filled black circle- multiplicity empty circle- optional multiplicity","title":"OMT Object Model Notation"},{"location":"software_design/patterns/reactor/","text":"Reactor Pattern any aliases this pattern is known by Intent Allows event-driving applications to demultiplex and dispatch service requests that are delivered to an application from one or more clients. Applicability When you need to decouple event handling from event detecting/demuxing/dispatching When multiple sources of events must be handled in a single thread Structure Consequences (+) Separation of concerns and portability (+) Simplify concurrency control (-) Non-preemptive Implementation Decouple event demultiplexing mechanisms from event dispatching? Handle many idfferent types of events (e.g. input/output events, signals, timers, etc.)","title":"Reactor"},{"location":"software_design/patterns/reactor/#reactor-pattern","text":"any aliases this pattern is known by","title":"Reactor Pattern"},{"location":"software_design/patterns/reactor/#intent","text":"Allows event-driving applications to demultiplex and dispatch service requests that are delivered to an application from one or more clients.","title":"Intent"},{"location":"software_design/patterns/reactor/#applicability","text":"When you need to decouple event handling from event detecting/demuxing/dispatching When multiple sources of events must be handled in a single thread","title":"Applicability"},{"location":"software_design/patterns/reactor/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/reactor/#consequences","text":"(+) Separation of concerns and portability (+) Simplify concurrency control (-) Non-preemptive","title":"Consequences"},{"location":"software_design/patterns/reactor/#implementation","text":"Decouple event demultiplexing mechanisms from event dispatching? Handle many idfferent types of events (e.g. input/output events, signals, timers, etc.)","title":"Implementation"},{"location":"software_design/patterns/singleton/","text":"Singleton Pattern Intent Ensure a class only ever has one instance and provide a global point of access Applicability When there must be exactly one instance of a class and it must be accessible from a well-known access point When the sole instance should be extensible by subclassing, and clients should be able to use an extended instance without modifying their code Structure Participants Singleton - defines an Instance operation (static member function) that lets clients access its unique instance Collaborations Clients access a singleton instance soley though the singleton's Instance operation Consequences (+) Reduces namespace pollution (+) easy to change and allow multiple instances (+) allow extension by subclassing (-) Same drawbacks of a global if misused (-) Implementation may be less efficient than a global variable (-) Concurrency pitfalls and communication overhead Implementation Static instance operation Registering the singleton instance runtime though instead of compiletime Deleting singletons Not automatically destroyed by anything Usually use a shared pointer instead of raw pointer to deal with this Lifecycle is not as well defined as simple variables Sample Code class Singleton { public: static Singleton& getInstance() { if (inst == nullptr) inst = new Singleton(); return *inst; } Singleton(Singleton const&) = delete; void operator=(Singleton const&) = delete; private: static Singleton* inst; Singleton() {} }; // must provide initial value for static variable outside of class Singleton* Singleton::inst = nullptr; Then a singleton would be created like: int main() { Singleton& one = Singleton::getInstance(); Singleton& two = Singleton::getInstance(); return 0; } Known Uses Hardware interface access Logger: so everything is logged to same place in correct order using access protections Related Patterns Many patterns such as the Abstract Factory, Builder, and Prototype pattern can be implemented using the Singleton","title":"Singleton"},{"location":"software_design/patterns/singleton/#singleton-pattern","text":"","title":"Singleton Pattern"},{"location":"software_design/patterns/singleton/#intent","text":"Ensure a class only ever has one instance and provide a global point of access","title":"Intent"},{"location":"software_design/patterns/singleton/#applicability","text":"When there must be exactly one instance of a class and it must be accessible from a well-known access point When the sole instance should be extensible by subclassing, and clients should be able to use an extended instance without modifying their code","title":"Applicability"},{"location":"software_design/patterns/singleton/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/singleton/#participants","text":"Singleton - defines an Instance operation (static member function) that lets clients access its unique instance","title":"Participants"},{"location":"software_design/patterns/singleton/#collaborations","text":"Clients access a singleton instance soley though the singleton's Instance operation","title":"Collaborations"},{"location":"software_design/patterns/singleton/#consequences","text":"(+) Reduces namespace pollution (+) easy to change and allow multiple instances (+) allow extension by subclassing (-) Same drawbacks of a global if misused (-) Implementation may be less efficient than a global variable (-) Concurrency pitfalls and communication overhead","title":"Consequences"},{"location":"software_design/patterns/singleton/#implementation","text":"Static instance operation Registering the singleton instance runtime though instead of compiletime Deleting singletons Not automatically destroyed by anything Usually use a shared pointer instead of raw pointer to deal with this Lifecycle is not as well defined as simple variables","title":"Implementation"},{"location":"software_design/patterns/singleton/#sample-code","text":"class Singleton { public: static Singleton& getInstance() { if (inst == nullptr) inst = new Singleton(); return *inst; } Singleton(Singleton const&) = delete; void operator=(Singleton const&) = delete; private: static Singleton* inst; Singleton() {} }; // must provide initial value for static variable outside of class Singleton* Singleton::inst = nullptr; Then a singleton would be created like: int main() { Singleton& one = Singleton::getInstance(); Singleton& two = Singleton::getInstance(); return 0; }","title":"Sample Code"},{"location":"software_design/patterns/singleton/#known-uses","text":"Hardware interface access Logger: so everything is logged to same place in correct order using access protections","title":"Known Uses"},{"location":"software_design/patterns/singleton/#related-patterns","text":"Many patterns such as the Abstract Factory, Builder, and Prototype pattern can be implemented using the Singleton","title":"Related Patterns"},{"location":"software_design/patterns/state/","text":"State Pattern Intent Allow an object to alter its behavior when its internal state changes. The object will appear to change its class. Applicability When an object's behavior depends on its state, and it must change its behavior at runtime depending on that state When several operatio onal structure that depends on the object's state When its beneficial to treat the object's state as an object that can vary independently of everything else Structure Participants Context (ex: TCPConnection) defines the interface of interest to clients maintains an instance of a ConcreteState subclass that defines the current state State (ex: TCPState) defines an interface the behavior associated with a particular state of the Context ConcreteState subclasses (ex: TCPEstablished, TCPListen, TCPClosed) each subclass implments a behavior associated with a state of the context Collaborations Context delegates state-specific request to the curent ConcreteState object A context may pass itsself as an argument to the State object handling the request so that the State object can access the context if necessary Context is the primary interface for clients so they don't have to deal with State objects directly Either Context or the ConcreteState subclasses can decide which state succeeds another and under what circumstances Consequences (+) Localizes state-specific behavior and partitions behavior for different states (+) Makes state transitions explicit (also protects context from incosistent states) (+) State objects can be shared if they have no instance variables (-) Can result in many subclasses that are hard to understand Implementation Who defines the state transitions? Context or the ConcreteState subclasses Consider using table-based alternatives Creating and destroying state objects: do you create and destroy them as needed or create them ahead of time and never destroy 1st option preferable when contexts change state frequently and it is unknown what states will be entered 2nd option preferable when state changes occur rapidly and want to avoid overhead of repeated creation/deletion Related Patterns The flyweight patterns explains when and how State objects can be shared State objects are often singletons Finite State Machine A state is a distinguishable, disjoint (one state at a time), condition that persists for a significant period of time (FSMs spend all their time in states) A transition is the changing from one state to another represent responses to events (from external or internal sources) A finite state machine is a model of computation with state behavior defined by a set of states and set of transitions Useful for mathematically proving safety in critical systems Ex: add states that are unsafe and prove they can't be reached","title":"State"},{"location":"software_design/patterns/state/#state-pattern","text":"","title":"State Pattern"},{"location":"software_design/patterns/state/#intent","text":"Allow an object to alter its behavior when its internal state changes. The object will appear to change its class.","title":"Intent"},{"location":"software_design/patterns/state/#applicability","text":"When an object's behavior depends on its state, and it must change its behavior at runtime depending on that state When several operatio onal structure that depends on the object's state When its beneficial to treat the object's state as an object that can vary independently of everything else","title":"Applicability"},{"location":"software_design/patterns/state/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/state/#participants","text":"Context (ex: TCPConnection) defines the interface of interest to clients maintains an instance of a ConcreteState subclass that defines the current state State (ex: TCPState) defines an interface the behavior associated with a particular state of the Context ConcreteState subclasses (ex: TCPEstablished, TCPListen, TCPClosed) each subclass implments a behavior associated with a state of the context","title":"Participants"},{"location":"software_design/patterns/state/#collaborations","text":"Context delegates state-specific request to the curent ConcreteState object A context may pass itsself as an argument to the State object handling the request so that the State object can access the context if necessary Context is the primary interface for clients so they don't have to deal with State objects directly Either Context or the ConcreteState subclasses can decide which state succeeds another and under what circumstances","title":"Collaborations"},{"location":"software_design/patterns/state/#consequences","text":"(+) Localizes state-specific behavior and partitions behavior for different states (+) Makes state transitions explicit (also protects context from incosistent states) (+) State objects can be shared if they have no instance variables (-) Can result in many subclasses that are hard to understand","title":"Consequences"},{"location":"software_design/patterns/state/#implementation","text":"Who defines the state transitions? Context or the ConcreteState subclasses Consider using table-based alternatives Creating and destroying state objects: do you create and destroy them as needed or create them ahead of time and never destroy 1st option preferable when contexts change state frequently and it is unknown what states will be entered 2nd option preferable when state changes occur rapidly and want to avoid overhead of repeated creation/deletion","title":"Implementation"},{"location":"software_design/patterns/state/#related-patterns","text":"The flyweight patterns explains when and how State objects can be shared State objects are often singletons","title":"Related Patterns"},{"location":"software_design/patterns/state/#finite-state-machine","text":"A state is a distinguishable, disjoint (one state at a time), condition that persists for a significant period of time (FSMs spend all their time in states) A transition is the changing from one state to another represent responses to events (from external or internal sources) A finite state machine is a model of computation with state behavior defined by a set of states and set of transitions Useful for mathematically proving safety in critical systems Ex: add states that are unsafe and prove they can't be reached","title":"Finite State Machine"},{"location":"software_design/patterns/strategy/","text":"Strategy Pattern Also known as Policy pattern Intent Define a family of algorithms, encapsulate each one, and make them interchangeable. Lets the algorithm vary independenty from the clients that use it Applicability When many related classes differ only in their behavior Strategy pattern lets us configure a class with one of many behaviors When you need different variants of an algorithm When an algorithm uses data structures that should not be exposed to clients Structure Participants Strategy - declares an interface common to all supported algorithms Context uses this interface to call the algorithm defined by a ConcreteStrategy ConcreteStrategy - implements a variant of the algortihm using the Strategy interface Context - configured with a ConcreteStrategy object and matinains a reference to a Strategy object Might define an interface that lets Strategy access its data Collaborations Strategy and Content interact to implement the chosen algorithm Context may pass all data required by the algorithm to the strategy when the algorithm is called Alternatively, context can pass itself as an argument to the strategy allowing the strategy to call it as required Context forwards requests from its clients to its strategy Clients usually create and pass a ConcreteStrategy object to the context and then only interact with the context from there on out Consequences (+) Families of related algorithms An altertive (+) Eliminate conditional statements for selecting the desired behavior Encapsulating different behaviors in seperate strategy classes eliminates conditional statements (+) Can provide different implementations (size/speed tradeoffs) of the same behavior (-) Clients must be aware of different strategies (-) Communication overhead between strategy and context Implementation How will the strategy have access to data it needs in the context? Can use templates to configure a class with a strategy if it can be selected at compile-time and doesn't need to be changed at runtime","title":"Strategy"},{"location":"software_design/patterns/strategy/#strategy-pattern","text":"Also known as Policy pattern","title":"Strategy Pattern"},{"location":"software_design/patterns/strategy/#intent","text":"Define a family of algorithms, encapsulate each one, and make them interchangeable. Lets the algorithm vary independenty from the clients that use it","title":"Intent"},{"location":"software_design/patterns/strategy/#applicability","text":"When many related classes differ only in their behavior Strategy pattern lets us configure a class with one of many behaviors When you need different variants of an algorithm When an algorithm uses data structures that should not be exposed to clients","title":"Applicability"},{"location":"software_design/patterns/strategy/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/strategy/#participants","text":"Strategy - declares an interface common to all supported algorithms Context uses this interface to call the algorithm defined by a ConcreteStrategy ConcreteStrategy - implements a variant of the algortihm using the Strategy interface Context - configured with a ConcreteStrategy object and matinains a reference to a Strategy object Might define an interface that lets Strategy access its data","title":"Participants"},{"location":"software_design/patterns/strategy/#collaborations","text":"Strategy and Content interact to implement the chosen algorithm Context may pass all data required by the algorithm to the strategy when the algorithm is called Alternatively, context can pass itself as an argument to the strategy allowing the strategy to call it as required Context forwards requests from its clients to its strategy Clients usually create and pass a ConcreteStrategy object to the context and then only interact with the context from there on out","title":"Collaborations"},{"location":"software_design/patterns/strategy/#consequences","text":"(+) Families of related algorithms An altertive (+) Eliminate conditional statements for selecting the desired behavior Encapsulating different behaviors in seperate strategy classes eliminates conditional statements (+) Can provide different implementations (size/speed tradeoffs) of the same behavior (-) Clients must be aware of different strategies (-) Communication overhead between strategy and context","title":"Consequences"},{"location":"software_design/patterns/strategy/#implementation","text":"How will the strategy have access to data it needs in the context? Can use templates to configure a class with a strategy if it can be selected at compile-time and doesn't need to be changed at runtime","title":"Implementation"},{"location":"software_design/patterns/temp/","text":"Pattern any aliases this pattern is known by Intent short description of the pattern and its purpose Applicability circumstances in which pattern applies Structure graphical representation of pattern using modified UML notation Participants participatnig classes/objects and their responsibilities Collaborations How participants cooperate to carry out their responsibilities Consequences results of application, benefits, and liabilities Implementation pitfalls, hints, techiques, plus language dependent issues Sample Code Known Uses Related Patterns","title":"Pattern"},{"location":"software_design/patterns/temp/#pattern","text":"any aliases this pattern is known by","title":"Pattern"},{"location":"software_design/patterns/temp/#intent","text":"short description of the pattern and its purpose","title":"Intent"},{"location":"software_design/patterns/temp/#applicability","text":"circumstances in which pattern applies","title":"Applicability"},{"location":"software_design/patterns/temp/#structure","text":"graphical representation of pattern using modified UML notation","title":"Structure"},{"location":"software_design/patterns/temp/#participants","text":"participatnig classes/objects and their responsibilities","title":"Participants"},{"location":"software_design/patterns/temp/#collaborations","text":"How participants cooperate to carry out their responsibilities","title":"Collaborations"},{"location":"software_design/patterns/temp/#consequences","text":"results of application, benefits, and liabilities","title":"Consequences"},{"location":"software_design/patterns/temp/#implementation","text":"pitfalls, hints, techiques, plus language dependent issues","title":"Implementation"},{"location":"software_design/patterns/temp/#sample-code","text":"","title":"Sample Code"},{"location":"software_design/patterns/temp/#known-uses","text":"","title":"Known Uses"},{"location":"software_design/patterns/temp/#related-patterns","text":"","title":"Related Patterns"},{"location":"software_design/patterns/template/","text":"Template Pattern Intent Define a skeleton of an algorithm in an operation, deferring some steps to subclasses. Subclasses redefine certain steps of an algorithm without changing the algorithm's structure. Applicability Used to implement the invariant parts of an algorithm once and then leave it to the subclasses to implement the behavior that can vary When common behavior among subclasses should be factored and localizied in a common class to avoid code duplication Structure Participants AbstractClass - defines abstract primitive operations that concrete subclasses define to implement steps of an algorithm Implements a template method defining the skelton of an algorithm by calling primitive operations as well as other necessary methods ConcreteClass - implements the primitive operations to carry out subclass-specific steps of the algorithm Collaborations ConcreteClass relies on AbstractClass to implement the invariant steps of the algorithm Consequences (+) Inverted control principle- parent calls the operations of a subclass (not the other way) Implementation Goal is to minimize the number of primitive operations a subclass must override to flesh out the algorithm Related Patterns Factory Methods are often called by template methods Template methods use inheritance to vary part of an algorithm while strategies use delegation to vary the entire algorithm","title":"Template"},{"location":"software_design/patterns/template/#template-pattern","text":"","title":"Template Pattern"},{"location":"software_design/patterns/template/#intent","text":"Define a skeleton of an algorithm in an operation, deferring some steps to subclasses. Subclasses redefine certain steps of an algorithm without changing the algorithm's structure.","title":"Intent"},{"location":"software_design/patterns/template/#applicability","text":"Used to implement the invariant parts of an algorithm once and then leave it to the subclasses to implement the behavior that can vary When common behavior among subclasses should be factored and localizied in a common class to avoid code duplication","title":"Applicability"},{"location":"software_design/patterns/template/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/template/#participants","text":"AbstractClass - defines abstract primitive operations that concrete subclasses define to implement steps of an algorithm Implements a template method defining the skelton of an algorithm by calling primitive operations as well as other necessary methods ConcreteClass - implements the primitive operations to carry out subclass-specific steps of the algorithm","title":"Participants"},{"location":"software_design/patterns/template/#collaborations","text":"ConcreteClass relies on AbstractClass to implement the invariant steps of the algorithm","title":"Collaborations"},{"location":"software_design/patterns/template/#consequences","text":"(+) Inverted control principle- parent calls the operations of a subclass (not the other way)","title":"Consequences"},{"location":"software_design/patterns/template/#implementation","text":"Goal is to minimize the number of primitive operations a subclass must override to flesh out the algorithm","title":"Implementation"},{"location":"software_design/patterns/template/#related-patterns","text":"Factory Methods are often called by template methods Template methods use inheritance to vary part of an algorithm while strategies use delegation to vary the entire algorithm","title":"Related Patterns"},{"location":"software_design/patterns/visitor/","text":"Visitor Pattern Intent Centralize operations on an object structure so that they can vary independently but still behave polymorphically. Lets you define a new operation without changing the classes of the elements on which it operates. Applicability when classes define many unrelated operations when relationships of objects in the structure rarely change, but the operations on them change often algorithms keep state that is updated during traversal Structure Participants Visitor - declares a Visit operation for each class of the ConcreteElement in the object structure ConcreteVisitor - implements each operation declared by Visitor and stores local state of the algorithm that is acculumated during the traversal of the object Element - defines an accept operation that takes a visitor as an argument (e.g. Node) ConcreteElement - implements an accept operation that takes a visitor as an argument (e.g. AddNode, SubtractNode, .. ) ObjectStructure- can enumerate its elements Collaborations Client that uses a visitor pattern must create a ConcreteVisitor object and then traverse the object structure, visiting each element with the visitor When an element is visited, it calls the visitor operation that corresponds to its class by supplying itself as an argument. to the operation Consequences (+) Flexibility: visitor algorithm(s) and object structure are independent Easy to add new operations (+) Localized functionality in the visitor subclass instance (related behaviors are grouped together in a visitor and unrelated behaviors have a seperate visitor) (-) Circular dependency between Visitor and Element interfaces (-) Visitor brittle to new ConcreteElement classes Implementation Double dispatch- operations that is executed depends on the kind of request and the types of two receivers (the Visitor's and the Element's) visitor pattern lets you add operations to classes without changing them by using this General interface to elements of object structure Who is responsbile for traversing the object structure? Related Patterns Visitors can be used to apply an operation over an object structure defined by a composite Visitor can be applied to do the interpretation in the Interpreter pattern","title":"Visitor"},{"location":"software_design/patterns/visitor/#visitor-pattern","text":"","title":"Visitor Pattern"},{"location":"software_design/patterns/visitor/#intent","text":"Centralize operations on an object structure so that they can vary independently but still behave polymorphically. Lets you define a new operation without changing the classes of the elements on which it operates.","title":"Intent"},{"location":"software_design/patterns/visitor/#applicability","text":"when classes define many unrelated operations when relationships of objects in the structure rarely change, but the operations on them change often algorithms keep state that is updated during traversal","title":"Applicability"},{"location":"software_design/patterns/visitor/#structure","text":"","title":"Structure"},{"location":"software_design/patterns/visitor/#participants","text":"Visitor - declares a Visit operation for each class of the ConcreteElement in the object structure ConcreteVisitor - implements each operation declared by Visitor and stores local state of the algorithm that is acculumated during the traversal of the object Element - defines an accept operation that takes a visitor as an argument (e.g. Node) ConcreteElement - implements an accept operation that takes a visitor as an argument (e.g. AddNode, SubtractNode, .. ) ObjectStructure- can enumerate its elements","title":"Participants"},{"location":"software_design/patterns/visitor/#collaborations","text":"Client that uses a visitor pattern must create a ConcreteVisitor object and then traverse the object structure, visiting each element with the visitor When an element is visited, it calls the visitor operation that corresponds to its class by supplying itself as an argument. to the operation","title":"Collaborations"},{"location":"software_design/patterns/visitor/#consequences","text":"(+) Flexibility: visitor algorithm(s) and object structure are independent Easy to add new operations (+) Localized functionality in the visitor subclass instance (related behaviors are grouped together in a visitor and unrelated behaviors have a seperate visitor) (-) Circular dependency between Visitor and Element interfaces (-) Visitor brittle to new ConcreteElement classes","title":"Consequences"},{"location":"software_design/patterns/visitor/#implementation","text":"Double dispatch- operations that is executed depends on the kind of request and the types of two receivers (the Visitor's and the Element's) visitor pattern lets you add operations to classes without changing them by using this General interface to elements of object structure Who is responsbile for traversing the object structure?","title":"Implementation"},{"location":"software_design/patterns/visitor/#related-patterns","text":"Visitors can be used to apply an operation over an object structure defined by a composite Visitor can be applied to do the interpretation in the Interpreter pattern","title":"Related Patterns"},{"location":"swe/docker/","text":"Docker Tool for running applications in an isolated environment Advantages : Same environment (Works on all computers if it works on docker) Sandbox Projects (Keeps them separate: no conflicts & better security) Simple to get started on others' projects Containers : the building blocks of Docker Stop by themselves when the main process finishes/exits (e.g. php or node.js dies) Should be one process per container b/c the life of the container is tied to that process Lightweight so lots of containers can be run on a computer at a time Docker vs. Virutal Machines Docker is less resource heavy than a virtual machine so it is faster than a VM Docker Images A Dockerfile is a file with a list of steps to create the image A Docker Image is a template for creating a desired environment and includes an OS, software, and application code A Docker Container is a running instance of a docker image Setting up a Docker Project Create Dockerfile in the root of the project/services directory (outside src folder) Where we will start from an existing image and build on top of it Can find thousands of images on Dockerhub Write the instructions to build your image in the Dockerfile FROM specifies the starting/base image to be downloaded from Dockerhub (Must be the 1st line) COPY copies the files from the first directory to the second location inside the image (specified in image's documentation) EXPOSE tells running containers to listen on the specified port FROM php:7-0-apache COPY src/ /var/www/html EXPOSE 80 Build the docker image from the terminal -t image-name specifies the image's name location is the path to the Dockerfile which is . if in the same directory docker build -t image-name location Run the docker container from the terminal -p 80:80 forwards port 80 in the host to port 80 in the container which was exposed in the docker file, allowing it to accept the request so that the code in the container can handle the request docker run -p 80:80 image-name Volumes One type allows the sharing of data between containers The other type allows the sharing of folders between the host and the container Useful for development since any changes to source code doesn't require a new image to be built and new container to be spun up Will need to rebuild the image to deploy it to somewhere else b/c volumes just give the ability for a container to see files on the host's filesystem, volumes don't change the image Building an image from a Dockerfile copies the src code so that it can be deployed elsewhere Mounting a volume is done when running the container Must use absolute paths of folders to be mounted docker run -p80:80 -v /Users/admin/project/src/:/var/www/html/ image-name Extra: FROM python:3-onbuild COPY . /usr/src/app CMD [\"python\",\"api.py\"] Docker Compose Lets you define all you services/containers in a configuration file With one command, all the containers can be spun up The configuration files save the hassel of writing the docker run commands for each container with all their specifications for volumes and ports Creates a virtual network for all the containers allowing communication for all the containers specified in the docker-compose file The host names of the containers match the service names defined in docker-compose.yml Setting up a Project w/ Docker Compose Create docker-compose.yml in root directory of project Write the configuration instructions in docker-compose.yml Directories are relative to where the docker-compose file is version specifies the version of docker-compose file format that you will be writing in (the formats are often updated so this helps specify what syntax you will be using) build takes ther relative path to the Dockerfile for a container volumes & ports allows you to list the volumes and ports for that docker image depends_on allows you to specify other services necessary for the service to run version: '3' services: product-service: build: ./product volumes: - ./product:/usr/src/app ports: - 5001:80 website: image: php:apache volumes: - ./website:/var/www/html ports: - 5000:80 depends_on: - product-service Spin up the containers running docker-compose up from the terminal from the directory where the docker-compose file is located Will build all the images and then run all the containers Running docker-compose up -d will spin up the containers in detached mode meaning you can continue working on the terminal run docker ps to see the status of the containers in detached mode run docker-compose stop to stop the containers in detached mode (ctr + c works in nondetached mode)","title":"Docker"},{"location":"swe/docker/#docker","text":"Tool for running applications in an isolated environment Advantages : Same environment (Works on all computers if it works on docker) Sandbox Projects (Keeps them separate: no conflicts & better security) Simple to get started on others' projects Containers : the building blocks of Docker Stop by themselves when the main process finishes/exits (e.g. php or node.js dies) Should be one process per container b/c the life of the container is tied to that process Lightweight so lots of containers can be run on a computer at a time","title":"Docker"},{"location":"swe/docker/#docker-vs-virutal-machines","text":"Docker is less resource heavy than a virtual machine so it is faster than a VM","title":"Docker vs. Virutal Machines"},{"location":"swe/docker/#docker-images","text":"A Dockerfile is a file with a list of steps to create the image A Docker Image is a template for creating a desired environment and includes an OS, software, and application code A Docker Container is a running instance of a docker image","title":"Docker Images"},{"location":"swe/docker/#setting-up-a-docker-project","text":"Create Dockerfile in the root of the project/services directory (outside src folder) Where we will start from an existing image and build on top of it Can find thousands of images on Dockerhub Write the instructions to build your image in the Dockerfile FROM specifies the starting/base image to be downloaded from Dockerhub (Must be the 1st line) COPY copies the files from the first directory to the second location inside the image (specified in image's documentation) EXPOSE tells running containers to listen on the specified port FROM php:7-0-apache COPY src/ /var/www/html EXPOSE 80 Build the docker image from the terminal -t image-name specifies the image's name location is the path to the Dockerfile which is . if in the same directory docker build -t image-name location Run the docker container from the terminal -p 80:80 forwards port 80 in the host to port 80 in the container which was exposed in the docker file, allowing it to accept the request so that the code in the container can handle the request docker run -p 80:80 image-name","title":"Setting up a Docker Project"},{"location":"swe/docker/#volumes","text":"One type allows the sharing of data between containers The other type allows the sharing of folders between the host and the container Useful for development since any changes to source code doesn't require a new image to be built and new container to be spun up Will need to rebuild the image to deploy it to somewhere else b/c volumes just give the ability for a container to see files on the host's filesystem, volumes don't change the image Building an image from a Dockerfile copies the src code so that it can be deployed elsewhere Mounting a volume is done when running the container Must use absolute paths of folders to be mounted docker run -p80:80 -v /Users/admin/project/src/:/var/www/html/ image-name","title":"Volumes"},{"location":"swe/docker/#extra","text":"FROM python:3-onbuild COPY . /usr/src/app CMD [\"python\",\"api.py\"]","title":"Extra:"},{"location":"swe/docker/#docker-compose","text":"Lets you define all you services/containers in a configuration file With one command, all the containers can be spun up The configuration files save the hassel of writing the docker run commands for each container with all their specifications for volumes and ports Creates a virtual network for all the containers allowing communication for all the containers specified in the docker-compose file The host names of the containers match the service names defined in docker-compose.yml","title":"Docker Compose"},{"location":"swe/docker/#setting-up-a-project-w-docker-compose","text":"Create docker-compose.yml in root directory of project Write the configuration instructions in docker-compose.yml Directories are relative to where the docker-compose file is version specifies the version of docker-compose file format that you will be writing in (the formats are often updated so this helps specify what syntax you will be using) build takes ther relative path to the Dockerfile for a container volumes & ports allows you to list the volumes and ports for that docker image depends_on allows you to specify other services necessary for the service to run version: '3' services: product-service: build: ./product volumes: - ./product:/usr/src/app ports: - 5001:80 website: image: php:apache volumes: - ./website:/var/www/html ports: - 5000:80 depends_on: - product-service Spin up the containers running docker-compose up from the terminal from the directory where the docker-compose file is located Will build all the images and then run all the containers Running docker-compose up -d will spin up the containers in detached mode meaning you can continue working on the terminal run docker ps to see the status of the containers in detached mode run docker-compose stop to stop the containers in detached mode (ctr + c works in nondetached mode)","title":"Setting up a Project w/ Docker Compose"},{"location":"swe/git/","text":"git reference undoing things git commit --ammend will add any staged changes to previous commit (technically 2nd commit replaces the previous one) only ammend local commits git restore replaces git reset . Unstaging changes: git reset HEAD <file-name> git restore --staged <file-name> Unmodifying an unstaged modified file: git restore <file> source diff unadded changes: git diff <file/folder-name> added changes: git diff --cached <file/folder-name> also works with --staged changes from commit 1 to commit 2: git diff <commit-1-hash> <commit-2-hash> --stats list changed files + insertions/deletions --name-only lists name of changed files --name-status list status of added/deleted/modified/renamed files changes from previous commit to current commit: git diff HEAD^ ( HEAD^ is previous commit) generate output to .diff file: git diff -output=patch.diff git diff > patch.diff git diff > changes.patch apply a diff/patch: git apply changes.patch (only performs the changes-- they still need to be added/commited) changes from one branch to another: git diff main <file-name> (comparing cur branch to main) adding ~ after branch name will use the previous commit (multiple ~ goes multiple commits back) pull vs fetch git fetch will bring down any changes from remote repo but won't change any of your local branchs Only updates .git/ directory with an updated version of the remote repo To integrate the fetched commits, need to run git merge git pull essentially does a fetch followed by a merge into the current branch git fetch is the command that says \"bring my local copy of the remote repository up to date.\" git pull says \"bring the changes in the remote repository to where I keep my own code.\" switch new version of checkout git switch <branch-name> use - as branch name to go back to original branch before from before switching create and switch to new branch: git switch -c <new-branch> switch to a remote branch (after fetching): git switch -c <branch> --track <remote>/<branch> branching add branch create local branch (doesn't checkout): git branch <new-branch> create and automatically checkout a new local-branch: git checkout -b <new-branch> add local branch to remote repo: git push --set-upstream origin <local-branch> -u is shorthand for upstream delete branch Local: git branch -d <local-branch> -d refuse to delete unmerged/unpushed changes -D force delete Remote: git push origin --delete <remote-branch-name> stash changes Stashing can be used to temporaliy store modified, tracked files in order to change branches git stash saves the modified and staged changes git stash list lists the stack of stashed file changes git stash pop writes working from the top of the stash stack git stash drop discards the changes from the top of the stash stack config preferences: Stored globally in ~/.gitconfig git config to update config settings --global for global config updates --local for project specific updates diff.noprefix true removes a/ and b/ prefixes in diff results credential.helper store and then type in your username and PAT the next time you login Will save and use your login credentials for any future remote requests can create git aliases git alias : [alias] unstaged = diff staged = diff --cached both = diff HEAD help.autocorrect <tenths-of-seconds> will auto run a mistyped command after specified tenths of a second More Config Settings how git works how git works from the bottom up - index = staging area = cache (all refer to same thing) - difference between git restore and git reset commit hashes Git generates a unique SHA-1 hash (40 char string of hex digits) for every commit and refers to commits by this ID (usually only displays first 7 digits) SHA-1 has been compromised (can spoof hashes) so they are moving to SHA-256 Making changes to previous commits in .git can be detected b/c each commit's hash is based on the previous commit's hash so the change to a previous commit would be easily detected Simple blockchain of basing commit hashes on previous commits and verifying chains of hashes","title":"Git"},{"location":"swe/git/#git-reference","text":"","title":"git reference"},{"location":"swe/git/#undoing-things","text":"git commit --ammend will add any staged changes to previous commit (technically 2nd commit replaces the previous one) only ammend local commits git restore replaces git reset . Unstaging changes: git reset HEAD <file-name> git restore --staged <file-name> Unmodifying an unstaged modified file: git restore <file> source","title":"undoing things"},{"location":"swe/git/#diff","text":"unadded changes: git diff <file/folder-name> added changes: git diff --cached <file/folder-name> also works with --staged changes from commit 1 to commit 2: git diff <commit-1-hash> <commit-2-hash> --stats list changed files + insertions/deletions --name-only lists name of changed files --name-status list status of added/deleted/modified/renamed files changes from previous commit to current commit: git diff HEAD^ ( HEAD^ is previous commit) generate output to .diff file: git diff -output=patch.diff git diff > patch.diff git diff > changes.patch apply a diff/patch: git apply changes.patch (only performs the changes-- they still need to be added/commited) changes from one branch to another: git diff main <file-name> (comparing cur branch to main) adding ~ after branch name will use the previous commit (multiple ~ goes multiple commits back)","title":"diff"},{"location":"swe/git/#pull-vs-fetch","text":"git fetch will bring down any changes from remote repo but won't change any of your local branchs Only updates .git/ directory with an updated version of the remote repo To integrate the fetched commits, need to run git merge git pull essentially does a fetch followed by a merge into the current branch git fetch is the command that says \"bring my local copy of the remote repository up to date.\" git pull says \"bring the changes in the remote repository to where I keep my own code.\"","title":"pull vs fetch"},{"location":"swe/git/#switch","text":"new version of checkout git switch <branch-name> use - as branch name to go back to original branch before from before switching create and switch to new branch: git switch -c <new-branch> switch to a remote branch (after fetching): git switch -c <branch> --track <remote>/<branch>","title":"switch"},{"location":"swe/git/#branching","text":"","title":"branching"},{"location":"swe/git/#add-branch","text":"create local branch (doesn't checkout): git branch <new-branch> create and automatically checkout a new local-branch: git checkout -b <new-branch> add local branch to remote repo: git push --set-upstream origin <local-branch> -u is shorthand for upstream","title":"add branch"},{"location":"swe/git/#delete-branch","text":"Local: git branch -d <local-branch> -d refuse to delete unmerged/unpushed changes -D force delete Remote: git push origin --delete <remote-branch-name>","title":"delete branch"},{"location":"swe/git/#stash-changes","text":"Stashing can be used to temporaliy store modified, tracked files in order to change branches git stash saves the modified and staged changes git stash list lists the stack of stashed file changes git stash pop writes working from the top of the stash stack git stash drop discards the changes from the top of the stash stack","title":"stash changes"},{"location":"swe/git/#config-preferences","text":"Stored globally in ~/.gitconfig git config to update config settings --global for global config updates --local for project specific updates diff.noprefix true removes a/ and b/ prefixes in diff results credential.helper store and then type in your username and PAT the next time you login Will save and use your login credentials for any future remote requests can create git aliases git alias : [alias] unstaged = diff staged = diff --cached both = diff HEAD help.autocorrect <tenths-of-seconds> will auto run a mistyped command after specified tenths of a second More Config Settings","title":"config preferences:"},{"location":"swe/git/#how-git-works","text":"how git works from the bottom up - index = staging area = cache (all refer to same thing) - difference between git restore and git reset","title":"how git works"},{"location":"swe/git/#commit-hashes","text":"Git generates a unique SHA-1 hash (40 char string of hex digits) for every commit and refers to commits by this ID (usually only displays first 7 digits) SHA-1 has been compromised (can spoof hashes) so they are moving to SHA-256 Making changes to previous commits in .git can be detected b/c each commit's hash is based on the previous commit's hash so the change to a previous commit would be easily detected Simple blockchain of basing commit hashes on previous commits and verifying chains of hashes","title":"commit hashes"},{"location":"swe/microservices/","text":"Microservice Architectual Style: Developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanics, often an HTTP resource API Encourages modularity and seperation of concerns ability to horizontally scale and partition the workload Microservices contain many aspects in reality: Clients, Caches, and Databases are all included in a microservice in conjuction with the service itself Stateless Service: Not a cache or database Frequently accessed metadata no instance affinity Losing a node is not a big deal and can be easily fixed Stateful Service: Databases & caches Custom apps which holds lots of data Losing a node is a notable event and it might take hours to get it fixed","title":"Microservices"},{"location":"swe/microservices/#microservice-architectual-style","text":"Developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanics, often an HTTP resource API Encourages modularity and seperation of concerns ability to horizontally scale and partition the workload Microservices contain many aspects in reality: Clients, Caches, and Databases are all included in a microservice in conjuction with the service itself","title":"Microservice Architectual Style:"},{"location":"swe/microservices/#stateless-service","text":"Not a cache or database Frequently accessed metadata no instance affinity Losing a node is not a big deal and can be easily fixed","title":"Stateless Service:"},{"location":"swe/microservices/#stateful-service","text":"Databases & caches Custom apps which holds lots of data Losing a node is a notable event and it might take hours to get it fixed","title":"Stateful Service:"},{"location":"swe/regex/","text":"Regular expressions operate by moving character by character, from left to right, through a piece of text. When the regular expression finds a character that matches the first piece of the expression, it looks to find a continuous sequence of matching characters. Alternation is performed in regular expressions with the pipe symbol, | , allowing us to match either the characters preceding the | OR the characters after the | . Grouping , denoted with the open parenthesis ( and the closing parenthesis ) , lets us group parts of a regular expression together, and allows us to limit alternation to part of the regex. Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters, allowing for matches with incorrect or different spellings. Negated Character Sets : at the front of a character set, the ^ negates the set, matching any character that is not stated. Thus the regex [^cat] will match any character that is not c , a , or t , and would completely match each character d , o or g . Wildcards . will match any single character (letter, number, symbol or whitespace) in a piece of text. We can use the escape character, \\ , to escape the wildcard functionality of the . and match an actual period. Ranges allow us to specify a range of characters in which we can make a match without having to type out each individual character. The - character allows us to specify that we are interested in matching a range of characters. Shorthand Character Classes represent common ranges and make writing regular expressions much simpler: \\w : the \u201cword character\u201d class represents the regex range [A-Za-z0-9_] , and it matches a single uppercase character, lowercase character, digit or underscore \\d : the \u201cdigit character\u201d class represents the regex range [0-9] , and it matches a single digit character \\s : the \u201cwhitespace character\u201d class represents the regex range [ \\t\\r\\n\\f\\v] , matching a single space, tab, carriage return, line break, form feed, or vertical tab Negated Character Classes are shorthands that match any character not in the regular shorthand classes: \\W : the \u201cnon-word character\u201d class represents the regex range [^A-Za-z0-9_] , matching any character that is not included in the range represented by \\w \\D : the \u201cnon-digit character\u201d class represents the regex range [^0-9] , matching any character that is not included in the range represented by \\d \\S : the \u201cnon-whitespace character\u201d class represents the regex range [^ \\t\\r\\n\\f\\v] , matching any character that is not included in the range represented by \\s Fixed quantifiers , denoted with curly braces {} , let us indicate the exact quantity of a character we wish to match, or allow us to provide a quantity range to match on. \\w{3} will match exactly 3 word characters \\w{4,7} will match at minimum 4 word characters and at maximum 7 word characters An important note is that quantifiers are considered to be greedy . This means that they will match the greatest quantity of characters they possibly can. For example, the regex mo{2,4} will match the text moooo in the string moooo , and not return a match of moo , or mooo . Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time. The ? only applies to the character/grouping directly before it. Use the escape character in your regex in order to match a question mark ? in a piece of text. The Kleene star , denoted with the asterisk * , is also a quantifier, and matches the preceding character 0 or more times. This means that the character doesn\u2019t need to appear, can appear once, or can appear many many times. The Kleene plus , denoted by the plus + matches the preceding character 1 or more times. The anchors hat ^ and dollar sign $ are used to match text at the start and the end of a string, respectively. The regex ^Monkeys: my mortal enemy$ will completely match the text Monkeys: my mortal enemy but not match Spider Monkeys: my mortal enemy in the wild Summary: Regular expressions are special sequences of characters that describe a pattern of text that is to be matched We can use literals to match the exact characters that we desire Alternation , using the pipe symbol | , allows us to match the text preceding or following the | Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters Wildcards , represented by the period or dot . , will match any single character (letter, number, symbol or whitespace) Ranges allow us to specify a range of characters in which we can make a match Shorthand character classes like \\w , \\d and \\s represent the ranges representing word characters, digit characters, and whitespace characters, respectively Groupings , denoted with parentheses () , group parts of a regular expression together, and allows us to limit alternation to part of a regex Fixed quantifiers , represented with curly braces {} , let us indicate the exact quantity or a range of quantity of a character we wish to match Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time The Kleene star , denoted with the asterisk * , is a quantifier that matches the preceding character 0 or more times The Kleene plus , denoted by the plus + , matches the preceding character 1 or more times The anchor symbols hat ^ and dollar sign $ are used to match text at the start and end of a string, respectively","title":"Regex"},{"location":"swe/regex/#summary","text":"Regular expressions are special sequences of characters that describe a pattern of text that is to be matched We can use literals to match the exact characters that we desire Alternation , using the pipe symbol | , allows us to match the text preceding or following the | Character sets , denoted by a pair of brackets [] , let us match one character from a series of characters Wildcards , represented by the period or dot . , will match any single character (letter, number, symbol or whitespace) Ranges allow us to specify a range of characters in which we can make a match Shorthand character classes like \\w , \\d and \\s represent the ranges representing word characters, digit characters, and whitespace characters, respectively Groupings , denoted with parentheses () , group parts of a regular expression together, and allows us to limit alternation to part of a regex Fixed quantifiers , represented with curly braces {} , let us indicate the exact quantity or a range of quantity of a character we wish to match Optional quantifiers , indicated by the question mark ? , allow us to indicate a character in a regex is optional, or can appear either 0 times or 1 time The Kleene star , denoted with the asterisk * , is a quantifier that matches the preceding character 0 or more times The Kleene plus , denoted by the plus + , matches the preceding character 1 or more times The anchor symbols hat ^ and dollar sign $ are used to match text at the start and end of a string, respectively","title":"Summary:"},{"location":"swe/swe-notes/","text":"Software Engineering Notebook UML Class Diagram Visual diagram used to demonstrate classes, their attributes/functions, and the relationships between classes Useful to start one before a large project to see how all the components interact Youtube Tutorial Lucid Chart (Online software used by numerous Fortune 500 companies for creating visual workspaces w/ things like UML diagrams) Class Construction Declare all fields as private/protected whenever possible Use getter and setter functions to access and update class fields Initialize the fields in the constructor Code Readability Readability and maintainability separate coders from good coders Focus on being able to read and understand parts of parts of code (e.g. modules/functions) without having to read entire rest of codebase Code should be Intuitive and self-documenting Readability > Cleverness/Shortness If you write the code as clever as possible, you will not be smart enough to debug it Consistency in style (e.g. spacing, braces) Commenting/Documentation Learning to write good comments is a skill Any good developer can figure out what your code does so your comments should explain why it does it that way Comment on why you made the decisions you did in your code Software Design Patterns Use encapsulation in order to separate concerns (i.e. possible points of breakdown in locally important assumptions such as object types) Try to limit managing global states (e.g. updating/referencing) since that can easily get messy, complicated, and buggy Clarity of a codebase greatly improves when pure functions that access no external state are used Functional languages like Haskell do this really well Don\u2019t switch between programming designs (e.g. pub/sub, actors, MVC) in connected parts of a codebase Create Data Abstraction Layers Ex: Don\u2019t have queries for your database in your application code. Instead create a separate library between the database and application that handles all the queries and provides easy to use getter functions like load_users(). Creates consistent styles in queries Limits the number of places to change queries if the DB schema changes Building a Software Stack Don\u2019t reinvent the wheel when not necessary Reliance on 3rd-party/open source software does leave you vulnerable to their security issues and makes you reliant on other people\u2019s maintenance of the dependencies Choose Appropriate Database: SQL: Postgres / MySQL / MariaDB / MemSQL / Amazon RDS Key Value Stores: Redis / Memcache / Riak NoSQL: MongoDB / Cassandra Hosted DBs: AWS RDS / DynamoDB / AppEngine Datastore Heavy Lifting: Amazon MR / Hadoop (Hive/Pig) / Cloudera / Google Big Query Debugging Come up w/ a hypothesis and test it (repeat until you fix the bug) Think like a scientist when debugging Record hypothesis and result Reproduce the bug locally rather than on a server (if convenient) Once you can fix it locally (which is faster & easier) you can change it on the server version Read the source code carefully and make minor alterations according to your hypothesis Use debuggers instead of messy print statements Problem Solving Define the problem Brainstorm (no idea is a bad idea) Pseudo-Code (don\u2019t worry about syntax- get the ideas down) Whiteboarding/writing is useful Implement (test as you go and make sure each component works before moving on) Avoid building out a whole solution w/o testing any of the parts Optimize efficiency (Go back and try to condense code, make more efficient, etc.) Time, memory, etc. Don't optimize too soon or overoptimize something that is fine Transition solution to another language if learning a new language General Tips You are responsible for code quality Use meaningful names Write code that expresses intent Code should speak for itself (Less comments = Less maintenance) Leave the code better than you found it Single-responsibility code Function does one thing well Less arguments = better function Tests! (Test Driven Development) Work on the big picture skeleton for the program and then fill in the details later Interface first, implementation later Independent components that can be used in different places Master your craft Create a minimum viable product (MVP) with the base functionality and then iterate by adding more features Notes on SWE Not an industry, it\u2019s a skill achieved with lots of practice Applicable to all industries available today (i.e. software runs everything) Solving problems is an art form-- you get better with lifelong practice Resources Readability & Software Design Practices Clean Code (Book) Commenting Less REST API Design","title":"Software Engineering Notebook"},{"location":"swe/swe-notes/#software-engineering-notebook","text":"","title":"Software Engineering Notebook"},{"location":"swe/swe-notes/#uml-class-diagram","text":"Visual diagram used to demonstrate classes, their attributes/functions, and the relationships between classes Useful to start one before a large project to see how all the components interact Youtube Tutorial Lucid Chart (Online software used by numerous Fortune 500 companies for creating visual workspaces w/ things like UML diagrams)","title":"UML Class Diagram"},{"location":"swe/swe-notes/#class-construction","text":"Declare all fields as private/protected whenever possible Use getter and setter functions to access and update class fields Initialize the fields in the constructor","title":"Class Construction"},{"location":"swe/swe-notes/#code-readability","text":"Readability and maintainability separate coders from good coders Focus on being able to read and understand parts of parts of code (e.g. modules/functions) without having to read entire rest of codebase Code should be Intuitive and self-documenting Readability > Cleverness/Shortness If you write the code as clever as possible, you will not be smart enough to debug it Consistency in style (e.g. spacing, braces)","title":"Code Readability"},{"location":"swe/swe-notes/#commentingdocumentation","text":"Learning to write good comments is a skill Any good developer can figure out what your code does so your comments should explain why it does it that way Comment on why you made the decisions you did in your code","title":"Commenting/Documentation"},{"location":"swe/swe-notes/#software-design-patterns","text":"Use encapsulation in order to separate concerns (i.e. possible points of breakdown in locally important assumptions such as object types) Try to limit managing global states (e.g. updating/referencing) since that can easily get messy, complicated, and buggy Clarity of a codebase greatly improves when pure functions that access no external state are used Functional languages like Haskell do this really well Don\u2019t switch between programming designs (e.g. pub/sub, actors, MVC) in connected parts of a codebase Create Data Abstraction Layers Ex: Don\u2019t have queries for your database in your application code. Instead create a separate library between the database and application that handles all the queries and provides easy to use getter functions like load_users(). Creates consistent styles in queries Limits the number of places to change queries if the DB schema changes","title":"Software Design Patterns"},{"location":"swe/swe-notes/#building-a-software-stack","text":"Don\u2019t reinvent the wheel when not necessary Reliance on 3rd-party/open source software does leave you vulnerable to their security issues and makes you reliant on other people\u2019s maintenance of the dependencies Choose Appropriate Database: SQL: Postgres / MySQL / MariaDB / MemSQL / Amazon RDS Key Value Stores: Redis / Memcache / Riak NoSQL: MongoDB / Cassandra Hosted DBs: AWS RDS / DynamoDB / AppEngine Datastore Heavy Lifting: Amazon MR / Hadoop (Hive/Pig) / Cloudera / Google Big Query","title":"Building a Software Stack"},{"location":"swe/swe-notes/#debugging","text":"Come up w/ a hypothesis and test it (repeat until you fix the bug) Think like a scientist when debugging Record hypothesis and result Reproduce the bug locally rather than on a server (if convenient) Once you can fix it locally (which is faster & easier) you can change it on the server version Read the source code carefully and make minor alterations according to your hypothesis Use debuggers instead of messy print statements","title":"Debugging"},{"location":"swe/swe-notes/#problem-solving","text":"Define the problem Brainstorm (no idea is a bad idea) Pseudo-Code (don\u2019t worry about syntax- get the ideas down) Whiteboarding/writing is useful Implement (test as you go and make sure each component works before moving on) Avoid building out a whole solution w/o testing any of the parts Optimize efficiency (Go back and try to condense code, make more efficient, etc.) Time, memory, etc. Don't optimize too soon or overoptimize something that is fine Transition solution to another language if learning a new language","title":"Problem Solving"},{"location":"swe/swe-notes/#general-tips","text":"You are responsible for code quality Use meaningful names Write code that expresses intent Code should speak for itself (Less comments = Less maintenance) Leave the code better than you found it Single-responsibility code Function does one thing well Less arguments = better function Tests! (Test Driven Development) Work on the big picture skeleton for the program and then fill in the details later Interface first, implementation later Independent components that can be used in different places Master your craft Create a minimum viable product (MVP) with the base functionality and then iterate by adding more features","title":"General Tips"},{"location":"swe/swe-notes/#notes-on-swe","text":"Not an industry, it\u2019s a skill achieved with lots of practice Applicable to all industries available today (i.e. software runs everything) Solving problems is an art form-- you get better with lifelong practice","title":"Notes on SWE"},{"location":"swe/swe-notes/#resources","text":"Readability & Software Design Practices Clean Code (Book) Commenting Less REST API Design","title":"Resources"},{"location":"swe/terminal-cmds/","text":"Terminal Commands (Mac) Navigation: cd {/path/to/folder} : changes directory to specified path cd / : goes to root directory cd ~ : goes to user directory ls : lists all files/folders in the current working directory pwd : prints the path to the current working directory| Creating & Deleting: mkdir {foldername} : makes a folder with the specified nam rm {filename} : removes the specified file rm -r {foldername} : removes the specified folder recursively touch {filename} : creates the specified file| mv {filename} {new filename} : renames the file/folder to the 2nd name Opening Files/Folders: open {filename} : opens the file with the default program open {filename} -a \"{program name}\" : opens the file in the specified application open . : opens the current folder in finder open . -a \"{program name}\" opens the folder in the specified application Terminal Commands Different in Windows: dir - list files echo > {filename} - create an empty file del {filename} - remove a file rmdir {directory name} - remove a directory and all files within rename {filename} {new filename} - rename a file or folder start {filename} - open file in default program start . - open current directory cls - clear the terminal screen Vim Commands Command Function i insert/typing mode esc leave insert mode :w save additions :wq save & quit :q! quit & discard changes Key Movement w front of next word b front of previous word 0 start of line $ end of line g last line a append to final line","title":"Terminal Cmds"},{"location":"swe/terminal-cmds/#terminal-commands-mac","text":"","title":"Terminal Commands (Mac)"},{"location":"swe/terminal-cmds/#navigation","text":"cd {/path/to/folder} : changes directory to specified path cd / : goes to root directory cd ~ : goes to user directory ls : lists all files/folders in the current working directory pwd : prints the path to the current working directory|","title":"Navigation:"},{"location":"swe/terminal-cmds/#creating-deleting","text":"mkdir {foldername} : makes a folder with the specified nam rm {filename} : removes the specified file rm -r {foldername} : removes the specified folder recursively touch {filename} : creates the specified file| mv {filename} {new filename} : renames the file/folder to the 2nd name","title":"Creating &amp; Deleting:"},{"location":"swe/terminal-cmds/#opening-filesfolders","text":"open {filename} : opens the file with the default program open {filename} -a \"{program name}\" : opens the file in the specified application open . : opens the current folder in finder open . -a \"{program name}\" opens the folder in the specified application","title":"Opening Files/Folders:"},{"location":"swe/terminal-cmds/#terminal-commands-different-in-windows","text":"dir - list files echo > {filename} - create an empty file del {filename} - remove a file rmdir {directory name} - remove a directory and all files within rename {filename} {new filename} - rename a file or folder start {filename} - open file in default program start . - open current directory cls - clear the terminal screen","title":"Terminal Commands Different in Windows:"},{"location":"swe/terminal-cmds/#vim-commands","text":"Command Function i insert/typing mode esc leave insert mode :w save additions :wq save & quit :q! quit & discard changes Key Movement w front of next word b front of previous word 0 start of line $ end of line g last line a append to final line","title":"Vim Commands"},{"location":"web_dev/static_sites/","text":"Static Sites Liquid Templating language Docs Jekyll Static site generator Ruby Gems RubyGems is software that allows you to download, install, and use ruby software pkgs Gem- ruby application or library gem named fire has file fire.rb Basically the pip","title":"Static Sites"},{"location":"web_dev/static_sites/#static-sites","text":"","title":"Static Sites"},{"location":"web_dev/static_sites/#liquid","text":"Templating language Docs","title":"Liquid"},{"location":"web_dev/static_sites/#jekyll","text":"Static site generator","title":"Jekyll"},{"location":"web_dev/static_sites/#ruby-gems","text":"RubyGems is software that allows you to download, install, and use ruby software pkgs Gem- ruby application or library gem named fire has file fire.rb Basically the pip","title":"Ruby Gems"},{"location":"web_dev/html-css/sass/","text":"Sass h1, h2, h3 { //Equivalent to h1.lg-heading &.lg-heading{} //Affects any nested elements w/in h1/h2/h3 with the specified class name .lg-heading{} } 6rem is 6 times the rem unit rem unit is a multiplier of the html tag's font size (default is 16 pixels) z-index is how close an element is to you (layering) //Allows the same transition to be used uniformly throughout a file @mixin easeOut(){ transition: all 0.5s ease-out; } a { //& uses the element it is nested in &:hover { color: $secondary-color @include easeOut(); } } vh & vw slice the screen into numerous slices of height and width 100 vh and 100 vw takes up whole screen 10 vh takes 10 slices of the height rgba(color,opacity) Sets the color and opacity for a property stands for red green blue alpha","title":"Sass"},{"location":"web_dev/html-css/sass/#sass","text":"h1, h2, h3 { //Equivalent to h1.lg-heading &.lg-heading{} //Affects any nested elements w/in h1/h2/h3 with the specified class name .lg-heading{} } 6rem is 6 times the rem unit rem unit is a multiplier of the html tag's font size (default is 16 pixels) z-index is how close an element is to you (layering) //Allows the same transition to be used uniformly throughout a file @mixin easeOut(){ transition: all 0.5s ease-out; } a { //& uses the element it is nested in &:hover { color: $secondary-color @include easeOut(); } } vh & vw slice the screen into numerous slices of height and width 100 vh and 100 vw takes up whole screen 10 vh takes 10 slices of the height rgba(color,opacity) Sets the color and opacity for a property stands for red green blue alpha","title":"Sass"},{"location":"web_dev/js/basics/","text":"What is JavaScript Dynamic Programming Language (operations done at run-time) E.g. Possible to change variable type or add new properties/methods to an object while the program is running Dynamically-Typed Language (Interpreter assigns variables a type at runtime based on its current value) Can provide interactivity on websites when applied to an html document Interpreted language (Doesn't have to be compiled) Runs on the client's computer/browser Object Based Prototype based instead of class based like Java Scripting language (lightweight) Uses for JavaScript: Put content in an HTML page on the fly Make webpages responsive Detect a user's browser and other info Create cookies Validate forms Create animations, slideshows, scrollers, etc Build apps w/ JS frameworks (ex: angularJS, reactJS, etc) Primitive Data Types Number- integers and decimals String- use single or double quotes (single preferred) .length property Boolean- true or false Null- intentional absence of a value represnted by null Undefined- absence of a valuae represented by undefined and is different than null Symbol- unique identifiers and useful in more complex coding Variables When declaring variables without assigning a value, their inital value is set to undefined Prior to ES6, var was the only keyword to declare variables ( More Info ) Variables declared using var are created before any code is executed in a process known as hoisting A variable's initial value is undefined and its actual value is intialized when the assignment statement is reached in execution This means a variable can be used before it is declared in the code since hoisting results in the equivalent of all variables being declared at the top In ES6, let and const were introduced let signals that the variable can be reassigned a different value const signals that the variable is a constant and cannot be reassigned Reassigning a const will throw a TypeError Variables can be transformed using mathematical asignment operators ( += , *= , /= ) and increment/decrement operators ( ++ , -- ) In ES6, we can insert (or interpolate) variables into strings using template literals Uses backticks instead of single/double quotes const myPet = 'armadillo'; console.log(`I own a pet ${myPet}`); // Output: I own a pet armadillo. typeof operator will return a string of the data type of the value to its right (e.g. typeof 'hello' returns 'string') Conditional Statements if (greeting) { console.log('Hello World!') } else if (goodbye){ console.log('Bye World!') } else { console.log('IDK') } Comparison Operators: < , > , <= , >= , === , !== Don't use == or != b/c types are not considered (Read More) Logical Operators: and && , or || , not: ! Values that are not explicitly true/false but evaluate to true/false are called truthy/falsy Falsy: 0 ,empty strings, null , undefined , NaN Truthy: If a variable's value exists, it evaluates to true in a logical comparison let defaultName; if (username) { defaultName = username; } else { defaultName = 'Stranger'; } //Is equivalent to let defaultName = username || 'Stranger'; //Stranger is the default if usrname is falsy (DNE) A ternary operator can condense if...else statements If the condition before the ? is true, the 1st expression executes. If false, the 2nd expression executes let isNight = true; if (isNight){ console.log('Sleep') } else { console.log('Wakeup') } //Is equivalent to: isNight ? console.log('Sleep') : console.log('Wakeup'); Supports switch statements for easier syntax than numerous else if statements let item = 'Pie' switch (item) { case 'bread': //Do something break; case 'muffin': //Do something else break; default: //Last resort break; } Functions Hoisting applies to functions as well, allowing a function to be called before it is defined in the code Not good code practice though A function declaration binds a function to an identifier like getUser() using the function keyword ES6 added the ability to use default parameters function calcArea(width,height=10){ return width * height; } Helper functions- functions called within another function Function Expressions are another way to define a function The anonymous functions created by function expressions are stored in variables so they can be referenced const is used to declare the variable const calcArea = function(width,height){ return width * height; } ES6 introduced arrow function syntax as a shorter way to write functions (Documentation) Remove the need to type out the function keyword Include parameters inside the parentheses and add an arrow => pointing to the function body const calcArea = (width,height) => { return width * height; } Conscise Body Arrow Functions Functions taking 1 parameter don't need parentheses but 0 & 2+ parameters require parentheses Pushing the function to the single-line eliminates need for curly braces and return statement (implicitly returns the contents of the block) const sumNums = num => num + num; //Will return num + num Scope Defines where variablescan be accessed or referenced In block scope variables are declared inside a block (set of {} ) and are called local variables Local variables can only be accessed within the block In global scope variables are declared outside of a block and are called global variables Global variables can be accessed by any code in the program The global namespace is where global variables go and it allows them to be accessed anywhere in the program Scope Pollution occurs when too many global variables exist in the global namespace or when variables are reused across different scopes Best practice not to define variables in the global scope to avoid this proble Scope variables as tightly as possible using block scope Makes code more legible & understandable since blocks organize the code into discrete sections Easier to maintain the modular code Saves memory b/c the variables are automatically erased after the block is finished running Arrays Documentation Can store any combination of data types( const list = ['Hello',45,true] ) Traditional array access & updates( list[0] and list[1] = 56 ) Can change the contents of an array declared with const but cannot reassign a new array or different value to the variable .length property just like strings .push(item) adds items to the end of an array & .unshift(item) adds items to the beginning ofan array Can take multipe arguments to add multiple items at a time Changes/mutates the original array (Also classified as a destructive array method since it changes the initial array ) .pop() removes the last item of an array & .shift() removes the first item (Neither take any arguments) Changes/mutates the original array .indexOf(item) returns the index of an item in the array (not found = -1) .slice() copies an array ( let copy = og.slice(); ) .splice(pos,n) removes the item at pos n times Changes the original array and returns the removed items as another array Pass-by-Reference is when an array is passed into a function, if the array is mutated inside the function, that change will be maintained outside the function as well Works because the argument to the function is just a reference to where the variable is stored in memory, allowing the memory of the array to be changed Nested arrays can be accessed by chaining on more bracket notation with index values (e.g. arry[1][3] ) let nums = [1,5,7,3,9]; let num2 = new Array(1,3,6,'Hi',3,7); nums.push(10); nums.length num2.sort() //Strings come last nums.reverse() //Reverses order Loops for loop consists of an initialization, stopping condition, and iteration statement Do while loops run a piece of code then check the condition compared to while loops that check the condition and then run the code Do while loops run at least once whether or not the condition evaluates to true break keyword allows programs to break out of a loop within the loop's block for (let i = 0; i < 5, i++){} for (let i = items.length - 1; i >= 0; i--){} //Reverse through a list while (condition) {} //Avoid infinite loops! do {} while (condition) Higher-Order Functions Functions that accept other functions as arguments and/or return functions as output Callback Functions are functions that are passed as arguments and invoked Get called during the excution of the higher-order function To pass a callback function as ana argument, the name is typed w/o the parentheses so that the reference to the function is passed, not the value from invoking the function Anonymous functions can be passed as arguments as well (they are defined in the higher-order function's call) Adds another level of abstraction to a program to make it more modular & easier to read/debug JS functions are first class objects meaning that like other objects, JS functions can have properties and methods Functions are special b/c they can be invoked and treated like any other type of data Every JS function is actually a Function object ( Documentation ) Iterators These iterators take a callback function as an argument and execute the callback function for each element in the array .forEach() const fruits = ['mango', 'papaya', 'pineapple', 'apple']; fruits.forEach(elem=>console.log(`I want to eat a ${elem}`)); //I want to eat a mango...papaya...etc. .map() returns a new array unlike forEach which mutates the original array const nums = [1,2,3,4]; const bigNums = nums.map(number => number * 10); //[10,20,30,40] .filter() takes a boolean callback function (returns T/F) as an argument. Returns a new array const favoriteWords = ['nostalgia', 'hyperbole', 'fervent', 'esoteric', 'serene']; const longFavoriteWords = favoriteWords.filter(elem=> { return elem.length > 7; }); .findIndex() Returns the index of the first element that evaluates to true in the boolean callback function No element that satisfies the callback returns -1 ``` javascript const jumbledNums = [123, 25, 78, 5, 9]; const lessThanTen = jumbledNums.findIndex(num => { return num < 10; }); //3 - `.reduce()` returns a single value after iterating through the elements of an array (Consists of an accumulator and iterator) - The optional 2nd argument sets the initial value for accumulator ```javascript const nums = [1,2,3,4]; const summedNums = nums.reduce((accumulator,currentVal) => { console.log('The value of accumulator: ', accumulator); console.log('The value of currentValue: ', currentValue); return accumulator + currentVal; },100); //110","title":"Basics"},{"location":"web_dev/js/basics/#what-is-javascript","text":"Dynamic Programming Language (operations done at run-time) E.g. Possible to change variable type or add new properties/methods to an object while the program is running Dynamically-Typed Language (Interpreter assigns variables a type at runtime based on its current value) Can provide interactivity on websites when applied to an html document Interpreted language (Doesn't have to be compiled) Runs on the client's computer/browser Object Based Prototype based instead of class based like Java Scripting language (lightweight)","title":"What is JavaScript"},{"location":"web_dev/js/basics/#uses-for-javascript","text":"Put content in an HTML page on the fly Make webpages responsive Detect a user's browser and other info Create cookies Validate forms Create animations, slideshows, scrollers, etc Build apps w/ JS frameworks (ex: angularJS, reactJS, etc)","title":"Uses for JavaScript:"},{"location":"web_dev/js/basics/#primitive-data-types","text":"Number- integers and decimals String- use single or double quotes (single preferred) .length property Boolean- true or false Null- intentional absence of a value represnted by null Undefined- absence of a valuae represented by undefined and is different than null Symbol- unique identifiers and useful in more complex coding","title":"Primitive Data Types"},{"location":"web_dev/js/basics/#variables","text":"When declaring variables without assigning a value, their inital value is set to undefined Prior to ES6, var was the only keyword to declare variables ( More Info ) Variables declared using var are created before any code is executed in a process known as hoisting A variable's initial value is undefined and its actual value is intialized when the assignment statement is reached in execution This means a variable can be used before it is declared in the code since hoisting results in the equivalent of all variables being declared at the top In ES6, let and const were introduced let signals that the variable can be reassigned a different value const signals that the variable is a constant and cannot be reassigned Reassigning a const will throw a TypeError Variables can be transformed using mathematical asignment operators ( += , *= , /= ) and increment/decrement operators ( ++ , -- ) In ES6, we can insert (or interpolate) variables into strings using template literals Uses backticks instead of single/double quotes const myPet = 'armadillo'; console.log(`I own a pet ${myPet}`); // Output: I own a pet armadillo. typeof operator will return a string of the data type of the value to its right (e.g. typeof 'hello' returns 'string')","title":"Variables"},{"location":"web_dev/js/basics/#conditional-statements","text":"if (greeting) { console.log('Hello World!') } else if (goodbye){ console.log('Bye World!') } else { console.log('IDK') } Comparison Operators: < , > , <= , >= , === , !== Don't use == or != b/c types are not considered (Read More) Logical Operators: and && , or || , not: ! Values that are not explicitly true/false but evaluate to true/false are called truthy/falsy Falsy: 0 ,empty strings, null , undefined , NaN Truthy: If a variable's value exists, it evaluates to true in a logical comparison let defaultName; if (username) { defaultName = username; } else { defaultName = 'Stranger'; } //Is equivalent to let defaultName = username || 'Stranger'; //Stranger is the default if usrname is falsy (DNE) A ternary operator can condense if...else statements If the condition before the ? is true, the 1st expression executes. If false, the 2nd expression executes let isNight = true; if (isNight){ console.log('Sleep') } else { console.log('Wakeup') } //Is equivalent to: isNight ? console.log('Sleep') : console.log('Wakeup'); Supports switch statements for easier syntax than numerous else if statements let item = 'Pie' switch (item) { case 'bread': //Do something break; case 'muffin': //Do something else break; default: //Last resort break; }","title":"Conditional Statements"},{"location":"web_dev/js/basics/#functions","text":"Hoisting applies to functions as well, allowing a function to be called before it is defined in the code Not good code practice though A function declaration binds a function to an identifier like getUser() using the function keyword ES6 added the ability to use default parameters function calcArea(width,height=10){ return width * height; } Helper functions- functions called within another function Function Expressions are another way to define a function The anonymous functions created by function expressions are stored in variables so they can be referenced const is used to declare the variable const calcArea = function(width,height){ return width * height; } ES6 introduced arrow function syntax as a shorter way to write functions (Documentation) Remove the need to type out the function keyword Include parameters inside the parentheses and add an arrow => pointing to the function body const calcArea = (width,height) => { return width * height; } Conscise Body Arrow Functions Functions taking 1 parameter don't need parentheses but 0 & 2+ parameters require parentheses Pushing the function to the single-line eliminates need for curly braces and return statement (implicitly returns the contents of the block) const sumNums = num => num + num; //Will return num + num","title":"Functions"},{"location":"web_dev/js/basics/#scope","text":"Defines where variablescan be accessed or referenced In block scope variables are declared inside a block (set of {} ) and are called local variables Local variables can only be accessed within the block In global scope variables are declared outside of a block and are called global variables Global variables can be accessed by any code in the program The global namespace is where global variables go and it allows them to be accessed anywhere in the program Scope Pollution occurs when too many global variables exist in the global namespace or when variables are reused across different scopes Best practice not to define variables in the global scope to avoid this proble Scope variables as tightly as possible using block scope Makes code more legible & understandable since blocks organize the code into discrete sections Easier to maintain the modular code Saves memory b/c the variables are automatically erased after the block is finished running","title":"Scope"},{"location":"web_dev/js/basics/#arrays","text":"Documentation Can store any combination of data types( const list = ['Hello',45,true] ) Traditional array access & updates( list[0] and list[1] = 56 ) Can change the contents of an array declared with const but cannot reassign a new array or different value to the variable .length property just like strings .push(item) adds items to the end of an array & .unshift(item) adds items to the beginning ofan array Can take multipe arguments to add multiple items at a time Changes/mutates the original array (Also classified as a destructive array method since it changes the initial array ) .pop() removes the last item of an array & .shift() removes the first item (Neither take any arguments) Changes/mutates the original array .indexOf(item) returns the index of an item in the array (not found = -1) .slice() copies an array ( let copy = og.slice(); ) .splice(pos,n) removes the item at pos n times Changes the original array and returns the removed items as another array Pass-by-Reference is when an array is passed into a function, if the array is mutated inside the function, that change will be maintained outside the function as well Works because the argument to the function is just a reference to where the variable is stored in memory, allowing the memory of the array to be changed Nested arrays can be accessed by chaining on more bracket notation with index values (e.g. arry[1][3] ) let nums = [1,5,7,3,9]; let num2 = new Array(1,3,6,'Hi',3,7); nums.push(10); nums.length num2.sort() //Strings come last nums.reverse() //Reverses order","title":"Arrays"},{"location":"web_dev/js/basics/#loops","text":"for loop consists of an initialization, stopping condition, and iteration statement Do while loops run a piece of code then check the condition compared to while loops that check the condition and then run the code Do while loops run at least once whether or not the condition evaluates to true break keyword allows programs to break out of a loop within the loop's block for (let i = 0; i < 5, i++){} for (let i = items.length - 1; i >= 0; i--){} //Reverse through a list while (condition) {} //Avoid infinite loops! do {} while (condition)","title":"Loops"},{"location":"web_dev/js/basics/#higher-order-functions","text":"Functions that accept other functions as arguments and/or return functions as output Callback Functions are functions that are passed as arguments and invoked Get called during the excution of the higher-order function To pass a callback function as ana argument, the name is typed w/o the parentheses so that the reference to the function is passed, not the value from invoking the function Anonymous functions can be passed as arguments as well (they are defined in the higher-order function's call) Adds another level of abstraction to a program to make it more modular & easier to read/debug JS functions are first class objects meaning that like other objects, JS functions can have properties and methods Functions are special b/c they can be invoked and treated like any other type of data Every JS function is actually a Function object ( Documentation )","title":"Higher-Order Functions"},{"location":"web_dev/js/basics/#iterators","text":"These iterators take a callback function as an argument and execute the callback function for each element in the array .forEach() const fruits = ['mango', 'papaya', 'pineapple', 'apple']; fruits.forEach(elem=>console.log(`I want to eat a ${elem}`)); //I want to eat a mango...papaya...etc. .map() returns a new array unlike forEach which mutates the original array const nums = [1,2,3,4]; const bigNums = nums.map(number => number * 10); //[10,20,30,40] .filter() takes a boolean callback function (returns T/F) as an argument. Returns a new array const favoriteWords = ['nostalgia', 'hyperbole', 'fervent', 'esoteric', 'serene']; const longFavoriteWords = favoriteWords.filter(elem=> { return elem.length > 7; }); .findIndex() Returns the index of the first element that evaluates to true in the boolean callback function No element that satisfies the callback returns -1 ``` javascript const jumbledNums = [123, 25, 78, 5, 9]; const lessThanTen = jumbledNums.findIndex(num => { return num < 10; }); //3 - `.reduce()` returns a single value after iterating through the elements of an array (Consists of an accumulator and iterator) - The optional 2nd argument sets the initial value for accumulator ```javascript const nums = [1,2,3,4]; const summedNums = nums.reduce((accumulator,currentVal) => { console.log('The value of accumulator: ', accumulator); console.log('The value of currentValue: ', currentValue); return accumulator + currentVal; },100); //110","title":"Iterators"},{"location":"web_dev/js/browser_compatibility/","text":"Browser Compatibility Some ES6 features, like modules, are still not supported by most web browsers caniuse.com is the bset resource for finding browser compatiblity info on a feature-by-feature basis ES5 updated to ES6: Better readability and requires fewer characters Fixes ES5 bugs common from the syntax Syntax more similar to other OOP languages Ecma (Organization in charge of JS standards) made ES6 backwards compatible meaning it can be mapped to ES5 Backwards compatibility helps decrease browser compatibility issues Babel is a library that transpiles ES6 to ES5 JavaScript Transpilation- the process of converting one programming language to another babel-cli - Node package w/ command line tools for Babel babel-preset-env - Node package w/ ES6+ to ES5 syntax mapping information Transpilation (Detailed Notes) Setup the project using the specified file structure and npm bash project |_ src |___ main.js |_ package.json Run npm init to create a package.json file in the root directory that contains info about the current project: Metdata- Project Title, Description, Authors, etc List of Required Node Packages- npm downloads the packages in this list when other developers want to run your project Key-value pairs for command line scripts- can use npm to run these shorthand scripts to perform some process Install necessary Babel packages using node package manager (npm) bash npm install babel-cli -D npm install babel-preset-env -D install creates a folder called node_modules and copies the package files to it while also installing all the dependencies for the given package -D flag instructs npm to add each package to a property called devDependencies in package.json devDependencies allows other developers to run your project without installing each package separately Instead they can run npm install to instruct npm to look inside package.json and download all the packages listed in devDependencies New Directory Structure: ( ... indicates 100+ packages that npm installed) bash project |_ node_modules |___ .bin |___ ... |_ src |___ main.js |_ package.json Specify the initial JS version in .babelrc Run touch .babelrc in the root directory to create the file Define the preset for the source JS file ( [\"env\"] insrtucts Babel to transpile any code from ES6+) { \"presets\": [\"env\"] } Specify a script in package.json that initiates ES6+ to ES5 transpilation In the \"scripts\" object, add a property called \"build\" below \"test\" \"build\" 's value ( babel src -d lib ) is a command line method that trasnpiles ES6+ code to ES5 babel \u2014 The Babel command call responsible for transpiling code. src \u2014 Instructs Babel to transpile all JavaScript code inside the src directory. -d \u2014 Instructs Babel to write the transpiled code to a directory. lib \u2014 Babel writes the transpiled code to a directory called lib . json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"build\": \"babel src -d lib\" }, ... Type npm run build to build the transpile the code to ES5 where it is stored in a directory called lib as a file with the same name as the original file (./lib/main.js) The command runs the build script in package.json The one command transpiles all code in src - good for larger projects with numerous JS files Transpilation Process (Summary): Initialize your project using npm init and create a directory called src Install babel dependencies by running npm install babel-cli -D npm install babel-preset-env -D Create a .babelrc file inside your project and add the following code inside it: { \"presets\": [\"env\"] } Add the following script to your scripts object in package.json: json \"build\": \"babel src -d lib\" Run npm run build whenever you want to transpile your code from your src to lib directories","title":"Browser Compatibility"},{"location":"web_dev/js/browser_compatibility/#browser-compatibility","text":"Some ES6 features, like modules, are still not supported by most web browsers caniuse.com is the bset resource for finding browser compatiblity info on a feature-by-feature basis ES5 updated to ES6: Better readability and requires fewer characters Fixes ES5 bugs common from the syntax Syntax more similar to other OOP languages Ecma (Organization in charge of JS standards) made ES6 backwards compatible meaning it can be mapped to ES5 Backwards compatibility helps decrease browser compatibility issues Babel is a library that transpiles ES6 to ES5 JavaScript Transpilation- the process of converting one programming language to another babel-cli - Node package w/ command line tools for Babel babel-preset-env - Node package w/ ES6+ to ES5 syntax mapping information","title":"Browser Compatibility"},{"location":"web_dev/js/browser_compatibility/#transpilation-detailed-notes","text":"Setup the project using the specified file structure and npm bash project |_ src |___ main.js |_ package.json Run npm init to create a package.json file in the root directory that contains info about the current project: Metdata- Project Title, Description, Authors, etc List of Required Node Packages- npm downloads the packages in this list when other developers want to run your project Key-value pairs for command line scripts- can use npm to run these shorthand scripts to perform some process Install necessary Babel packages using node package manager (npm) bash npm install babel-cli -D npm install babel-preset-env -D install creates a folder called node_modules and copies the package files to it while also installing all the dependencies for the given package -D flag instructs npm to add each package to a property called devDependencies in package.json devDependencies allows other developers to run your project without installing each package separately Instead they can run npm install to instruct npm to look inside package.json and download all the packages listed in devDependencies New Directory Structure: ( ... indicates 100+ packages that npm installed) bash project |_ node_modules |___ .bin |___ ... |_ src |___ main.js |_ package.json Specify the initial JS version in .babelrc Run touch .babelrc in the root directory to create the file Define the preset for the source JS file ( [\"env\"] insrtucts Babel to transpile any code from ES6+) { \"presets\": [\"env\"] } Specify a script in package.json that initiates ES6+ to ES5 transpilation In the \"scripts\" object, add a property called \"build\" below \"test\" \"build\" 's value ( babel src -d lib ) is a command line method that trasnpiles ES6+ code to ES5 babel \u2014 The Babel command call responsible for transpiling code. src \u2014 Instructs Babel to transpile all JavaScript code inside the src directory. -d \u2014 Instructs Babel to write the transpiled code to a directory. lib \u2014 Babel writes the transpiled code to a directory called lib . json ... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"build\": \"babel src -d lib\" }, ... Type npm run build to build the transpile the code to ES5 where it is stored in a directory called lib as a file with the same name as the original file (./lib/main.js) The command runs the build script in package.json The one command transpiles all code in src - good for larger projects with numerous JS files","title":"Transpilation (Detailed Notes)"},{"location":"web_dev/js/browser_compatibility/#transpilation-process-summary","text":"Initialize your project using npm init and create a directory called src Install babel dependencies by running npm install babel-cli -D npm install babel-preset-env -D Create a .babelrc file inside your project and add the following code inside it: { \"presets\": [\"env\"] } Add the following script to your scripts object in package.json: json \"build\": \"babel src -d lib\" Run npm run build whenever you want to transpile your code from your src to lib directories","title":"Transpilation Process (Summary):"},{"location":"web_dev/js/classes/","text":"Classes Constructor JavaScript calls the constructor() method every time it creates a new instance of a class. class Dog { constructor(name) { this.name = name; this.behavior = 0; } } Instances An instance is an object that contains the property names and methods of a class, but with unique property values. const halley = new Dog('Halley'); console.log(halley.name); // Output: 'Halley' Methods Class method and getter syntax is the same as it is for objects except you can not include commas between methods. class Dog { constructor(name) { this._name = name; } get name() { return this._name; } incrementBehavior() { this._behavior++; } } Static Methods aren't available to instances and can only be called by the class Calling static methods from an instance throws a TypeError class Animal { constructor(name) { this._name = name; this._behavior = 0; } static generateName() { const names = ['Angel', 'Spike', 'Buffy', 'Willow', 'Tara']; const randomNumber = Math.floor(Math.random()*5); return names[randomNumber]; } } console.log(Animal.generateName()); // returns a name Inheritance Create a parent class (also known as a superclass) with properties and methods that multiple child classes (also known as subclasses) share Child classes inherit the properties and methods from their parent class Benefits (time saved, readability, efficiency) grow as the number and size of subclasses increase Adheres to DRY best practice JS uses extends keyword to extend the properties/methods of one clas to a subclass super() Calls the constructor of the parent class (with the appropriate parameters if necessary) super() must always be called before this can be used to define new properties (ReferenceError will be thrown otherwise) Best Practice: Always call super() on the first line of subclass constructors class Animal { constructor(name) { this._name = name; this._behavior = 0; } get name() { return this._name; } get behavior() { return this._behavior; } } class Cat extends Animal { constructor(name, usesLitter) { super(name); this._usesLitter = usesLitter; } }","title":"Classes"},{"location":"web_dev/js/classes/#classes","text":"","title":"Classes"},{"location":"web_dev/js/classes/#constructor","text":"JavaScript calls the constructor() method every time it creates a new instance of a class. class Dog { constructor(name) { this.name = name; this.behavior = 0; } }","title":"Constructor"},{"location":"web_dev/js/classes/#instances","text":"An instance is an object that contains the property names and methods of a class, but with unique property values. const halley = new Dog('Halley'); console.log(halley.name); // Output: 'Halley'","title":"Instances"},{"location":"web_dev/js/classes/#methods","text":"Class method and getter syntax is the same as it is for objects except you can not include commas between methods. class Dog { constructor(name) { this._name = name; } get name() { return this._name; } incrementBehavior() { this._behavior++; } } Static Methods aren't available to instances and can only be called by the class Calling static methods from an instance throws a TypeError class Animal { constructor(name) { this._name = name; this._behavior = 0; } static generateName() { const names = ['Angel', 'Spike', 'Buffy', 'Willow', 'Tara']; const randomNumber = Math.floor(Math.random()*5); return names[randomNumber]; } } console.log(Animal.generateName()); // returns a name","title":"Methods"},{"location":"web_dev/js/classes/#inheritance","text":"Create a parent class (also known as a superclass) with properties and methods that multiple child classes (also known as subclasses) share Child classes inherit the properties and methods from their parent class Benefits (time saved, readability, efficiency) grow as the number and size of subclasses increase Adheres to DRY best practice JS uses extends keyword to extend the properties/methods of one clas to a subclass super() Calls the constructor of the parent class (with the appropriate parameters if necessary) super() must always be called before this can be used to define new properties (ReferenceError will be thrown otherwise) Best Practice: Always call super() on the first line of subclass constructors class Animal { constructor(name) { this._name = name; this._behavior = 0; } get name() { return this._name; } get behavior() { return this._behavior; } } class Cat extends Animal { constructor(name, usesLitter) { super(name); this._usesLitter = usesLitter; } }","title":"Inheritance"},{"location":"web_dev/js/jQuery/","text":"jQuery An easy to learn JS library that simplifies JS web programming Wraps common, lengthy tasks into methods that can be called in a single line Simplifies complicated JS things such as AJAX calls & DOM manipulation Contains Following Features: HTML/DOM manipulation CSS manipulation HTML event methods Effects and animations AJAX Utilities Many other plugins for other tasks Add to Webpages: Download production or development version from jQuery.com into project folder and add it to your project file <head> <script src=\"jquery-3.5.1.min.js\"></script> </head> OR include it from a CDN (Content Delivery Network) such as google: Loaded from users cache when they visit your site and it uses google's CDN (faster loading) <head> <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script> </head> Syntax Tailor-made for selecting HTML elements and performing some action on the element(s). Basic syntax is: $(selector).action() A $ sign to define/access jQuery A (selector) to \"query (or find)\" HTML elements A jQuery action() to be performed on the element(s) Document Ready Event All jQuery methods are inside a document ready event to prevent any jQuery code from running before the document is finished loading (is ready) Actions on the DOM can fail if document is fully loaded before code is executed $(document).ready(function(){ // jQuery methods go here.. }); //or the shorter version: $(function(){ // jQuery methods go here... }); Selectors Allow you to select and manipulate HTML elements Used to \"find\" (or select) HTML elements based on their name, id, classes, types, attributes, values of attributes and much more. Based on the existing CSS Selectors andit has some own custom selectors Element: $(\"p\") Id: $(#ex_id) Class: $(\".ex_class\")","title":"jQuery"},{"location":"web_dev/js/jQuery/#jquery","text":"An easy to learn JS library that simplifies JS web programming Wraps common, lengthy tasks into methods that can be called in a single line Simplifies complicated JS things such as AJAX calls & DOM manipulation Contains Following Features: HTML/DOM manipulation CSS manipulation HTML event methods Effects and animations AJAX Utilities Many other plugins for other tasks","title":"jQuery"},{"location":"web_dev/js/jQuery/#add-to-webpages","text":"Download production or development version from jQuery.com into project folder and add it to your project file <head> <script src=\"jquery-3.5.1.min.js\"></script> </head> OR include it from a CDN (Content Delivery Network) such as google: Loaded from users cache when they visit your site and it uses google's CDN (faster loading) <head> <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script> </head>","title":"Add to Webpages:"},{"location":"web_dev/js/jQuery/#syntax","text":"Tailor-made for selecting HTML elements and performing some action on the element(s). Basic syntax is: $(selector).action() A $ sign to define/access jQuery A (selector) to \"query (or find)\" HTML elements A jQuery action() to be performed on the element(s)","title":"Syntax"},{"location":"web_dev/js/jQuery/#document-ready-event","text":"All jQuery methods are inside a document ready event to prevent any jQuery code from running before the document is finished loading (is ready) Actions on the DOM can fail if document is fully loaded before code is executed $(document).ready(function(){ // jQuery methods go here.. }); //or the shorter version: $(function(){ // jQuery methods go here... });","title":"Document Ready Event"},{"location":"web_dev/js/jQuery/#selectors","text":"Allow you to select and manipulate HTML elements Used to \"find\" (or select) HTML elements based on their name, id, classes, types, attributes, values of attributes and much more. Based on the existing CSS Selectors andit has some own custom selectors Element: $(\"p\") Id: $(#ex_id) Class: $(\".ex_class\")","title":"Selectors"},{"location":"web_dev/js/modules/","text":"Modules Overview Reusable pieces of code that can be exported from one program and imported for use in another program Benefits of Using Modules: Find, fix, and debug code more easily Reuse and recycle logic defined in different parts of our application Keep information private and protected from other modules Prevent pollution of the global namespace and potential naming collisions, by cautiously selecting variables and behavior we load into a program Two Ways of Implementing Modules: Node.js's module.exports and require() syntax ES6 import / export syntax Node.js Syntax module.exports Every JavaScript file run in Node has a local module object with an exports property used to define what should be exported from the file The pattern we use to export modules: Create an object to represent the module. Add properties or methods to the module object. Export the module with module.exports . let Menu = {}; Menu.specialty = \"Roasted Beet Burger with Mint Sauce\"; module.exports = Menu; Can also wrap any collection of data/functions in an object and export the object (Equivalent to above block) module.exports = { specialty: \"Roasted Beet Burger with Mint Sauce\", getSpecialty: function() { return this.specialty; } }; require() Used in Node to import the exported module into another file so its defined behavior can be used Takes a file path argument pointing to the original module file The .js extension in the file path is optional and will be assumed if not included The pattern to import a module: Import the module with require() and assign it to a local variable. Use the module and its properties within a program. const Menu = require('./menu.js'); function placeOrder() { console.log('My order is: ' + Menu.specialty); } placeOrder(); ES6 Syntax export default Works similarly to the module.exports syntax, allowing us to export 1 module per file Not supported in Node.js so this syntax is used for front-end development let Menu = {}; export default Menu; import The name following import specifies the name of the variable to store the default export in When specifying the path name after from , .js is left off because it specifically refers to the name of the file w/o the extension of the file when dealing with local files import Menu from './menu'; Named Exports Allow us to export data through the use of variables let specialty = ''; function isVegetarian() {}; export { specialty, isVegetarian }; Named exports can have their name changed when exported using as let specialty = ''; let isVegetarian = function() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; Variables can be exported as soon as they are declared by placing export in front of variable declarations export let specialty = ''; export function isVegetarian() {}; Named exports and default exports can be used together Best not to use both methods but can occasionally be useful Ex: If you suspect developers may only be interested in importing a specific function and won\u2019t need to import the entire default export. let specialty = ''; function isVegetarian() {}; function isGlutenFree() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; export default isGlutenFree; Named Imports To import objects stored in a variable, we use the import keyword and include the variables in a set of {} Don't have to import all the variables exported in the other module import { specialty, isVegetarian } from './menu'; console.log(specialty); Named exports can have their name changed when exported/imported using as import {speciality as chefsSpecial, isVegetarian as isVeg} from './menu'; //or import * as Carte from './menu'; Carte.speciality; Carte.isVegetarian(); Named imports and normal imports can be used together import { specialty, isVegetarian } from './menu'; import GlutenFree from './menu';","title":"Modules"},{"location":"web_dev/js/modules/#modules-overview","text":"Reusable pieces of code that can be exported from one program and imported for use in another program Benefits of Using Modules: Find, fix, and debug code more easily Reuse and recycle logic defined in different parts of our application Keep information private and protected from other modules Prevent pollution of the global namespace and potential naming collisions, by cautiously selecting variables and behavior we load into a program Two Ways of Implementing Modules: Node.js's module.exports and require() syntax ES6 import / export syntax","title":"Modules Overview"},{"location":"web_dev/js/modules/#nodejs-syntax","text":"","title":"Node.js Syntax"},{"location":"web_dev/js/modules/#moduleexports","text":"Every JavaScript file run in Node has a local module object with an exports property used to define what should be exported from the file The pattern we use to export modules: Create an object to represent the module. Add properties or methods to the module object. Export the module with module.exports . let Menu = {}; Menu.specialty = \"Roasted Beet Burger with Mint Sauce\"; module.exports = Menu; Can also wrap any collection of data/functions in an object and export the object (Equivalent to above block) module.exports = { specialty: \"Roasted Beet Burger with Mint Sauce\", getSpecialty: function() { return this.specialty; } };","title":"module.exports"},{"location":"web_dev/js/modules/#require","text":"Used in Node to import the exported module into another file so its defined behavior can be used Takes a file path argument pointing to the original module file The .js extension in the file path is optional and will be assumed if not included The pattern to import a module: Import the module with require() and assign it to a local variable. Use the module and its properties within a program. const Menu = require('./menu.js'); function placeOrder() { console.log('My order is: ' + Menu.specialty); } placeOrder();","title":"require()"},{"location":"web_dev/js/modules/#es6-syntax","text":"","title":"ES6 Syntax"},{"location":"web_dev/js/modules/#export-default","text":"Works similarly to the module.exports syntax, allowing us to export 1 module per file Not supported in Node.js so this syntax is used for front-end development let Menu = {}; export default Menu;","title":"export default"},{"location":"web_dev/js/modules/#import","text":"The name following import specifies the name of the variable to store the default export in When specifying the path name after from , .js is left off because it specifically refers to the name of the file w/o the extension of the file when dealing with local files import Menu from './menu';","title":"import"},{"location":"web_dev/js/modules/#named-exports","text":"Allow us to export data through the use of variables let specialty = ''; function isVegetarian() {}; export { specialty, isVegetarian }; Named exports can have their name changed when exported using as let specialty = ''; let isVegetarian = function() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; Variables can be exported as soon as they are declared by placing export in front of variable declarations export let specialty = ''; export function isVegetarian() {}; Named exports and default exports can be used together Best not to use both methods but can occasionally be useful Ex: If you suspect developers may only be interested in importing a specific function and won\u2019t need to import the entire default export. let specialty = ''; function isVegetarian() {}; function isGlutenFree() {}; export { specialty as chefsSpecial, isVegetarian as isVeg }; export default isGlutenFree;","title":"Named Exports"},{"location":"web_dev/js/modules/#named-imports","text":"To import objects stored in a variable, we use the import keyword and include the variables in a set of {} Don't have to import all the variables exported in the other module import { specialty, isVegetarian } from './menu'; console.log(specialty); Named exports can have their name changed when exported/imported using as import {speciality as chefsSpecial, isVegetarian as isVeg} from './menu'; //or import * as Carte from './menu'; Carte.speciality; Carte.isVegetarian(); Named imports and normal imports can be used together import { specialty, isVegetarian } from './menu'; import GlutenFree from './menu';","title":"Named Imports"},{"location":"web_dev/js/objects/","text":"Objects Are passed by reference meaning the variable assigned to an object points to the space in memory holding the object when passed into a function as an argument Functions that change object properties actually mutate the object permanently even when assigned to a const variable Can be iterated through using the for...in syntax that executes a given block of code for each property in an object ( Documentation ) for (let member in spaceship.crew) {} Object Literal Data is organized into key-value pairs where a key points to a location in memory that holds a value Keys are strings but values can be any data type When the keys don't have special characters, JS allows the quotation marks to be omitted Key serves as a method's name and the value is an anonymous function expression ES6 syntax allows omission of the colon and function keyword let person = { firstName: 'John', secondName: 'Doe', age: 30, children: ['Bob','Joe'] //Embedded Object address : { street: '555 Heaven Ave', city: 'Boston', state: 'MA' }, fullName: function(){ return this.firstname + ' ' + this.lastName; } //Same as fullName2 () { console.log(this.firstname) } } There are 2 notations used for accessing object properties: dot and bracket Braket notation must be used when accessing keys that have numbers, spaces, or special characters Also used for property assignment/creation Can't reassign an object declared with const delete operator is used to delete properties //Dot Notation person.age; person.children[0]; person.address.street; //Bracket Notation property = 'age'; person[property]; person['children'][0]; person['address']['street']; Object Constructor let apple = new Object(); apple.color = 'red'; apple.shape = 'round'; apple.describe = function(){ return \"Color: \" +this.color+' Shape: '+this.shape; } Constructor Pattern: function Fruit(name,color,shape){ this.name = name; this.color = color; this.shape = shape; this.describe = function(){ return \"This is \"+this.color; } } let apple = new Fruit('apple','red','round'); this Keyword Similar functionality to self keyword used for clases in python Used to reference other properties/methods of an object from within the object this references the calling object which provides access to the calling object's properties A ReferenceError is thrown if this is not used const goat = { dietType: 'herbivore', diet() { console.log(this.dietType); } }; goat.diet(); //Output: herbivore arrow functions bind/tie this to the function itself, not the calling object In the below example, the value of this is the global object (an object that exists in the global scope), which doesn't have a dietType property, therefore returnining undefined Avoid using arrow functions when using this in a method const goat = { dietType: 'herbivore', diet: () => { console.log(this.dietType); } }; goat.diet(); // Prints undefined Privacy Only certain properties should be mutable/able to change in value JS does not have privacy built-in for objects Naming conventions indicate how a developer should interact with a property Underscores _ before the name of a property: do not alter Getters are used to return internal properties of an object Syntax: get keyword followed by a function(){} Can perform an action on the data when getting a property Can return different values using conditionals Easier readability const person = { _firstName: 'John', _lastName: 'Doe', get fullName() { if (this._firstName && this._lastName){ return `${this._firstName} ${this._lastName}`; } else { return 'Missing a first name or a last name.'; } } } //Using a Getter person.fullName; // 'John Doe' Setters are used to reassign values of an object's properties const person = { _age: 37, set age(newAge){ if (typeof newAge === 'number'){ this._age = newAge; } else { console.log('You must assign a number to age'); } } }; //Using a Setter person.age = 40 console.log(person._age) //40 Factory Functions Returns an object that can be reused to make multiple object instances Simply returns an object Can have parameters allowing customization of the returned object const monsterFactory = (name, age, energySource, catchPhrase) => { return { name: name, age: age, energySource: energySource, scare() { console.log(catchPhrase); } } }; const ghost = monsterFactory('Ghouly', 251, 'ectoplasm', 'BOO!'); ghost.scare(); // 'BOO!' Destructuring An ES6 shortcut for assigning an object's properties to variables Property Value Shorthand can be used in creating factory functions where the property's name is the same as the variable it is being assigned to const monsterFactory = (name, age) => { return { name, age } }; Destructured Assignment is similar to unpacking in python where an object's properties can be concisely assigned to new variables const vampire = { name: 'Dracula', residence: 'Transylvania', preferences: { day: 'stay inside', night: 'satisfy appetite' } }; const {residence} = vampire; //Transylvania const {day} = vampire.preferences //Stay inside Built-In Object Methods Object Instance Methods: (Documentation) .hasOwnProperty() , .valueOf() Object Class Methods: Object.keys(name_of_obj) : Returns an array of the keys/property names of an object Object.entries(name_of_obj) : Returns an array containing arrays that have the key & value for each property Object.assign(target_obj,src_object) : Copies properties from the source object (s) to the target object and returns the target object","title":"Objects"},{"location":"web_dev/js/objects/#objects","text":"Are passed by reference meaning the variable assigned to an object points to the space in memory holding the object when passed into a function as an argument Functions that change object properties actually mutate the object permanently even when assigned to a const variable Can be iterated through using the for...in syntax that executes a given block of code for each property in an object ( Documentation ) for (let member in spaceship.crew) {}","title":"Objects"},{"location":"web_dev/js/objects/#object-literal","text":"Data is organized into key-value pairs where a key points to a location in memory that holds a value Keys are strings but values can be any data type When the keys don't have special characters, JS allows the quotation marks to be omitted Key serves as a method's name and the value is an anonymous function expression ES6 syntax allows omission of the colon and function keyword let person = { firstName: 'John', secondName: 'Doe', age: 30, children: ['Bob','Joe'] //Embedded Object address : { street: '555 Heaven Ave', city: 'Boston', state: 'MA' }, fullName: function(){ return this.firstname + ' ' + this.lastName; } //Same as fullName2 () { console.log(this.firstname) } } There are 2 notations used for accessing object properties: dot and bracket Braket notation must be used when accessing keys that have numbers, spaces, or special characters Also used for property assignment/creation Can't reassign an object declared with const delete operator is used to delete properties //Dot Notation person.age; person.children[0]; person.address.street; //Bracket Notation property = 'age'; person[property]; person['children'][0]; person['address']['street'];","title":"Object Literal"},{"location":"web_dev/js/objects/#object-constructor","text":"let apple = new Object(); apple.color = 'red'; apple.shape = 'round'; apple.describe = function(){ return \"Color: \" +this.color+' Shape: '+this.shape; }","title":"Object Constructor"},{"location":"web_dev/js/objects/#constructor-pattern","text":"function Fruit(name,color,shape){ this.name = name; this.color = color; this.shape = shape; this.describe = function(){ return \"This is \"+this.color; } } let apple = new Fruit('apple','red','round');","title":"Constructor Pattern:"},{"location":"web_dev/js/objects/#this-keyword","text":"Similar functionality to self keyword used for clases in python Used to reference other properties/methods of an object from within the object this references the calling object which provides access to the calling object's properties A ReferenceError is thrown if this is not used const goat = { dietType: 'herbivore', diet() { console.log(this.dietType); } }; goat.diet(); //Output: herbivore arrow functions bind/tie this to the function itself, not the calling object In the below example, the value of this is the global object (an object that exists in the global scope), which doesn't have a dietType property, therefore returnining undefined Avoid using arrow functions when using this in a method const goat = { dietType: 'herbivore', diet: () => { console.log(this.dietType); } }; goat.diet(); // Prints undefined","title":"this Keyword"},{"location":"web_dev/js/objects/#privacy","text":"Only certain properties should be mutable/able to change in value JS does not have privacy built-in for objects Naming conventions indicate how a developer should interact with a property Underscores _ before the name of a property: do not alter Getters are used to return internal properties of an object Syntax: get keyword followed by a function(){} Can perform an action on the data when getting a property Can return different values using conditionals Easier readability const person = { _firstName: 'John', _lastName: 'Doe', get fullName() { if (this._firstName && this._lastName){ return `${this._firstName} ${this._lastName}`; } else { return 'Missing a first name or a last name.'; } } } //Using a Getter person.fullName; // 'John Doe' Setters are used to reassign values of an object's properties const person = { _age: 37, set age(newAge){ if (typeof newAge === 'number'){ this._age = newAge; } else { console.log('You must assign a number to age'); } } }; //Using a Setter person.age = 40 console.log(person._age) //40","title":"Privacy"},{"location":"web_dev/js/objects/#factory-functions","text":"Returns an object that can be reused to make multiple object instances Simply returns an object Can have parameters allowing customization of the returned object const monsterFactory = (name, age, energySource, catchPhrase) => { return { name: name, age: age, energySource: energySource, scare() { console.log(catchPhrase); } } }; const ghost = monsterFactory('Ghouly', 251, 'ectoplasm', 'BOO!'); ghost.scare(); // 'BOO!'","title":"Factory Functions"},{"location":"web_dev/js/objects/#destructuring","text":"An ES6 shortcut for assigning an object's properties to variables Property Value Shorthand can be used in creating factory functions where the property's name is the same as the variable it is being assigned to const monsterFactory = (name, age) => { return { name, age } }; Destructured Assignment is similar to unpacking in python where an object's properties can be concisely assigned to new variables const vampire = { name: 'Dracula', residence: 'Transylvania', preferences: { day: 'stay inside', night: 'satisfy appetite' } }; const {residence} = vampire; //Transylvania const {day} = vampire.preferences //Stay inside","title":"Destructuring"},{"location":"web_dev/js/objects/#built-in-object-methods","text":"Object Instance Methods: (Documentation) .hasOwnProperty() , .valueOf() Object Class Methods: Object.keys(name_of_obj) : Returns an array of the keys/property names of an object Object.entries(name_of_obj) : Returns an array containing arrays that have the key & value for each property Object.assign(target_obj,src_object) : Copies properties from the source object (s) to the target object and returns the target object","title":"Built-In Object Methods"},{"location":"web_dev/js/promises/","text":"Ayscnhronous Programming An asynchronous operation is one that allows the computer to \u201cmove on\u201d to other tasks while waiting for the asynchronous operation to complete Asynchronous programming means that time-consuming operations don\u2019t have to bring everything else in our programs to a halt JS handles asynchronicity using the Promise object, introduced with ES6 What is a Promise? Promises are objects that represent the eventual outcome of an asynchronous operation A Promise object can be in one of three states: Pending : The initial state\u2014 the operation has not completed yet. Fulfilled : The operation has completed successfully and the promise now has a resolved value . For example, a request\u2019s promise might resolve with a JSON object as its value. Rejected : The operation has failed and the promise has a reason for the failure. This reason is usually an Error of some kind. A promise is settled if it is no longer pending (it is either fufilled or rejected) All promises eventually settle Enables us to write logic for what to do if the promise fulfills or is rejected Promises are returned from a asyncrhonous operations Constructing a Promise Object Promise constructor takes a function called the executor function as an argument Executor Function runs automatically when constructor is called, generally starts an asynchronous operation, and dictates how the promsie should be settled Has 2 function parameters: resolve() and reject() (These functions aren't defined by the progammer but are rather passed by JS into the executor function when the Promise constructor runs) resolve has one argument and will change the promise's status from pending to fulfilled if invoked and will set the resolved value to the argument passed in reject takes a reason or error as an argument and will change the promise's status from pending to rejected if invoked and will set the rejection's reason to the argument passed in Promises settle based on the results of an asynch operation (e.g. Database request is fulfilled with data from the query or is rejected with an error thrown) const executorFunction = (resolve,reject) => { if (condition){ resolve('Say Something') } else { reject('Say a different thing') } } const myPromise = new Promise(executorFunction) setTimeout() in Node: Takes a callback function and delay in milliseconds as arguments The callback function will execute in at least the passed in delay (Could be longer) This happens b/c after the delay, the line of code is added to be run but any synchronous code from the program will run before it, possibly delaying the callback functions execution","title":"Promises"},{"location":"web_dev/js/promises/#ayscnhronous-programming","text":"An asynchronous operation is one that allows the computer to \u201cmove on\u201d to other tasks while waiting for the asynchronous operation to complete Asynchronous programming means that time-consuming operations don\u2019t have to bring everything else in our programs to a halt JS handles asynchronicity using the Promise object, introduced with ES6","title":"Ayscnhronous Programming"},{"location":"web_dev/js/promises/#what-is-a-promise","text":"Promises are objects that represent the eventual outcome of an asynchronous operation A Promise object can be in one of three states: Pending : The initial state\u2014 the operation has not completed yet. Fulfilled : The operation has completed successfully and the promise now has a resolved value . For example, a request\u2019s promise might resolve with a JSON object as its value. Rejected : The operation has failed and the promise has a reason for the failure. This reason is usually an Error of some kind. A promise is settled if it is no longer pending (it is either fufilled or rejected) All promises eventually settle Enables us to write logic for what to do if the promise fulfills or is rejected Promises are returned from a asyncrhonous operations","title":"What is a Promise?"},{"location":"web_dev/js/promises/#constructing-a-promise-object","text":"Promise constructor takes a function called the executor function as an argument Executor Function runs automatically when constructor is called, generally starts an asynchronous operation, and dictates how the promsie should be settled Has 2 function parameters: resolve() and reject() (These functions aren't defined by the progammer but are rather passed by JS into the executor function when the Promise constructor runs) resolve has one argument and will change the promise's status from pending to fulfilled if invoked and will set the resolved value to the argument passed in reject takes a reason or error as an argument and will change the promise's status from pending to rejected if invoked and will set the rejection's reason to the argument passed in Promises settle based on the results of an asynch operation (e.g. Database request is fulfilled with data from the query or is rejected with an error thrown) const executorFunction = (resolve,reject) => { if (condition){ resolve('Say Something') } else { reject('Say a different thing') } } const myPromise = new Promise(executorFunction)","title":"Constructing a Promise Object"},{"location":"web_dev/js/promises/#settimeout-in-node","text":"Takes a callback function and delay in milliseconds as arguments The callback function will execute in at least the passed in delay (Could be longer) This happens b/c after the delay, the line of code is added to be run but any synchronous code from the program will run before it, possibly delaying the callback functions execution","title":"setTimeout() in Node:"},{"location":"web_dev/js/using_node_pkgs/","text":"Using Node Packages in a Project Initialize the project with npm init Install the desired packages with npm i package -D flag (Shorthand for --save-dev ) is used to save packages for necessary for development purposes (e.g. unit tests, minification, etc. ) Saves the package to \"devDependencies\" in package.json -S flag (Shorthand for --save) is used to save packages required for the application to run Saves them to \"dependencies\" in package.json Automatically saves new packages in npm 5+ Edit the \"scripts\" object in package.json to include necessary commands Run the scripts using npm run script_name Scripts: Sass (CSS Pre-Compiler): node-sass package should be saved to devDependencies \"sass\": \"node-sass -w scss/ -o dist/css/ --recursive\" Command watches (-w) the scss folder and outputs (-o) the compiled css to the css folder in the dist directory --recursive prevets issues with partials and auto-reloading Jest (JS Testing Framework): jest package should be saved to devDependencies \"test\": \"jest\" Babel (ES6+ to ES5 Transpilation): babel-cli and babel-preset-env packes should be saved to devDependencies \"build\": \"babel src -d lib\"","title":"Node Pkgs"},{"location":"web_dev/js/using_node_pkgs/#using-node-packages-in-a-project","text":"Initialize the project with npm init Install the desired packages with npm i package -D flag (Shorthand for --save-dev ) is used to save packages for necessary for development purposes (e.g. unit tests, minification, etc. ) Saves the package to \"devDependencies\" in package.json -S flag (Shorthand for --save) is used to save packages required for the application to run Saves them to \"dependencies\" in package.json Automatically saves new packages in npm 5+ Edit the \"scripts\" object in package.json to include necessary commands Run the scripts using npm run script_name","title":"Using Node Packages in a Project"},{"location":"web_dev/js/using_node_pkgs/#scripts","text":"","title":"Scripts:"},{"location":"web_dev/js/using_node_pkgs/#sass-css-pre-compiler","text":"node-sass package should be saved to devDependencies \"sass\": \"node-sass -w scss/ -o dist/css/ --recursive\" Command watches (-w) the scss folder and outputs (-o) the compiled css to the css folder in the dist directory --recursive prevets issues with partials and auto-reloading","title":"Sass (CSS Pre-Compiler):"},{"location":"web_dev/js/using_node_pkgs/#jest-js-testing-framework","text":"jest package should be saved to devDependencies \"test\": \"jest\"","title":"Jest (JS Testing Framework):"},{"location":"web_dev/js/using_node_pkgs/#babel-es6-to-es5-transpilation","text":"babel-cli and babel-preset-env packes should be saved to devDependencies \"build\": \"babel src -d lib\"","title":"Babel (ES6+ to ES5 Transpilation):"}]}